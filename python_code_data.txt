#!/usr/bin/python3<N>import gi<N>import magic<N>import os<N>import threading<N>from gi.repository import Gio, GObject, Gtk<N><N># Used as a decorator to run things in the background<N>def _async(func):<N>    def wrapper(*args, **kwargs):<N>        thread = threading.Thread(target=func, args=args, kwargs=kwargs)<N>        thread.daemon = True<N>        thread.start()<N>        return thread<N>    return wrapper<N><N>
# Used as a decorator to run things in the main loop, from another thread<N>def idle(func):<N>    def wrapper(*args):<N>        GObject.idle_add(func, *args)<N>    return wrapper<N><N># This is a data structure representing<N># the file object<N>class FileObject():<N><N>
#!/usr/bin/python3<N>import gettext<N>import gi<N>import locale<N>import os<N>import re<N>import setproctitle<N>import subprocess<N>import warnings<N>import sys<N><N># Suppress GTK deprecation warnings<N>warnings.filterwarnings("ignore")<N><N>gi.require_version("Gtk", "3.0")<N>from gi.repository import Gtk, Gdk, Gio, GdkPixbuf, GLib<N><N>
from common import *<N><N>setproctitle.setproctitle("bulky")<N><N># i18n<N>APP = 'bulky'<N>LOCALE_DIR = "/usr/share/locale"<N>locale.bindtextdomain(APP, LOCALE_DIR)<N>gettext.bindtextdomain(APP, LOCALE_DIR)<N>gettext.textdomain(APP)<N>_ = gettext.gettext<N><N>
COL_ICON, COL_NAME, COL_NEW_NAME, COL_FILE = range(4)<N><N>class MyApplication(Gtk.Application):<N>    # Main initialization routine<N>    def __init__(self, application_id, flags):<N>        Gtk.Application.__init__(self, application_id=application_id, flags=flags)<N>        self.connect("activate", self.activate)<N><N>
    def activate(self, application):<N>        windows = self.get_windows()<N>        if (len(windows) > 0):<N>            window = windows[0]<N>            window.present()<N>            window.show()<N>        else:<N>            window = MainWindow(self)<N>            self.add_window(window.window)<N>            window.window.show()<N><N>
class MainWindow():<N><N>    def __init__(self, application):<N><N>        self.application = application<N>        self.settings = Gio.Settings(schema_id="org.x.bulky")<N>        self.selected_files = []<N>        self.icon_theme = Gtk.IconTheme.get_default()<N><N>
        # Set the Glade file<N>        gladefile = "/usr/share/bulky/bulky.ui"<N>        self.builder = Gtk.Builder()<N>        self.builder.set_translation_domain(APP)<N>        self.builder.add_from_file(gladefile)<N>        self.window = self.builder.get_object("main_window")<N>        self.window.set_title(_("Rename Files"))<N>        self.window.set_icon_name("bulky")<N><N>
        # Create variables to quickly access dynamic widgets<N>        self.headerbar = self.builder.get_object("headerbar")<N>        self.add_button = self.builder.get_object("add_button")<N>        self.remove_button = self.builder.get_object("remove_button")<N>        self.clear_button = self.builder.get_object("clear_button")<N>        self.close_button = self.builder.get_object("close_button")<N>        self.rename_button = self.builder.get_object("rename_button")<N><N>
        # Widget signals<N>        self.add_button.connect("clicked", self.on_add_button)<N>        self.remove_button.connect("clicked", self.on_remove_button)<N>        self.clear_button.connect("clicked", self.on_clear_button)<N>        self.close_button.connect("clicked", self.on_close_button)<N>        self.rename_button.connect("clicked", self.on_rename_button)<N>        self.window.connect("key-press-event",self.on_key_press_event)<N><N>
import numpy as np<N>from sklearn.datasets import load_iris<N>from sklearn.tree import DecisionTreeClassifier<N>from sklearn.metrics import accuracy_score<N>from scipy import stats<N><N><N>class RandomForest:<N>    """Eine Klasse zum ausfÃ¼hren eines Random Forest."""<N>    # Klasse selber hat keine Argumente (nur zum Vererben), sondern nur der Konstruktor (init)<N><N>
from .app import App<N>import sys<N>import toml<N><N>file = sys.argv[1]<N><N>with open(file) as f:<N>    config = toml.load(f)<N>    App.run(config)<N>
from __future__ import annotations<N><N>from tornado.web import Application, StaticFileHandler, RedirectHandler<N>import importlib<N>import asyncio<N><N>from .utils import DB, TornadoUvloop, Tokens, RequestHandler<N>from typing import List, Tuple, Any, TYPE_CHECKING<N><N>
class App(Application):<N>    def __init__(self, database: DB, config):<N>        self.database = database<N>        self.config = config<N><N>        self.version = config["version"]<N><N>        token_config = config["tokens"]<N>        self.tokens = Tokens(token_config["epoch"], token_config["worker_id"], token_config["process_id"], token_config["secret_key"])<N><N>
        self.args = {"database": self.database, "tokens": self.tokens}<N><N>        files = config["extensions"]<N>        routes = []<N>        for file in files:<N>            module = importlib.import_module(f"app.extensions.{file}")<N>            module_routes = module.setup(self)  # type: ignore<N>            <N>            routes.extend(module_routes)<N><N>
from .database import DB<N>from .errors import JsonErrors, HTTPErrors, CustomError, GatewayErrors, GatewayOps<N>from .route import RequestHandler, WebSocketHandler<N>from .validator import spec<N>from .loop import TornadoUvloop<N>from .token import Tokens<N>
import uvloop<N>from tornado.platform.asyncio import BaseAsyncIOLoop<N><N>class TornadoUvloop(BaseAsyncIOLoop):<N>    def initialize(self, **kwargs):<N>        loop = uvloop.new_event_loop()<N>        try:<N>            super().initialize(loop, close_loop=True, **kwargs)<N>        except Exception:<N>            loop.close()<N>            raise<N>
class CustomError(Exception):<N>    pass<N><N>class JsonErrors:<N>    general = (0, "Invalid")<N>    missing_key = (0, "Missing Required Key")<N>    invalid_form = (50035, "Invalid Form Body")<N><N>class HTTPErrors:<N>    invalid_method = (0, "405: Method Not Allowed")<N>    unauthorized = (0, "401: Unauthorized")<N><N>
class GatewayOps:<N>    dispatch = 0<N>    heartbeat = 1<N>    identify = 2<N>    presence_update = 3<N>    voice_state_update = 4<N>    resume = 5<N>    reconnect = 6<N>    request_guild_members = 7<N>    invalid_session = 9<N>    hello = 10<N>    heartbeat_ack = 11<N><N>
from __future__ import annotations<N><N>import asyncpg<N>import contextlib<N>import argon2<N><N>from .errors import CustomError<N><N>all_discrims = set(str(d).rjust(4, "0") for d in range(1, 1000))<N><N>class DB:<N>    def __init__(self, pool: asyncpg.Pool):<N>        self.pool = pool<N>        self.hasher = argon2.PasswordHasher()<N><N>
    @classmethod<N>    async def from_args(cls, args):<N>        pool = await asyncpg.create_pool(**args)<N>        assert pool<N>        return cls(pool)<N><N>    @contextlib.asynccontextmanager<N>    async def accqire(self):<N>        async with self.pool.acquire() as conn:<N>            async with conn.transaction():<N>                conn: asyncpg.Connection<N>                yield conn<N><N>
    async def create_account(self, username, email, password, id):<N>        async with self.accqire() as conn:<N>            hashed = self.hasher.hash(password)<N><N>            users = await conn.fetch("select discriminator from users where username=$1", username)<N>            discrims = [row["discriminator"] for row in users]<N>            diff = iter(all_discrims - set(discrims))<N>            discrim = next(diff)<N><N>
            try:<N>                await conn.execute("insert into users(id, username, hashed_password, email, discriminator) values($1, $2, $3, $4, $5)", id, username, hashed, email, discrim)<N>            except asyncpg.exceptions.UniqueViolationError:<N>                raise CustomError<N><N>
            return {"username": username, "discriminator": discrim, "email": email, "id": id}<N><N>    async def get_account(self, email, password, *, with_settings=False):<N>        async with self.accqire() as conn:<N>            row = await conn.fetchrow("select * from users where email=$1", email)<N><N>
            if not row:<N>                raise CustomError<N>            try:<N>                self.hasher.verify(row["hashed_password"], password)<N>            except argon2.exceptions.VerificationError:<N>                raise CustomError<N><N>            row = dict(row)<N><N>
            if with_settings:<N>                user_settings = await conn.fetchrow("select locale, theme from user_settings where user_id=$1", row["id"])<N>                if not user_settings:<N>                    user_settings = await conn.fetchrow("insert into user_settings(user_id) values ($1) returning theme, locale;", row["id"])<N><N>
from __future__ import annotations<N><N>from tornado.web import RequestHandler as BaseRequestHandler<N>from tornado.websocket import WebSocketHandler as BaseWebSocketHandler, WebSocketClosedError<N>import ujson<N><N>from typing import Tuple, Optional, Callable, Awaitable, TYPE_CHECKING, Union, Dict, Any<N><N>
from .errors import HTTPErrors<N><N>if TYPE_CHECKING:<N>    from app.app import App<N>    from .database import DB<N>    from .token import Tokens<N><N>class RequestHandler(BaseRequestHandler):<N>    require_token: bool<N>    application: App<N><N>    def __init_subclass__(cls, require_token=True) -> None:<N>        cls.require_token = require_token<N><N>
    def initialize(self, database: DB, tokens: Tokens):<N>        self.database = database<N>        self.tokens = tokens<N>        self.user_id = None<N><N>        self.body: Optional[dict] = None<N><N>    async def prepare(self):<N>        if not self.require_token:<N>            return <N><N>
        try:<N>            token: str = self.request.headers["Authorization"]<N>        except KeyError:<N>            return self.error(HTTPErrors.unauthorized, status_code=401)<N>            <N>        try:<N>            self.user_id = self.tokens.validate_token(token)<N>        except:<N>            return self.error(HTTPErrors.unauthorized, status_code=401)<N><N>
import time<N>import itsdangerous<N>import base64<N><N>class Tokens:<N>    def __init__(self, epoch: int, worker_id: int, process_id: int, secret: str):<N>        self.epoch = epoch<N>        self.worker_id = worker_id<N>        self.process_id = process_id<N>        self.secret = secret<N><N>
        self.inc = 0<N>        self.signer = itsdangerous.TimestampSigner(secret)<N><N>    def create_token(self, id: str) -> str:<N>        based_token = base64.b64encode(id.encode())<N>        return self.signer.sign(based_token).decode()<N><N>    def create_id(self) -> str:<N>        self.inc += 1<N>        now = int(time.time() * 1000 - self.epoch)<N><N>
        snowflake = now << 22<N>        snowflake |= (self.worker_id) << 17<N>        snowflake |= (self.process_id) << 12<N>        snowflake |= self.inc<N><N>        return str(snowflake)<N><N>    def validate_token(self, token: str, *, max_age: int = None) -> str:<N>        encoded_token = token.encode()<N>        data = self.signer.unsign(encoded_token, max_age=max_age)<N>        if isinstance(data, tuple):<N>            id = data[0]<N>        else:<N>            id = data<N><N>
from app.utils import GatewayOps, GatewayErrors, WebSocketHandler, DB, Tokens, CustomError<N><N>from typing import Optional, Any<N>import datetime<N>import ujson<N>import cerberus<N>import asyncio<N>import logging<N><N>class Specs:<N>    generic = cerberus.Validator({<N>        "op": {<N>            "type": "integer",<N>            "allowed": [0,1,2,3,4,5,6,7,9,10,11]<N>        },<N>        "d": {<N>            "type": "dict",<N>            "allow_unknown": True<N>        }<N>    })<N><N>
    identify = cerberus.Validator({<N>        "token": {"type": "string"},<N>        "intents": {"type": "integer"},<N>        "properties": {<N>            "type": "dict",<N>            "schema": {<N>                "$os": {"type": "string"},<N>                "$browser": {"type": "string"},<N>                "$device": {"type": "string"}<N>            }<N>        }<N>    })<N><N>
from app.utils import spec, RequestHandler<N><N><N>class Test(RequestHandler):<N>    async def get(self):<N>        self.write({"id": self.user_id})<N>        self.flush()<N><N>def setup(app):<N>    return [(f"/api/v{app.version}/test", Test, app.args)]<N>
# -*- coding: utf-8 -*-<N>from setuptools import setup, find_packages  # Always prefer setuptools over distutils<N>from codecs import open  # To use a consistent encoding<N>from os import path<N><N>here = path.abspath(path.dirname(__file__))<N><N># Get the long description from the relevant file<N>with open(path.join(here, 'README.md'), encoding='utf-8') as f:<N>    long_description = f.read()<N><N>
setup(<N>    name='''ckanext-dataexplorer''',<N><N>    # Versions should comply with PEP440.  For a discussion on single-sourcing<N>    # the version across setup.py and the project code, see<N>    # http://packaging.python.org/en/latest/tutorial.html#version<N>    version='0.0.1',<N><N>
    description='''Ckan extension that extends the default reclineview to support extracting functionality''',<N>    long_description=long_description,<N><N>    # The project's main homepage.<N>    url='https://github.com/duskobogdanovski/ckanext-dataexplorer',<N><N>
    # Author details<N>    author='''Dusko Bogdanovski''',<N>    author_email='''dusko.bogdanovski@keitaro.com''',<N><N>    # Choose your license<N>    license='AGPL',<N><N>    # See https://pypi.python.org/pypi?%3Aaction=list_classifiers<N>    classifiers=[<N>        # How mature is this project? Common values are<N>        # 3 - Alpha<N>        # 4 - Beta<N>        # 5 - Production/Stable<N>        'Development Status :: 4 - Beta',<N><N>
        # Pick your license as you wish (should match "license" above)<N>        'License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)',<N><N>        # Specify the Python versions you support here. In particular, ensure<N>        # that you indicate whether you support Python 2, Python 3 or both.<N>        'Programming Language :: Python :: 2.7',<N>    ],<N><N>
<N>    # What does your project relate to?<N>    keywords='''CKAN dataexplorer dataextractor''',<N><N>    # You can just specify the packages manually here if your project is<N>    # simple. Or you can use find_packages().<N>    packages=find_packages(exclude=['contrib', 'docs', 'tests*']),<N>    namespace_packages=['ckanext'],<N><N>
    install_requires=[<N>      # CKAN extensions should not list dependencies here, but in a separate<N>      # ``requirements.txt`` file.<N>      #<N>      # http://docs.ckan.org/en/latest/extensions/best-practices.html#add-third-party-libraries-to-requirements-txt<N>    ],<N><N>
    # If there are data files included in your packages that need to be<N>    # installed, specify them here.  If using Python 2.6 or less, then these<N>    # have to be included in MANIFEST.in as well.<N>    include_package_data=True,<N>    package_data={<N>    },<N><N>
    # Although 'package_data' is the preferred approach, in some case you may<N>    # need to place data files outside of your packages.<N>    # see http://docs.python.org/3.4/distutils/setupscript.html#installing-additional-files<N>    # In this case, 'data_file' will be installed into '<sys.prefix>/my_data'<N>    data_files=[],<N><N>
    # To provide executable scripts, use entry points in preference to the<N>    # "scripts" keyword. Entry points provide cross-platform support and allow<N>    # pip to create the appropriate form of executable for the target platform.<N>    entry_points='''<N>        [ckan.plugins]<N>        dataexplorer=ckanext.dataexplorer.plugin:ReclineView<N>        [babel.extractors]<N>        ckan = ckan.lib.extract:extract_ckan<N>    ''',<N><N>
    # If you are changing from the default layout of your extension, you may<N>    # have to change the message extractors, you can read more about babel<N>    # message extraction at<N>    # http://babel.pocoo.org/docs/messages/#extraction-method-mapping-and-configuration<N>    message_extractors={<N>        'ckanext': [<N>            ('**.py', 'python', None),<N>            ('**.js', 'javascript', None),<N>            ('**/templates/**.html', 'ckan', None),<N>        ],<N>    }<N>)<N><N><N>
# encoding: utf-8<N><N># this is a namespace package<N>try:<N>    import pkg_resources<N>    pkg_resources.declare_namespace(__name__)<N>except ImportError:<N>    import pkgutil<N>    __path__ = pkgutil.extend_path(__path__, __name__)<N>
# encoding: utf-8<N><N>from logging import getLogger<N><N>from ckan.common import json, config<N>import ckan.plugins as p<N>import ckan.plugins.toolkit as toolkit<N>from ckan.lib.plugins import DefaultTranslation<N><N>log = getLogger(__name__)<N>ignore_empty = p.toolkit.get_validator('ignore_empty')<N>natural_number_validator = p.toolkit.get_validator('natural_number_validator')<N>Invalid = p.toolkit.Invalid<N><N>
def get_datastore_search_rows_max():<N>    return config.get('ckan.datastore_search_rows_max', 0)<N><N><N>def get_mapview_config():<N>    '''<N>    Extracts and returns map view configuration of the reclineview extension.<N>    '''<N>    namespace = 'ckanext.spatial.common_map.'<N>    return dict([(k.replace(namespace, ''), v) for k, v in config.iteritems()<N>                 if k.startswith(namespace)])<N><N>
<N>def in_list(list_possible_values):<N>    '''<N>    Validator that checks that the input value is one of the given<N>    possible values.<N><N>    :param list_possible_values: function that returns list of possible values<N>        for validated field<N>    :type possible_values: function<N>    '''<N>    def validate(key, data, errors, context):<N>        if not data[key] in list_possible_values():<N>            raise Invalid('"{0}" is not a valid parameter'.format(data[key]))<N>    return validate<N><N>
# -*- coding: utf-8 -<N><N>try:<N>    # CKAN 2.7 and later<N>    from ckan.common import config<N>except ImportError:<N>    # CKAN 2.6 and earlier<N>    from pylons import config<N><N><N>import logging<N>import json<N>from datetime import date, timedelta, datetime<N>from decimal import Decimal<N><N>
log = logging.getLogger(__name__)<N><N>NAIVE_DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'<N>DATE_FORMAT = '%Y-%m-%d'<N><N><N>class CustomJSONEncoder(json.JSONEncoder):<N>    def default(self, obj):<N>        try:<N>            return json.JSONEncoder.default(self, obj)<N>        except TypeError:<N>            if type(obj) is date:<N>                return obj.strftime(DATE_FORMAT)<N><N>
            if type(obj) is datetime:<N>                return obj.strftime(NAIVE_DATETIME_FORMAT)<N><N>            if type(obj) is timedelta:<N>                # return it as rounded milliseconds<N>                return int(obj.total_seconds() * 1000)<N><N>
            if type(obj) is Decimal:<N>                return str(obj)<N><N>            raise<N><N>def _get_logic_functions(module_root, logic_functions={}):<N>    '''Helper function that scans extension logic dir for all logic functions.'''<N>    for module_name in ['create', 'delete', 'get', 'patch', 'update']:<N>        module_path = '%s.%s' % (module_root, module_name,)<N><N>
        module = __import__(module_path)<N><N>        for part in module_path.split('.')[1:]:<N>            module = getattr(module, part)<N><N>        for key, value in module.__dict__.items():<N>            if not key.startswith('_') and (hasattr(value, '__call__')<N>                                            and (value.__module__ == module_path)):<N>                logic_functions[key] = value<N><N>
import logging<N>import json<N><N>try:<N>    # CKAN 2.7 and later<N>    from ckan.common import config<N>except ImportError:<N>    # CKAN 2.6 and earlier<N>    from pylons import config<N><N>from ckan.lib import base<N>from ckan.plugins import toolkit<N>from ckan.plugins.toolkit import abort, ObjectNotFound, ValidationError<N>from ckan import model, logic<N>from ckan.common import c, _, request, response<N>from ckanext.dataexplorer.lib import FileWriterService<N><N>
log = logging.getLogger(__name__)<N><N>DUMP_FORMATS = 'csv', 'xlsx', 'json', 'xml'<N><N>class DataExplorer(base.BaseController):<N><N>    ctrl = 'ckanext.dataexplorer.controllers.dataexplorer:DataExplorer'<N><N>    def _get_ctx(self):<N>        return {<N>            'model': model, 'session': model.Session,<N>            'user': c.user,<N>            'auth_user_obj': c.userobj,<N>            'for_view': True<N>        }<N><N>
try:<N>    # CKAN 2.7 and later<N>    from ckan.common import config<N>except ImportError:<N>    # CKAN 2.6 and earlier<N>    from pylons import config<N><N>import logging<N>import json<N>import csv<N>import cStringIO<N>import codecs<N>import zipfile<N><N>
import ckan.logic as l<N><N>from email.utils import encode_rfc2231<N>from xlsxwriter.workbook import Workbook<N>from xml.etree.cElementTree import Element, SubElement, ElementTree<N>from ckan.common import _<N>from ckanext.dataexplorer.helpers import CustomJSONEncoder<N><N>
# encoding: utf-8<N><N>import paste.fixture<N>from ckan.common import config<N><N>import ckan.model as model<N>import ckan.tests.legacy as tests<N>import ckan.plugins as p<N>import ckan.lib.helpers as h<N>import ckanext.reclineview.plugin as plugin<N>import ckan.lib.create_test_data as create_test_data<N>import ckan.config.middleware as middleware<N><N>
from ckan.tests import helpers, factories<N><N><N>class BaseTestReclineViewBase(object):<N>    @classmethod<N>    def setup_class(cls):<N><N>        cls.app = helpers._get_test_app()<N><N>        p.load(cls.view_type)<N><N>        cls.p = cls.view_class()<N><N>
        create_test_data.CreateTestData.create()<N><N>        cls.resource_view, cls.package, cls.resource_id = \<N>            _create_test_view(cls.view_type)<N><N>    @classmethod<N>    def teardown_class(cls):<N>        p.unload(cls.view_type)<N>        model.repo.rebuild_db()<N><N>
    def test_can_view(self):<N>        data_dict = {'resource': {'datastore_active': True}}<N>        assert self.p.can_view(data_dict)<N><N>        data_dict = {'resource': {'datastore_active': False}}<N>        assert not self.p.can_view(data_dict)<N><N>
    def test_title_description_iframe_shown(self):<N><N>        with self.app.flask_app.test_request_context():<N>            url = h.url_for(controller='package', action='resource_read',<N>                            id=self.package.name, resource_id=self.resource_id)<N>        result = self.app.get(url)<N>        assert self.resource_view['title'] in result<N>        assert self.resource_view['description'] in result<N>        assert 'data-module="data-viewer"' in result.body<N><N>
<N>class TestReclineView(BaseTestReclineViewBase):<N>    view_type = 'recline_view'<N>    view_class = plugin.ReclineView<N><N>    def test_it_has_no_schema(self):<N>        schema = self.p.info().get('schema')<N>        assert schema is None, schema<N><N>
    def test_can_view_format_no_datastore(self):<N>        '''<N>        Test can_view with acceptable formats when datastore_active is False<N>        (DataProxy in use).<N>        '''<N>        formats = ['CSV', 'XLS', 'TSV', 'csv', 'xls', 'tsv']<N>        for resource_format in formats:<N>            data_dict = {'resource': {'datastore_active': False,<N>                                      'format': resource_format}}<N>            assert self.p.can_view(data_dict)<N><N>
    def test_can_view_bad_format_no_datastore(self):<N>        '''<N>        Test can_view with incorrect formats when datastore_active is False.<N>        '''<N>        formats = ['TXT', 'txt', 'doc', 'JSON']<N>        for resource_format in formats:<N>            data_dict = {'resource': {'datastore_active': False,<N>                                      'format': resource_format}}<N>            assert not self.p.can_view(data_dict)<N><N>
<N>class TestReclineViewDatastoreOnly(helpers.FunctionalTestBase):<N><N>    @classmethod<N>    def setup_class(cls):<N><N>        cls.app = helpers._get_test_app()<N>        if not p.plugin_loaded('recline_view'):<N>            p.load('recline_view')<N>        if not p.plugin_loaded('datastore'):<N>            p.load('datastore')<N><N>
'''<N>Write a script that takes in two numbers from the user and calculates the quotient. Using a try/except,<N>the script should handle:<N><N>- if the user enters a string instead of a number<N>- if the user enters a zero as the divisor<N><N>Test it and make sure it does not crash when you enter incorrect values.<N><N>'''
'''<N>In this exercise, you will practice both File I/O as well as using Exceptions<N>in a real-world scenario.<N><N>You have a folder containing three text files of books from Project Gutenberg:<N>- war_and_peace.txt<N>- pride_and_prejudice.txt<N>- crime_and_punishment.txt<N><N>
1) Open war_and_peace.txt, read the whole file content and store it in a variable<N><N>2) Open crime_and_punishment.txt and overwrite the whole content with an empty string<N><N>3) Loop over all three files and print out only the first character each. Your program<N>    should NEVER terminate with a Traceback.<N><N>
    a) Which Exception can you expect to encounter? Why?<N><N>    b) How do you catch it to avoid the program from terminating with a Traceback?<N><N><N>BONUS CHALLENGE: write a custom Exception that inherits from Exception and raise it if the<N>first 100 characters of any of the files contain the string "Prince".<N><N>
'''<N>Write a script that generates an exception. Handle this exception with a try/except.<N>For example:<N><N>list_ = ["hello world!"]<N>print(list_[1])<N><N>This raises and exception that needs to be handled.<N><N>'''
'''<N>Create a script that asks a user to input an integer, checks for the<N>validity of the input type, and displays a message depending on whether<N>the input was an integer or not.<N><N>The script should keep prompting the user until they enter an integer.<N><N>'''<N>
'''<N>Read in the first number from 'integers.txt'and perform a calculation<N>with it.<N>Make sure to catch at least two possible Exceptions (IOError and ValueError)<N>with specific except statements, and continue to do the calculation<N>only if neither of them applies.<N><N>'''<N><N>file_name = 'integers.txt'<N>
'''<N>Write the necessary code to display the follow message to the console<N><N>	I'm a programmer now.<N>	Yeehaw!<N>	Coding here I come!<N><N>'''
'''<N><N>Write the necessary code to display the area and perimeter of a rectangle that has a width of 2.4 and a height of 6.4.<N><N>'''
'''<N>Write the necessary code to print out the result of the following:<N><N>	2 + 4 + 6 + 8 + 9 + 10 + 12 + 14 + 16 + 18<N><N>'''
'''<N>Write the necessary code to print the result of the following formula:<N><N>	(15.7 * 3.6 - 34.9 * 0.9) / (68.9 - 2.1)<N><N>'''
'''<N>Write a script that prints the total number of vowels that are used in a user-inputted string.<N><N><N>CHALLENGE: Can you change the script so that it counts the occurrence of each individual vowel<N>           in the string and print a count for each of them?<N><N>'''<N>
'''<N><N>Using string slicing, take in the user's name and print out their name translated to pig latin.<N>For the purpose of this program, we will say that any word or name can be<N>translated to pig latin by moving the first letter to the end, followed by "ay".<N><N>For example: ryan -> yanray, caden -> adencay<N><N>'''
'''<N>Write a script that takes three strings from the user and prints them together with their length.<N><N>Example Output:<N><N>5, hello<N>5, world<N>9, greetings<N><N>CHALLENGE: Can you edit to script to print only the string with the most characters? You can look<N>           into the topic "Conditionals" to solve this challenge.<N><N>'''<N>
'''<N>Write a script that takes a string of words and a letter from the user.<N>Find the index of first occurrence of the letter in the string. For example:<N><N>String input: hello world<N>Letter input: o<N>Result: 4<N><N>'''<N>
'''<N>Write a script that takes a string of words and a symbol from the user.<N>Replace all occurrences of the first letter with the symbol. For example:<N><N>String input: more python programming please<N>Symbol input: #<N>Result: #ore python progra##ing please<N><N>'''<N><N>
'''<N>Fahrenheit to Celsius:<N><N>Write the necessary code to read a degree in Fahrenheit from the console<N>then convert it to Celsius and print it to the console.<N><N>    C = (F - 32) * (5 / 9)<N><N>Output should read like - "81.32 degrees fahrenheit = 27.4 degrees celsius"<N><N><N>'''
'''<N>Take in the following three values from the user:<N>    - investment amount<N>    - interest rate in percentage<N>    - number of years to invest<N><N>Print the future values to the console.<N><N>'''
'''<N><N>If a runner runs 10 miles in 30 minutes and 30 seconds,<N>What is his/her average speed in kilometers per hour? (Tip: 1 mile = 1.6 km)<N><N>'''<N>
'''<N>Write the necessary code calculate the volume and surface area<N>of a cylinder with a radius of 3.14 and a height of 5. Print out the result.<N><N><N>'''
'''<N><N>Demonstrate how to:<N><N>    1) Convert an int to a float<N>    2) Convert a float to an int<N>    3) Perform floor division using a float and an int.<N>    4) Use two user inputted values to perform multiplication.<N><N>    Take note of what information is lost when some conversions take place.<N><N>'''
'''<N>Write a script that demonstrates TDD. Using pseudocode, plan out a couple simple functions. They could be<N>as simple as add and subtract or more complex such as functions that read and write to files.<N><N>Instead of writing out the functions, only provide the tests. Think about how the functions might<N>fail and write tests that will check and prevent failure.<N><N>You do not need to implement the actual functions after writing the tests but you may.<N><N>'''
'''<N>Demonstrate your knowledge of unittest by first creating a function with input parameters and a return value.<N><N>Once you have a function, write at least two tests for the function that use various assertions. The<N>tests should pass. Also include a test that does not pass.<N><N>
NOTE: You can write both the code as well as the tests for it in this single file.<N>However, feel free to adhere to best practices and separate your tests and the functions you are testing<N>into different files. Note that you will run into an error when attempting to import this file,<N>because Python modules can't begin with a number.<N><N>
'''<N>Write a program that takes a number between 1 and 1,000,000,000<N>from the user and determines whether it is divisible by 3 using an if statement.<N>Print the result.<N><N>'''
'''<N>Write a script that takes in a number from the user as input and prints the following structure.<N><N>Suppose the input is 5, you will output<N>*<N>* *<N>* * * <N>* * * *<N>* * * * * <N>i.e. number of rows will be 5, 1st row will have 1 star, 2nd row will have 2 stars, 3rd row 3 stars, 4th row will have 4 stars and 5th row will have 5 stars.<N><N>Another example: if input is 3, you will output<N>*<N>* *<N>* * *<N><N>Hint: Think of nested for loops<N><N>'''
'''<N>Take two numbers from the user, one representing the start and one the end of a sequence.<N>Using a loop, sum all numbers from the first number through to the second number.<N><N>For example, if a user enters 1 and 100, the sequence would be all integer numbers from 1 to 100.<N>The output of your calculation should therefore look like this:<N><N>The sum is: 5050<N>'''<N>
'''<N>Write a script that prints out all the squares of numbers from 1- 50<N><N>Use a for loop that demonstrates the use of the range function.<N><N>'''<N><N>
'''<N><N>Receive a number between 0 and 1,000,000,000 from the user.<N>Use while loop to find the number - when the number is found exit the loop and print the number to the console.<N><N>'''
'''<N>Take in a number from the user and print "January", "February", ...<N>"December", or "Other" if the number from the user is 1, 2,... 12,<N>or other respectively. Use a "nested-if" statement.<N><N>'''
'''<N>Use a loop to print the following table to the console:<N><N> 0 1 2 3 4 5 6 7 8 9<N> 10 11 12 13 14 15 16 17 18 19<N> 20 21 22 23 24 25 26 27 28 29<N> 30 31 32 33 34 35 36 37 38 39<N> 40 41 42 43 44 45 46 47 48 49<N><N>'''
'''<N><N>Write a loop that for a number n prints n rows of stars in a triangle shape.<N><N>For example if n is 3, you print:<N><N>*<N>**<N>***<N><N>'''<N><N>n = 5<N>
'''<N>In 3 lines of code, fetch the HTML text from codingnomads' main page<N>and print it to your console.<N><N>TIP:<N>- if you wonder what to use, google something like<N>    "most popular python package"<N>- if you run into encoding/decoding errors, you're experiencing something<N>    very common. head over to SO and find a solution!<N><N>'''<N>
'''<N>Do some research on other popular python packages and what the are used for. Feel free to import them<N>and play around a little.<N><N>'''
'''<N>Improve the decorator from the previous exercise by allowing it to take<N>any specified HTML tag as an input - making it more general.<N><N>'''<N>
'''<N>Demonstrate how to create a generator object. Print the object to the console to see what you get.<N>Then iterate over the generator object and print out each item.<N><N>'''
'''<N>Create a Generator that loops over the given list and prints out only<N>the items that are divisible by 1111.<N><N>'''<N>
'''<N>Adapt your Generator expression from the previous Exercise<N>(remove the print() statement), then run a floor division by 1111 on it.<N>What numbers do you get?<N><N>'''<N>
'''<N>Write a lambda function that does not take in an arguments but returns a value.<N>Print the return value.<N><N>'''<N>
'''<N>Create a lambda expression that takes no input and prints "hello world" to the console.<N><N>What does it return?<N><N>'''<N>
'''<N>Use a lambda expression to sort a list of tuples based on the number value in the tuple.<N>For example:<N><N>unsorted_list = [('first_element', 4), ('second_element', 2), ('third_element', 6)]<N>sorted_list = [('second_element', 2), ('first_element', 4), ('third_element', 6)]<N><N>'''<N><N>unsorted_list = [('first_element', 4), ('second_element', 2), ('third_element', 6)]
'''<N>You're about to have a baby and you don't have a name yet. ðŸ˜±<N>You and your partner agree that it should start with an 'M', but that's<N>about all you've got so far.<N><N>To save the day, use the filter() method and a lambda expression<N>to map all the baby names that begin with a 'M' to an output list.<N><N>
'''<N>Write a program that reads words.txt and prints only the words<N>with more than 20 characters (not counting whitespace).<N>'''<N>
'''<N>Write a script that reads in the contents of words.txt and writes the contents in reverse<N>to a new file words_reverse.txt.<N>'''
'''<N>Write a script that reads in the words from the words.txt file and finds and prints:<N><N>1. The shortest word (if there is a tie, print all)<N>2. The longest word (if there is a tie, print all)<N>3. The total number of words in the file.<N><N><N>'''<N>
'''<N><N>Write a script that completes the following tasks.<N><N>'''<N><N># define a function that determines whether the number is divisible by 4 or 7 and returns a boolean<N><N># define a function that determines whether a number is divisible by both 4 and 7 and returns a boolean<N><N># take in a number from the user between 1 and 1,000,000,000<N><N># call your functions, passing in the user input as the arguments, and set their output equal to new variables <N><N># print your new variables to display the results<N>
'''<N>Write a program with 3 functions. Each function must call<N>at least one other function and use the return value to do something.<N><N>'''<N>
'''<N>Write a function stats() that takes in a list of numbers and finds the max, min, average and sum.<N>Print these values to the console when calling the function.<N><N>'''<N><N>example_list = [1, 2, 3, 4, 5, 6, 7]<N><N>def stats():<N>  # define the function here<N>  pass<N><N># call the function below here<N>
'''<N>Create a Planet class that models attributes and methods of<N>a planet object.<N><N>Use the appropriate dunder method to get informative output with print()<N><N>'''<N><N>class Planet():<N>    pass<N>
'''<N>Build on your previous freeform exercise.<N><N>Create subclasses of two of the existing classes. Create a subclass of<N>one of those so that the hierarchy is at least three levels.<N><N>Build these classes out like we did in the previous exercises.<N><N>
If you cannot think of a way to build on your freeform exercise,<N>you can start from scratch here.<N><N>We encourage you to be creative and try to think of an example of<N>your own for this exercise but if you are stuck, some ideas include:<N><N>- A Vehicle superclass, with Truck and Motorcycle subclasses.<N>- A Restaurant superclass, with Gourmet and FastFood subclasses.<N><N>
'''<N>Write a class to model a car. The class should:<N><N>1. Set the attributes model, year, and max_speed in the __init__() method.<N>2. Have a method that increases the max_speed of the car by 5 when called.<N>3. Have a method that prints the details of the car.<N><N>Create at least two different objects of this Car class and demonstrate<N>changing the objects attributes.<N><N>'''
'''<N>CLASSES AND INHERITANCE<N>=======================<N><N>1) Define an empty Movie class.<N><N>2) Add a dunder init method that takes two arguments "year" and "title"<N><N>3) Create a sub-class called "RomCom" that inherits from the Movie class<N><N>4) Create another sub-class of the Movie class called "ActionMovie"<N>    that overwrites the dunder init method of Movie and adds another<N>    instance variable called "pg" that is set by default to the number 13.<N><N>
5) EXTRA: If you finish early, use the time to practice flushing out these<N>    classes and white-boarding code. What attributes could a Movie class<N>    contain? What methods? What tricks can you use through inheritance?<N>    Any class attributes you could add?<N><N>
'''<N>Create two classes that model a rectangle and a circle. The rectangle class should<N>be constructed by length and width while the circle class should be constructed by<N>radius.<N><N>Write methods in the appropriate class so that you can calculate the area (of the rectangle and circle),<N>perimeter (of the rectangle) and circumference of the circle.<N><N>'''
'''<N>Write a script that takes in a list of numbers and:<N>    - sorts the numbers<N>    - stores the numbers in tuples of two in a list<N>    - prints each tuple<N><N>If the user enters an odd numbered list, add the last item<N>to a tuple with the number 0.<N><N>Note: This lab might be challenging! Make sure to discuss it with your mentor<N>or chat about it on our forum.<N><N>'''<N>
'''<N>Write a script that takes a string from the user and creates a list of tuples with each word.<N>For example:<N><N>input = "hello world"<N>result_list = [('h', 'e', 'l', 'l', 'o'), ('w', 'o', 'r', 'l', 'd')]<N><N>'''
'''<N>Write a script that creates a list of all unique values in a list. For example:<N><N>list_ = [1, 2, 6, 55, 2, 'hi', 4, 6, 1, 13]<N>unique_list = [55, 'hi', 4, 13]<N><N><N>'''<N>
'''<N>Write a script that "flattens" a shallow list. For example:<N><N>starting_list = [[1, 2, 3, 4], [5, 6], [7, 8, 9]]<N>flattened_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]<N><N>Note that your input list only contains one level of nested lists.<N>This is called a "shallow list".<N><N>CHALLENGE: Do some research online and find a solution that works<N>to flatten a list of any depth. Can you understand the code used?<N><N>'''<N><N>starting_list = [[1, 2, 3, 4], [5, 6], [7, 8, 9]]<N>
'''<N>Read in 10 numbers from the user. Place all 10 numbers into an list in the order they were received.<N>Print out the second number received, followed by the 4th, then the 6th, then the 8th, then the 10th.<N>Then print out the 9th, 7th, 5th, 3rd, and 1st.<N><N>Example input:  1,2,3,4,5,6,7,8,9,10<N>Example output: 2,4,6,8,10,9,7,5,3,1<N><N>'''<N>
'''<N>Write a script that takes in a string from the user. Using the split() method,<N>create a list of all the words in the string and print the word with the most<N>occurrences.<N><N>'''
'''<N>Take in 10 numbers from the user. Place the numbers in a list.<N>Find the largest number in the list.<N>Print the results.<N><N>CHALLENGE: Calculate the product of all of the numbers in the list.<N>(you will need to use "looping" - a concept common to list operations<N>that we haven't looked at yet. See if you can figure it out, otherwise<N>come back to this task after you have learned about loops)<N><N>'''<N>
'''<N>Write a script that takes a string from the user and creates a dictionary of letter that exist<N>in the string and the number of times they occur. For example:<N><N>user_input = "hello"<N>result = {"h": 1, "e": 1, "l": 2, "o": 1}<N><N>'''
'''<N>Write a script that takes the following two dictionaries and creates a new dictionary by combining<N>the common keys and adding the values of duplicate keys together. Please use For Loops to iterate <N>over these dictionaries to accomplish this task.<N><N>Example input/output:<N><N>dict_1 = {"a": 1, "b": 2, "c": 3}<N>dict_2 = {"a": 2, "c": 4 , "d": 2}<N><N>result = {"a": 3, "b": 2, "c": 7 , "d": 2}<N><N>'''<N>
'''<N>Write a script that creates a dictionary of keys, n and values n*n for numbers 1-10. For example:<N><N>result = {1: 1, 2: 4, 3: 9, ...and so on}<N><N>'''
'''<N>Using f-strings, print out the name, last name, and favorite<N>office supply item of each person in the given dictionary,<N>formatted like so:<N><N>LASTNAME, Name           Office supply item<N>LONGERLASTNAME, Name     Office supply item<N><N>'''<N><N>
'''<N>Using a list comprehension, create a *cartesian product* (google this!)<N>of the given lists.<N><N>Then open up your online shop ;)<N><N>'''<N><N>colors = ["neon orange", "spring green"]<N>sizes = ["S", "M", "L"]<N>
'''<N>Using list comprehension, create a list "positive" from the list<N>"numbers" that contains only the positive numbers from the list "numbers".<N><N>'''<N><N>numbers = [5, -8, 3, 10, -19, -22, 44, 2, -1, 4, 42]<N>
'''<N>Using a listcomp, create a list from the following tuple that includes<N>only words ending with *fish.<N><N>Tip: Use an if statement in the listcomp<N><N>'''<N><N>fish_tuple = ('blowfish', 'clownfish', 'catfish', 'octopus')<N>
'''<N>Use a one-line list comprehension to express the following functionality:<N><N>letters = []<N><N>for letter in 'suchalongword':<N>    letters.append(letter)<N><N>print(letters)<N><N>'''<N>
'''<N>Using list comprehension, create a list that contains the individual<N>letters using the word "CodingNomads".<N><N>For example:<N><N>word = "CodingNomads"<N>..your code<N>result_list = ['C', 'o', 'd', 'i', 'n', 'g', 'N', 'o', 'm', 'a', 'd', 's']<N><N>'''<N>
'''<N>Reproduce the functionality of python's .enumerate()<N><N>Define a function my_enumerate() that takes an iterable as input<N>and yields the element and its index<N><N>'''<N><N>def my_enumerate(# your arguments):<N>      # pass<N>
'''<N>In your CodingNomads folder create a new folder. Inside of that folder:<N><N>1. Create a new virtual environment<N>2. Activate the virtual environment<N>3. Install at least 3 packages in the virtual environment.<N>4. Freeze the installed packages to a requirements.txt file.<N>5. Deactivate the virtual environment.<N>6. Delete the virtual environment.<N>7. Create a new virtual environment and install the packages from the requirements.txt file.<N><N>'''
import os<N>import sys<N>import numpy as np<N>import pandas as pd<N>import scipy as sp<N>from scipy import stats<N>import matplotlib.pyplot as plt<N><N>#import dataset<N>file_name = "users_cleaned.csv"<N>file_dir = os.path.join(sys.path[0], file_name)<N>data = pd.read_csv(file_dir, delimiter = ',')<N>columns = list(data.columns)<N><N>
#initialize variable<N>quit = False<N><N>#menu functions<N>def get_column(purpose, frequency_enabled = False):<N>    while True:<N>        column = input("Enter which column "+ purpose +": ")<N>        if column not in columns:<N>            if frequency_enabled and column == "frequency":<N>                break<N>            print("That is not a valid column!")<N>        else:<N>            break<N>    return column<N><N>
def get_graph_type():<N>    while True:<N>        print("============GRAPH MENU============")<N>        print("1. Histogram")<N>        print("2. Bar Graph")<N>        print("3. Scatter plot")<N>        print("4. Back")<N>        choice = int(input("Enter your choice(1-4): ")) #don't forget to do a check for data type (rn it crashes if you input string)<N>        if choice < 1 or choice > 4:<N>            print("That is not a valid choice!")<N>        else:<N>            break<N>    return choice<N><N>
def visualize_hist(column, data):<N>    column_data = data[column]<N>    if(type(column_data[0]) == str):<N>        print("You cannot create a histogram from this column!")<N>    else:<N>        bins = int(input("How many bins do you want: "))<N>        n, bins, patches = plt.hist(column_data, bins=bins, edgecolor='black') #histogram for the total list answer<N>        plt.xlabel(column)<N>        plt.ylabel("Frequency")<N>        plt.show()<N><N>
import kivy<N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.lang import Builder<N>from kivy.uix.recycleview import RecycleView<N>from kivy.properties import StringProperty, ObjectProperty<N>from kivy.core.window import Window<N>from kivy.uix.tabbedpanel import  TabbedPanel<N><N>
from py_librus_api import Librus<N>from datetime import date<N><N>from collections.abc import Mapping<N>import os<N><N>import time<N><N>librus = Librus()<N><N>Builder.load_file('gui_tab.kv')<N><N>Window.clearcolor = (30/255,30/255,30/255,0)<N><N>class MyLibrus():<N>    def __init__(self, login, password, nr):<N>        self.login = login<N>        self.password = password<N>        self.nr = nr<N><N>
    def czyZalogowano(self):<N>        if not librus.logged_in:<N>            if not librus.login(self.login, self.password):<N>                return False<N>            else:<N>                return True<N><N>    def nieObecnosci(self):<N>        tajne_akta = librus.get_teacher_free_days()<N><N>
        def ToDate(text):<N>            text = text.split('-')<N>            return date(int(text[0]), int(text[1]), int(text[2]))<N><N>        actual = []<N>        for x in tajne_akta:<N>            if date.today() <= ToDate(x["DateTo"]):<N>                actual.append(x)<N><N>
        data = [{'text': str(j)} for j in actual]<N><N>        nieobecnosc = ''<N><N>        for i in data:<N>            s = eval(i['text'])<N>            if 'Teacher' in s:<N>                for x in s['Teacher']:<N>                    nieobecnosc += str(s['Teacher'][x]) + " "<N>                del s['Teacher']<N>            for j in s:<N>                nieobecnosc += str(s[j]) + " "<N>            nieobecnosc += '\n'<N><N>
        return nieobecnosc<N><N>class MyGridLayout(TabbedPanel):<N><N>    login = ObjectProperty(None)<N>    password = ObjectProperty(None)<N>    nr = ObjectProperty(None)<N><N>    def press(self):<N>        login = self.ids.login.text<N>        password = self.ids.password.text<N>        nr = self.ids.sz_nr.text<N><N>
        lib = MyLibrus(login, password, nr)<N><N>        if lib.czyZalogowano():<N>            self.ids.zal.text = 'Zalogowano'<N>            self.ids.nie.text, self.ids.nie.halign = lib.nieObecnosci(), 'left'<N>        else:<N>            self.ids.zal.text = 'Nie zalogowano'<N><N>
from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.factory import Factory<N>from kivy.properties import ObjectProperty<N>from kivy.uix.popup import Popup<N><N>import os<N><N><N>class LoadDialog(FloatLayout):<N>    load = ObjectProperty(None)<N>    cancel = ObjectProperty(None)<N><N>
<N>class SaveDialog(FloatLayout):<N>    save = ObjectProperty(None)<N>    text_input = ObjectProperty(None)<N>    cancel = ObjectProperty(None)<N><N><N>class Root(FloatLayout):<N>    loadfile = ObjectProperty(None)<N>    savefile = ObjectProperty(None)<N>    text_input = ObjectProperty(None)<N><N>
    def dismiss_popup(self):<N>        self._popup.dismiss()<N><N>    def show_load(self):<N>        content = LoadDialog(load=self.load, cancel=self.dismiss_popup)<N>        self._popup = Popup(title="Load file", content=content,<N>                            size_hint=(0.9, 0.9))<N>        self._popup.open()<N><N>
    def show_save(self):<N>        content = SaveDialog(save=self.save, cancel=self.dismiss_popup)<N>        self._popup = Popup(title="Save file", content=content,<N>                            size_hint=(0.9, 0.9))<N>        self._popup.open()<N><N>    def load(self, path, filename):<N>        with open(os.path.join(path, filename[0])) as stream:<N>            self.text_input.text = stream.read()<N><N>
        self.dismiss_popup()<N><N>    def save(self, path, filename):<N>        with open(os.path.join(path, filename), 'w') as stream:<N>            stream.write(self.text_input.text)<N><N>        self.dismiss_popup()<N><N><N>class Editor(App):<N>    pass<N><N>
'''Example shows the recommended way of how to run Kivy with a trio<N>event loop as just another async coroutine.<N>'''<N>import trio<N>from kivy.app import async_runTouchApp<N>from kivy.lang.builder import Builder<N><N>kv = '''<N>BoxLayout:<N>    orientation: 'vertical'<N>    Button:<N>        id: btn<N>        text: 'Press me'<N>    BoxLayout:<N>        Label:<N>            id: label<N>            text: 'Button is "{}"'.format(btn.state)<N>'''<N><N>
<N>async def run_app_happily(root, nursery):<N>    '''This method, which runs Kivy, is run by trio as one of the coroutines.<N>    '''<N>    # trio needs to be set so that it'll be used for the event loop<N>    await async_runTouchApp(root, async_lib='trio')  # run Kivy<N>    print('App done')<N>    # now cancel all the other tasks that may be running<N>    nursery.cancel_scope.cancel()<N><N>
<N>async def waste_time_freely():<N>    '''This method is also run by trio and periodically prints something.'''<N>    try:<N>        while True:<N>            print('Sitting on the beach')<N>            await trio.sleep(2)<N>    except trio.Cancelled as e:<N>        print('Wasting time was canceled', e)<N>    finally:<N>        # when canceled, print that it finished<N>        print('Done wasting time')<N><N>
if __name__ == '__main__':<N>    async def root_func():<N>        '''trio needs to run a function, so this is it. '''<N><N>        root = Builder.load_string(kv)  # root widget<N>        async with trio.open_nursery() as nursery:<N>            '''In trio you create a nursery, in which you schedule async<N>            functions to be run by the nursery simultaneously as tasks.<N><N>
            This will run all two methods starting in random order<N>            asynchronously and then block until they are finished or canceled<N>            at the `with` level. '''<N>            nursery.start_soon(run_app_happily, root, nursery)<N>            nursery.start_soon(waste_time_freely)<N><N>
'''Example shows the recommended way of how to run Kivy with the Python built<N>in asyncio event loop as just another async coroutine.<N>'''<N>import asyncio<N><N>from kivy.app import async_runTouchApp<N>from kivy.lang.builder import Builder<N><N>kv = '''<N>BoxLayout:<N>    orientation: 'vertical'<N>    Button:<N>        id: btn<N>        text: 'Press me'<N>    BoxLayout:<N>        Label:<N>            id: label<N>            text: 'Button is "{}"'.format(btn.state)<N>'''<N><N>
<N>async def run_app_happily(root, other_task):<N>    '''This method, which runs Kivy, is run by the asyncio loop as one of the<N>    coroutines.<N>    '''<N>    # we don't actually need to set asyncio as the lib because it is the<N>    # default, but it doesn't hurt to be explicit<N>    await async_runTouchApp(root, async_lib='asyncio')  # run Kivy<N>    print('App done')<N>    # now cancel all the other tasks that may be running<N>    other_task.cancel()<N><N>
<N>async def waste_time_freely():<N>    '''This method is also run by the asyncio loop and periodically prints<N>    something.<N>    '''<N>    try:<N>        while True:<N>            print('Sitting on the beach')<N>            await asyncio.sleep(2)<N>    except asyncio.CancelledError as e:<N>        print('Wasting time was canceled', e)<N>    finally:<N>        # when canceled, print that it finished<N>        print('Done wasting time')<N><N>
if __name__ == '__main__':<N>    def root_func():<N>        '''This will run both methods asynchronously and then block until they<N>        are finished<N>        '''<N>        root = Builder.load_string(kv)  # root widget<N>        other_task = asyncio.ensure_future(waste_time_freely())<N>        return asyncio.gather(run_app_happily(root, other_task), other_task)<N><N>
from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.lang import Builder<N>from kivy.core.window import Window<N><N><N>class KvApp(App):<N>    def __init__(self, filename, **kwargs):<N>        self.filename = filename<N>        super(KvApp, self).__init__(**kwargs)<N><N>
    def _print_fps(self, *largs):<N>        print('FPS: %2.4f (real draw: %d)' % (<N>            Clock.get_fps(), Clock.get_rfps()))<N><N>    def _reload_keypress(self, instance, code, *largs):<N>        if code != 286:<N>            return<N>        for child in Window.children[:]:<N>            Window.remove_widget(child)<N>        root = Builder.load_file(self.filename)<N>        Window.add_widget(root)<N><N>
    def build(self):<N>        Clock.schedule_interval(self._print_fps, 1)<N>        Window.bind(on_keyboard=self._reload_keypress)<N>        return Builder.load_file(self.filename)<N><N><N>if __name__ == '__main__':<N>    import sys<N>    import os<N><N>    if len(sys.argv) < 2:<N>        print('Usage: %s filename.kv' % os.path.basename(sys.argv[0]))<N>        sys.exit(1)<N><N>
from kivy.lang import Builder<N>from kivy.app import App<N>from kivy.uix.boxlayout import BoxLayout<N><N>Builder.load_string('''<N>[BlehItem@BoxLayout]:<N>    orientation: 'vertical'<N>    Label:<N>        text: str(ctx.idx)<N>    Button:<N>        text: ctx.word<N>''')<N><N>
<N>class BlehApp(App):<N><N>    def build(self):<N>        root = BoxLayout()<N>        for idx, word in enumerate(('Hello', 'World')):<N>            wid = Builder.template('BlehItem', **{<N>                'idx': idx, 'word': word,<N>            })<N>            root.add_widget(wid)<N>        return root<N><N>
'''<N>The use of id in KV<N>===================<N><N>This small example shows how to refer from one widget<N>to another within KV.<N>'''<N><N>import kivy<N>kivy.require('1.8.0')<N><N>from kivy.app import App<N><N><N>class TestApp(App):<N>    pass<N><N><N>if __name__ == '__main__':<N>    TestApp().run()<N>
'''<N>Referring on ids from Python<N>=============================<N><N>This example shows how to refer to an id from a Python file.<N>'''<N><N>import kivy<N>kivy.require('1.8.0')<N><N>from kivy.app import App<N>from kivy.uix.boxlayout import BoxLayout<N><N>
class MeshData(object):<N>    def __init__(self, **kwargs):<N>        self.name = kwargs.get("name")<N>        self.vertex_format = [<N>            (b'v_pos', 3, 'float'),<N>            (b'v_normal', 3, 'float'),<N>            (b'v_tc0', 2, 'float')]<N>        self.vertices = []<N>        self.indices = []<N><N>
    def calculate_normals(self):<N>        for i in range(len(self.indices) / (3)):<N>            fi = i * 3<N>            v1i = self.indices[fi]<N>            v2i = self.indices[fi + 1]<N>            v3i = self.indices[fi + 2]<N><N>            vs = self.vertices<N>            p1 = [vs[v1i + c] for c in range(3)]<N>            p2 = [vs[v2i + c] for c in range(3)]<N>            p3 = [vs[v3i + c] for c in range(3)]<N><N>
            u, v = [0, 0, 0], [0, 0, 0]<N>            for j in range(3):<N>                v[j] = p2[j] - p1[j]<N>                u[j] = p3[j] - p1[j]<N><N>            n = [0, 0, 0]<N>            n[0] = u[1] * v[2] - u[2] * v[1]<N>            n[1] = u[2] * v[0] - u[0] * v[2]<N>            n[2] = u[0] * v[1] - u[1] * v[0]<N><N>
            for k in range(3):<N>                self.vertices[v1i + 3 + k] = n[k]<N>                self.vertices[v2i + 3 + k] = n[k]<N>                self.vertices[v3i + 3 + k] = n[k]<N><N><N>class ObjFile:<N>    def finish_object(self):<N>        if self._current_object is None:<N>            return<N><N>
        mesh = MeshData()<N>        idx = 0<N>        for f in self.faces:<N>            verts = f[0]<N>            norms = f[1]<N>            tcs = f[2]<N>            for i in range(3):<N>                # get normal components<N>                n = (0.0, 0.0, 0.0)<N>                if norms[i] != -1:<N>                    n = self.normals[norms[i] - 1]<N><N>
                # get texture coordinate components<N>                t = (0.0, 0.0)<N>                if tcs[i] != -1:<N>                    t = self.texcoords[tcs[i] - 1]<N><N>                # get vertex components<N>                v = self.vertices[verts[i] - 1]<N><N>
                data = [v[0], v[1], v[2], n[0], n[1], n[2], t[0], t[1]]<N>                mesh.vertices.extend(data)<N><N>            tri = [idx, idx + 1, idx + 2]<N>            mesh.indices.extend(tri)<N>            idx += 3<N><N>        self.objects[self._current_object] = mesh<N>        # mesh.calculate_normals()<N>        self.faces = []<N><N>
    def __init__(self, filename, swapyz=False):<N>        """Loads a Wavefront OBJ file. """<N>        self.objects = {}<N>        self.vertices = []<N>        self.normals = []<N>        self.texcoords = []<N>        self.faces = []<N><N>        self._current_object = None<N><N>
'''<N>3D Rotating Monkey Head<N>========================<N><N>This example demonstrates using OpenGL to display a rotating monkey head. This<N>includes loading a Blender OBJ file, shaders written in OpenGL's Shading<N>Language (GLSL), and using scheduled callbacks.<N><N>
The monkey.obj file is an OBJ file output from the Blender free 3D creation<N>software. The file is text, listing vertices and faces and is loaded<N>using a class in the file objloader.py. The file simple.glsl is<N>a simple vertex and fragment shader written in GLSL.<N>'''<N><N>
from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.core.window import Window<N>from kivy.uix.widget import Widget<N>from kivy.resources import resource_find<N>from kivy.graphics.transformation import Matrix<N>from kivy.graphics.opengl import glEnable, glDisable, GL_DEPTH_TEST<N>from kivy.graphics import RenderContext, Callback, PushMatrix, PopMatrix, \<N>    Color, Translate, Rotate, Mesh, UpdateNormalMatrix<N>from objloader import ObjFile<N><N>
'''<N>Application from a .kv in a Template Directory<N>==============================================<N><N>This example shows how you can change the directory for the .kv file. You<N>should see "Hello from template1/test.ky" as a button.<N><N>As kivy instantiates the TestApp subclass of App, the variable kv_directory<N>is set. Kivy then implicitly searches for a .kv file matching the name<N>of the subclass in that directory, finding the file template1/test.kv. That<N>file contains the root widget.<N><N>
'''<N>Suite of Application Builders<N>=============================<N><N>This explores different methods of starting an application. If you run<N>this without a command line parameter, you should see a menu in your terminal.<N>You can also run this with a 'r' parameter to pick a random method.<N>There are lots of logging options to make this easier to debug: the execution<N>order may not be obvious. Each time you run the command, only one kivy<N>application is created.<N><N>
This uses the file testkvfile.kv and the file app_suite_data/testkvdir.kv.<N><N>'''<N><N>from __future__ import print_function<N>import sys<N>import re<N>from random import choice<N><N>import kivy<N>kivy.require('1.8.0')  # 1.8 is when kv_directory became part of app.<N>from kivy.app import App<N>from kivy.uix.button import Button<N>from kivy.lang import Builder<N><N>
'''<N>Application example using build() + return<N>==========================================<N><N>An application can be built if you return a widget on build(), or if you set<N>self.root.<N>'''<N><N>import kivy<N>kivy.require('1.0.7')<N><N>from kivy.app import App<N>from kivy.uix.button import Button<N><N><N>class TestApp(App):<N><N>    def build(self):<N>        # return a Button() as a root widget<N>        return Button(text='hello world')<N><N><N>if __name__ == '__main__':<N>    TestApp().run()<N>
'''<N>Application built from a  .kv file<N>==================================<N><N>This shows how to implicitly use a .kv file for your application. You<N>should see a full screen button labelled "Hello from test.kv".<N><N>After Kivy instantiates a subclass of App, it implicitly searches for a .kv<N>file. The file test.kv is selected because the name of the subclass of App is<N>TestApp, which implies that kivy should try to load "test.kv". That file<N>contains a root Widget.<N>'''<N><N>
from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.properties import ConfigParserProperty<N><N>KV = '''<N>FloatLayout:<N>    BoxLayout:<N>        size_hint: .5, .5<N>        pos_hint: {'center': (.5, .5)}<N><N>        orientation: 'vertical'<N><N>
        TextInput:<N>            text: app.text<N>            on_text: app.text = self.text<N><N>        Slider:<N>            min: 0<N>            max: 100<N>            value: app.number<N>            on_value: app.number = self.value<N>'''<N><N><N>class ConfigApp(App):<N>    number = ConfigParserProperty(<N>        0, 'general', 'number',<N>        'app', val_type=float<N>    )<N>    text = ConfigParserProperty(<N>        '', 'general', 'text',<N>        'app', val_type=str<N>    )<N><N>
    def build_config(self, config):<N>        config.setdefaults(<N>            'general',<N>            {<N>                'number': 0,<N>                'text': 'test'<N>            }<N>        )<N><N>    def build(self):<N>        return Builder.load_string(KV)<N><N>
import kivy<N>from kivy.app import App<N>from kivy.uix.behaviors import CoverBehavior<N>from kivy.uix.image import Image<N><N><N>class CoverImage(CoverBehavior, Image):<N>    """Image using cover behavior.<N>    """<N><N>    def __init__(self, **kwargs):<N>        super(CoverImage, self).__init__(**kwargs)<N>        texture = self._coreimage.texture<N>        self.reference_size = texture.size<N>        self.texture = texture<N><N>
'''<N>Shuffled Camera Feed Puzzle<N>===========================<N><N>This demonstrates using Scatter widgets with a live camera.<N>You should see a shuffled grid of rectangles that make up the<N>camera feed. You can drag the squares around to see the<N>unscrambled camera feed or double click to scramble the grid<N>again.<N>'''<N><N>
<N>from kivy.app import App<N>from kivy.uix.camera import Camera<N>from kivy.uix.widget import Widget<N>from kivy.uix.slider import Slider<N>from kivy.uix.scatter import Scatter<N>from kivy.animation import Animation<N>from kivy.graphics import Color, Rectangle<N>from kivy.properties import NumericProperty<N>from random import randint, random<N>from functools import partial<N><N>
__all__ = ('GestureHistoryManager', 'GestureVisualizer')<N><N>from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.lang import Builder<N>from kivy.uix.widget import Widget<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.uix.label import Label<N>from kivy.graphics import Color, Line<N>from kivy.properties import ObjectProperty, BooleanProperty<N>from kivy.compat import PY2<N><N>
# local libraries<N>from helpers import InformationPopup<N>from settings import MultistrokeSettingsContainer<N><N><N># refuse heap permute for gestures with more strokes than 3<N># (you can increase it, but 4 strokes = 384 templates, 5 = 3840)<N>MAX_PERMUTE_STROKES = 3<N><N>
__all__ = ('GestureDatabase', 'GestureDatabaseItem')<N><N>from kivy.clock import Clock<N>from kivy.lang import Builder<N>from kivy.properties import NumericProperty, StringProperty<N>from kivy.properties import ListProperty, ObjectProperty<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.uix.popup import Popup<N>from kivy.graphics import Rectangle, Color<N>from kivy.multistroke import Recognizer<N><N>
# local libraries<N>from helpers import InformationPopup<N><N><N>Builder.load_file('gesturedatabase.kv')<N><N><N>class GestureExportPopup(Popup):<N>    pass<N><N><N>class GestureImportPopup(Popup):<N>    pass<N><N><N>class GestureDatabaseItem(FloatLayout):<N>    name = StringProperty('(no name)')<N>    template_count = NumericProperty(0)<N>    gesture_list = ListProperty([])<N><N>
    def __init__(self, **kwargs):<N>        super(GestureDatabaseItem, self).__init__(**kwargs)<N>        self.rect = None<N>        self._draw_trigger = Clock.create_trigger(self.draw_item, 0)<N>        self.update_template_count()<N>        self.bind(gesture_list=self.update_template_count)<N>        self.register_event_type('on_select')<N>        self.register_event_type('on_deselect')<N><N>
    def toggle_selected(self, *l):<N>        self._draw_rect(clear=True)<N>        if self.ids.select.state == 'down':<N>            self.dispatch('on_select')<N>            self.ids.select.text = 'Deselect'<N>        else:<N>            self.dispatch('on_deselect')<N>            self.ids.select.text = 'Select'<N><N>
    def update_template_count(self, *l):<N>        tpl_count = 0<N>        for g in self.gesture_list:<N>            tpl_count += len(g.templates)<N>        self.template_count = tpl_count<N><N>    def draw_item(self, *l):<N>        self.ids.namelbl.pos = self.pos<N>        self.ids.namelbl.y += 90<N>        self.ids.stats.pos = self.pos<N>        self.ids.stats.y += 40<N>        self.ids.select.pos = self.pos<N>        self._draw_rect()<N><N>
    def _draw_rect(self, clear=False, *l):<N>        col = self.ids.select.state == 'down' and 1 or .2<N>        with self.canvas:<N>            Color(col, 0, 0, .15)<N>            if self.rect or clear:<N>                self.canvas.remove(self.rect)<N>            self.rect = Rectangle(size=self.size, pos=self.pos)<N><N>
    def on_select(*l):<N>        pass<N><N>    def on_deselect(*l):<N>        pass<N><N><N>class GestureDatabase(GridLayout):<N>    selected_count = NumericProperty(0)<N>    recognizer = ObjectProperty(None)<N>    export_popup = ObjectProperty(GestureExportPopup())<N>    import_popup = ObjectProperty(GestureImportPopup())<N>    info_popup = ObjectProperty(InformationPopup())<N><N>
    def __init__(self, **kwargs):<N>        super(GestureDatabase, self).__init__(**kwargs)<N>        self.redraw_all = Clock.create_trigger(self._redraw_gesture_list, 0)<N>        self.export_popup.ids.save_btn.bind(on_press=self.perform_export)<N>        self.import_popup.ids.filechooser.bind(on_submit=self.perform_import)<N><N>
__all__ = ('InformationPopup', )<N><N>from kivy.uix.popup import Popup<N>from kivy.properties import StringProperty<N>from kivy.factory import Factory<N>from kivy.lang import Builder<N>from kivy.clock import Clock<N><N>Builder.load_string('''<N><InformationPopup>:<N>    auto_dismiss: True<N>    size_hint: None, None<N>    size: 400, 200<N>    on_open: root.dismiss_trigger()<N>    title: root.title<N>    Label:<N>        text: root.text<N>''')<N><N>
<N>class InformationPopup(Popup):<N>    title = StringProperty('Information')<N>    text = StringProperty('')<N><N>    def __init__(self, time=1.5, **kwargs):<N>        super(InformationPopup, self).__init__(**kwargs)<N>        self.dismiss_trigger = Clock.create_trigger(self.dismiss, time)<N><N>
'''<N>Showcase of Kivy Features<N>=========================<N><N>This showcases many features of Kivy. You should see a<N>menu bar across the top with a demonstration area below. The<N>first demonstration is the accordion layout. You can see, but not<N>edit, the kv language code for any screen by pressing the bug or<N>'show source' icon. Scroll through the demonstrations using the<N>left and right icons in the top right or selecting from the menu<N>bar.<N><N>
'''<N>Basic Picture Viewer<N>====================<N><N>This simple image browser demonstrates the scatter widget. You should<N>see three framed photographs on a background. You can click and drag<N>the photos around, or multi-touch to drop a red dot to scale and rotate the<N>photos.<N><N>
The photos are loaded from the local images directory, while the background<N>picture is from the data shipped with kivy in kivy/data/images/background.jpg.<N>The file pictures.kv describes the interface and the file shadow32.png is<N>the border to make the images look like framed photographs. Finally,<N>the file android.txt is used to package the application for use with the<N>Kivy Launcher Android application.<N><N>
For Android devices, you can copy/paste this directory into<N>/sdcard/kivy/pictures on your Android device.<N><N>The images in the image directory are from the Internet Archive,<N>`https://archive.org/details/PublicDomainImages`, and are in the public<N>domain.<N><N>
'''<N><N>import kivy<N>kivy.require('1.0.6')<N><N>from glob import glob<N>from random import randint<N>from os.path import join, dirname<N>from kivy.app import App<N>from kivy.logger import Logger<N>from kivy.uix.scatter import Scatter<N>from kivy.properties import StringProperty<N><N>
<N>class Picture(Scatter):<N>    '''Picture is the class that will show the image with a white border and a<N>    shadow. They are nothing here because almost everything is inside the<N>    picture.kv. Check the rule named <Picture> inside the file, and you'll see<N>    how the Picture() is really constructed and used.<N><N>
'''<N>Live Shader Editor<N>==================<N><N>This provides a live editor for vertex and fragment editors.<N>You should see a window with two editable panes on the left<N>and a large kivy logo on the right.The top pane is the<N>Vertex shader and the bottom is the Fragment shader. The file shadereditor.kv<N>describes the interface.<N><N>
On each keystroke to either shader, declarations are added and the shaders<N>are compiled. If there are no errors, the screen is updated. Otherwise,<N>the error is visible as logging message in your terminal.<N>'''<N><N><N>import sys<N>import kivy<N>kivy.require('1.0.6')<N><N>
from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.core.window import Window<N>from kivy.factory import Factory<N>from kivy.graphics import RenderContext<N>from kivy.properties import StringProperty, ObjectProperty<N>from kivy.clock import Clock<N>from kivy.compat import PY2<N><N>
fs_header = '''<N>#ifdef GL_ES<N>    precision highp float;<N>#endif<N><N>/* Outputs from the vertex shader */<N>varying vec4 frag_color;<N>varying vec2 tex_coord0;<N><N>/* uniform texture samplers */<N>uniform sampler2D texture0;<N><N>/* custom one */<N>uniform vec2 resolution;<N>uniform float time;<N>'''<N><N>
vs_header = '''<N>#ifdef GL_ES<N>    precision highp float;<N>#endif<N><N>/* Outputs to the fragment shader */<N>varying vec4 frag_color;<N>varying vec2 tex_coord0;<N><N>/* vertex attributes */<N>attribute vec2     vPosition;<N>attribute vec2     vTexCoords0;<N><N>
/* uniform variables */<N>uniform mat4       modelview_mat;<N>uniform mat4       projection_mat;<N>uniform vec4       color;<N>'''<N><N><N>class ShaderViewer(FloatLayout):<N>    fs = StringProperty(None)<N>    vs = StringProperty(None)<N><N>    def __init__(self, **kwargs):<N>        self.canvas = RenderContext()<N>        super(ShaderViewer, self).__init__(**kwargs)<N>        Clock.schedule_interval(self.update_shader, 0)<N><N>
    def update_shader(self, *args):<N>        s = self.canvas<N>        s['projection_mat'] = Window.render_context['projection_mat']<N>        s['time'] = Clock.get_boottime()<N>        s['resolution'] = list(map(float, self.size))<N>        s.ask_update()<N><N>
    def on_fs(self, instance, value):<N>        self.canvas.shader.fs = value<N><N>    def on_vs(self, instance, value):<N>        self.canvas.shader.vs = value<N><N><N>Factory.register('ShaderViewer', cls=ShaderViewer)<N><N><N>class ShaderEditor(FloatLayout):<N><N>
    source = StringProperty('data/logo/kivy-icon-512.png')<N><N>    fs = StringProperty('''<N>void main (void){<N>    gl_FragColor = frag_color * texture2D(texture0, tex_coord0);<N>}<N>''')<N>    vs = StringProperty('''<N>void main (void) {<N>  frag_color = color;<N>  tex_coord0 = vTexCoords0;<N>  gl_Position = projection_mat * modelview_mat * vec4(vPosition.xy, 0.0, 1.0);<N>}<N>''')<N><N>
    viewer = ObjectProperty(None)<N><N>    def __init__(self, **kwargs):<N>        super(ShaderEditor, self).__init__(**kwargs)<N>        self.test_canvas = RenderContext()<N>        s = self.test_canvas.shader<N>        self.trigger_compile = Clock.create_trigger(self.compile_shaders, -1)<N>        self.bind(fs=self.trigger_compile, vs=self.trigger_compile)<N><N>
    def compile_shaders(self, *largs):<N>        print('try compile')<N>        if not self.viewer:<N>            return<N><N>        # we don't use str() here because it will crash with non-ascii char<N>        if PY2:<N>            fs = fs_header + self.fs.encode('utf-8')<N>            vs = vs_header + self.vs.encode('utf-8')<N>        else:<N>            fs = fs_header + self.fs<N>            vs = vs_header + self.vs<N><N>
        print('-->', fs)<N>        self.viewer.fs = fs<N>        print('-->', vs)<N>        self.viewer.vs = vs<N><N><N>class ShaderEditorApp(App):<N>    def build(self):<N>        kwargs = {}<N>        if len(sys.argv) > 1:<N>            kwargs['source'] = sys.argv[1]<N>        return ShaderEditor(**kwargs)<N><N>
'''<N>Touch Tracer Line Drawing Demonstration<N>=======================================<N><N>This demonstrates tracking each touch registered to a device. You should<N>see a basic background image. When you press and hold the mouse, you<N>should see cross-hairs with the coordinates written next to them. As<N>you drag, it leaves a trail. Additional information, like pressure,<N>will be shown if they are in your device's touch.profile.<N><N>
.. note::<N><N>   A function `calculate_points` handling the points which will be drawn<N>   has by default implemented a delay of 5 steps. To get more precise visual<N>   results lower the value of the optional keyword argument `steps`.<N><N>This program specifies an icon, the file icon.png, in its App subclass.<N>It also uses the particle.png file as the source for drawing the trails which<N>are white on transparent. The file touchtracer.kv describes the application.<N><N>
The file android.txt is used to package the application for use with the<N>Kivy Launcher Android application. For Android devices, you can<N>copy/paste this directory into /sdcard/kivy/touchtracer on your Android device.<N><N>'''<N>__version__ = '1.0'<N><N>
import kivy<N>kivy.require('1.0.6')<N><N>from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.uix.label import Label<N>from kivy.graphics import Color, Rectangle, Point, GraphicException<N>from random import random<N>from math import sqrt<N><N>
<N>def calculate_points(x1, y1, x2, y2, steps=5):<N>    dx = x2 - x1<N>    dy = y2 - y1<N>    dist = sqrt(dx * dx + dy * dy)<N>    if dist < steps:<N>        return<N>    o = []<N>    m = dist / steps<N>    for i in range(1, int(m)):<N>        mi = i / m<N>        lastx = x1 + dx * mi<N>        lasty = y1 + dy * mi<N>        o.extend([lastx, lasty])<N>    return o<N><N>
<N>class Touchtracer(FloatLayout):<N><N>    def on_touch_down(self, touch):<N>        win = self.get_parent_window()<N>        ud = touch.ud<N>        ud['group'] = g = str(touch.uid)<N>        pointsize = 5<N>        if 'pressure' in touch.profile:<N>            ud['pressure'] = touch.pressure<N>            pointsize = (touch.pressure * 100000) ** 2<N>        ud['color'] = random()<N><N>
        with self.canvas:<N>            Color(ud['color'], 1, 1, mode='hsv', group=g)<N>            ud['lines'] = [<N>                Rectangle(pos=(touch.x, 0), size=(1, win.height), group=g),<N>                Rectangle(pos=(0, touch.y), size=(win.width, 1), group=g),<N>                Point(points=(touch.x, touch.y), source='particle.png',<N>                      pointsize=pointsize, group=g)]<N><N>
        ud['label'] = Label(size_hint=(None, None))<N>        self.update_touch_label(ud['label'], touch)<N>        self.add_widget(ud['label'])<N>        touch.grab(self)<N>        return True<N><N>    def on_touch_move(self, touch):<N>        if touch.grab_current is not self:<N>            return<N>        ud = touch.ud<N>        ud['lines'][0].pos = touch.x, 0<N>        ud['lines'][1].pos = 0, touch.y<N><N>
        index = -1<N><N>        while True:<N>            try:<N>                points = ud['lines'][index].points<N>                oldx, oldy = points[-2], points[-1]<N>                break<N>            except:<N>                index -= 1<N><N>        points = calculate_points(oldx, oldy, touch.x, touch.y)<N><N>
# encoding: utf8<N><N>from kivy.app import App<N>from kivy.core.audio import SoundLoader<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.button import Button<N><N>from sys import version_info<N><N><N>NOTES = (<N>    ('Do', 1),<N>    ('RÃ©', 9 / 8.),<N>    ('Mi', 5 / 4.),<N>    ('Fa', 4 / 3.),<N>    ('Sol', 3 / 2.),<N>    ('La', 5 / 3.),<N>    ('Si', 15 / 8.),<N>)<N><N>
'''<N>Audio example<N>=============<N><N>This example plays sounds of different formats. You should see a grid of<N>buttons labelled with filenames. Clicking on the buttons will play, or<N>restart, each sound. Not all sound formats will play on all platforms.<N><N>
All the sounds are from the http://woolyss.com/chipmusic-samples.php<N>"THE FREESOUND PROJECT", Under Creative Commons Sampling Plus 1.0 License.<N><N>'''<N><N>import kivy<N>kivy.require('1.0.8')<N><N>from kivy.app import App<N>from kivy.uix.button import Button<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.core.audio import SoundLoader<N>from kivy.properties import StringProperty, ObjectProperty, NumericProperty<N>from glob import glob<N>from os.path import dirname, join, basename<N><N>
<N>class AudioButton(Button):<N><N>    filename = StringProperty(None)<N>    sound = ObjectProperty(None, allownone=True)<N>    volume = NumericProperty(1.0)<N><N>    def on_press(self):<N>        if self.sound is None:<N>            self.sound = SoundLoader.load(self.filename)<N>        # stop the sound if it's currently playing<N>        if self.sound.status != 'stop':<N>            self.sound.stop()<N>        self.sound.volume = self.volume<N>        self.sound.play()<N><N>
    def release_audio(self):<N>        if self.sound:<N>            self.sound.stop()<N>            self.sound.unload()<N>            self.sound = None<N><N>    def set_volume(self, volume):<N>        self.volume = volume<N>        if self.sound:<N>            self.sound.volume = volume<N><N>
<N>class AudioBackground(BoxLayout):<N>    pass<N><N><N>class AudioApp(App):<N><N>    def build(self):<N><N>        root = AudioBackground(spacing=5)<N>        for fn in glob(join(dirname(__file__), '*.wav')):<N>            btn = AudioButton(<N>                text=basename(fn[:-4]).replace('_', ' '), filename=fn,<N>                size_hint=(None, None), halign='center',<N>                size=(128, 128), text_size=(118, None))<N>            root.ids.sl.add_widget(btn)<N><N>
        return root<N><N>    def release_audio(self):<N>        for audiobutton in self.root.ids.sl.children:<N>            audiobutton.release_audio()<N><N>    def set_volume(self, value):<N>        for audiobutton in self.root.ids.sl.children:<N>            audiobutton.set_volume(value)<N><N>
from kivy.app import App<N><N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.graphics import Color, Ellipse, Line<N>from kivy.gesture import Gesture, GestureDatabase<N><N>from my_gestures import cross, circle, check, square<N><N><N>def simplegesture(name, point_list):<N>    """<N>    A simple helper function<N>    """<N>    g = Gesture()<N>    g.add_stroke(point_list)<N>    g.normalize()<N>    g.name = name<N>    return g<N><N>
<N>class GestureBoard(FloatLayout):<N>    """<N>    Our application main widget, derived from touchtracer example, use data<N>    constructed from touches to match symboles loaded from my_gestures.<N><N>    """<N>    def __init__(self, *args, **kwargs):<N>        super(GestureBoard, self).__init__()<N>        self.gdb = GestureDatabase()<N><N>
'''<N>Notes<N>=====<N><N>Simple application for reading/writing notes.<N><N>'''<N><N>__version__ = '1.0'<N><N>import json<N>from os.path import join, exists<N>from kivy.app import App<N>from kivy.uix.screenmanager import ScreenManager, Screen, SlideTransition<N>from kivy.properties import ListProperty, StringProperty, \<N>        NumericProperty, BooleanProperty, AliasProperty<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.clock import Clock<N><N>
<N>class MutableTextInput(FloatLayout):<N><N>    text = StringProperty()<N>    multiline = BooleanProperty(True)<N><N>    def __init__(self, **kwargs):<N>        super(MutableTextInput, self).__init__(**kwargs)<N>        Clock.schedule_once(self.prepare, 0)<N><N>
    def prepare(self, *args):<N>        self.w_textinput = self.ids.w_textinput.__self__<N>        self.w_label = self.ids.w_label.__self__<N>        self.view()<N><N>    def on_touch_down(self, touch):<N>        if self.collide_point(*touch.pos) and touch.is_double_tap:<N>            self.edit()<N>        return super(MutableTextInput, self).on_touch_down(touch)<N><N>
    def edit(self):<N>        self.clear_widgets()<N>        self.add_widget(self.w_textinput)<N>        self.w_textinput.focus = True<N><N>    def view(self):<N>        self.clear_widgets()<N>        if not self.text:<N>            self.w_label.text = "Double tap/click to edit"<N>        self.add_widget(self.w_label)<N><N>
    def check_focus_and_view(self, textinput):<N>        if not textinput.focus:<N>            self.text = textinput.text<N>            self.view()<N><N><N>class NoteView(Screen):<N><N>    note_index = NumericProperty()<N>    note_title = StringProperty()<N>    note_content = StringProperty()<N><N>
<N>class NoteListItem(BoxLayout):<N>    note_content = StringProperty()<N>    note_title = StringProperty()<N>    note_index = NumericProperty()<N><N><N>class Notes(Screen):<N><N>    data = ListProperty()<N><N>    def _get_data_for_widgets(self):<N>        return [{<N>            'note_index': index,<N>            'note_content': item['content'],<N>            'note_title': item['title']}<N>            for index, item in enumerate(self.data)]<N><N>
    data_for_widgets = AliasProperty(_get_data_for_widgets, bind=['data'])<N><N><N>class NoteApp(App):<N><N>    def build(self):<N>        self.notes = Notes(name='notes')<N>        self.load_notes()<N><N>        self.transition = SlideTransition(duration=.35)<N>        root = ScreenManager(transition=self.transition)<N>        root.add_widget(self.notes)<N>        return root<N><N>
    def load_notes(self):<N>        if not exists(self.notes_fn):<N>            return<N>        with open(self.notes_fn) as fd:<N>            data = json.load(fd)<N>        self.notes.data = data<N><N>    def save_notes(self):<N>        with open(self.notes_fn, 'w') as fd:<N>            json.dump(self.notes.data, fd)<N><N>
    def del_note(self, note_index):<N>        del self.notes.data[note_index]<N>        self.save_notes()<N>        self.refresh_notes()<N>        self.go_notes()<N><N>    def edit_note(self, note_index):<N>        note = self.notes.data[note_index]<N>        name = 'note{}'.format(note_index)<N><N>
        if self.root.has_screen(name):<N>            self.root.remove_widget(self.root.get_screen(name))<N><N>        view = NoteView(<N>            name=name,<N>            note_index=note_index,<N>            note_title=note.get('title'),<N>            note_content=note.get('content'))<N><N>
        self.root.add_widget(view)<N>        self.transition.direction = 'left'<N>        self.root.current = view.name<N><N>    def add_note(self):<N>        self.notes.data.append({'title': 'New note', 'content': ''})<N>        note_index = len(self.notes.data) - 1<N>        self.edit_note(note_index)<N><N>
    def set_note_content(self, note_index, note_content):<N>        self.notes.data[note_index]['content'] = note_content<N>        data = self.notes.data<N>        self.notes.data = []<N>        self.notes.data = data<N>        self.save_notes()<N>        self.refresh_notes()<N><N>
    def set_note_title(self, note_index, note_title):<N>        self.notes.data[note_index]['title'] = note_title<N>        self.save_notes()<N>        self.refresh_notes()<N><N>    def refresh_notes(self):<N>        data = self.notes.data<N>        self.notes.data = []<N>        self.notes.data = data<N><N>
    def go_notes(self):<N>        self.transition.direction = 'right'<N>        self.root.current = 'notes'<N><N>    @property<N>    def notes_fn(self):<N>        return join(self.user_data_dir, 'notes.json')<N><N><N>if __name__ == '__main__':<N>    NoteApp().run()<N><N><N>
import kivy<N>kivy.require('1.1.1')<N><N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.properties import (<N>    NumericProperty, ReferenceListProperty, ObjectProperty, BooleanProperty<N>)<N>from kivy.vector import Vector<N>from kivy.clock import Clock<N><N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N><N><N>class PongGame(Widget):<N>    pass<N><N><N>class PongApp(App):<N>    def build(self):<N>        return PongGame()<N><N><N>if __name__ == '__main__':<N>    PongApp().run()<N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.properties import NumericProperty, ReferenceListProperty<N>from kivy.vector import Vector<N><N><N>class PongBall(Widget):<N>    velocity_x = NumericProperty(0)<N>    velocity_y = NumericProperty(0)<N>    velocity = ReferenceListProperty(velocity_x, velocity_y)<N><N>
    def move(self):<N>        self.pos = Vector(*self.velocity) + self.pos<N><N><N>class PongGame(Widget):<N>    pass<N><N><N>class PongApp(App):<N>    def build(self):<N>        return PongGame()<N><N><N>if __name__ == '__main__':<N>    PongApp().run()<N><N><N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.properties import (<N>    NumericProperty, ReferenceListProperty, ObjectProperty<N>)<N>from kivy.vector import Vector<N>from kivy.clock import Clock<N>from random import randint<N><N>
<N>class PongBall(Widget):<N>    velocity_x = NumericProperty(0)<N>    velocity_y = NumericProperty(0)<N>    velocity = ReferenceListProperty(velocity_x, velocity_y)<N><N>    def move(self):<N>        self.pos = Vector(*self.velocity) + self.pos<N><N><N>class PongGame(Widget):<N>    ball = ObjectProperty(None)<N><N>
    def serve_ball(self):<N>        self.ball.center = self.center<N>        self.ball.velocity = Vector(4, 0).rotate(randint(0, 360))<N><N>    def update(self, dt):<N>        self.ball.move()<N><N>        # bounce off top and bottom<N>        if (self.ball.y < 0) or (self.ball.top > self.height):<N>            self.ball.velocity_y *= -1<N><N>
        # bounce off left and right<N>        if (self.ball.x < 0) or (self.ball.right > self.width):<N>            self.ball.velocity_x *= -1<N><N><N>class PongApp(App):<N>    def build(self):<N>        game = PongGame()<N>        game.serve_ball()<N>        Clock.schedule_interval(game.update, 1.0 / 60.0)<N>        return game<N><N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N><N><N>class PongGame(Widget):<N>    pass<N><N><N>class PongApp(App):<N>    def build(self):<N>        return PongGame()<N><N><N>if __name__ == '__main__':<N>    PongApp().run()<N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.properties import (<N>    NumericProperty, ReferenceListProperty, ObjectProperty<N>)<N>from kivy.vector import Vector<N>from kivy.clock import Clock<N><N><N>class PongPaddle(Widget):<N>    score = NumericProperty(0)<N><N>
    def bounce_ball(self, ball):<N>        if self.collide_widget(ball):<N>            vx, vy = ball.velocity<N>            offset = (ball.center_y - self.center_y) / (self.height / 2)<N>            bounced = Vector(-1 * vx, vy)<N>            vel = bounced * 1.1<N>            ball.velocity = vel.x, vel.y + offset<N><N>
<N>class PongBall(Widget):<N>    velocity_x = NumericProperty(0)<N>    velocity_y = NumericProperty(0)<N>    velocity = ReferenceListProperty(velocity_x, velocity_y)<N><N>    def move(self):<N>        self.pos = Vector(*self.velocity) + self.pos<N><N><N>class PongGame(Widget):<N>    ball = ObjectProperty(None)<N>    player1 = ObjectProperty(None)<N>    player2 = ObjectProperty(None)<N><N>
    def serve_ball(self, vel=(4, 0)):<N>        self.ball.center = self.center<N>        self.ball.velocity = vel<N><N>    def update(self, dt):<N>        self.ball.move()<N><N>        # bounce of paddles<N>        self.player1.bounce_ball(self.ball)<N>        self.player2.bounce_ball(self.ball)<N><N>
        # bounce ball off bottom or top<N>        if (self.ball.y < self.y) or (self.ball.top > self.top):<N>            self.ball.velocity_y *= -1<N><N>        # went of to a side to score point?<N>        if self.ball.x < self.x:<N>            self.player2.score += 1<N>            self.serve_ball(vel=(4, 0))<N>        if self.ball.x > self.width:<N>            self.player1.score += 1<N>            self.serve_ball(vel=(-4, 0))<N><N>
    def on_touch_move(self, touch):<N>        if touch.x < self.width / 3:<N>            self.player1.center_y = touch.y<N>        if touch.x > self.width - self.width / 3:<N>            self.player2.center_y = touch.y<N><N><N>class PongApp(App):<N>    def build(self):<N>        game = PongGame()<N>        game.serve_ball()<N>        Clock.schedule_interval(game.update, 1.0 / 60.0)<N>        return game<N><N>
'''<N>Camera Example<N>==============<N><N>This example demonstrates a simple use of the camera. It shows a window with<N>a buttoned labelled 'play' to turn the camera on and off. Note that<N>not finding a camera, perhaps because gstreamer is not installed, will<N>throw an exception during the kv language processing.<N><N>
'''<N>Compass example<N>===============<N><N>This example is a demonstration of Hardware class usage.<N>But it has severals drawbacks, like using only the magnetic sensor, and<N>extrapolating values to get the orientation. The compass is absolutely not<N>accurate.<N><N>
The right way would be to get the accelerometer + magnetic, and computer<N>everything according to the phone orientation. This is not the purpose of this<N>example right now.<N><N>You can compile it with::<N><N>    ./build.py --package org.test.compass --name compass \<N>        --private ~/code/kivy/examples/android/compass \<N>        --window --version 1.0 debug installd<N>'''<N><N>
<N>import kivy<N>kivy.require('1.7.0')<N><N>from jnius import autoclass<N>from math import floor<N>from kivy.app import App<N>from kivy.properties import NumericProperty<N>from kivy.clock import Clock<N>from kivy.vector import Vector<N>from kivy.animation import Animation<N><N>
Hardware = autoclass('org.renpy.android.Hardware')<N><N><N>class CompassApp(App):<N><N>    needle_angle = NumericProperty(0)<N><N>    def build(self):<N>        self._anim = None<N>        Hardware.magneticFieldSensorEnable(True)<N>        Clock.schedule_interval(self.update_compass, 1 / 10.)<N><N>
    def update_compass(self, *args):<N>        # read the magnetic sensor from the Hardware class<N>        (x, y, z) = Hardware.magneticFieldSensorReading()<N><N>        # calculate the angle<N>        needle_angle = Vector(x, y).angle((0, 1)) + 90.<N><N>
        # fix animation transition around the unit circle<N>        if (self.needle_angle % 360) - needle_angle > 180:<N>            needle_angle += 360<N>        elif (self.needle_angle % 360) - needle_angle < -180:<N>            needle_angle -= 360<N>        # add the number of revolutions to the result<N>        needle_angle += 360 * floor(self.needle_angle / 360.)<N><N>
        # animate the needle<N>        if self._anim:<N>            self._anim.stop(self)<N>        self._anim = Animation(needle_angle=needle_angle, d=.2, t='out_quad')<N>        self._anim.start(self)<N><N>    def on_pause(self):<N>        # when you are going on pause, don't forget to stop the sensor<N>        Hardware.magneticFieldSensorEnable(False)<N>        return True<N><N>
'''<N>Take picture<N>============<N><N>.. author:: Mathieu Virbel <mat@kivy.org><N><N>Little example to demonstrate how to start an Intent, and get the result.<N>When you use the Android.startActivityForResult(), the result will be<N>dispatched into onActivityResult. You can catch the event with the<N>android.activity API from python-for-android project.<N><N>
If you want to compile it, don't forget to add the CAMERA permission::<N><N>    ./build.py --name 'TakePicture' --package org.test.takepicture \<N>            --permission CAMERA --version 1 \<N>            --private ~/code/kivy/examples/android/takepicture \<N>            debug installd<N><N>
'''<N><N>__version__ = '0.1'<N><N>from kivy.app import App<N>from os.path import exists<N>from jnius import autoclass, cast<N>from android import activity, mActivity<N>from functools import partial<N>from kivy.clock import Clock<N>from kivy.uix.scatter import Scatter<N>from kivy.properties import StringProperty<N><N>
from PIL import Image<N><N>Intent = autoclass('android.content.Intent')<N>MediaStore = autoclass('android.provider.MediaStore')<N>Uri = autoclass('android.net.Uri')<N>Environment = autoclass('android.os.Environment')<N><N><N>class Picture(Scatter):<N>    source = StringProperty(None)<N><N>
<N>class TakePictureApp(App):<N>    def build(self):<N>        self.index = 0<N>        activity.bind(on_activity_result=self.on_activity_result)<N><N>    def get_filename(self):<N>        while True:<N>            self.index += 1<N>            fn = (Environment.getExternalStorageDirectory().getPath() +<N>                  '/takepicture{}.jpg'.format(self.index))<N>            if not exists(fn):<N>                return fn<N><N>
    def take_picture(self):<N>        intent = Intent(MediaStore.ACTION_IMAGE_CAPTURE)<N>        self.last_fn = self.get_filename()<N>        self.uri = Uri.parse('file://' + self.last_fn)<N>        self.uri = cast('android.os.Parcelable', self.uri)<N>        intent.putExtra(MediaStore.EXTRA_OUTPUT, self.uri)<N>        mActivity.startActivityForResult(intent, 0x123)<N><N>
    def on_activity_result(self, requestCode, resultCode, intent):<N>        if requestCode == 0x123:<N>            Clock.schedule_once(partial(self.add_picture, self.last_fn), 0)<N><N>    def add_picture(self, fn, *args):<N>        im = Image.open(fn)<N>        width, height = im.size<N>        im.thumbnail((width / 4, height / 4), Image.ANTIALIAS)<N>        im.save(fn, quality=95)<N>        self.root.add_widget(Picture(source=fn, center=self.root.center))<N><N>
'''<N>Tree shader<N>===========<N><N>This example is an experimentation to show how we can use shader for a tree<N>subset. Here, we made a ShaderTreeWidget, different than the ShaderWidget<N>in the plasma.py example.<N><N>The ShaderTree widget create a Frambuffer, render his children on it, and<N>render the Framebuffer with a specific Shader.<N>With this way, you can apply cool effect on your widgets :)<N><N>
'''<N><N>from kivy.clock import Clock<N>from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.core.window import Window  # side effects needed by Shader<N>from kivy.properties import StringProperty, ObjectProperty<N>from kivy.graphics import (RenderContext, Fbo, Color, ClearColor, ClearBuffers,<N>        Rectangle)<N><N>
import itertools<N><N><N>header = '''<N>$HEADER$<N><N>uniform vec2 resolution;<N>uniform float time;<N>'''<N><N># pulse (Danguafer/Silexars, 2010)<N>shader_pulse = header + '''<N>void main(void)<N>{<N>    vec2 halfres = resolution.xy/2.0;<N>    vec2 cPos = vec4(frag_modelview_mat * gl_FragCoord).xy;<N><N>
    cPos.x -= 0.5*halfres.x*sin(time/2.0)+0.3*halfres.x*cos(time)+halfres.x;<N>    cPos.y -= 0.4*halfres.y*sin(time/5.0)+0.3*halfres.y*cos(time)+halfres.y;<N>    float cLength = length(cPos);<N><N>    vec2 uv = tex_coord0+(cPos/cLength)*sin(cLength/30.0-time*10.0)/25.0;<N>    vec3 col = texture2D(texture0,uv).xyz*50.0/cLength;<N><N>
    gl_FragColor = vec4(col,1.0);<N>}<N>'''<N><N># post processing (by iq, 2009)<N>shader_postprocessing = header + '''<N>uniform vec2 uvsize;<N>uniform vec2 uvpos;<N>void main(void)<N>{<N>    vec2 q = tex_coord0 * vec2(1, -1);<N>    vec2 uv = 0.5 + (q-0.5);//*(0.9);// + 0.1*sin(0.2*time));<N><N>
    vec3 oricol = texture2D(texture0,vec2(q.x,1.0-q.y)).xyz;<N>    vec3 col;<N><N>    col.r = texture2D(texture0,vec2(uv.x+0.003,-uv.y)).x;<N>    col.g = texture2D(texture0,vec2(uv.x+0.000,-uv.y)).y;<N>    col.b = texture2D(texture0,vec2(uv.x-0.003,-uv.y)).z;<N><N>
    col = clamp(col*0.5+0.5*col*col*1.2,0.0,1.0);<N><N>    //col *= 0.5 + 0.5*16.0*uv.x*uv.y*(1.0-uv.x)*(1.0-uv.y);<N><N>    col *= vec3(0.8,1.0,0.7);<N><N>    col *= 0.9+0.1*sin(10.0*time+uv.y*1000.0);<N><N>    col *= 0.97+0.03*sin(110.0*time);<N><N>    float comp = smoothstep( 0.2, 0.7, sin(time) );<N>    //col = mix( col, oricol, clamp(-2.0+2.0*q.x+3.0*comp,0.0,1.0) );<N><N>
    gl_FragColor = vec4(col,1.0);<N>}<N>'''<N><N>shader_monochrome = header + '''<N>void main() {<N>    vec4 rgb = texture2D(texture0, tex_coord0);<N>    float c = (rgb.x + rgb.y + rgb.z) * 0.3333;<N>    gl_FragColor = vec4(c, c, c, 1.0);<N>}<N>'''<N><N><N>class ShaderWidget(FloatLayout):<N><N>
'''<N>Plasma Shader<N>=============<N><N>This shader example have been taken from<N>http://www.iquilezles.org/apps/shadertoy/ with some adaptation.<N><N>This might become a Kivy widget when experimentation will be done.<N>'''<N><N><N>from kivy.clock import Clock<N>from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.core.window import Window<N>from kivy.graphics import RenderContext<N>from kivy.properties import StringProperty<N><N>
'''<N>Rotated Shader<N>=============<N><N>This shader example is a modified version of plasma.py that shows how to<N>rotate areas of fragment shaders bounded by vertex_instructions.<N>'''<N>from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.factory import Factory<N>from kivy.graphics import RenderContext<N>from kivy.properties import StringProperty<N>from kivy.uix.widget import Widget<N><N>
# -*- coding: utf-8 -*-<N>'''<N>Container Example<N>==============<N><N>This example shows how to add a container to our screen.<N>A container is simply an empty place on the screen which<N>could be filled with any other content from a .kv file.<N>'''<N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.properties import ObjectProperty<N><N>
import kivy<N>kivy.require('1.8.0')<N><N><N>class RootWidget(BoxLayout):<N>    '''Create a controller that receives a custom widget from the kv lang file.<N>    Add an action to be called from a kv file.<N>    '''<N><N>    container = ObjectProperty(None)<N><N>
<N>class EzsApp(App):<N><N>    '''This is the app itself'''<N><N>    def build(self):<N>        '''This method loads the root.kv file automatically<N><N>        :rtype: none<N>        '''<N>        # loading the content of root.kv<N>        self.root = Builder.load_file('kv/root.kv')<N><N>
    def next_screen(self, screen):<N>        '''Clear container and load the given screen object from file in kv<N>        folder.<N><N>        :param screen: name of the screen object made from the loaded .kv file<N>        :type screen: str<N>        :rtype: none<N>    '''<N><N>
        filename = screen + '.kv'<N>        # unload the content of the .kv file<N>        # reason: it could have data from previous calls<N>        Builder.unload_file('kv/' + filename)<N>        # clear the container<N>        self.root.container.clear_widgets()<N>        # load the content of the .kv file<N>        screen = Builder.load_file('kv/' + filename)<N>        # add the content of the .kv file to the container<N>        self.root.container.add_widget(screen)<N><N>
'''<N>Widget animation<N>================<N><N>This example demonstrates creating and applying a multi-part animation to<N>a button widget. You should see a button labelled 'plop' that will move with<N>an animation when clicked.<N>'''<N><N>import kivy<N>kivy.require('1.0.7')<N><N>
import sys<N>from glob import glob<N>from os.path import join, dirname<N>from kivy.uix.scatter import Scatter<N>from kivy.uix.widget import Widget<N>from kivy.uix.label import Label<N>from kivy.app import App<N>from kivy.graphics.svg import Svg<N>from kivy.core.window import Window<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.lang import Builder<N><N>
import sys<N>from glob import glob<N>from os.path import join, dirname<N>from kivy.uix.scatter import Scatter<N>from kivy.app import App<N>from kivy.graphics.svg import Svg<N>from kivy.core.window import Window<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.lang import Builder<N><N>
Builder.load_string("""<N><SvgWidget>:<N>    do_rotation: False<N><FloatLayout>:<N>    canvas.before:<N>        Color:<N>            rgb: (1, 1, 1)<N>        Rectangle:<N>            pos: self.pos<N>            size: self.size<N>""")<N><N><N>class SvgWidget(Scatter):<N><N>
    def __init__(self, filename, **kwargs):<N>        super(SvgWidget, self).__init__(**kwargs)<N>        with self.canvas:<N>            svg = Svg(filename)<N>        self.size = svg.width, svg.height<N><N><N>class SvgApp(App):<N><N>    def build(self):<N>        self.root = FloatLayout()<N><N>
        filenames = sys.argv[1:]<N>        if not filenames:<N>            filenames = glob(join(dirname(__file__), '*.svg'))<N><N>        for filename in filenames:<N>            svg = SvgWidget(filename, size_hint=(None, None))<N>            self.root.add_widget(svg)<N>            svg.scale = 5.<N>            svg.center = Window.center<N><N>
from kivy.config import Config<N>Config.set('graphics', 'shaped', 1)<N><N>from kivy.resources import resource_find<N>default_shape = Config.get('kivy', 'window_shape')<N>alpha_shape = resource_find('data/logo/kivy-icon-512.png')<N><N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.core.window import Window<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.properties import (<N>    BooleanProperty,<N>    StringProperty,<N>    ListProperty,<N>)<N><N>
<N>Builder.load_string('''<N>#:import win kivy.core.window.Window<N><N><Root>:<N>    orientation: 'vertical'<N>    BoxLayout:<N>        Button:<N>            text: 'default_shape'<N>            on_release: app.shape_image = app.default_shape<N>        Button:<N>            text: 'alpha_shape'<N>            on_release: app.shape_image = app.alpha_shape<N><N>
from kivy.app import App<N>from kivy.uix.button import Button<N>from kivy.core.window import Window<N>from kivy.uix.boxlayout import BoxLayout<N><N><N>class DropFile(Button):<N>    def __init__(self, **kwargs):<N>        super(DropFile, self).__init__(**kwargs)<N><N>
        # get app instance to add function from widget<N>        app = App.get_running_app()<N><N>        # add function to the list<N>        app.drops.append(self.on_dropfile)<N><N>    def on_dropfile(self, widget, filename):<N>        # a function catching a dropped file<N>        # if it's dropped in the widget's area<N>        if self.collide_point(*Window.mouse_pos):<N>            # on_dropfile's filename is bytes (py3)<N>            self.text = filename.decode('utf-8')<N><N>
<N>class DropApp(App):<N>    def build(self):<N>        # set an empty list that will be later populated<N>        # with functions from widgets themselves<N>        self.drops = []<N><N>        # bind handling function to 'on_dropfile'<N>        Window.bind(on_dropfile=self.handledrops)<N><N>
# save an image into bytesio<N><N>from kivy.core.image import Image<N>from io import BytesIO<N><N>img = Image.load("data/logo/kivy-icon-512.png")<N><N>bio = BytesIO()<N>ret = img.save(bio, fmt="png")<N>print("len=", len(bio.read()))<N><N>bio = BytesIO()<N>ret = img.save(bio, fmt="jpg")<N>print("len=", len(bio.read()))<N>
from kivy.lang import Builder<N>from kivy.app import App<N>from kivy.network.urlrequest import UrlRequest<N>from kivy.properties import NumericProperty, StringProperty, DictProperty<N><N>import json<N><N><N>KV = '''<N>#:import json json<N>#:import C kivy.utils.get_color_from_hex<N><N>
BoxLayout:<N>    orientation: 'vertical'<N>    Label:<N>        text: 'see https://httpbin.org for more information'<N><N>    TextInput:<N>        id: ti<N>        hint_text: 'type url or select from dropdown'<N>        size_hint_y: None<N>        height: 48<N>        multiline: False<N>        foreground_color:<N>            (<N>            C('000000')<N>            if (self.text).startswith('http') else<N>            C('FF2222')<N>            )<N><N>
# -*- coding: utf-8 -*-<N><N>'''<N>on_textedit event sample.<N>'''<N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.lang import Builder<N>from kivy.properties import StringProperty<N>from kivy.core.text import LabelBase, DEFAULT_FONT<N>from kivy.uix.textinput import TextInput<N>from kivy.base import EventLoop<N><N>
<N>class TextInputIME(TextInput):<N>    testtext = StringProperty()<N><N>    def __init__(self, **kwargs):<N>        super(TextInputIME, self).__init__(**kwargs)<N>        EventLoop.window.bind(on_textedit=self._on_textedit)<N><N>    def _on_textedit(self, window, text):<N>        self.testtext = text<N><N>
<N>class MainWidget(Widget):<N>    text = StringProperty()<N><N>    def __init__(self, **kwargs):<N>        super(MainWidget, self).__init__(**kwargs)<N>        self.text = ''<N><N>    def confim(self):<N>        self.text = self.ids["text_box"].text<N><N>
    def changeFont(self):<N>        try:<N>            LabelBase.register(DEFAULT_FONT, self.ids["text_font"].text)<N>        except Exception:<N>            self.ids["text_font"].text = "can't load font."<N><N><N>class TextEditTestApp(App):<N>    def __init__(self, **kwargs):<N>        super(TextEditTestApp, self).__init__(**kwargs)<N><N>
# Joystick / Gamepad example<N># STOP_FIRE from https://wiki.libsdl.org/SDL_JoyAxisEvent<N><N>from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.uix.widget import Widget<N>from kivy.core.window import Window<N>from kivy.properties import ObjectProperty, ListProperty<N><N>
<N>class Listener(Widget):<N>    # fire / trigger axis<N>    FIRE = (2, 5)<N>    STOP_FIRE = -32767<N><N>    # min value for user to actually trigger axis<N>    OFFSET = 15000<N><N>    # current values + event instance<N>    VALUES = ListProperty([])<N>    HOLD = ObjectProperty(None)<N><N>
    def __init__(self, **kwargs):<N>        super(Listener, self).__init__(**kwargs)<N><N>        # get joystick events first<N>        Window.bind(on_joy_hat=self.on_joy_hat)<N>        Window.bind(on_joy_ball=self.on_joy_ball)<N>        Window.bind(on_joy_axis=self.on_joy_axis)<N>        Window.bind(on_joy_button_up=self.on_joy_button_up)<N>        Window.bind(on_joy_button_down=self.on_joy_button_down)<N><N>
    # show values in console<N>    def print_values(self, *args):<N>        print(self.VALUES)<N><N>    def joy_motion(self, event, id, axis, value):<N>        # HAT first, returns max values<N>        if isinstance(value, tuple):<N>            if not value[0] and not value[1]:<N>                Clock.unschedule(self.HOLD)<N>            else:<N>                self.VALUES = [event, id, axis, value]<N>                self.HOLD = Clock.schedule_interval(self.print_values, 0)<N>            return<N><N>
        # unschedule if at zero or at minimum (FIRE)<N>        if axis in self.FIRE and value < self.STOP_FIRE:<N>            Clock.unschedule(self.HOLD)<N>            return<N>        elif abs(value) < self.OFFSET or self.HOLD:<N>            Clock.unschedule(self.HOLD)<N><N>
        # schedule if over OFFSET (to prevent accidental event with low value)<N>        if (axis in self.FIRE and value > self.STOP_FIRE or<N>                axis not in self.FIRE and abs(value) >= self.OFFSET):<N>            self.VALUES = [event, id, axis, value]<N>            self.HOLD = Clock.schedule_interval(self.print_values, 0)<N><N>
    # replace window instance with identifier<N>    def on_joy_axis(self, win, stickid, axisid, value):<N>        self.joy_motion('axis', stickid, axisid, value)<N><N>    def on_joy_ball(self, win, stickid, ballid, xvalue, yvalue):<N>        self.joy_motion('ball', stickid, ballid, (xvalue, yvalue))<N><N>
    def on_joy_hat(self, win, stickid, hatid, value):<N>        self.joy_motion('hat', stickid, hatid, value)<N><N>    def on_joy_button_down(self, win, stickid, buttonid):<N>        print('button_down', stickid, buttonid)<N><N>    def on_joy_button_up(self, win, stickid, buttonid):<N>        print('button_up', stickid, buttonid)<N><N>
# This is a simple demo for advanced collisions and mesh creation from a set<N># of points. Its purpose is only to give an idea on how to make complex stuff.<N><N># Check garden.collider for better performance.<N><N>from math import cos, sin, pi, sqrt<N>from random import random, randint<N>from itertools import combinations<N><N>
from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.uix.label import Label<N>from kivy.uix.widget import Widget<N>from kivy.core.window import Window<N>from kivy.graphics import Color, Mesh, Point<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.properties import (<N>    ListProperty,<N>    StringProperty,<N>    ObjectProperty,<N>    NumericProperty<N>)<N><N>
"""<N>Config Example<N>==============<N><N>This file contains a simple example of how the use the Kivy settings classes in<N>a real app. It allows the user to change the caption and font_size of the label<N>and stores these changes.<N><N>When the user next runs the programs, their changes are restored.<N><N>
"""<N><N>from kivy.app import App<N>from kivy.uix.settings import SettingsWithTabbedPanel<N>from kivy.logger import Logger<N>from kivy.lang import Builder<N><N># We first define our GUI<N>kv = '''<N>BoxLayout:<N>    orientation: 'vertical'<N>    Button:<N>        text: 'Configure app (or press F1)'<N>        on_release: app.open_settings()<N>    Label:<N>        id: label<N>        text: 'Hello'<N>'''<N><N>
# This JSON defines entries we want to appear in our App configuration screen<N>json = '''<N>[<N>    {<N>        "type": "string",<N>        "title": "Label caption",<N>        "desc": "Choose the text that appears in the label",<N>        "section": "My Label",<N>        "key": "text"<N>    },<N>    {<N>        "type": "numeric",<N>        "title": "Label font size",<N>        "desc": "Choose the font size the label",<N>        "section": "My Label",<N>        "key": "font_size"<N>    }<N>]<N>'''<N><N>
<N>class MyApp(App):<N>    def build(self):<N>        """<N>        Build and return the root widget.<N>        """<N>        # The line below is optional. You could leave it out or use one of the<N>        # standard options, such as SettingsWithSidebar, SettingsWithSpinner<N>        # etc.<N>        self.settings_cls = MySettingsWithTabbedPanel<N><N>
        # We apply the saved configuration settings or the defaults<N>        root = Builder.load_string(kv)<N>        label = root.ids.label<N>        label.text = self.config.get('My Label', 'text')<N>        label.font_size = float(self.config.get('My Label', 'font_size'))<N>        return root<N><N>
'''<N>Example usage of the effectwidget.<N><N>Currently highly experimental.<N>'''<N><N>from kivy.app import App<N>from kivy.uix.effectwidget import EffectWidget<N>from kivy.uix.spinner import Spinner<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.lang import Builder<N>from kivy.properties import ObjectProperty<N><N>
from kivy.uix.effectwidget import (MonochromeEffect,<N>                                   InvertEffect,<N>                                   ChannelMixEffect,<N>                                   ScanlinesEffect,<N>                                   FXAAEffect,<N>                                   PixelateEffect,<N>                                   HorizontalBlurEffect,<N>                                   VerticalBlurEffect)<N><N>
from kivy.uix.scatter import Scatter<N>from kivy.app import App<N><N><N>class MyScatter(Scatter):<N>    pass<N><N><N>class ScatterApp(App):<N>    def build(self):<N>        s = MyScatter(size=(400, 400), size_hint=(None, None))<N>        s.top = 500<N>        return s<N><N><N>ScatterApp().run()<N>
from kivy.uix.accordion import Accordion, AccordionItem<N>from kivy.uix.label import Label<N>from kivy.app import App<N><N><N>class AccordionApp(App):<N>    def build(self):<N>        root = Accordion()<N>        for x in range(5):<N>            item = AccordionItem(title='Title %d' % x)<N>            item.add_widget(Label(text='Very big content\n' * 10))<N>            root.add_widget(item)<N>        return root<N><N><N>if __name__ == '__main__':<N>    AccordionApp().run()<N>
import kivy<N>kivy.require('1.2.0')<N><N>from sys import argv<N>from os.path import dirname, join<N>from kivy.app import App<N>from kivy.uix.videoplayer import VideoPlayer<N><N># check what formats are supported for your targeted devices<N># for example try h264 video and acc audo for android using an mp4<N># container<N><N>
<N>class VideoPlayerApp(App):<N><N>    def build(self):<N>        if len(argv) > 1:<N>            filename = argv[1]<N>        else:<N>            curdir = dirname(__file__)<N>            filename = join(curdir, 'cityCC0.mpg')<N>        return VideoPlayer(source=filename, state='play')<N><N>
'''<N>Asynchronous image loading<N>==========================<N><N>Test of the widget AsyncImage.<N>We are just putting it in a CenteredAsyncImage for being able to center the<N>image on screen without doing upscale like the original AsyncImage.<N>'''<N><N>
from kivy.app import App<N>from kivy.uix.image import AsyncImage<N>from kivy.lang import Builder<N><N><N>Builder.load_string('''<N><CenteredAsyncImage>:<N>    size_hint: 0.8, 0.8<N>    pos_hint: {'center_x': 0.5, 'center_y': 0.5}<N>    mipmap: True<N>''')<N><N>
<N>class CenteredAsyncImage(AsyncImage):<N>    pass<N><N><N>class TestAsyncApp(App):<N>    def build(self):<N>        url = ('https://upload.wikimedia.org/wikipedia/commons/thumb/8/89/'<N>               'STS-116_spacewalk_1.jpg/1024px-STS-116_spacewalk_1.jpg')<N>        return CenteredAsyncImage(source=url)<N><N>
from kivy.uix.spinner import Spinner<N>from kivy.base import runTouchApp<N><N>spinner = Spinner(<N>    text='Home',<N>    values=('Home', 'Work', 'Other', 'Custom'),<N>    size_hint=(None, None), size=(100, 44),<N>    pos_hint={'center_x': .5, 'center_y': .5})<N><N><N>def show_selected_value(spinner, text):<N>    print('The spinner', spinner, 'has text', text)<N><N><N>spinner.bind(text=show_selected_value)<N><N>runTouchApp(spinner)<N>
'''<N>Carousel example with button inside.<N>This is a tiny test for testing the scroll distance/timeout<N>And ensure the down/up are dispatched if no gesture is done.<N>'''<N>from kivy.uix.carousel import Carousel<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.app import App<N>from kivy.lang import Builder<N><N>
from kivy.app import App<N>from kivy.lang import Builder<N><N><N>kv = '''<N>BoxLayout:<N>    orientation: 'vertical'<N><N>    Camera:<N>        id: camera<N>        resolution: 399, 299<N><N>    BoxLayout:<N>        orientation: 'horizontal'<N>        size_hint_y: None<N>        height: '48dp'<N>        Button:<N>            text: 'Start'<N>            on_release: camera.play = True<N><N>
        Button:<N>            text: 'Stop'<N>            on_release: camera.play = False<N>'''<N><N><N>class CameraApp(App):<N>    def build(self):<N>        return Builder.load_string(kv)<N><N><N>if __name__ == '__main__':<N>    CameraApp().run()<N><N><N>
from kivy.base import runTouchApp<N>from kivy.lang import Builder<N><N>kv = '''<N>PageLayout:<N>    BoxLayout:<N>        canvas:<N>            Color:<N>                rgba: 216/255., 195/255., 88/255., 1<N>            Rectangle:<N>                pos: self.pos<N>                size: self.size<N><N>
        orientation: 'vertical'<N>        Label:<N>            size_hint_y: None<N>            height: 1.5 * self.texture_size[1]<N>            text: 'page 1'<N><N>        Button:<N>            text: 'test'<N>            on_press: print("test")<N><N>    BoxLayout:<N>        orientation: 'vertical'<N>        canvas:<N>            Color:<N>                rgba: 109/255., 8/255., 57/255., 1<N>            Rectangle:<N>                pos: self.pos<N>                size: self.size<N><N>
        Label:<N>            text: 'page 2'<N><N>        AsyncImage:<N>            source: 'http://kivy.org/logos/kivy-logo-black-64.png'<N><N>    GridLayout:<N>        canvas:<N>            Color:<N>                rgba: 37/255., 39/255., 30/255., 1<N>            Rectangle:<N>                pos: self.pos<N>                size: self.size<N><N>
        cols: 2<N>        Label:<N>            text: 'page 3'<N>        AsyncImage:<N>            source: 'http://kivy.org/slides/kivyandroid-thumb.jpg'<N>        Button:<N>            text: 'test'<N>            on_press: print("test last page")<N>        AsyncImage:<N>            source: 'http://kivy.org/slides/kivypictures-thumb.jpg'<N>        Widget<N>        AsyncImage:<N>            source: 'http://kivy.org/slides/particlepanda-thumb.jpg'<N>'''<N><N>
'''<N>TabbedPanel<N>============<N><N>Test of the widget TabbedPanel.<N>'''<N><N>from kivy.app import App<N>from kivy.uix.tabbedpanel import TabbedPanel<N>from kivy.lang import Builder<N><N>Builder.load_string("""<N><N><Test>:<N>    size_hint: .5, .5<N>    pos_hint: {'center_x': .5, 'center_y': .5}<N>    do_default_tab: False<N><N>
from kivy.app import App<N>from kivy.lang import Builder<N><N>root = Builder.load_string('''<N>Label:<N>    text:<N>        ('[b]Hello[/b] [color=ff0099]World[/color]\\n'<N>        '[color=ff0099]Hello[/color] [b]World[/b]\\n'<N>        '[b]Hello[/b] [color=ff0099]World[/color]')<N>    markup: True<N>    font_size: '64pt'<N>''')<N><N><N>class LabelWithMarkup(App):<N>    def build(self):<N>        return root<N><N><N>if __name__ == '__main__':<N>    LabelWithMarkup().run()<N>
<N>"""<N>Label textsize<N>============<N><N>This example shows how to size a Label to its content (texture_size) and how<N>setting text_size controls text wrapping.<N>"""<N>from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.lang import Builder<N>from kivy.properties import StringProperty, NumericProperty, BooleanProperty<N><N>
from kivy.uix.gridlayout import GridLayout<N>from kivy.app import App<N>from kivy.lang import Builder<N><N>Builder.load_string('''<N><Demo>:<N>    cols: 1<N><N>    BoxLayout:<N>        orientation: 'vertical'<N>        Button:<N>            size_hint_x: 0.4<N>            pos_hint: {'x': 0}<N>            text: 'pos_hint: x=0'<N><N>
        Button:<N>            size_hint_x: 0.2<N>            pos_hint: {'center_x': 0.5}<N>            text: 'pos_hint: center_x=0.5'<N><N>        Button:<N>            size_hint_x: 0.4<N>            pos_hint: {'right': 1}<N>            text: 'pos_hint: right=1'<N><N>
    BoxLayout:<N>        Button:<N>            size_hint_y: 0.4<N>            pos_hint: {'y': 0}<N>            text: 'pos_hint: y=0'<N><N>        Button:<N>            size_hint_y: 0.2<N>            pos_hint: {'center_y': .5}<N>            text: 'pos_hint: center_y=0.5'<N><N>
        Button:<N>            size_hint_y: 0.4<N>            pos_hint: {'top': 1}<N>            text: 'pos_hint: top=1'<N>''')<N><N><N>class Demo(GridLayout):<N>    pass<N><N><N>class DemoApp(App):<N>    def build(self):<N>        return Demo()<N><N><N>if __name__ == '__main__':<N>    DemoApp().run()<N><N><N>
from kivy.app import App<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.label import Label<N>from kivy.uix.behaviors import FocusBehavior<N>from kivy.graphics import Color, Rectangle<N><N><N>class FocusWithColor(FocusBehavior):<N>    ''' Class that when focused, changes its background color to red.<N>    '''<N><N>
    _color = None<N>    _rect = None<N><N>    def __init__(self, **kwargs):<N>        super(FocusWithColor, self).__init__(**kwargs)<N>        with self.canvas:<N>            self._color = Color(1, 1, 1, .2)<N>            self._rect = Rectangle(size=self.size, pos=self.pos)<N>            self.bind(size=self._update_rect, pos=self._update_rect)<N><N>
    def _update_rect(self, instance, value):<N>        self._rect.pos = instance.pos<N>        self._rect.size = instance.size<N><N>    def on_focused(self, instance, value, *largs):<N>        self._color.rgba = [1, 0, 0, .2] if value else [1, 1, 1, .2]<N><N>
from kivy.app import App<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.scatter import Scatter<N>from kivy.uix.popup import Popup<N>from kivy.properties import ObjectProperty, StringProperty<N>from kivy.graphics import Color, Point, GraphicException<N><N>
# Dynamic kv classes<N><N>from kivy.lang import Builder<N>from kivy.base import runTouchApp<N><N>root = Builder.load_string('''<N><ImageButton@Button>:<N>    source: None<N>    Image:<N>        source: root.source<N>        center: root.center<N><N>ImageButton:<N>    source: 'kivy/data/logo/kivy-icon-512.png'<N>''')<N><N><N>runTouchApp(root)<N>
'''<N>Image mipmap<N>============<N><N>Difference between a mipmapped image and no mipmap image.<N>The lower image is normal, and the top image is mipmapped.<N>'''<N><N>import kivy<N>kivy.require('1.0.7')<N><N>from kivy.app import App<N>from kivy.uix.scatter import ScatterPlane<N>from kivy.uix.image import Image<N>from os.path import join<N><N>
<N>class LabelMipmapTest(App):<N>    def build(self):<N>        s = ScatterPlane(scale=.5)<N>        filename = join(kivy.kivy_data_dir, 'logo', 'kivy-icon-256.png')<N>        l1 = Image(source=filename, pos=(400, 100), size=(256, 256))<N>        l2 = Image(source=filename, pos=(400, 356), size=(256, 256),<N>                   mipmap=True)<N>        s.add_widget(l1)<N>        s.add_widget(l2)<N>        return s<N><N>
'''<N>TabbedPanel<N>============<N><N>Test of the widget TabbedPanel showing all capabilities.<N>'''<N><N>from kivy.app import App<N>from kivy.animation import Animation<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.uix.tabbedpanel import TabbedPanel, TabbedPanelHeader<N>from kivy.factory import Factory<N><N>
<N>class StandingHeader(TabbedPanelHeader):<N>    pass<N><N><N>class CloseableHeader(TabbedPanelHeader):<N>    pass<N><N><N>Factory.register('StandingHeader', cls=StandingHeader)<N>Factory.register('CloseableHeader', cls=CloseableHeader)<N><N>from kivy.lang import Builder<N><N>
<N>'''<N>Label textsize<N>============<N><N>This example shows how the textsize and line_height property are used<N>to format label widget<N>'''<N><N>import kivy<N>kivy.require('1.0.7')<N><N>from kivy.app import App<N>from kivy.uix.label import Label<N><N>
'''<N>FBO example<N>===========<N><N>This is an example of how to use FBO (Frame Buffer Object) to speedup graphics.<N>An Fbo is like a texture that you can draw on it.<N><N>By default, all the children are added in the canvas of the parent.<N>When you are displaying thousand of widget, you'll do thousands of graphics<N>instructions each frame.<N>The idea is to do this drawing only one time in a Fbo, and then, draw the Fbo<N>every frame instead of all children's graphics instructions.<N><N>
We created a FboFloatLayout that create his canvas, and a Fbo.<N>After the Fbo is created, we are adding Color and Rectangle instruction to<N>display the texture of the Fbo itself.<N>The overload of on_pos/on_size are here to update size of Fbo if needed, and<N>adapt the position/size of the rectangle too.<N><N>
Then, when a child is added or removed, we are redirecting addition/removal of<N>graphics instruction to our Fbo. This is why add_widget/remove_widget are<N>overloaded too.<N><N>.. note::<N><N>    This solution can be helpful but not ideal. Multisampling are not available<N>    in Framebuffer. We will work to add the support of it if the hardware is<N>    capable of, but it could be not the same.<N><N>
'''<N><N><N># needed to create Fbo, must be resolved in future kivy version<N>from kivy.core.window import Window<N><N>from kivy.graphics import Color, Rectangle, Canvas<N>from kivy.graphics.fbo import Fbo<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.properties import ObjectProperty<N><N>
<N>class FboFloatLayout(FloatLayout):<N><N>    texture = ObjectProperty(None, allownone=True)<N><N>    def __init__(self, **kwargs):<N>        self.canvas = Canvas()<N>        with self.canvas:<N>            self.fbo = Fbo(size=self.size)<N>            Color(1, 1, 1)<N>            self.fbo_rect = Rectangle()<N><N>
        # wait that all the instructions are in the canvas to set texture<N>        self.texture = self.fbo.texture<N>        super(FboFloatLayout, self).__init__(**kwargs)<N><N>    def add_widget(self, *largs):<N>        # trick to attach graphics instruction to fbo instead of canvas<N>        canvas = self.canvas<N>        self.canvas = self.fbo<N>        ret = super(FboFloatLayout, self).add_widget(*largs)<N>        self.canvas = canvas<N>        return ret<N><N>
    def remove_widget(self, *largs):<N>        canvas = self.canvas<N>        self.canvas = self.fbo<N>        super(FboFloatLayout, self).remove_widget(*largs)<N>        self.canvas = canvas<N><N>    def on_size(self, instance, value):<N>        self.fbo.size = value<N>        self.texture = self.fbo.texture<N>        self.fbo_rect.size = value<N><N>
    def on_pos(self, instance, value):<N>        self.fbo_rect.pos = value<N><N>    def on_texture(self, instance, value):<N>        self.fbo_rect.texture = value<N><N><N>if __name__ == '__main__':<N>    from kivy.uix.button import Button<N>    from kivy.app import App<N><N>
from kivy.app import App<N>from kivy.uix.label import Label<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.properties import ObjectProperty<N><N><N>class BoundedLabel(Label):<N>    pass<N><N><N>class Selector(FloatLayout):<N>    app = ObjectProperty(None)<N>    grid = ObjectProperty(None)<N><N>
'''<N>QuickReference for Rst<N>======================<N><N>This is a markup example: [b]Hello[/b] [i]world[/i]<N>And if i really want to write my code: &amp;bl; Hello world &amp;br;<N><N>And video widget<N>----------------<N><N>.. video:: cityCC0.mpg<N><N>
<N>Inline Markup<N>-------------<N><N>- *emphasis*<N>- **strong emphasis**<N>- `interpreted text`<N>- ``inline literal``<N>- reference_<N>- `phrase reference`_<N>- anonymous__<N>- _`inline internal target`<N><N>.. _top:<N><N>Internal crossreferences, like example_, or bottom_.<N><N>
Image<N>-----<N><N>Woot!<N><N>What about a little image ?<N><N>.. image:: kivy/data/logo/kivy-icon-256.png<N><N>Grid<N>----<N><N>+------------+------------+-----------+<N>| Header 1   | Header 2   | Header 3  |<N>+============+============+===========+<N>| body row 1 | column 2   | column 3  |<N>+------------+------------+-----------+<N>| body row 2 | column 2   | column 3  |<N>+------------+------------+-----------+<N>| body row 3 | column 2   | column 3  |<N>+------------+------------+-----------+<N><N>
Term list<N>---------<N><N>:Authors:<N>    Tony J. (Tibs) Ibbs,<N>    David Goodger<N>    (and sundry other good-natured folks)<N><N>.. _example:<N><N>:Version: 1.0 of 2001/08/08<N>:Dedication: To my father.<N><N>Definition list<N>---------------<N><N>what<N>  Definition lists associate a term with a definition.<N><N>
how<N>  The term is a one-line phrase, and the definition is one or more paragraphs<N>  or body elements, indented relative to the term. Blank lines are not allowed<N>  between term and definition.<N><N><N>Block quotes<N>------------<N><N>Block quotes are just:<N><N>
    Indented paragraphs,<N><N>        and they may nest.<N><N>Admonitions<N>-----------<N><N>.. warning::<N><N>    This is just a Test.<N><N>.. note::<N><N>    And this is just a note. Let's test some literal::<N><N>        $ echo 'Hello world'<N>        Hello world<N><N>
Ordered list<N>------------<N><N>#. My item number one<N>#. My item number two with some more content<N>   and it's continuing on the second line?<N>#. My third item::<N><N>    Oh wait, we can put code!<N><N>#. My four item::<N><N>    No way.<N><N>.. _bottom:<N><N>
'''<N>This example demonstrates creating and usind an AdvancedEffectBase. In<N>this case, we use it to efficiently pass the touch coordinates into the shader.<N>'''<N><N>from kivy.base import runTouchApp<N>from kivy.properties import ListProperty<N>from kivy.lang import Builder<N>from kivy.uix.effectwidget import EffectWidget, AdvancedEffectBase<N><N>
<N>effect_string = '''<N>uniform vec2 touch;<N><N>vec4 effect(vec4 color, sampler2D texture, vec2 tex_coords, vec2 coords)<N>{<N>    vec2 distance = 0.025*(coords - touch);<N>    float dist_mag = (distance.x*distance.x + distance.y*distance.y);<N>    vec3 multiplier = vec3(abs(sin(dist_mag - time)));<N>    return vec4(multiplier * color.xyz, 1.0);<N>}<N>'''<N><N>
<N>class TouchEffect(AdvancedEffectBase):<N>    touch = ListProperty([0.0, 0.0])<N><N>    def __init__(self, *args, **kwargs):<N>        super(TouchEffect, self).__init__(*args, **kwargs)<N>        self.glsl = effect_string<N><N>        self.uniforms = {'touch': [0.0, 0.0]}<N><N>
    def on_touch(self, *args, **kwargs):<N>        self.uniforms['touch'] = [float(i) for i in self.touch]<N><N><N>class TouchWidget(EffectWidget):<N>    def __init__(self, *args, **kwargs):<N>        super(TouchWidget, self).__init__(*args, **kwargs)<N>        self.effect = TouchEffect()<N>        self.effects = [self.effect]<N><N>
    def on_touch_down(self, touch):<N>        super(TouchWidget, self).on_touch_down(touch)<N>        self.on_touch_move(touch)<N><N>    def on_touch_move(self, touch):<N>        self.effect.touch = touch.pos<N><N><N>root = Builder.load_string('''<N>TouchWidget:<N>    Button:<N>        text: 'Some text!'<N>    Image:<N>        source: 'data/logo/kivy-icon-512.png'<N>        allow_stretch: True<N>        keep_ratio: False<N>''')<N><N>
import kivy<N>kivy.require('1.0.8')<N><N>from kivy.app import App<N>from kivy.uix.button import Button<N>from kivy.uix.scrollview import ScrollView<N>from kivy.uix.gridlayout import GridLayout<N><N><N>class ScrollViewApp(App):<N><N>    def build(self):<N><N>
'''<N>Custom shape & collide widget<N>=============================<N><N>This is a Triangle widget with a triangle shape based on 3 points (p1, p2, p3),<N>plus a custom collision function.<N><N>The p1, p2, p3 are automatically calculated from the position and the size of<N>the Widget bounding box. We are using them to draw the triangle shape.<N>(Please note in the kv the special case for Scatter.)<N><N>
Then we need to setup a new collision function to collide only on the triangle.<N>We are using a external method that will check if a point is inside a polygon<N>(we consider our triangle as a polygon).<N>'''<N><N><N>import kivy<N>kivy.require('1.0.8')<N><N>
from kivy.uix.scatter import Scatter<N>from kivy.properties import ListProperty<N>from kivy.lang import Builder<N><N><N>Builder.load_string('''<N><Triangle>:<N>    # example for doing a triangle<N>    # this will automatically recalculate pX from pos/size<N>    p1: 0, 0<N>    p2: self.width, 0<N>    p3: self.width / 2, self.height<N><N>
    # If you use a Widget instead of Scatter as base class, you need that:<N>    #p1: self.pos<N>    #p2: self.right, self.y<N>    #p3: self.center_x, self.top<N><N>    # draw something<N>    canvas:<N>        Color:<N>            rgb: 1, 0, 0<N>        Triangle:<N>            points: self.p1 + self.p2 + self.p3<N>''')<N><N>
'''<N>Example to show a Popup usage with the content from kv lang.<N>'''<N>from kivy.uix.popup import Popup<N>from kivy.uix.button import Button<N>from kivy.app import App<N>from kivy.lang import Builder<N><N>Builder.load_string('''<N><CustomPopup>:<N>    size_hint: .5, .5<N>    auto_dismiss: False<N>    title: 'Hello world'<N>    Button:<N>        text: 'Click me to dismiss'<N>        on_press: root.dismiss()<N><N>
''')<N><N><N>class CustomPopup(Popup):<N>    pass<N><N><N>class TestApp(App):<N>    def build(self):<N>        b = Button(on_press=self.show_popup, text="Show Popup")<N>        return b<N><N>    def show_popup(self, b):<N>        p = CustomPopup()<N>        p.open()<N><N>
from kivy.uix.gridlayout import GridLayout<N>from kivy.uix.button import Button<N>from kivy.uix.behaviors import CompoundSelectionBehavior<N>from kivy.uix.behaviors import FocusBehavior<N>from kivy.app import runTouchApp<N><N><N>class SelectableGrid(FocusBehavior, CompoundSelectionBehavior, GridLayout):<N><N>
    def __init__(self, **kwargs):<N>        super(SelectableGrid, self).__init__(**kwargs)<N><N>        def print_selection(*l):<N>            print('selected: ', [x.text for x in self.selected_nodes])<N>        self.bind(selected_nodes=print_selection)<N><N>
    def keyboard_on_key_down(self, window, keycode, text, modifiers):<N>        if super(SelectableGrid, self).keyboard_on_key_down(<N>                window, keycode, text, modifiers):<N>            return True<N>        if self.select_with_key_down(window, keycode, text, modifiers):<N>            return True<N>        return False<N><N>
    def keyboard_on_key_up(self, window, keycode):<N>        if super(SelectableGrid, self).keyboard_on_key_up(window, keycode):<N>            return True<N>        if self.select_with_key_up(window, keycode):<N>            return True<N>        return False<N><N>
    def goto_node(self, key, last_node, last_node_idx):<N>        ''' This function is used to go to the node by typing the number<N>        of the text of the button.<N>        '''<N>        node, idx = super(SelectableGrid, self).goto_node(key, last_node,<N>                                                          last_node_idx)<N>        if node != last_node:<N>            return node, idx<N><N>
from kivy.app import App<N>from kivy.uix.button import Button<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.label import Label<N>from kivy.uix.popup import Popup<N>from kivy.uix.settings import (SettingsWithSidebar,<N>                               SettingsWithSpinner,<N>                               SettingsWithTabbedPanel)<N>from kivy.properties import OptionProperty, ObjectProperty<N><N>
<N>class SettingsApp(App):<N><N>    display_type = OptionProperty('normal', options=['normal', 'popup'])<N><N>    settings_popup = ObjectProperty(None, allownone=True)<N><N>    def build(self):<N><N>        paneltype = Label(text='What kind of settings panel to use?')<N><N>
        sidebar_button = Button(text='Sidebar')<N>        sidebar_button.bind(on_press=lambda j: self.set_settings_cls(<N>            SettingsWithSidebar))<N>        spinner_button = Button(text='Spinner')<N>        spinner_button.bind(on_press=lambda j: self.set_settings_cls(<N>            SettingsWithSpinner))<N>        tabbed_button = Button(text='TabbedPanel')<N>        tabbed_button.bind(on_press=lambda j: self.set_settings_cls(<N>            SettingsWithTabbedPanel))<N><N>
# -*- coding: utf-8 -*-<N><N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.properties import StringProperty, ObjectProperty<N>from kivy.core.text import Label as CoreLabel<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.uix.spinner import SpinnerOption<N>from kivy.uix.popup import Popup<N>import os<N><N>
'''<N>Label mipmap<N>============<N><N>This show how to create a mipmapped label, and the visual difference between a<N>non mipmapped and mipmapped label.<N>'''<N><N>import kivy<N>kivy.require('1.0.7')<N><N>from kivy.app import App<N>from kivy.uix.scatter import ScatterPlane<N>from kivy.uix.label import Label<N><N>
<N>class LabelMipmapTest(App):<N>    def build(self):<N>        s = ScatterPlane(scale=.5)<N>        l1 = Label(text='Kivy rulz', font_size=98, pos=(400, 100), mipmap=True)<N>        l2 = Label(text='Kivy rulz', font_size=98, pos=(400, 328))<N>        s.add_widget(l1)<N>        s.add_widget(l2)<N>        return s<N><N>
from kivy.app import App<N>from kivy.extras.highlight import KivyLexer<N>from kivy.uix.spinner import Spinner, SpinnerOption<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.codeinput import CodeInput<N>from kivy.uix.behaviors import EmacsBehavior<N>from kivy.uix.popup import Popup<N>from kivy.properties import ListProperty<N>from kivy.core.window import Window<N>from kivy.core.text import LabelBase<N>from pygments import lexers<N>import codecs<N>import os<N><N>
example_text = '''<N>---------------------Python----------------------------------<N>import kivy<N>kivy.require('1.0.6') # replace with your current kivy version !<N>from kivy.app import App<N>from kivy.uix.button import Button<N><N>class MyApp(App):<N>    def build(self):<N>        return Button(text='Hello World')<N><N>
if __name__ == '__main__':<N>    MyApp().run()<N>----------------------Java-----------------------------------<N><N>public static byte toUnsignedByte(int intVal) {<N>    byte byteVal;<N>    return (byte)(intVal & 0xFF);<N>}<N>---------------------kv lang---------------------------------<N>#:kivy 1.0<N><N>
<YourWidget>:<N>    canvas:<N>        Color:<N>            rgb: .5, .5, .5<N>        Rectangle:<N>            pos: self.pos<N>            size: self.size<N>---------------------HTML------------------------------------<N><!-- Place this tag where you want the +1 button to render. --><N><div class="g-plusone" data-annotation="inline" data-width="300"></div><N><N>
from kivy.app import App<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.lang import Builder<N><N>Builder.load_string("""<N>#:import hex kivy.utils.get_color_from_hex<N><N><Root>:<N>    cols: 2<N>    canvas:<N>        Color:<N>            rgba: 1, 1, 1, 1<N>        Rectangle:<N>            pos: self.pos<N>            size: self.size<N><N>
import kivy<N>kivy.require('1.0.8')<N><N>from kivy.app import App<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.uix.gridlayout import GridLayout<N>from uix.custom_button import AnimatedButton<N>from kivy.uix.scatter import Scatter<N>from kivy.properties import ObjectProperty<N><N>
<N>class gifScatter(Scatter):<N>    def __init__(self, **kwargs):<N>        super(gifScatter, self).__init__()<N><N><N>class zipScatter(Scatter):<N>    def __init__(self, **kwargs):<N>        super(zipScatter, self).__init__()<N><N><N>class jpgScatter(Scatter):<N>    def __init__(self, **kwargs):<N>        super(jpgScatter, self).__init__()<N><N>
'''<N>UIX<N>===<N><N>The `uix` contains all the class for creating and arranging Custom Widgets.<N>A widget is an element of a graphical user interface.<N>'''<N>
<N>__all__ = ('AnimatedButton')<N><N>from kivy.factory import Factory<N>from kivy.uix.label import Label<N>from kivy.uix.image import Image<N>from kivy.properties import StringProperty, OptionProperty, \<N>                            ObjectProperty, BooleanProperty<N><N>
'''How to use Animation with RecycleView items?<N><N>In case you really want to use the Animation class with RecycleView, you'll<N>likely encounter an issue, as widgets are moved around, they are used to<N>represent different items, so an animation on a specific item is going to<N>affect others, and this will lead to really confusing results.<N><N>
This example works around that by creating a "proxy" widget for the animation,<N>and, by putting it in the data, allowing the displayed widget to mimic the<N>animation. As the item always refers to its proxy, whichever widget is used to<N>display the item will keep in sync with the animation.<N><N>
'''<N>from copy import copy<N><N>from kivy.app import App<N>from kivy.clock import triggered<N>from kivy.lang import Builder<N>from kivy.uix.widget import Widget<N>from kivy.animation import Animation<N>from kivy.uix.button import Button<N>from kivy.properties import (<N>    ObjectProperty, ListProperty<N>)<N><N>
<N>KV = '''<N><Item>:<N>    index: None<N>    animation_proxy: None<N>    on_release: app.animate_item(self.index)<N><N><N>RecycleView:<N>    data: app.data<N>    viewclass: 'Item'<N>    RecycleBoxLayout:<N>        orientation: 'vertical'<N>        size_hint: 1, None<N>        height: self.minimum_height<N>        default_size_hint: 1, None<N>        default_size: 0, dp(40)<N>'''<N><N>
<N>class Item(Button):<N>    animation_proxy = ObjectProperty(allownone=True)<N>    _animation_proxy = None<N><N>    def update_opacity(self, proxy, opacity):<N>        # sync one animated property to the value in the proxy<N>        self.opacity = opacity<N><N>
    def on_animation_proxy(self, *args):<N>        """When we create an animation proxy for an item, we need to bind to<N>        the animated property to update our own.<N>        """<N>        if self._animation_proxy:<N>            self._animation_proxy.unbind(opacity=self.update_opacity)<N><N>
"""<N>A constantly appending log, using recycleview.<N>- use variable size widgets using the key_size property to cache texture_size<N>- keeps current position in scroll when new data is happened, unless the view<N>  is at the very bottom, in which case it follows the log<N>- works well with mouse scrolling, but less nicely when using swipes,<N>  improvements welcome.<N>"""<N><N>
from random import sample<N>from string import printable<N>from time import asctime<N><N>from kivy.app import App<N>from kivy.uix.recycleview import RecycleView<N>from kivy.lang import Builder<N>from kivy.properties import NumericProperty, ListProperty<N>from kivy.clock import Clock<N><N>
<N>KV = """<N>#:import rgba kivy.utils.rgba<N><N><LogLabel@RelativeLayout>:<N>    # using a boxlayout here allows us to have better control of the text<N>    # position<N>    text: ''<N>    index: None<N>    Label:<N>        y: 0<N>        x: 5<N>        size_hint: None, None<N>        size: self.texture_size<N>        padding: dp(5), dp(5)<N>        color: rgba("#3f3e36")<N>        text: root.text<N>        on_texture_size: app.update_size(root.index, self.texture_size)<N><N>
        canvas.before:<N>            Color:<N>                rgba: rgba("#dbeeff")<N>            RoundedRectangle:<N>                pos: self.pos<N>                size: self.size<N>                radius: dp(5), dp(5)<N><N>BoxLayout:<N>    orientation: 'vertical'<N>    spacing: dp(2)<N><N>
'''<N>A form generator, using random data, but can be data driven (json or whatever)<N><N>Shows that you can use the key_viewclass attribute of RecycleView to select a<N>different Widget for each item.<N>'''<N><N>from random import choice, choices<N>from string import ascii_lowercase<N><N>
"""Detecting and acting upon "Pull down actions" in a RecycleView<N>- When using overscroll or being at the to, a "pull down to refresh" message<N>  appears<N>- if the user pulls down far enough, then a refresh is triggered, which adds<N>  new elements at the top of the list.<N><N>
"""<N>from threading import Thread<N>from time import sleep<N>from datetime import datetime<N><N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.properties import ListProperty, BooleanProperty<N>from kivy.metrics import dp<N>from kivy.clock import mainthread<N><N>
<N>KV = r'''<N>FloatLayout:<N>    Label:<N>        opacity: 1 if app.refreshing or rv.scroll_y > 1 else 0<N>        size_hint_y: None<N>        pos_hint: {'top': 1}<N>        text: 'Refreshingâ€¦' if app.refreshing else 'Pull down to refresh'<N><N>    RecycleView:<N>        id: rv<N>        data: app.data<N>        viewclass: 'Row'<N>        do_scroll_y: True<N>        do_scroll_x: False<N>        on_scroll_y: app.check_pull_refresh(self, grid)<N><N>
        RecycleGridLayout:<N>            id: grid<N>            cols: 1<N>            size_hint_y: None<N>            height: self.minimum_height<N>            default_size: 0, 36<N>            default_size_hint: 1, None<N><N><N><Row@Label>:<N>    _id: 0<N>    text: ''<N>    canvas:<N>        Line:<N>            rectangle: self.pos + self.size<N>            width: 0.6<N>'''<N><N>
from random import sample, randint<N>from string import ascii_lowercase<N><N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.uix.boxlayout import BoxLayout<N><N><N>kv = """<N><Row@RecycleKVIDsDataViewBehavior+BoxLayout>:<N>    canvas.before:<N>        Color:<N>            rgba: 0.5, 0.5, 0.5, 1<N>        Rectangle:<N>            size: self.size<N>            pos: self.pos<N>    value: ''<N>    Label:<N>        id: name<N>    Label:<N>        text: root.value<N><N>
from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.clock import Clock<N>from kivy.properties import ListProperty<N>from kivy.animation import Animation<N>from kivy.metrics import dp<N><N>KV = '''<N>#:import RGBA kivy.utils.rgba<N><N><ImageButton@ButtonBehavior+Image>:<N>    size_hint: None, None<N>    size: self.texture_size<N><N>
    canvas.before:<N>        PushMatrix<N>        Scale:<N>            origin: self.center<N>            x: .75 if self.state == 'down' else 1<N>            y: .75 if self.state == 'down' else 1<N><N>    canvas.after:<N>        PopMatrix<N><N>BoxLayout:<N>    orientation: 'vertical'<N>    padding: dp(5), dp(5)<N>    RecycleView:<N>        id: rv<N>        data: app.messages<N>        viewclass: 'Message'<N>        do_scroll_x: False<N><N>
        RecycleBoxLayout:<N>            id: box<N>            orientation: 'vertical'<N>            size_hint_y: None<N>            size: self.minimum_size<N>            default_size_hint: 1, None<N>            # magic value for the default height of the message<N>            default_size: 0, 38<N>            key_size: '_size'<N><N>
    FloatLayout:<N>        size_hint_y: None<N>        height: 0<N>        Button:<N>            size_hint_y: None<N>            height: self.texture_size[1]<N>            opacity: 0 if not self.height else 1<N>            text:<N>                (<N>                'go to last message'<N>                if rv.height < box.height and rv.scroll_y > 0 else<N>                ''<N>                )<N>            pos_hint: {'pos': (0, 0)}<N>            on_release: app.scroll_bottom()<N><N>
    BoxLayout:<N>        size_hint: 1, None<N>        size: self.minimum_size<N>        TextInput:<N>            id: ti<N>            size_hint: 1, None<N>            height: min(max(self.line_height, self.minimum_height), 150)<N>            multiline: False<N><N>
            on_text_validate:<N>                app.send_message(self)<N><N>        ImageButton:<N>            source: 'data/logo/kivy-icon-48.png'<N>            on_release:<N>                app.send_message(ti)<N><N><Message@FloatLayout>:<N>    message_id: -1<N>    bg_color: '#223344'<N>    side: 'left'<N>    text: ''<N>    size_hint_y: None<N>    _size: 0, 0<N>    size: self._size<N>    text_size: None, None<N>    opacity: min(1, self._size[0])<N><N>
    Label:<N>        text: root.text<N>        padding: 10, 10<N>        size_hint: None, 1<N>        size: self.texture_size<N>        text_size: root.text_size<N><N>        on_texture_size:<N>            app.update_message_size(<N>            root.message_id,<N>            self.texture_size,<N>            root.width,<N>            )<N><N>
        pos_hint:<N>            (<N>            {'x': 0, 'center_y': .5}<N>            if root.side == 'left' else<N>            {'right': 1, 'center_y': .5}<N>            )<N><N>        canvas.before:<N>            Color:<N>                rgba: RGBA(root.bg_color)<N>            RoundedRectangle:<N>                size: self.texture_size<N>                radius: dp(5), dp(5), dp(5), dp(5)<N>                pos: self.pos<N><N>
        canvas.after:<N>            Color:<N>            Line:<N>                rounded_rectangle: self.pos + self.texture_size + [dp(5)]<N>                width: 1.01<N>'''<N><N><N>class MessengerApp(App):<N>    messages = ListProperty()<N><N>    def build(self):<N>        return Builder.load_string(KV)<N><N>
    def add_message(self, text, side, color):<N>        # create a message for the recycleview<N>        self.messages.append({<N>            'message_id': len(self.messages),<N>            'text': text,<N>            'side': side,<N>            'bg_color': color,<N>            'text_size': [None, None],<N>        })<N><N>
    def update_message_size(self, message_id, texture_size, max_width):<N>        # when the label is updated, we want to make sure the displayed size is<N>        # proper<N>        if max_width == 0:<N>            return<N><N>        one_line = dp(50)  # a bit of  hack, YMMV<N><N>
        # if the texture is too big, limit its size<N>        if texture_size[0] >= max_width * 2 / 3:<N>            self.messages[message_id] = {<N>                **self.messages[message_id],<N>                'text_size': (max_width * 2 / 3, None),<N>            }<N><N>
        # if it was limited, but is now too small to be limited, raise the limit<N>        elif texture_size[0] < max_width * 2 / 3 and \<N>                texture_size[1] > one_line:<N>            self.messages[message_id] = {<N>                **self.messages[message_id],<N>                'text_size': (max_width * 2 / 3, None),<N>                '_size': texture_size,<N>            }<N><N>
        # just set the size<N>        else:<N>            self.messages[message_id] = {<N>                **self.messages[message_id],<N>                '_size': texture_size,<N>            }<N><N>    @staticmethod<N>    def focus_textinput(textinput):<N>        textinput.focus = True<N><N>
    def send_message(self, textinput):<N>        text = textinput.text<N>        textinput.text = ''<N>        self.add_message(text, 'right', '#223344')<N>        self.focus_textinput(textinput)<N>        Clock.schedule_once(lambda *args: self.answer(text), 1)<N>        self.scroll_bottom()<N><N>
    def answer(self, text, *args):<N>        self.add_message('do you really think so?', 'left', '#332211')<N><N>    def scroll_bottom(self):<N>        rv = self.root.ids.rv<N>        box = self.root.ids.box<N>        if rv.height < box.height:<N>            Animation.cancel_all(rv, 'scroll_y')<N>            Animation(scroll_y=0, t='out_quad', d=.5).start(rv)<N><N>
import kivy<N>kivy.require('1.0.6')  # replace with your current kivy version !<N><N>from kivy.app import App<N>from kivy.uix.button import Button<N><N><N>class MyApp(App):<N><N>    def build(self):<N>        return Button(text='Hello World')<N><N><N>if __name__ == '__main__':<N>    MyApp().run()<N>
import kivy<N>kivy.require('1.0.5')<N><N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.app import App<N>from kivy.properties import ObjectProperty, StringProperty<N><N><N>class Controller(FloatLayout):<N>    '''Create a controller that receives a custom widget from the kv lang file.<N><N>
    Add an action to be called from the kv lang file.<N>    '''<N>    label_wid = ObjectProperty()<N>    info = StringProperty()<N><N>    def do_action(self):<N>        self.label_wid.text = 'My label after button press'<N>        self.info = 'New info text'<N><N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N><N><N>class MyPaintWidget(Widget):<N>    def on_touch_down(self, touch):<N>        print(touch)<N><N><N>class MyPaintApp(App):<N>    def build(self):<N>        return MyPaintWidget()<N><N><N>if __name__ == '__main__':<N>    MyPaintApp().run()<N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N><N><N>class MyPaintWidget(Widget):<N>    pass<N><N><N>class MyPaintApp(App):<N>    def build(self):<N>        return MyPaintWidget()<N><N><N>if __name__ == '__main__':<N>    MyPaintApp().run()<N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.graphics import Color, Ellipse<N><N><N>class MyPaintWidget(Widget):<N><N>    def on_touch_down(self, touch):<N>        with self.canvas:<N>            Color(1, 1, 0)<N>            d = 30.<N>            Ellipse(pos=(touch.x - d / 2, touch.y - d / 2), size=(d, d))<N><N><N>class MyPaintApp(App):<N><N>    def build(self):<N>        return MyPaintWidget()<N><N><N>if __name__ == '__main__':<N>    MyPaintApp().run()<N>
from random import random<N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.graphics import Color, Ellipse, Line<N><N><N>class MyPaintWidget(Widget):<N><N>    def on_touch_down(self, touch):<N>        color = (random(), random(), random())<N>        with self.canvas:<N>            Color(*color)<N>            d = 30.<N>            Ellipse(pos=(touch.x - d / 2, touch.y - d / 2), size=(d, d))<N>            touch.ud['line'] = Line(points=(touch.x, touch.y))<N><N>
from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.graphics import Color, Ellipse, Line<N><N><N>class MyPaintWidget(Widget):<N><N>    def on_touch_down(self, touch):<N>        with self.canvas:<N>            Color(1, 1, 0)<N>            d = 30.<N>            Ellipse(pos=(touch.x - d / 2, touch.y - d / 2), size=(d, d))<N>            touch.ud['line'] = Line(points=(touch.x, touch.y))<N><N>
# -*- coding: utf-8 -*-<N><N>from kivy.base import runTouchApp<N>from kivy.lang import Builder<N>from kivy.factory import Factory as F<N><N><N>class DemoBox(F.ButtonBehavior, F.BoxLayout):<N>    base_direction = F.StringProperty(None, allownone=True)<N>    font_context = F.StringProperty(None, allownone=True)<N>    font_size = F.NumericProperty(10)<N><N>
# -*- coding: utf-8 -*-<N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.graphics import Color, Ellipse, Rectangle, RoundedRectangle<N>from kivy.lang import Builder<N><N>TEXTURE = 'kiwi.jpg'<N>YELLOW = (1, .7, 0)<N>ORANGE = (1, .45, 0)<N>RED = (1, 0, 0)<N>WHITE = (1, 1, 1)<N><N>
<N>class RoundedRectangleWidget(Widget):<N>    def prepare(self):<N>        with self.canvas:<N>            Color(*WHITE)<N><N>            # Rectangle of default size 100x100<N>            Rectangle(pos=(50, 400))<N><N>            # RoundedRectangles of default size 100x100:<N><N>
            # Textured:<N>            RoundedRectangle(<N>                pos=(175, 400), radius=[0, 50, 0, 50], source=TEXTURE)<N><N>            # Colored:<N>            Color(*YELLOW)<N>            RoundedRectangle(pos=(300, 400), radius=[0, 50, 0, 50])<N><N>
            # Textured + Colored<N>            # Color(.3,.3,.3, 1)<N>            RoundedRectangle(<N>                pos=(425, 400), radius=[0, 50, 0, 50], source=TEXTURE)<N><N>            # Possible radius arguments:<N>            # 1) Same value for each corner<N>            Color(*ORANGE)<N><N>
            # With same radius 20x20<N>            RoundedRectangle(pos=(50, 275), radius=[20])<N><N>            # With same radius dimensions 20x40<N>            RoundedRectangle(pos=(175, 275), radius=[(20, 40)])<N><N>            # 2) Different values for each corner<N>            Color(*RED)<N><N>
            # With different radiuses NxN:<N>            RoundedRectangle(pos=(300, 275), radius=[10, 20, 30, 40])<N><N>            # With different radiuses:<N>            RoundedRectangle(<N>                pos=(425, 275),<N>                radius=[(10, 20), (20, 30), (30, 40), (40, 50)])<N><N>
            # Default ellipses<N>            Color(*WHITE)<N>            Ellipse(pos=(50, 150))<N>            Ellipse(pos=(175, 150))<N>            Ellipse(pos=(300, 150))<N>            Ellipse(pos=(425, 150))<N><N>            # Radius dimensions can't be bigger than half of the figure side<N>            RoundedRectangle(pos=(175, 150), radius=[9000], source=TEXTURE)<N><N>
            # Segments parameter defines how many segments each corner has.<N>            # More segments - more roundness<N>            Color(*RED)<N>            RoundedRectangle(pos=(300, 150), radius=[9000])<N>            RoundedRectangle(pos=(425, 150), radius=[9000], segments=15)<N><N>
'''<N>Tesselate Demonstration<N>=======================<N><N>This demonstrates the experimental library for tesselating polygons. You<N>should see a hollow square with some buttons below it. You can click and<N>drag to create additional shapes, watching the number of vertexes and elements<N>at the top of the screen. The 'debug' button toggles showing the mesh in<N>different colors.<N>'''<N><N>
<N>from kivy.app import App<N>from kivy.graphics import Mesh, Color<N>from kivy.graphics.tesselator import Tesselator, WINDING_ODD, TYPE_POLYGONS<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.lang import Builder<N>from kivy.logger import Logger<N><N>
'''<N>Canvas stress<N>=============<N><N>This example tests the performance of our Graphics engine by drawing large<N>numbers of small squares. You should see a black canvas with buttons and a<N>label at the bottom. Pressing the buttons adds small colored squares to the<N>canvas.<N><N>
'''<N><N>from kivy.uix.button import Button<N>from kivy.uix.widget import Widget<N>from kivy.uix.label import Label<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.app import App<N>from kivy.graphics import Color, Rectangle<N>from random import random as r<N>from functools import partial<N><N>
<N>class StressCanvasApp(App):<N><N>    def add_rects(self, label, wid, count, *largs):<N>        label.text = str(int(label.text) + count)<N>        with wid.canvas:<N>            for x in range(count):<N>                Color(r(), 1, 1, mode='hsv')<N>                Rectangle(pos=(r() * wid.width + wid.x,<N>                               r() * wid.height + wid.y), size=(20, 20))<N><N>
    def double_rects(self, label, wid, *largs):<N>        count = int(label.text)<N>        self.add_rects(label, wid, count, *largs)<N><N>    def reset_rects(self, label, wid, *largs):<N>        label.text = '0'<N>        wid.canvas.clear()<N><N>    def build(self):<N>        wid = Widget()<N><N>
        label = Label(text='0')<N><N>        btn_add100 = Button(text='+ 100 rects',<N>                            on_press=partial(self.add_rects, label, wid, 100))<N><N>        btn_add500 = Button(text='+ 500 rects',<N>                            on_press=partial(self.add_rects, label, wid, 500))<N><N>
        btn_double = Button(text='x 2',<N>                            on_press=partial(self.double_rects, label, wid))<N><N>        btn_reset = Button(text='Reset',<N>                           on_press=partial(self.reset_rects, label, wid))<N><N>        layout = BoxLayout(size_hint=(1, None), height=50)<N>        layout.add_widget(btn_add100)<N>        layout.add_widget(btn_add500)<N>        layout.add_widget(btn_double)<N>        layout.add_widget(btn_reset)<N>        layout.add_widget(label)<N><N>
'''<N>Mesh Manipulation Example<N>=========================<N><N>This demonstrates creating a mesh and using it to deform the texture (the<N>kivy log). You should see the kivy logo with a five sliders to right.<N>The sliders change the mesh points' x and y offsets, radius, and a<N>'wobble' deformation's magnitude and speed.<N><N>
This example is developed in gabriel's blog post at<N>http://kivy.org/planet/2014/01/kivy-image-manipulations-with-mesh-and-textures/<N>'''<N><N>from kivy.app import App<N>from kivy.lang import Builder<N>from kivy.core.image import Image as CoreImage<N>from kivy.properties import ListProperty, ObjectProperty, NumericProperty<N>from kivy.clock import Clock<N>from kivy.core.window import Window<N>from math import sin, cos, pi<N><N>
'''<N>Scaling Example<N>================<N><N>This example scales a button using PushMatrix and PopMatrix. It shows<N>a static button with the words 'hello world', stretched about its centre by<N>a factor of 1.5 horizontally and 5 vertically.<N>'''<N><N><N>from kivy.app import App<N>from kivy.lang import Builder<N><N>
kv = '''<N>FloatLayout:<N><N>    Button:<N>        text: 'hello world'<N>        size_hint: None, None<N>        pos_hint: {'center_x': .5, 'center_y': .5}<N>        canvas.before:<N>            PushMatrix<N>            Scale:<N>                x: 1.5<N>                y: 5<N>                origin: self.center<N>        canvas.after:<N>            PopMatrix<N>'''<N><N>
'''<N>Mesh test<N>=========<N><N>This demonstrates the use of a mesh mode to distort an image. You should see<N>a line of buttons across the bottom of a canvas. Pressing them displays<N>the mesh, a small circle of points, with different mesh.mode settings.<N>'''<N><N>
from kivy.uix.button import Button<N>from kivy.uix.widget import Widget<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.app import App<N>from kivy.graphics import Mesh<N>from functools import partial<N>from math import cos, sin, pi<N><N><N>class MeshTestApp(App):<N><N>
'''<N>Stencil demo<N>============<N><N>This is a test of the stencil graphics instruction inside the stencil view<N>widget. When you use a stencil, nothing will be drawn outside the bounding<N>box. All the graphics will draw only in the stencil view.<N><N>
'''<N>Circle Example<N>==============<N><N>This example exercises circle (ellipse) drawing. You should see sliders at the<N>top of the screen with the Kivy logo below it. The sliders control the<N>angle start and stop and the height and width scales. There is a button<N>to reset the sliders. The logo used for the circle's background image is<N>from the kivy/data directory. The entire example is coded in the<N>kv language description.<N>'''<N><N>
'''<N>Lines Extended Demo<N>===================<N><N>This demonstrates how to use the extended line drawing routines such<N>as circles, ellipses, and rectangles. You should see a static image of<N>labelled shapes on the screen.<N>'''<N><N>from kivy.app import App<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.uix.widget import Widget<N>from kivy.lang import Builder<N><N>
Builder.load_string('''<N><LineEllipse1>:<N>    canvas:<N>        Color:<N>            rgba: 1, .1, .1, .9<N>        Line:<N>            width: 2.<N>            ellipse: (self.x, self.y, self.width, self.height)<N>    Label:<N>        center: root.center<N>        text: 'Ellipse'<N><N>
<LineEllipse2>:<N>    canvas:<N>        Color:<N>            rgba: 1, .1, .1, .9<N>        Line:<N>            width: 2.<N>            ellipse: (self.x, self.y, self.width, self.height, 90, 180)<N>    Label:<N>        center: root.center<N>        text: 'Ellipse from 90 to 180'<N><N>
# fun result with low segments!<N><LineEllipse3>:<N>    canvas:<N>        Color:<N>            rgba: 1, .1, .1, .9<N>        Line:<N>            width: 2.<N>            ellipse: (self.x, self.y, self.width, self.height, 90, 720, 10)<N>    Label:<N>        center: root.center<N>        text: 'Ellipse from 90 to 720\\n10 segments'<N>        halign: 'center'<N><N>
<LineCircle1>:<N>    canvas:<N>        Color:<N>            rgba: .1, 1, .1, .9<N>        Line:<N>            width: 2.<N>            circle:<N>                (self.center_x, self.center_y, min(self.width, self.height)<N>                / 2)<N>    Label:<N>        center: root.center<N>        text: 'Circle'<N><N>
<LineCircle2>:<N>    canvas:<N>        Color:<N>            rgba: .1, 1, .1, .9<N>        Line:<N>            width: 2.<N>            circle:<N>                (self.center_x, self.center_y, min(self.width, self.height)<N>                / 2, 90, 180)<N>    Label:<N>        center: root.center<N>        text: 'Circle from 90 to 180'<N><N>
<LineCircle3>:<N>    canvas:<N>        Color:<N>            rgba: .1, 1, .1, .9<N>        Line:<N>            width: 2.<N>            circle:<N>                (self.center_x, self.center_y, min(self.width, self.height)<N>                / 2, 90, 180, 10)<N>    Label:<N>        center: root.center<N>        text: 'Circle from 90 to 180\\n10 segments'<N>        halign: 'center'<N><N>
<LineCircle4>:<N>    canvas:<N>        Color:<N>            rgba: .1, 1, .1, .9<N>        Line:<N>            width: 2.<N>            circle:<N>                (self.center_x, self.center_y, min(self.width, self.height)<N>                / 2, 0, 360)<N>    Label:<N>        center: root.center<N>        text: 'Circle from 0 to 360'<N>        halign: 'center'<N><N>
<LineRectangle>:<N>    canvas:<N>        Color:<N>            rgba: .1, .1, 1, .9<N>        Line:<N>            width: 2.<N>            rectangle: (self.x, self.y, self.width, self.height)<N>    Label:<N>        center: root.center<N>        text: 'Rectangle'<N><N>
<LineBezier>:<N>    canvas:<N>        Color:<N>            rgba: .1, .1, 1, .9<N>        Line:<N>            width: 2.<N>            bezier:<N>                (self.x, self.y, self.center_x - 40, self.y + 100,<N>                self.center_x + 40, self.y - 100, self.right, self.y)<N>    Label:<N>        center: root.center<N>        text: 'Bezier'<N>''')<N><N>
<N>class LineEllipse1(Widget):<N>    pass<N><N><N>class LineEllipse2(Widget):<N>    pass<N><N><N>class LineEllipse3(Widget):<N>    pass<N><N><N>class LineCircle1(Widget):<N>    pass<N><N><N>class LineCircle2(Widget):<N>    pass<N><N><N>class LineCircle3(Widget):<N>    pass<N><N>
'''<N>Repeat Texture on Resize<N>========================<N><N>This examples repeats the letter 'K' (mtexture1.png) 64 times in a window.<N>You should see 8 rows and 8 columns of white K letters, along a label<N>showing the current size. As you resize the window, it stays an 8x8.<N>This example includes a label with a colored background.<N><N>
Note the image mtexture1.png is a white 'K' on a transparent background, which<N>makes it hard to see.<N>'''<N><N>from kivy.app import App<N>from kivy.uix.image import Image<N>from kivy.uix.label import Label<N>from kivy.properties import ObjectProperty, ListProperty<N>from kivy.lang import Builder<N><N>
kv = '''<N><LabelOnBackground>:<N>    canvas.before:<N>        Color:<N>            rgb: self.background<N>        Rectangle:<N>            pos: self.pos<N>            size: self.size<N><N>FloatLayout:<N>    canvas.before:<N>        Color:<N>            rgb: 1, 1, 1<N>        Rectangle:<N>            pos: self.pos<N>            size: self.size<N>            texture: app.texture<N><N>
    LabelOnBackground:<N>        text: '{} (try to resize the window)'.format(root.size)<N>        color: (0.4, 1, 1, 1)<N>        background: (.3, .3, .3)<N>        pos_hint: {'center_x': .5, 'center_y': .5 }<N>        size_hint: None, None<N>        height: 30<N>        width: 250<N><N>
'''<N><N><N>class LabelOnBackground(Label):<N>    background = ListProperty((0.2, 0.2, 0.2))<N><N><N>class RepeatTexture(App):<N><N>    texture = ObjectProperty()<N><N>    def build(self):<N>        self.texture = Image(source='mtexture1.png').texture<N>        self.texture.wrap = 'repeat'<N>        self.texture.uvsize = (8, 8)<N>        return Builder.load_string(kv)<N><N>
'''<N>Rotation Example<N>================<N><N>This example rotates a button using PushMatrix and PopMatrix. You should see<N>a static button with the words 'hello world' rotated at a 45 degree angle.<N>'''<N><N><N>from kivy.app import App<N>from kivy.lang import Builder<N><N>
kv = '''<N>FloatLayout:<N><N>    Button:<N>        text: 'hello world'<N>        size_hint: None, None<N>        pos_hint: {'center_x': .5, 'center_y': .5}<N>        canvas.before:<N>            PushMatrix<N>            Rotate:<N>                angle: 45<N>                origin: self.center<N>        canvas.after:<N>            PopMatrix<N>'''<N><N>
'''<N>Multitexture Example<N>====================<N><N>This example blends two textures: the image mtexture1.png of the letter K<N>and the image mtexture2.png of an orange circle. You should see an orange<N>K clipped to a circle. It uses a custom shader, written in glsl<N>(OpenGL Shading Language), stored in a local string.<N><N>
Note the image mtexture1.png is a white 'K' on a transparent background, which<N>makes it hard to see.<N>'''<N><N>from kivy.clock import Clock<N>from kivy.app import App<N>from kivy.uix.widget import Widget<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.lang import Builder<N>from kivy.core.window import Window<N>from kivy.graphics import RenderContext, Color, Rectangle, BindTexture<N><N>
<N>fs_multitexture = '''<N>$HEADER$<N><N>// New uniform that will receive texture at index 1<N>uniform sampler2D texture1;<N><N>void main(void) {<N><N>    // multiple current color with both texture (0 and 1).<N>    // currently, both will use exactly the same texture coordinates.<N>    gl_FragColor = frag_color * \<N>        texture2D(texture0, tex_coord0) * \<N>        texture2D(texture1, tex_coord0);<N>}<N>'''<N><N>
<N>kv = """<N><MultitextureLayout>:<N><N>    Image:<N>        source: "mtexture1.png"<N>        size_hint: .3,.3<N>        id: 1<N>        pos: 0,200<N>    Image:<N>        source: "mtexture2.png"<N>        size_hint: .3,.3<N>        id: 2<N>        pos: 200,200<N><N>
    MultitextureWidget:<N><N>"""<N><N>Builder.load_string(kv)<N><N><N>class MultitextureWidget(Widget):<N><N>    def __init__(self, **kwargs):<N>        self.canvas = RenderContext()<N>        # setting shader.fs to new source code automatically compiles it.<N>        self.canvas.shader.fs = fs_multitexture<N>        with self.canvas:<N>            Color(1, 1, 1)<N><N>
            # here, we are binding a custom texture at index 1<N>            # this will be used as texture1 in shader.<N>            # The filenames are misleading: they do not correspond to the<N>            # index here or in the shader.<N>            BindTexture(source='mtexture2.png', index=1)<N><N>
            # create a rectangle with texture (will be at index 0)<N>            Rectangle(size=(150, 150), source='mtexture1.png', pos=(500, 200))<N><N>        # set the texture1 to use texture index 1<N>        self.canvas['texture1'] = 1<N><N>        # call the constructor of parent<N>        # if they are any graphics objects, they will be added on our new<N>        # canvas<N>        super(MultitextureWidget, self).__init__(**kwargs)<N><N>
        # We'll update our glsl variables in a clock<N>        Clock.schedule_interval(self.update_glsl, 0)<N><N>    def update_glsl(self, *largs):<N>        # This is needed for the default vertex shader.<N>        self.canvas['projection_mat'] = Window.render_context['projection_mat']<N>        self.canvas['modelview_mat'] = Window.render_context['modelview_mat']<N><N>
<N>class MultitextureLayout(FloatLayout):<N><N>    def __init__(self, **kwargs):<N>        self.size = kwargs['size']<N>        super(MultitextureLayout, self).__init__(**kwargs)<N><N><N>class MultitextureApp(App):<N><N>    def build(self):<N>        return MultitextureLayout(size=(600, 600))<N><N>
'''<N>Bezier Example<N>==============<N><N>This example shows a closed Bezier curve computed from a polygon. You<N>should see a purple polygon, a red bezier curve computed from the polygon,<N>and two sliders. You can drag points on the polygon to recompute the curve.<N>The two sliders control the dash length of the dashed lines making up the two<N>shapes.<N><N>
'''<N>FBO Canvas<N>==========<N><N>This demonstrates a layout using an FBO (Frame Buffer Off-screen)<N>instead of a plain canvas. You should see a black canvas with a<N>button labelled 'FBO' in the bottom left corner. Clicking it<N>animates the button moving right to left.<N>'''<N><N>
__all__ = ('FboFloatLayout', )<N><N>from kivy.graphics import Color, Rectangle, Canvas, ClearBuffers, ClearColor<N>from kivy.graphics.fbo import Fbo<N>from kivy.uix.floatlayout import FloatLayout<N>from kivy.properties import ObjectProperty, NumericProperty<N>from kivy.app import App<N>from kivy.core.window import Window<N>from kivy.animation import Animation<N>from kivy.factory import Factory<N><N>
<N>class FboFloatLayout(FloatLayout):<N><N>    texture = ObjectProperty(None, allownone=True)<N><N>    alpha = NumericProperty(1)<N><N>    def __init__(self, **kwargs):<N>        self.canvas = Canvas()<N>        with self.canvas:<N>            self.fbo = Fbo(size=self.size)<N>            self.fbo_color = Color(1, 1, 1, 1)<N>            self.fbo_rect = Rectangle()<N><N>
        with self.fbo:<N>            ClearColor(0, 0, 0, 0)<N>            ClearBuffers()<N><N>        # wait that all the instructions are in the canvas to set texture<N>        self.texture = self.fbo.texture<N>        super(FboFloatLayout, self).__init__(**kwargs)<N><N>
    def add_widget(self, *largs):<N>        # trick to attach graphics instruction to fbo instead of canvas<N>        canvas = self.canvas<N>        self.canvas = self.fbo<N>        ret = super(FboFloatLayout, self).add_widget(*largs)<N>        self.canvas = canvas<N>        return ret<N><N>
    def remove_widget(self, *largs):<N>        canvas = self.canvas<N>        self.canvas = self.fbo<N>        super(FboFloatLayout, self).remove_widget(*largs)<N>        self.canvas = canvas<N><N>    def on_size(self, instance, value):<N>        self.fbo.size = value<N>        self.texture = self.fbo.texture<N>        self.fbo_rect.size = value<N><N>
    def on_pos(self, instance, value):<N>        self.fbo_rect.pos = value<N><N>    def on_texture(self, instance, value):<N>        self.fbo_rect.texture = value<N><N>    def on_alpha(self, instance, value):<N>        self.fbo_color.rgba = (1, 1, 1, value)<N><N>
<N>class ScreenLayerApp(App):<N>    def build(self):<N><N>        f = FboFloatLayout()<N>        b = Factory.Button(text="FBO", size_hint=(None, None))<N>        f.add_widget(b)<N><N>        def anim_btn(*args):<N>            if b.pos[0] == 0:<N>                Animation(x=f.width - b.width).start(b)<N>            else:<N>                Animation(x=0).start(b)<N>        b.bind(on_press=anim_btn)<N><N>
from kivy.app import App<N>from kivy.uix.boxlayout import BoxLayout<N>from kivy.uix.button import Button<N><N><N>class SpecialButton(Button):<N>    pass<N><N><N>class CustomLayout(BoxLayout):<N>    pass<N><N><N>class TestApp(App):<N>    pass<N><N><N>if __name__ == '__main__':<N>    TestApp().run()<N>
import freenect<N>from time import sleep<N>from threading import Thread<N>from collections import deque<N>from kivy.app import App<N>from kivy.clock import Clock<N>from kivy.properties import NumericProperty, StringProperty<N>from kivy.graphics import RenderContext, Color, Rectangle<N>from kivy.graphics.texture import Texture<N>from kivy.core.window import Window<N>from kivy.uix.widget import Widget<N>from kivy.uix.slider import Slider<N>from kivy.uix.boxlayout import BoxLayout<N><N>
<N>fragment_header = '''<N>#ifdef GL_ES<N>    precision highp float;<N>#endif<N><N>/* Outputs from the vertex shader */<N>varying vec4 frag_color;<N>varying vec2 tex_coord0;<N><N>/* uniform texture samplers */<N>uniform sampler2D texture0;<N><N>/* custom input */<N>uniform float depth_range;<N>uniform vec2 size;<N>'''<N><N>
hsv_func = '''<N>vec3 HSVtoRGB(vec3 color) {<N>    float f,p,q,t, hueRound;<N>    int hueIndex;<N>    float hue, saturation, v;<N>    vec3 result;<N><N>    /* just for clarity */<N>    hue = color.r;<N>    saturation = color.g;<N>    v = color.b;<N><N>    hueRound = floor(hue * 6.0);<N>    hueIndex = mod(int(hueRound), 6.);<N>    f = (hue * 6.0) - hueRound;<N>    p = v * (1.0 - saturation);<N>    q = v * (1.0 - f*saturation);<N>    t = v * (1.0 - (1.0 - f)*saturation);<N><N>
    switch(hueIndex) {<N>        case 0:<N>            result = vec3(v,t,p);<N>        break;<N>        case 1:<N>            result = vec3(q,v,p);<N>        break;<N>        case 2:<N>            result = vec3(p,v,t);<N>        break;<N>        case 3:<N>            result = vec3(p,q,v);<N>        break;<N>        case 4:<N>            result = vec3(t,p,v);<N>        break;<N>        case 5:<N>            result = vec3(v,p,q);<N>        break;<N>    }<N>    return result;<N>}<N>'''<N><N>
rgb_kinect = fragment_header + '''<N>void main (void) {<N>    float value = texture2D(texture0, tex_coord0).r;<N>    value = mod(value * depth_range, 1.);<N>    vec3 col = vec3(0., 0., 0.);<N>    if ( value <= 0.33 )<N>        col.r = clamp(value, 0., 0.33) * 3.;<N>    if ( value <= 0.66 )<N>        col.g = clamp(value - 0.33, 0., 0.33) * 3.;<N>    col.b = clamp(value - 0.66, 0., 0.33) * 3.;<N>    gl_FragColor = vec4(col, 1.);<N>}<N>'''<N><N>
points_kinect = fragment_header + hsv_func + '''<N>void main (void) {<N>    // threshold used to reduce the depth (better result)<N>    const int th = 5;<N><N>    // size of a square<N>    int square = floor(depth_range);<N><N>    // number of square on the display<N>    vec2 count = size / square;<N><N>
    // current position of the square<N>    vec2 pos = floor(tex_coord0.xy * count) / count;<N><N>    // texture step to pass to another square<N>    vec2 step = 1 / count;<N><N>    // texture step to pass to another pixel<N>    vec2 pxstep = 1 / size;<N><N>
    // center of the square<N>    vec2 center = pos + step / 2.;<N><N>    // calculate average of every pixels in the square<N>    float s = 0, x, y;<N>    for (x = 0; x < square; x++) {<N>        for (y = 0; y < square; y++) {<N>            s += texture2D(texture0, pos + pxstep * vec2(x,y)).r;<N>        }<N>    }<N>    float v = s / (square * square);<N><N>
# install_twisted_rector must be called before importing the reactor<N>from __future__ import unicode_literals<N><N>from kivy.support import install_twisted_reactor<N><N>install_twisted_reactor()<N><N># A Simple Client that send messages to the Echo Server<N>from twisted.internet import reactor, protocol<N><N>
<N>class EchoClient(protocol.Protocol):<N>    def connectionMade(self):<N>        self.factory.app.on_connection(self.transport)<N><N>    def dataReceived(self, data):<N>        self.factory.app.print_message(data.decode('utf-8'))<N><N><N>class EchoClientFactory(protocol.ClientFactory):<N>    protocol = EchoClient<N><N>
    def __init__(self, app):<N>        self.app = app<N><N>    def startedConnecting(self, connector):<N>        self.app.print_message('Started to connect.')<N><N>    def clientConnectionLost(self, connector, reason):<N>        self.app.print_message('Lost connection.')<N><N>
    def clientConnectionFailed(self, connector, reason):<N>        self.app.print_message('Connection failed.')<N><N><N>from kivy.app import App<N>from kivy.uix.label import Label<N>from kivy.uix.textinput import TextInput<N>from kivy.uix.boxlayout import BoxLayout<N><N>
<N># A simple kivy App, with a textbox to enter messages, and<N># a large label to display all the messages received from<N># the server<N>class TwistedClientApp(App):<N>    connection = None<N>    textbox = None<N>    label = None<N><N>    def build(self):<N>        root = self.setup_gui()<N>        self.connect_to_server()<N>        return root<N><N>
    def setup_gui(self):<N>        self.textbox = TextInput(size_hint_y=.1, multiline=False)<N>        self.textbox.bind(on_text_validate=self.send_message)<N>        self.label = Label(text='connecting...\n')<N>        layout = BoxLayout(orientation='vertical')<N>        layout.add_widget(self.label)<N>        layout.add_widget(self.textbox)<N>        return layout<N><N>
    def connect_to_server(self):<N>        reactor.connectTCP('localhost', 8000, EchoClientFactory(self))<N><N>    def on_connection(self, connection):<N>        self.print_message("Connected successfully!")<N>        self.connection = connection<N><N>    def send_message(self, *args):<N>        msg = self.textbox.text<N>        if msg and self.connection:<N>            self.connection.write(msg.encode('utf-8'))<N>            self.textbox.text = ""<N><N>
from kivy.support import install_twisted_reactor<N>install_twisted_reactor()<N><N>import os<N>import sys<N><N>from kivy.app import App<N>from kivy.uix.gridlayout import GridLayout<N>from kivy.properties import BooleanProperty<N>from kivy.lang import Builder<N><N>
from twisted.scripts._twistd_unix import UnixApplicationRunner, ServerOptions<N>from twisted.application.service import IServiceCollection<N><N>TWISTD = 'twistd web --listen=tcp:8087'<N><N><N>class AndroidApplicationRunner(UnixApplicationRunner):<N><N>    def run(self):<N><N>
        self.preApplication()<N>        self.application = self.createOrGetApplication()<N>        self.logger.start(self.application)<N>        sc = IServiceCollection(self.application)<N><N>        # reactor is already running, so we just start the service collection<N>        sc.startService()<N>        return self.application<N><N>
<N>Builder.load_string('''<N><TwistedTwistd>:<N>    cols: 1<N>    Button:<N>        text: root.running and 'STOP' or 'START'<N>        on_release: root.cb_twistd()<N>''')<N><N><N>class TwistedTwistd(GridLayout):<N><N>    running = BooleanProperty(False)<N><N>
    def cb_twistd(self, *la):<N><N>        if self.running:<N>            IServiceCollection(self.app).stopService()<N>            self.running = False<N>        else:<N>            sys.path.insert(0, os.path.abspath(os.getcwd()))<N>            sys.argv = TWISTD.split(' ')<N>            config = ServerOptions()<N>            config.parseOptions()<N>            self.app = AndroidApplicationRunner(config).run()<N>            self.running = True<N><N>
# install_twisted_rector must be called before importing and using the reactor<N>from kivy.support import install_twisted_reactor<N><N>install_twisted_reactor()<N><N>from twisted.internet import reactor<N>from twisted.internet import protocol<N><N><N>class EchoServer(protocol.Protocol):<N>    def dataReceived(self, data):<N>        response = self.factory.app.handle_message(data)<N>        if response:<N>            self.transport.write(response)<N><N>
<N>class EchoServerFactory(protocol.Factory):<N>    protocol = EchoServer<N><N>    def __init__(self, app):<N>        self.app = app<N><N><N>from kivy.app import App<N>from kivy.uix.label import Label<N><N><N>class TwistedServerApp(App):<N>    label = None<N><N>
    def build(self):<N>        self.label = Label(text="server started\n")<N>        reactor.listenTCP(8000, EchoServerFactory(self))<N>        return self.label<N><N>    def handle_message(self, msg):<N>        msg = msg.decode('utf-8')<N>        self.label.text = "received:  {}\n".format(msg)<N><N>
        if msg == "ping":<N>            msg = "Pong"<N>        if msg == "plop":<N>            msg = "Kivy Rocks!!!"<N>        self.label.text += "responded: {}\n".format(msg)<N>        return msg.encode('utf-8')<N><N><N>if __name__ == '__main__':<N>    TwistedServerApp().run()<N><N><N>
# Magic utility that "redirects" to pythoncomxx.dll<N>import pywintypes<N>pywintypes.__import_pywin32_system_module__("pythoncom", globals())<N>
import io<N>import posixpath<N>import zipfile<N>import itertools<N>import contextlib<N>import sys<N>import pathlib<N><N>if sys.version_info < (3, 7):<N>    from collections import OrderedDict<N>else:<N>    OrderedDict = dict<N><N><N>def _parents(path):<N>    """<N>    Given a path with elements separated by<N>    posixpath.sep, generate all parents of that path.<N><N>
    >>> list(_parents('b/d'))<N>    ['b']<N>    >>> list(_parents('/b/d/'))<N>    ['/b']<N>    >>> list(_parents('b/d/f/'))<N>    ['b/d', 'b']<N>    >>> list(_parents('b'))<N>    []<N>    >>> list(_parents(''))<N>    []<N>    """<N>    return itertools.islice(_ancestry(path), 1, None)<N><N>
"""Patches that are applied at runtime to the virtual environment"""<N># -*- coding: utf-8 -*-<N><N>import os<N>import sys<N><N>VIRTUALENV_PATCH_FILE = os.path.join(__file__)<N><N><N>def patch_dist(dist):<N>    """<N>    Distutils allows user to configure some arguments via a configuration file:<N>    https://docs.python.org/3/install/index.html#distutils-configuration-files<N><N>
    Some of this arguments though don't make sense in context of the virtual environment files, let's fix them up.<N>    """<N>    # we cannot allow some install config as that would get packages installed outside of the virtual environment<N>    old_parse_config_files = dist.Distribution.parse_config_files<N><N>
"""<N>All of the Enums that are used throughout the chardet package.<N><N>:author: Dan Blanchard (dan.blanchard@gmail.com)<N>"""<N><N><N>class InputState(object):<N>    """<N>    This enum represents the different states a universal detector can be in.<N>    """<N>    PURE_ASCII = 0<N>    ESC_ASCII = 1<N>    HIGH_BYTE = 2<N><N>
<N>class LanguageFilter(object):<N>    """<N>    This enum represents the different language filters we can apply to a<N>    ``UniversalDetector``.<N>    """<N>    CHINESE_SIMPLIFIED = 0x01<N>    CHINESE_TRADITIONAL = 0x02<N>    JAPANESE = 0x04<N>    KOREAN = 0x08<N>    NON_CJK = 0x10<N>    ALL = 0x1F<N>    CHINESE = CHINESE_SIMPLIFIED | CHINESE_TRADITIONAL<N>    CJK = CHINESE | JAPANESE | KOREAN<N><N>
<N>class ProbingState(object):<N>    """<N>    This enum represents the different states a prober can be in.<N>    """<N>    DETECTING = 0<N>    FOUND_IT = 1<N>    NOT_ME = 2<N><N><N>class MachineState(object):<N>    """<N>    This enum represents the different states a state machine can be in.<N>    """<N>    START = 0<N>    ERROR = 1<N>    ITS_ME = 2<N><N>
<N>class SequenceLikelihood(object):<N>    """<N>    This enum represents the likelihood of a character following the previous one.<N>    """<N>    NEGATIVE = 0<N>    UNLIKELY = 1<N>    LIKELY = 2<N>    POSITIVE = 3<N><N>    @classmethod<N>    def get_num_categories(cls):<N>        """:returns: The number of likelihood categories in the enum."""<N>        return 4<N><N>
<N>class CharacterCategory(object):<N>    """<N>    This enum represents the different categories language models for<N>    ``SingleByteCharsetProber`` put characters into.<N><N>    Anything less than CONTROL is considered a letter.<N>    """<N>    UNDEFINED = 255<N>    LINE_BREAK = 254<N>    SYMBOL = 253<N>    DIGIT = 252<N>    CONTROL = 251<N><N><N>
"""<N>This module exists only to simplify retrieving the version number of chardet<N>from within setup.py and from chardet subpackages.<N><N>:author: Dan Blanchard (dan.blanchard@gmail.com)<N>"""<N><N>__version__ = "4.0.0"<N>VERSION = __version__.split('.')<N>
#!/usr/bin/env python<N># -*- coding: utf-8 -*-<N>"""<N>Metadata about languages used by our model training code for our<N>SingleByteCharSetProbers.  Could be used for other things in the future.<N><N>This code is based on the language metadata from the uchardet project.<N>"""<N>from __future__ import absolute_import, print_function<N><N>
"""<N>Script which takes one or more file paths and reports on their detected<N>encodings<N><N>Example::<N><N>    % chardetect somefile someotherfile<N>    somefile: windows-1252 with confidence 0.5<N>    someotherfile: ascii with confidence 1.0<N><N>If no paths are provided, it takes its input from stdin.<N><N>
"""<N><N>from __future__ import absolute_import, print_function, unicode_literals<N><N>import argparse<N>import sys<N><N>from chardet import __version__<N>from chardet.compat import PY2<N>from chardet.universaldetector import UniversalDetector<N><N><N>def description_of(lines, name='stdin'):<N>    """<N>    Return a string describing the probable encoding of a file or<N>    list of strings.<N><N>
"""Run a subprocess in a pseudo terminal"""<N>from .ptyprocess import PtyProcess, PtyProcessUnicode, PtyProcessError<N><N>__version__ = '0.7.0'<N>
"""Substitute for the forkpty system call, to support Solaris.<N>"""<N>import os<N>import errno<N><N>from pty import (STDIN_FILENO, STDOUT_FILENO, STDERR_FILENO, CHILD)<N>from .util import PtyProcessError<N><N>def fork_pty():<N>    '''This implements a substitute for the forkpty system call. This<N>    should be more portable than the pty.fork() function. Specifically,<N>    this should work on Solaris.<N><N>
    Modified 10.06.05 by Geoff Marshall: Implemented __fork_pty() method to<N>    resolve the issue with Python's pty.fork() not supporting Solaris,<N>    particularly ssh. Based on patch to posixmodule.c authored by Noah<N>    Spurrier::<N><N>        http://mail.python.org/pipermail/python-dev/2003-May/035281.html<N><N>
    '''<N><N>    parent_fd, child_fd = os.openpty()<N>    if parent_fd < 0 or child_fd < 0:<N>        raise OSError("os.openpty() failed")<N><N>    pid = os.fork()<N>    if pid == CHILD:<N>        # Child.<N>        os.close(parent_fd)<N>        pty_make_controlling_tty(child_fd)<N><N>
        os.dup2(child_fd, STDIN_FILENO)<N>        os.dup2(child_fd, STDOUT_FILENO)<N>        os.dup2(child_fd, STDERR_FILENO)<N><N>    else:<N>        # Parent.<N>        os.close(child_fd)<N><N>    return pid, parent_fd<N><N>def pty_make_controlling_tty(tty_fd):<N>    '''This makes the pseudo-terminal the controlling tty. This should be<N>    more portable than the pty.fork() function. Specifically, this should<N>    work on Solaris. '''<N><N>
    child_name = os.ttyname(tty_fd)<N><N>    # Disconnect from controlling tty, if any.  Raises OSError of ENXIO<N>    # if there was no controlling tty to begin with, such as when<N>    # executed by a cron(1) job.<N>    try:<N>        fd = os.open("/dev/tty", os.O_RDWR | os.O_NOCTTY)<N>        os.close(fd)<N>    except OSError as err:<N>        if err.errno != errno.ENXIO:<N>            raise<N><N>
    os.setsid()<N><N>    # Verify we are disconnected from controlling tty by attempting to open<N>    # it again.  We expect that OSError of ENXIO should always be raised.<N>    try:<N>        fd = os.open("/dev/tty", os.O_RDWR | os.O_NOCTTY)<N>        os.close(fd)<N>        raise PtyProcessError("OSError of errno.ENXIO should be raised.")<N>    except OSError as err:<N>        if err.errno != errno.ENXIO:<N>            raise<N><N>
import codecs<N>import errno<N>import fcntl<N>import io<N>import os<N>import pty<N>import resource<N>import signal<N>import struct<N>import sys<N>import termios<N>import time<N><N>try:<N>    import builtins  # Python 3<N>except ImportError:<N>    import __builtin__ as builtins  # Python 2<N><N>
# Constants<N>from pty import (STDIN_FILENO, CHILD)<N><N>from .util import which, PtyProcessError<N><N>_platform = sys.platform.lower()<N><N># Solaris uses internal __fork_pty(). All others use pty.fork().<N>_is_solaris = (<N>    _platform.startswith('solaris') or<N>    _platform.startswith('sunos'))<N><N>
if _is_solaris:<N>    use_native_pty_fork = False<N>    from . import _fork_pty<N>else:<N>    use_native_pty_fork = True<N><N>PY3 = sys.version_info[0] >= 3<N><N>if PY3:<N>    def _byte(i):<N>        return bytes([i])<N>else:<N>    def _byte(i):<N>        return chr(i)<N>    <N>    class FileNotFoundError(OSError): pass<N>    class TimeoutError(OSError): pass<N><N>
_EOF, _INTR = None, None<N><N>def _make_eof_intr():<N>    """Set constants _EOF and _INTR.<N>    <N>    This avoids doing potentially costly operations on module load.<N>    """<N>    global _EOF, _INTR<N>    if (_EOF is not None) and (_INTR is not None):<N>        return<N><N>
"""<N>Filename globbing utility. Mostly a copy of `glob` from Python 3.5.<N><N>Changes include:<N> * `yield from` and PEP3102 `*` removed.<N> * Hidden files are not ignored.<N>"""<N><N>import os<N>import re<N>import fnmatch<N><N>__all__ = ["glob", "iglob", "escape"]<N><N>
<N>def glob(pathname, recursive=False):<N>    """Return a list of paths matching a pathname pattern.<N><N>    The pattern may contain simple shell-style wildcards a la<N>    fnmatch. However, unlike fnmatch, filenames starting with a<N>    dot are special cases that are not matched by '*' and '?'<N>    patterns.<N><N>
    If recursive is true, the pattern '**' will match any files and<N>    zero or more directories and subdirectories.<N>    """<N>    return list(iglob(pathname, recursive=recursive))<N><N><N>def iglob(pathname, recursive=False):<N>    """Return an iterator which yields the paths matching a pathname pattern.<N><N>
"""<N>Customized Mixin2to3 support:<N><N> - adds support for converting doctests<N>"""<N><N>import warnings<N>from distutils.util import Mixin2to3 as _Mixin2to3<N>from distutils import log<N>from lib2to3.refactor import RefactoringTool, get_fixers_from_package<N><N>
import setuptools<N>from ._deprecation_warning import SetuptoolsDeprecationWarning<N><N><N>class DistutilsRefactoringTool(RefactoringTool):<N>    def log_error(self, msg, *args, **kw):<N>        log.error(msg, *args)<N><N>    def log_message(self, msg, *args):<N>        log.info(msg, *args)<N><N>
    def log_debug(self, msg, *args):<N>        log.debug(msg, *args)<N><N><N>class Mixin2to3(_Mixin2to3):<N>    def run_2to3(self, files, doctests=False):<N>        # See of the distribution option has been set, otherwise check the<N>        # setuptools default.<N>        if self.distribution.use_2to3 is not True:<N>            return<N>        if not files:<N>            return<N><N>
"""Extensions to the 'distutils' for large or complex distributions"""<N><N>from fnmatch import fnmatchcase<N>import functools<N>import os<N>import re<N><N>import _distutils_hack.override  # noqa: F401<N><N>import distutils.core<N>from distutils.errors import DistutilsOptionError<N>from distutils.util import convert_path<N><N>
from ._deprecation_warning import SetuptoolsDeprecationWarning<N><N>import setuptools.version<N>from setuptools.extension import Extension<N>from setuptools.dist import Distribution<N>from setuptools.depends import Require<N>from . import monkey<N><N><N>__all__ = [<N>    'setup', 'Distribution', 'Command', 'Extension', 'Require',<N>    'SetuptoolsDeprecationWarning',<N>    'find_packages', 'find_namespace_packages',<N>]<N><N>
__version__ = setuptools.version.__version__<N><N>bootstrap_install_from = None<N><N># If we run 2to3 on .py files, should we also convert docstrings?<N># Default: yes; assume that we can detect doctests reliably<N>run_2to3_on_doctests = True<N># Standard package names for fixer packages<N>lib2to3_fixer_packages = ['lib2to3.fixes']<N><N>
<N>class PackageFinder:<N>    """<N>    Generate a list of all Python packages found within a directory<N>    """<N><N>    @classmethod<N>    def find(cls, where='.', exclude=(), include=('*',)):<N>        """Return a list all Python packages found within directory 'where'<N><N>
        'where' is the root directory which will be searched for packages.  It<N>        should be supplied as a "cross-platform" (i.e. URL-style) path; it will<N>        be converted to the appropriate local path syntax.<N><N>        'exclude' is a sequence of package names to exclude; '*' can be used<N>        as a wildcard in the names, such that 'foo.*' will exclude all<N>        subpackages of 'foo' (but not 'foo' itself).<N><N>
        'include' is a sequence of package names to include.  If it's<N>        specified, only the named packages will be included.  If it's not<N>        specified, all found packages will be included.  'include' can contain<N>        shell style wildcard patterns just like 'exclude'.<N>        """<N><N>
import glob<N>import os<N>import subprocess<N>import sys<N>import tempfile<N>from distutils import log<N>from distutils.errors import DistutilsError<N><N>import pkg_resources<N>from setuptools.wheel import Wheel<N><N><N>def _fixup_find_links(find_links):<N>    """Ensure find-links option end-up being a list of strings."""<N>    if isinstance(find_links, str):<N>        return find_links.split()<N>    assert isinstance(find_links, (tuple, list))<N>    return find_links<N><N>
# -*- coding: utf-8 -*-<N>__all__ = ['Distribution']<N><N>import io<N>import sys<N>import re<N>import os<N>import warnings<N>import numbers<N>import distutils.log<N>import distutils.core<N>import distutils.cmd<N>import distutils.dist<N>import distutils.command<N>from distutils.util import strtobool<N>from distutils.debug import DEBUG<N>from distutils.fancy_getopt import translate_longopt<N>import itertools<N><N>
from collections import defaultdict<N>from email import message_from_file<N><N>from distutils.errors import DistutilsOptionError, DistutilsSetupError<N>from distutils.util import rfc822_escape<N>from distutils.version import StrictVersion<N><N>from setuptools.extern import packaging<N>from setuptools.extern import ordered_set<N><N>
from . import SetuptoolsDeprecationWarning<N><N>import setuptools<N>import setuptools.command<N>from setuptools import windows_support<N>from setuptools.monkey import get_unpatched<N>from setuptools.config import parse_configuration<N>import pkg_resources<N><N>
__import__('setuptools.extern.packaging.specifiers')<N>__import__('setuptools.extern.packaging.version')<N><N><N>def _get_unpatched(cls):<N>    warnings.warn("Do not call this function", DistDeprecationWarning)<N>    return get_unpatched(cls)<N><N><N>def get_metadata_version(self):<N>    mv = getattr(self, 'metadata_version', None)<N><N>
import os<N>import socket<N>import atexit<N>import re<N>import functools<N>import urllib.request<N>import http.client<N><N><N>from pkg_resources import ResolutionError, ExtractionError<N><N>try:<N>    import ssl<N>except ImportError:<N>    ssl = None<N><N>
__all__ = [<N>    'VerifyingHTTPSHandler', 'find_ca_bundle', 'is_available', 'cert_paths',<N>    'opener_for'<N>]<N><N>cert_paths = """<N>/etc/pki/tls/certs/ca-bundle.crt<N>/etc/ssl/certs/ca-certificates.crt<N>/usr/share/ssl/certs/ca-bundle.crt<N>/usr/local/share/certs/ca-root.crt<N>/etc/ssl/cert.pem<N>/System/Library/OpenSSL/certs/cert.pem<N>/usr/local/share/certs/ca-root-nss.crt<N>/etc/ssl/ca-bundle.pem<N>""".strip().split()<N><N>
try:<N>    HTTPSHandler = urllib.request.HTTPSHandler<N>    HTTPSConnection = http.client.HTTPSConnection<N>except AttributeError:<N>    HTTPSHandler = HTTPSConnection = object<N><N>is_available = ssl is not None and object not in (<N>    HTTPSHandler, HTTPSConnection)<N><N>
<N>try:<N>    from ssl import CertificateError, match_hostname<N>except ImportError:<N>    try:<N>        from backports.ssl_match_hostname import CertificateError<N>        from backports.ssl_match_hostname import match_hostname<N>    except ImportError:<N>        CertificateError = None<N>        match_hostname = None<N><N>
if not CertificateError:<N><N>    class CertificateError(ValueError):<N>        pass<N><N><N>if not match_hostname:  # noqa: C901  # 'If 59' is too complex (21)  # FIXME<N><N>    def _dnsname_match(dn, hostname, max_wildcards=1):<N>        """Matching according to RFC 6125, section 6.4.3<N><N>
        https://tools.ietf.org/html/rfc6125#section-6.4.3<N>        """<N>        pats = []<N>        if not dn:<N>            return False<N><N>        # Ported from python3-syntax:<N>        # leftmost, *remainder = dn.split(r'.')<N>        parts = dn.split(r'.')<N>        leftmost = parts[0]<N>        remainder = parts[1:]<N><N>
        wildcards = leftmost.count('*')<N>        if wildcards > max_wildcards:<N>            # Issue #17980: avoid denials of service by refusing more<N>            # than one wildcard per fragment.  A survey of established<N>            # policy among SSL implementations showed it to be a<N>            # reasonable choice.<N>            raise CertificateError(<N>                "too many wildcards in certificate DNS name: " + repr(dn))<N><N>
"""Utilities for extracting common archive formats"""<N><N>import zipfile<N>import tarfile<N>import os<N>import shutil<N>import posixpath<N>import contextlib<N>from distutils.errors import DistutilsError<N><N>from pkg_resources import ensure_directory<N><N>
__all__ = [<N>    "unpack_archive", "unpack_zipfile", "unpack_tarfile", "default_filter",<N>    "UnrecognizedFormat", "extraction_drivers", "unpack_directory",<N>]<N><N><N>class UnrecognizedFormat(DistutilsError):<N>    """Couldn't recognize the archive type"""<N><N>
<N>def default_filter(src, dst):<N>    """The default progress/filter callback; returns True for all files"""<N>    return dst<N><N><N>def unpack_archive(<N>        filename, extract_dir, progress_filter=default_filter,<N>        drivers=None):<N>    """Unpack `filename` to `extract_dir`, or raise ``UnrecognizedFormat``<N><N>
    `progress_filter` is a function taking two arguments: a source path<N>    internal to the archive ('/'-separated), and a filesystem path where it<N>    will be extracted.  The callback must return the desired extract path<N>    (which may be the same as the one passed in), or else ``None`` to skip<N>    that file or directory.  The callback can thus be used to report on the<N>    progress of the extraction, as well as to filter the items extracted or<N>    alter their extraction paths.<N><N>
import platform<N>import ctypes<N><N><N>def windows_only(func):<N>    if platform.system() != 'Windows':<N>        return lambda *args, **kwargs: None<N>    return func<N><N><N>@windows_only<N>def hide_file(path):<N>    """<N>    Set the hidden attribute on a file or directory.<N><N>
    From http://stackoverflow.com/questions/19622133/<N><N>    `path` must be text.<N>    """<N>    __import__('ctypes.wintypes')<N>    SetFileAttributes = ctypes.windll.kernel32.SetFileAttributesW<N>    SetFileAttributes.argtypes = ctypes.wintypes.LPWSTR, ctypes.wintypes.DWORD<N>    SetFileAttributes.restype = ctypes.wintypes.BOOL<N><N>
import pkg_resources<N><N>try:<N>    __version__ = pkg_resources.get_distribution('setuptools').version<N>except Exception:<N>    __version__ = 'unknown'<N>
import ast<N>import io<N>import os<N>import sys<N><N>import warnings<N>import functools<N>import importlib<N>from collections import defaultdict<N>from functools import partial<N>from functools import wraps<N>import contextlib<N><N>from distutils.errors import DistutilsOptionError, DistutilsFileError<N>from setuptools.extern.packaging.version import LegacyVersion, parse<N>from setuptools.extern.packaging.specifiers import SpecifierSet<N><N>
<N>class StaticModule:<N>    """<N>    Attempt to load the module by the name<N>    """<N>    def __init__(self, name):<N>        spec = importlib.util.find_spec(name)<N>        with open(spec.origin) as strm:<N>            src = strm.read()<N>        module = ast.parse(src)<N>        vars(self).update(locals())<N>        del self.self<N><N>
import re<N>import functools<N>import distutils.core<N>import distutils.errors<N>import distutils.extension<N><N>from .monkey import get_unpatched<N><N><N>def _have_cython():<N>    """<N>    Return True if Cython can be imported.<N>    """<N>    cython_impl = 'Cython.Distutils.build_ext'<N>    try:<N>        # from (cython_impl) import build_ext<N>        __import__(cython_impl, fromlist=['build_ext']).build_ext<N>        return True<N>    except Exception:<N>        pass<N>    return False<N><N>
import importlib<N><N>try:<N>    import importlib.util<N>except ImportError:<N>    pass<N><N><N>try:<N>    module_from_spec = importlib.util.module_from_spec<N>except AttributeError:<N>    def module_from_spec(spec):<N>        return spec.loader.load_module(spec.name)<N>
import unicodedata<N>import sys<N><N><N># HFS Plus uses decomposed UTF-8<N>def decompose(path):<N>    if isinstance(path, str):<N>        return unicodedata.normalize('NFD', path)<N>    try:<N>        path = path.decode('utf-8')<N>        path = unicodedata.normalize('NFD', path)<N>        path = path.encode('utf-8')<N>    except UnicodeError:<N>        pass  # Not UTF-8<N>    return path<N><N>
<N>def filesys_decode(path):<N>    """<N>    Ensure that the given path is decoded,<N>    NONE when no expected encoding works<N>    """<N><N>    if isinstance(path, str):<N>        return path<N><N>    fs_enc = sys.getfilesystemencoding() or 'utf-8'<N>    candidates = fs_enc, 'utf-8'<N><N>
    for enc in candidates:<N>        try:<N>            return path.decode(enc)<N>        except UnicodeDecodeError:<N>            continue<N><N><N>def try_encode(string, enc):<N>    "turn unicode encoding into a functional routine"<N>    try:<N>        return string.encode(enc)<N>    except UnicodeEncodeError:<N>        return None<N><N><N>
"""<N>Launch the Python script on the command line after<N>setuptools is bootstrapped via import.<N>"""<N><N># Note that setuptools gets imported implicitly by the<N># invocation of this script using python -m setuptools.launch<N><N>import tokenize<N>import sys<N><N>
<N>def run():<N>    """<N>    Run the script in sys.argv[1] as if it had<N>    been invoked naturally.<N>    """<N>    __builtins__<N>    script_name = sys.argv[1]<N>    namespace = dict(<N>        __file__=script_name,<N>        __name__='__main__',<N>        __doc__=None,<N>    )<N>    sys.argv[:] = sys.argv[1:]<N><N>
    open_ = getattr(tokenize, 'open', open)<N>    with open_(script_name) as fid:<N>        script = fid.read()<N>    norm_script = script.replace('\\r\\n', '\\n')<N>    code = compile(norm_script, script_name, 'exec')<N>    exec(code, namespace)<N><N><N>if __name__ == '__main__':<N>    run()<N><N><N>
"""A PEP 517 interface to setuptools<N><N>Previously, when a user or a command line tool (let's call it a "frontend")<N>needed to make a request of setuptools to take a certain action, for<N>example, generating a list of installation requirements, the frontend would<N>would call "setup.py egg_info" or "setup.py bdist_wheel" on the command line.<N><N>
PEP 517 defines a different method of interfacing with setuptools. Rather<N>than calling "setup.py" directly, the frontend should:<N><N>  1. Set the current directory to the directory with a setup.py file<N>  2. Import this module into a safe python interpreter (one in which<N>     setuptools can potentially set global variables or crash hard).<N>  3. Call one of the functions defined in PEP 517.<N><N>
class SetuptoolsDeprecationWarning(Warning):<N>    """<N>    Base class for warning deprecations in ``setuptools``<N><N>    This class is not derived from ``DeprecationWarning``, and as such is<N>    visible by default.<N>    """<N>
import os<N>import sys<N>import tempfile<N>import operator<N>import functools<N>import itertools<N>import re<N>import contextlib<N>import pickle<N>import textwrap<N>import builtins<N><N>import pkg_resources<N>from distutils.errors import DistutilsError<N>from pkg_resources import working_set<N><N>
if sys.platform.startswith('java'):<N>    import org.python.modules.posix.PosixModule as _os<N>else:<N>    _os = sys.modules[os.name]<N>try:<N>    _file = file<N>except NameError:<N>    _file = None<N>_open = open<N><N><N>__all__ = [<N>    "AbstractSandbox", "DirectorySandbox", "SandboxViolation", "run_setup",<N>]<N><N>
<N>def _execfile(filename, globals, locals=None):<N>    """<N>    Python 3 implementation of execfile.<N>    """<N>    mode = 'rb'<N>    with open(filename, mode) as stream:<N>        script = stream.read()<N>    if locals is None:<N>        locals = globals<N>    code = compile(script, filename, 'exec')<N>    exec(code, globals, locals)<N><N>
<N>@contextlib.contextmanager<N>def save_argv(repl=None):<N>    saved = sys.argv[:]<N>    if repl is not None:<N>        sys.argv[:] = repl<N>    try:<N>        yield saved<N>    finally:<N>        sys.argv[:] = saved<N><N><N>@contextlib.contextmanager<N>def save_path():<N>    saved = sys.path[:]<N>    try:<N>        yield saved<N>    finally:<N>        sys.path[:] = saved<N><N>
<N>@contextlib.contextmanager<N>def override_temp(replacement):<N>    """<N>    Monkey-patch tempfile.tempdir with replacement, ensuring it exists<N>    """<N>    os.makedirs(replacement, exist_ok=True)<N><N>    saved = tempfile.tempdir<N><N>    tempfile.tempdir = replacement<N><N>
    try:<N>        yield<N>    finally:<N>        tempfile.tempdir = saved<N><N><N>@contextlib.contextmanager<N>def pushd(target):<N>    saved = os.getcwd()<N>    os.chdir(target)<N>    try:<N>        yield saved<N>    finally:<N>        os.chdir(saved)<N><N>
"""setuptools.errors<N><N>Provides exceptions used by setuptools modules.<N>"""<N><N>from distutils.errors import DistutilsError<N><N><N>class RemovedCommandError(DistutilsError, RuntimeError):<N>    """Error used for commands that have been removed in setuptools.<N><N>
    Since ``setuptools`` is built on ``distutils``, simply removing a command<N>    from ``setuptools`` will make the behavior fall back to ``distutils``; this<N>    error is raised if a command exists in ``distutils`` but has been actively<N>    removed in ``setuptools``.<N>    """<N><N><N>
"""<N>Re-implementation of find_module and get_frozen_object<N>from the deprecated imp module.<N>"""<N><N>import os<N>import importlib.util<N>import importlib.machinery<N><N>from .py34compat import module_from_spec<N><N><N>PY_SOURCE = 1<N>PY_COMPILED = 2<N>C_EXTENSION = 3<N>C_BUILTIN = 6<N>PY_FROZEN = 7<N><N>
"""<N>Improved support for Microsoft Visual C++ compilers.<N><N>Known supported compilers:<N>--------------------------<N>Microsoft Visual C++ 9.0:<N>    Microsoft Visual C++ Compiler for Python 2.7 (x86, amd64)<N>    Microsoft Windows SDK 6.1 (x86, x64, ia64)<N>    Microsoft Windows SDK 7.0 (x86, x64, ia64)<N><N>
Microsoft Visual C++ 10.0:<N>    Microsoft Windows SDK 7.1 (x86, x64, ia64)<N><N>Microsoft Visual C++ 14.X:<N>    Microsoft Visual C++ Build Tools 2015 (x86, x64, arm)<N>    Microsoft Visual Studio Build Tools 2017 (x86, x64, arm, arm64)<N>    Microsoft Visual Studio Build Tools 2019 (x86, x64, arm, arm64)<N><N>
This may also support compilers shipped with compatible Visual Studio versions.<N>"""<N><N>import json<N>from io import open<N>from os import listdir, pathsep<N>from os.path import join, isfile, isdir, dirname<N>import sys<N>import contextlib<N>import platform<N>import itertools<N>import subprocess<N>import distutils.errors<N>from setuptools.extern.packaging.version import LegacyVersion<N><N>
from .monkey import get_unpatched<N><N>if platform.system() == 'Windows':<N>    import winreg<N>    from os import environ<N>else:<N>    # Mock winreg and environ so the module can be imported on this platform.<N><N>    class winreg:<N>        HKEY_USERS = None<N>        HKEY_CURRENT_USER = None<N>        HKEY_LOCAL_MACHINE = None<N>        HKEY_CLASSES_ROOT = None<N><N>
    environ = dict()<N><N>_msvc9_suppress_errors = (<N>    # msvc9compiler isn't available on some platforms<N>    ImportError,<N><N>    # msvc9compiler raises DistutilsPlatformError in some<N>    # environments. See #1118.<N>    distutils.errors.DistutilsPlatformError,<N>)<N><N>
try:<N>    from distutils.msvc9compiler import Reg<N>except _msvc9_suppress_errors:<N>    pass<N><N><N>def msvc9_find_vcvarsall(version):<N>    """<N>    Patched "distutils.msvc9compiler.find_vcvarsall" to use the standalone<N>    compiler build for Python<N>    (VCForPython / Microsoft Visual C++ Compiler for Python 2.7).<N><N>
"""Wheels support."""<N><N>from distutils.util import get_platform<N>from distutils import log<N>import email<N>import itertools<N>import os<N>import posixpath<N>import re<N>import zipfile<N><N>import pkg_resources<N>import setuptools<N>from pkg_resources import parse_version<N>from setuptools.extern.packaging.tags import sys_tags<N>from setuptools.extern.packaging.utils import canonicalize_name<N>from setuptools.command.egg_info import write_requirements<N><N>
<N>WHEEL_NAME = re.compile(<N>    r"""^(?P<project_name>.+?)-(?P<version>\d.*?)<N>    ((-(?P<build>\d.*?))?-(?P<py_version>.+?)-(?P<abi>.+?)-(?P<platform>.+?)<N>    )\.whl$""",<N>    re.VERBOSE).match<N><N>NAMESPACE_PACKAGE_INIT = \<N>    "__import__('pkg_resources').declare_namespace(__name__)\n"<N><N>
import sys<N>import marshal<N>import contextlib<N>import dis<N>from distutils.version import StrictVersion<N><N>from ._imp import find_module, PY_COMPILED, PY_FROZEN, PY_SOURCE<N>from . import _imp<N><N><N>__all__ = [<N>    'Require', 'find_module', 'get_module_constant', 'extract_constant'<N>]<N><N>
<N>class Require:<N>    """A prerequisite to building or installing a distribution"""<N><N>    def __init__(<N>            self, name, requested_version, module, homepage='',<N>            attribute=None, format=None):<N><N>        if format is None and requested_version is not None:<N>            format = StrictVersion<N><N>
        if format is not None:<N>            requested_version = format(requested_version)<N>            if attribute is None:<N>                attribute = '__version__'<N><N>        self.__dict__.update(locals())<N>        del self.self<N><N>    def full_name(self):<N>        """Return full package/distribution name, w/version"""<N>        if self.requested_version is not None:<N>            return '%s-%s' % (self.name, self.requested_version)<N>        return self.name<N><N>
    def version_ok(self, version):<N>        """Is 'version' sufficiently up-to-date?"""<N>        return self.attribute is None or self.format is None or \<N>            str(version) != "unknown" and version >= self.requested_version<N><N>    def get_version(self, paths=None, default="unknown"):<N>        """Get version number of installed module, 'None', or 'default'<N><N>
        Search 'paths' for module.  If not found, return 'None'.  If found,<N>        return the extracted version attribute, or 'default' if no version<N>        attribute was specified, or the value cannot be determined without<N>        importing the module.  The version is formatted according to the<N>        requirement's version format (if any), unless it is 'None' or the<N>        supplied 'default'.<N>        """<N><N>
        if self.attribute is None:<N>            try:<N>                f, p, i = find_module(self.module, paths)<N>                if f:<N>                    f.close()<N>                return default<N>            except ImportError:<N>                return None<N><N>
        v = get_module_constant(self.module, self.attribute, default, paths)<N><N>        if v is not None and v is not default and self.format is not None:<N>            return self.format(v)<N><N>        return v<N><N>    def is_present(self, paths=None):<N>        """Return true if dependency is present on 'paths'"""<N>        return self.get_version(paths) is not None<N><N>
    def is_current(self, paths=None):<N>        """Return true if dependency is present and up-to-date on 'paths'"""<N>        version = self.get_version(paths)<N>        if version is None:<N>            return False<N>        return self.version_ok(version)<N><N>
<N>def maybe_close(f):<N>    @contextlib.contextmanager<N>    def empty():<N>        yield<N>        return<N>    if not f:<N>        return empty()<N><N>    return contextlib.closing(f)<N><N><N>def get_module_constant(module, symbol, default=-1, paths=None):<N>    """Find 'module' by searching 'paths', and extract 'symbol'<N><N>
    Return 'None' if 'module' does not exist on 'paths', or it does not define<N>    'symbol'.  If the module defines 'symbol' as a constant, return the<N>    constant.  Otherwise, return 'default'."""<N><N>    try:<N>        f, path, (suffix, mode, kind) = info = find_module(module, paths)<N>    except ImportError:<N>        # Module doesn't exist<N>        return None<N><N>
"""PyPI and direct package downloading"""<N>import sys<N>import os<N>import re<N>import io<N>import shutil<N>import socket<N>import base64<N>import hashlib<N>import itertools<N>import warnings<N>import configparser<N>import html<N>import http.client<N>import urllib.parse<N>import urllib.request<N>import urllib.error<N>from functools import wraps<N><N>
import setuptools<N>from pkg_resources import (<N>    CHECKOUT_DIST, Distribution, BINARY_DIST, normalize_path, SOURCE_DIST,<N>    Environment, find_distributions, safe_name, safe_version,<N>    to_filename, Requirement, DEVELOP_DIST, EGG_DIST,<N>)<N>from setuptools import ssl_support<N>from distutils import log<N>from distutils.errors import DistutilsError<N>from fnmatch import translate<N>from setuptools.wheel import Wheel<N><N>
EGG_FRAGMENT = re.compile(r'^egg=([-A-Za-z0-9_.+!]+)$')<N>HREF = re.compile(r"""href\s*=\s*['"]?([^'"> ]+)""", re.I)<N>PYPI_MD5 = re.compile(<N>    r'<a href="([^"#]+)">([^<]+)</a>\n\s+\(<a (?:title="MD5 hash"\n\s+)'<N>    r'href="[^?]+\?:action=show_md5&amp;digest=([0-9a-f]{32})">md5</a>\)'<N>)<N>URL_SCHEME = re.compile('([-+.a-z0-9]{2,}):', re.I).match<N>EXTENSIONS = ".tar.gz .tar.bz2 .tar .zip .tgz".split()<N><N>
__all__ = [<N>    'PackageIndex', 'distros_for_url', 'parse_bdist_wininst',<N>    'interpret_distro_name',<N>]<N><N>_SOCKET_TIMEOUT = 15<N><N>_tmpl = "setuptools/{setuptools.__version__} Python-urllib/{py_major}"<N>user_agent = _tmpl.format(<N>    py_major='{}.{}'.format(*sys.version_info), setuptools=setuptools)<N><N>
<N>def parse_requirement_arg(spec):<N>    try:<N>        return Requirement.parse(spec)<N>    except ValueError as e:<N>        raise DistutilsError(<N>            "Not a URL, existing file, or requirement spec: %r" % (spec,)<N>        ) from e<N><N><N>def parse_bdist_wininst(name):<N>    """Return (base,pyversion) or (None,None) for possible .exe name"""<N><N>
"""<N>Monkey patching of distutils.<N>"""<N><N>import sys<N>import distutils.filelist<N>import platform<N>import types<N>import functools<N>from importlib import import_module<N>import inspect<N><N>import setuptools<N><N>__all__ = []<N>"""<N>Everything is private. Contact the project team<N>if you think you need this functionality.<N>"""<N><N>
"""distutils.filelist<N><N>Provides the FileList class, used for poking about the filesystem<N>and building lists of files.<N>"""<N><N>import os, re<N>import fnmatch<N>import functools<N>from distutils.util import convert_path<N>from distutils.errors import DistutilsTemplateError, DistutilsInternalError<N>from distutils import log<N><N>
"""distutils.fancy_getopt<N><N>Wrapper around the standard getopt module that provides the following<N>additional features:<N>  * short and long options are tied together<N>  * options have help strings, so fancy_getopt could potentially<N>    create a complete usage summary<N>  * options set attributes of a passed-in object<N>"""<N><N>
import sys, string, re<N>import getopt<N>from distutils.errors import *<N><N># Much like command_re in distutils.core, this is close to but not quite<N># the same as a Python NAME -- except, in the spirit of most GNU<N># utilities, we use '-' in place of '_'.  (The spirit of LISP lives on!)<N># The similarities to NAME are again not a coincidence...<N>longopt_pat = r'[a-zA-Z](?:[a-zA-Z0-9-]*)'<N>longopt_re = re.compile(r'^%s$' % longopt_pat)<N><N>
# For recognizing "negative alias" options, eg. "quiet=!verbose"<N>neg_alias_re = re.compile("^(%s)=!(%s)$" % (longopt_pat, longopt_pat))<N><N># This is used to translate long options to legitimate Python identifiers<N># (for use as attributes of some object).<N>longopt_xlate = str.maketrans('-', '_')<N><N>
"""Module for parsing and testing package version predicate strings.<N>"""<N>import re<N>import distutils.version<N>import operator<N><N><N>re_validPackage = re.compile(r"(?i)^\s*([a-z_]\w*(?:\.[a-z_]\w*)*)(.*)",<N>    re.ASCII)<N># (package) (rest)<N><N>re_paren = re.compile(r"^\s*\((.*)\)\s*$") # (list) inside of parentheses<N>re_splitComparison = re.compile(r"^\s*(<=|>=|<|>|!=|==)\s*([^\s,]+)\s*$")<N># (comp) (version)<N><N>
<N>def splitUp(pred):<N>    """Parse a single version comparison.<N><N>    Return (comparison string, StrictVersion)<N>    """<N>    res = re_splitComparison.match(pred)<N>    if not res:<N>        raise ValueError("bad package restriction syntax: %r" % pred)<N>    comp, verStr = res.groups()<N>    return (comp, distutils.version.StrictVersion(verStr))<N><N>
compmap = {"<": operator.lt, "<=": operator.le, "==": operator.eq,<N>           ">": operator.gt, ">=": operator.ge, "!=": operator.ne}<N><N>class VersionPredicate:<N>    """Parse and test package version predicates.<N><N>    >>> v = VersionPredicate('pyepat.abc (>1.0, <3333.3a1, !=1555.1b3)')<N><N>
    The `name` attribute provides the full dotted name that is given::<N><N>    >>> v.name<N>    'pyepat.abc'<N><N>    The str() of a `VersionPredicate` provides a normalized<N>    human-readable version of the expression::<N><N>    >>> print(v)<N>    pyepat.abc (> 1.0, < 3333.3a1, != 1555.1b3)<N><N>
    The `satisfied_by()` method can be used to determine with a given<N>    version number is included in the set described by the version<N>    restrictions::<N><N>    >>> v.satisfied_by('1.1')<N>    True<N>    >>> v.satisfied_by('1.4')<N>    True<N>    >>> v.satisfied_by('1.0')<N>    False<N>    >>> v.satisfied_by('4444.4')<N>    False<N>    >>> v.satisfied_by('1555.1b3')<N>    False<N><N>
    `VersionPredicate` is flexible in accepting extra whitespace::<N><N>    >>> v = VersionPredicate(' pat( ==  0.1  )  ')<N>    >>> v.name<N>    'pat'<N>    >>> v.satisfied_by('0.1')<N>    True<N>    >>> v.satisfied_by('0.2')<N>    False<N><N>    If any version numbers passed in do not conform to the<N>    restrictions of `StrictVersion`, a `ValueError` is raised::<N><N>
    >>> v = VersionPredicate('p1.p2.p3.p4(>=1.0, <=1.3a1, !=1.2zb3)')<N>    Traceback (most recent call last):<N>      ...<N>    ValueError: invalid version number '1.2zb3'<N><N>    It the module or package name given does not conform to what's<N>    allowed as a legal module or package name, `ValueError` is<N>    raised::<N><N>
    >>> v = VersionPredicate('foo-bar')<N>    Traceback (most recent call last):<N>      ...<N>    ValueError: expected parenthesized list: '-bar'<N><N>    >>> v = VersionPredicate('foo bar (12.21)')<N>    Traceback (most recent call last):<N>      ...<N>    ValueError: expected parenthesized list: 'bar (12.21)'<N><N>
"""distutils.msvccompiler<N><N>Contains MSVCCompiler, an implementation of the abstract CCompiler class<N>for the Microsoft Visual Studio.<N>"""<N><N># Written by Perry Stoll<N># hacked by Robin Becker and Thomas Heller to do a better job of<N>#   finding DevStudio (through the registry)<N><N>
import sys, os<N>from distutils.errors import \<N>     DistutilsExecError, DistutilsPlatformError, \<N>     CompileError, LibError, LinkError<N>from distutils.ccompiler import \<N>     CCompiler, gen_lib_options<N>from distutils import log<N><N>_can_read_reg = False<N>try:<N>    import winreg<N><N>
    _can_read_reg = True<N>    hkey_mod = winreg<N><N>    RegOpenKeyEx = winreg.OpenKeyEx<N>    RegEnumKey = winreg.EnumKey<N>    RegEnumValue = winreg.EnumValue<N>    RegError = winreg.error<N><N>except ImportError:<N>    try:<N>        import win32api<N>        import win32con<N>        _can_read_reg = True<N>        hkey_mod = win32con<N><N>
        RegOpenKeyEx = win32api.RegOpenKeyEx<N>        RegEnumKey = win32api.RegEnumKey<N>        RegEnumValue = win32api.RegEnumValue<N>        RegError = win32api.error<N>    except ImportError:<N>        log.info("Warning: Can't read registry to find the "<N>                 "necessary compiler setting\n"<N>                 "Make sure that Python modules winreg, "<N>                 "win32api or win32con are installed.")<N>        pass<N><N>
"""distutils<N><N>The main package for the Python Module Distribution Utilities.  Normally<N>used from a setup script as<N><N>   from distutils.core import setup<N><N>   setup (...)<N>"""<N><N>import sys<N><N>__version__ = sys.version[:sys.version.index(' ')]<N><N>local = True<N>
def aix_platform(osname, version, release):<N>    try:<N>        import _aix_support<N>        return _aix_support.aix_platform()<N>    except ImportError:<N>        pass<N>    return "%s-%s.%s" % (osname, version, release)<N>
"""Provide access to Python's configuration information.  The specific<N>configuration variables available depend heavily on the platform and<N>configuration.  The values may be retrieved using<N>get_config_var(name), and the list of variables is available via<N>get_config_vars().keys().  Additional convenience functions are also<N>available.<N><N>
Written by:   Fred L. Drake, Jr.<N>Email:        <fdrake@acm.org><N>"""<N><N>import _imp<N>import os<N>import re<N>import sys<N><N>from .errors import DistutilsPlatformError<N><N>IS_PYPY = '__pypy__' in sys.builtin_module_names<N><N># These are needed in a couple of spots, so just compute them once.<N>PREFIX = os.path.normpath(sys.prefix)<N>EXEC_PREFIX = os.path.normpath(sys.exec_prefix)<N>BASE_PREFIX = os.path.normpath(sys.base_prefix)<N>BASE_EXEC_PREFIX = os.path.normpath(sys.base_exec_prefix)<N><N>
"""distutils.dist<N><N>Provides the Distribution class, which represents the module distribution<N>being built/installed/distributed.<N>"""<N><N>import sys<N>import os<N>import re<N>from email import message_from_file<N><N>try:<N>    import warnings<N>except ImportError:<N>    warnings = None<N><N>
"""A simple log mechanism styled after PEP 282."""<N><N># The class here is styled after PEP 282 so that it could later be<N># replaced with a standard Python logging implementation.<N><N>DEBUG = 1<N>INFO = 2<N>WARN = 3<N>ERROR = 4<N>FATAL = 5<N><N>import sys<N><N>
class Log:<N><N>    def __init__(self, threshold=WARN):<N>        self.threshold = threshold<N><N>    def _log(self, level, msg, args):<N>        if level not in (DEBUG, INFO, WARN, ERROR, FATAL):<N>            raise ValueError('%s wrong log level' % str(level))<N><N>
"""distutils.archive_util<N><N>Utility functions for creating archive files (tarballs, zip files,<N>that sort of thing)."""<N><N>import os<N>from warnings import warn<N>import sys<N><N>try:<N>    import zipfile<N>except ImportError:<N>    zipfile = None<N><N>
<N>from distutils.errors import DistutilsExecError<N>from distutils.spawn import spawn<N>from distutils.dir_util import mkpath<N>from distutils import log<N><N>try:<N>    from pwd import getpwnam<N>except ImportError:<N>    getpwnam = None<N><N>try:<N>    from grp import getgrnam<N>except ImportError:<N>    getgrnam = None<N><N>
def _get_gid(name):<N>    """Returns a gid, given a group name."""<N>    if getgrnam is None or name is None:<N>        return None<N>    try:<N>        result = getgrnam(name)<N>    except KeyError:<N>        result = None<N>    if result is not None:<N>        return result[2]<N>    return None<N><N>
def _get_uid(name):<N>    """Returns an uid, given a user name."""<N>    if getpwnam is None or name is None:<N>        return None<N>    try:<N>        result = getpwnam(name)<N>    except KeyError:<N>        result = None<N>    if result is not None:<N>        return result[2]<N>    return None<N><N>
def make_tarball(base_name, base_dir, compress="gzip", verbose=0, dry_run=0,<N>                 owner=None, group=None):<N>    """Create a (possibly compressed) tar file from all the files under<N>    'base_dir'.<N><N>    'compress' must be "gzip" (the default), "bzip2", "xz", "compress", or<N>    None.  ("compress" will be deprecated in Python 3.2)<N><N>
    'owner' and 'group' can be used to define an owner and a group for the<N>    archive that is being built. If not provided, the current owner and group<N>    will be used.<N><N>    The output tar file will be named 'base_dir' +  ".tar", possibly plus<N>    the appropriate compression extension (".gz", ".bz2", ".xz" or ".Z").<N><N>
    Returns the output filename.<N>    """<N>    tar_compression = {'gzip': 'gz', 'bzip2': 'bz2', 'xz': 'xz', None: '',<N>                       'compress': ''}<N>    compress_ext = {'gzip': '.gz', 'bzip2': '.bz2', 'xz': '.xz',<N>                    'compress': '.Z'}<N><N>
    # flags for compression program, each element of list will be an argument<N>    if compress is not None and compress not in compress_ext.keys():<N>        raise ValueError(<N>              "bad value for 'compress': must be None, 'gzip', 'bzip2', "<N>              "'xz' or 'compress'")<N><N>
    archive_name = base_name + '.tar'<N>    if compress != 'compress':<N>        archive_name += compress_ext.get(compress, '')<N><N>    mkpath(os.path.dirname(archive_name), dry_run=dry_run)<N><N>    # creating the tarball<N>    import tarfile  # late import so Python build itself doesn't break<N><N>
    log.info('Creating tar archive')<N><N>    uid = _get_uid(owner)<N>    gid = _get_gid(group)<N><N>    def _set_uid_gid(tarinfo):<N>        if gid is not None:<N>            tarinfo.gid = gid<N>            tarinfo.gname = group<N>        if uid is not None:<N>            tarinfo.uid = uid<N>            tarinfo.uname = owner<N>        return tarinfo<N><N>
#<N># distutils/version.py<N>#<N># Implements multiple version numbering conventions for the<N># Python Module Distribution Utilities.<N>#<N># $Id$<N>#<N><N>"""Provides classes to represent module version numbers (one class for<N>each style of version numbering).  There are currently two such classes<N>implemented: StrictVersion and LooseVersion.<N><N>
"""distutils.core<N><N>The only module that needs to be imported to use the Distutils; provides<N>the 'setup' function (which is to be called from the setup script).  Also<N>indirectly provides the Distribution and Command classes, although they are<N>really defined in distutils.dist and distutils.cmd.<N>"""<N><N>
import os<N>import sys<N><N>from distutils.debug import DEBUG<N>from distutils.errors import *<N><N># Mainly import these so setup scripts can "from distutils.core import" them.<N>from distutils.dist import Distribution<N>from distutils.cmd import Command<N>from distutils.config import PyPIRCCommand<N>from distutils.extension import Extension<N><N>
# This is a barebones help message generated displayed when the user<N># runs the setup script with no arguments at all.  More useful help<N># is generated with various --help options: global help, list commands,<N># and per-command help.<N>USAGE = """\<N>usage: %(script)s [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]<N>   or: %(script)s --help [cmd1 cmd2 ...]<N>   or: %(script)s --help-commands<N>   or: %(script)s cmd --help<N>"""<N><N>
"""distutils.pypirc<N><N>Provides the PyPIRCCommand class, the base class for the command classes<N>that uses .pypirc in the distutils.command package.<N>"""<N>import os<N>from configparser import RawConfigParser<N><N>from distutils.cmd import Command<N><N>
DEFAULT_PYPIRC = """\<N>[distutils]<N>index-servers =<N>    pypi<N><N>[pypi]<N>username:%s<N>password:%s<N>"""<N><N>class PyPIRCCommand(Command):<N>    """Base command that knows how to handle the .pypirc file<N>    """<N>    DEFAULT_REPOSITORY = 'https://upload.pypi.org/legacy/'<N>    DEFAULT_REALM = 'pypi'<N>    repository = None<N>    realm = None<N><N>
    user_options = [<N>        ('repository=', 'r',<N>         "url of repository [default: %s]" % \<N>            DEFAULT_REPOSITORY),<N>        ('show-response', None,<N>         'display full response text from server')]<N><N>    boolean_options = ['show-response']<N><N>
    def _get_rc_file(self):<N>        """Returns rc file path."""<N>        return os.path.join(os.path.expanduser('~'), '.pypirc')<N><N>    def _store_pypirc(self, username, password):<N>        """Creates a default .pypirc file."""<N>        rc = self._get_rc_file()<N>        with os.fdopen(os.open(rc, os.O_CREAT | os.O_WRONLY, 0o600), 'w') as f:<N>            f.write(DEFAULT_PYPIRC % (username, password))<N><N>
    def _read_pypirc(self):<N>        """Reads the .pypirc file."""<N>        rc = self._get_rc_file()<N>        if os.path.exists(rc):<N>            self.announce('Using PyPI login from %s' % rc)<N>            repository = self.repository or self.DEFAULT_REPOSITORY<N><N>
"""distutils.msvc9compiler<N><N>Contains MSVCCompiler, an implementation of the abstract CCompiler class<N>for the Microsoft Visual Studio 2008.<N><N>The module is compatible with VS 2005 and VS 2008. You can find legacy support<N>for older versions of VS in distutils.msvccompiler.<N>"""<N><N>
# Written by Perry Stoll<N># hacked by Robin Becker and Thomas Heller to do a better job of<N>#   finding DevStudio (through the registry)<N># ported to VS2005 and VS 2008 by Christian Heimes<N><N>import os<N>import subprocess<N>import sys<N>import re<N><N>
from distutils.errors import DistutilsExecError, DistutilsPlatformError, \<N>                             CompileError, LibError, LinkError<N>from distutils.ccompiler import CCompiler, gen_lib_options<N>from distutils import log<N>from distutils.util import get_platform<N><N>
import winreg<N><N>RegOpenKeyEx = winreg.OpenKeyEx<N>RegEnumKey = winreg.EnumKey<N>RegEnumValue = winreg.EnumValue<N>RegError = winreg.error<N><N>HKEYS = (winreg.HKEY_USERS,<N>         winreg.HKEY_CURRENT_USER,<N>         winreg.HKEY_LOCAL_MACHINE,<N>         winreg.HKEY_CLASSES_ROOT)<N><N>
import sys<N>import subprocess<N><N><N>def __optim_args_from_interpreter_flags():<N>    """Return a list of command-line arguments reproducing the current<N>    optimization settings in sys.flags."""<N>    args = []<N>    value = sys.flags.optimize<N>    if value > 0:<N>        args.append("-" + "O" * value)<N>    return args<N><N><N>_optim_args_from_interpreter_flags = getattr(<N>    subprocess,<N>    "_optim_args_from_interpreter_flags",<N>    __optim_args_from_interpreter_flags,<N>)<N>
"""distutils.dep_util<N><N>Utility functions for simple, timestamp-based dependency of files<N>and groups of files; also, function based entirely on such<N>timestamp dependency analysis."""<N><N>import os<N>from distutils.errors import DistutilsFileError<N><N>
import os<N><N># If DISTUTILS_DEBUG is anything other than the empty string, we run in<N># debug mode.<N>DEBUG = os.environ.get('DISTUTILS_DEBUG')<N>
"""distutils.cygwinccompiler<N><N>Provides the CygwinCCompiler class, a subclass of UnixCCompiler that<N>handles the Cygwin port of the GNU C compiler to Windows.  It also contains<N>the Mingw32CCompiler class which handles the mingw32 port of GCC (same as<N>cygwin in no-cygwin mode).<N>"""<N><N>
"""distutils.dir_util<N><N>Utility functions for manipulating directories and directory trees."""<N><N>import os<N>import errno<N>from distutils.errors import DistutilsFileError, DistutilsInternalError<N>from distutils import log<N><N># cache for by mkpath() -- in addition to cheapening redundant calls,<N># eliminates redundant "creating /foo/bar/baz" messages in dry-run mode<N>_path_created = {}<N><N>
# I don't use os.makedirs because a) it's new to Python 1.5.2, and<N># b) it blows up if the directory already exists (I want to silently<N># succeed in that case).<N>def mkpath(name, mode=0o777, verbose=1, dry_run=0):<N>    """Create a directory and any missing ancestor directories.<N><N>
    If the directory already exists (or if 'name' is the empty string, which<N>    means the current directory, which of course exists), then do nothing.<N>    Raise DistutilsFileError if unable to create some directory along the way<N>    (eg. some sub-path exists, but is a file rather than a directory).<N>    If 'verbose' is true, print a one-line summary of each mkdir to stdout.<N>    Return the list of directories actually created.<N>    """<N><N>
    global _path_created<N><N>    # Detect a common bug -- name is None<N>    if not isinstance(name, str):<N>        raise DistutilsInternalError(<N>              "mkpath: 'name' must be a string (got %r)" % (name,))<N><N>    # XXX what's the better way to handle verbosity? print as we create<N>    # each directory in the path (the current behaviour), or only announce<N>    # the creation of the whole path? (quite easy to do the latter since<N>    # we're not using a recursive algorithm)<N><N>
    name = os.path.normpath(name)<N>    created_dirs = []<N>    if os.path.isdir(name) or name == '':<N>        return created_dirs<N>    if _path_created.get(os.path.abspath(name)):<N>        return created_dirs<N><N>    (head, tail) = os.path.split(name)<N>    tails = [tail]                      # stack of lone dirs to create<N><N>
    while head and tail and not os.path.isdir(head):<N>        (head, tail) = os.path.split(head)<N>        tails.insert(0, tail)          # push next higher dir onto stack<N><N>    # now 'head' contains the deepest directory that already exists<N>    # (that is, the child of 'head' in 'name' is the highest directory<N>    # that does *not* exist)<N>    for d in tails:<N>        #print "head = %s, d = %s: " % (head, d),<N>        head = os.path.join(head, d)<N>        abs_head = os.path.abspath(head)<N><N>
        if _path_created.get(abs_head):<N>            continue<N><N>        if verbose >= 1:<N>            log.info("creating %s", head)<N><N>        if not dry_run:<N>            try:<N>                os.mkdir(head, mode)<N>            except OSError as exc:<N>                if not (exc.errno == errno.EEXIST and os.path.isdir(head)):<N>                    raise DistutilsFileError(<N>                          "could not create '%s': %s" % (head, exc.args[-1]))<N>            created_dirs.append(head)<N><N>
"""distutils.bcppcompiler<N><N>Contains BorlandCCompiler, an implementation of the abstract CCompiler class<N>for the Borland C++ compiler.<N>"""<N><N># This implementation by Lyle Johnson, based on the original msvccompiler.py<N># module and using the directions originally published by Gordon Williams.<N><N>
# XXX looks like there's a LOT of overlap between these two classes:<N># someone should sit down and factor out the common code as<N># WindowsCCompiler!  --GPW<N><N><N>import os<N>from distutils.errors import \<N>     DistutilsExecError, \<N>     CompileError, LibError, LinkError, UnknownFileError<N>from distutils.ccompiler import \<N>     CCompiler, gen_preprocess_options<N>from distutils.file_util import write_file<N>from distutils.dep_util import newer<N>from distutils import log<N><N>
"""distutils.errors<N><N>Provides exceptions used by the Distutils modules.  Note that Distutils<N>modules may raise standard exceptions; in particular, SystemExit is<N>usually raised for errors that are obviously the end-user's fault<N>(eg. bad command-line arguments).<N><N>
This module is safe to use in "from ... import *" mode; it only exports<N>symbols whose names start with "Distutils" and end with "Error"."""<N><N>class DistutilsError (Exception):<N>    """The root of all Distutils evil."""<N>    pass<N><N>class DistutilsModuleError (DistutilsError):<N>    """Unable to load an expected module, or to find an expected class<N>    within some module (in particular, command modules and classes)."""<N>    pass<N><N>
class DistutilsClassError (DistutilsError):<N>    """Some command class (or possibly distribution class, if anyone<N>    feels a need to subclass Distribution) is found not to be holding<N>    up its end of the bargain, ie. implementing some part of the<N>    "command "interface."""<N>    pass<N><N>
class DistutilsGetoptError (DistutilsError):<N>    """The option table provided to 'fancy_getopt()' is bogus."""<N>    pass<N><N>class DistutilsArgError (DistutilsError):<N>    """Raised by fancy_getopt in response to getopt.error -- ie. an<N>    error in the command line usage."""<N>    pass<N><N>
"""distutils.spawn<N><N>Provides the 'spawn()' function, a front-end to various platform-<N>specific functions for launching another program in a sub-process.<N>Also provides the 'find_executable()' to search the path for a given<N>executable name.<N>"""<N><N>
import sys<N>import os<N>import subprocess<N><N>from distutils.errors import DistutilsPlatformError, DistutilsExecError<N>from distutils.debug import DEBUG<N>from distutils import log<N><N><N>if sys.platform == 'darwin':<N>    _cfg_target = None<N>    _cfg_target_split = None<N><N>
<N>def spawn(cmd, search_path=1, verbose=0, dry_run=0, env=None):<N>    """Run another program, specified as a command list 'cmd', in a new process.<N><N>    'cmd' is just the argument list for the new process, ie.<N>    cmd[0] is the program to run and cmd[1:] are the rest of its arguments.<N>    There is no way to run a program with a name different from that of its<N>    executable.<N><N>
    If 'search_path' is true (the default), the system's executable<N>    search path will be used to find the program; otherwise, cmd[0]<N>    must be the exact path to the executable.  If 'dry_run' is true,<N>    the command will not actually be run.<N><N>
    Raise DistutilsExecError if running the program fails in any way; just<N>    return on success.<N>    """<N>    # cmd is documented as a list, but just in case some code passes a tuple<N>    # in, protect our %-formatting code against horrible death<N>    cmd = list(cmd)<N><N>
    log.info(' '.join(cmd))<N>    if dry_run:<N>        return<N><N>    if search_path:<N>        executable = find_executable(cmd[0])<N>        if executable is not None:<N>            cmd[0] = executable<N><N>    env = env if env is not None else dict(os.environ)<N><N>
"""distutils.file_util<N><N>Utility functions for operating on single files.<N>"""<N><N>import os<N>from distutils.errors import DistutilsFileError<N>from distutils import log<N><N># for generating verbose output in 'copy_file()'<N>_copy_action = { None:   'copying',<N>                 'hard': 'hard linking',<N>                 'sym':  'symbolically linking' }<N><N>
"""distutils.cmd<N><N>Provides the Command class, the base class for the command classes<N>in the distutils.command package.<N>"""<N><N>import sys, os, re<N>from distutils.errors import DistutilsOptionError<N>from distutils import util, dir_util, file_util, archive_util, dep_util<N>from distutils import log<N><N>
"""distutils._msvccompiler<N><N>Contains MSVCCompiler, an implementation of the abstract CCompiler class<N>for Microsoft Visual Studio 2015.<N><N>The module is compatible with VS 2015 and later. You can find legacy support<N>for older versions in distutils.msvc9compiler and distutils.msvccompiler.<N>"""<N><N>
# Written by Perry Stoll<N># hacked by Robin Becker and Thomas Heller to do a better job of<N>#   finding DevStudio (through the registry)<N># ported to VS 2005 and VS 2008 by Christian Heimes<N># ported to VS 2015 by Steve Dower<N><N>import os<N>import subprocess<N>import contextlib<N>import warnings<N>import unittest.mock<N>with contextlib.suppress(ImportError):<N>    import winreg<N><N>
from distutils.errors import DistutilsExecError, DistutilsPlatformError, \<N>                             CompileError, LibError, LinkError<N>from distutils.ccompiler import CCompiler, gen_lib_options<N>from distutils import log<N>from distutils.util import get_platform<N><N>
from itertools import count<N><N>def _find_vc2015():<N>    try:<N>        key = winreg.OpenKeyEx(<N>            winreg.HKEY_LOCAL_MACHINE,<N>            r"Software\Microsoft\VisualStudio\SxS\VC7",<N>            access=winreg.KEY_READ | winreg.KEY_WOW64_32KEY<N>        )<N>    except OSError:<N>        log.debug("Visual C++ is not registered")<N>        return None, None<N><N>
"""distutils.util<N><N>Miscellaneous utility functions -- anything that doesn't fit into<N>one of the other *util.py modules.<N>"""<N><N>import os<N>import re<N>import importlib.util<N>import string<N>import sys<N>from distutils.errors import DistutilsPlatformError<N>from distutils.dep_util import newer<N>from distutils.spawn import spawn<N>from distutils import log<N>from distutils.errors import DistutilsByteCompileError<N>from .py35compat import _optim_args_from_interpreter_flags<N><N>
<N>def get_host_platform():<N>    """Return a string that identifies the current platform.  This is used mainly to<N>    distinguish platform-specific build directories and platform-specific built<N>    distributions.  Typically includes the OS name and version and the<N>    architecture (as supplied by 'os.uname()'), although the exact information<N>    included depends on the OS; eg. on Linux, the kernel version isn't<N>    particularly important.<N><N>
    Examples of returned values:<N>       linux-i586<N>       linux-alpha (?)<N>       solaris-2.6-sun4u<N><N>    Windows will return one of:<N>       win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)<N>       win32 (all others - specifically, sys.platform is returned)<N><N>
    For other non-POSIX platforms, currently just returns 'sys.platform'.<N><N>    """<N>    if os.name == 'nt':<N>        if 'amd64' in sys.version.lower():<N>            return 'win-amd64'<N>        if '(arm)' in sys.version.lower():<N>            return 'win-arm32'<N>        if '(arm64)' in sys.version.lower():<N>            return 'win-arm64'<N>        return sys.platform<N><N>
    # Set for cross builds explicitly<N>    if "_PYTHON_HOST_PLATFORM" in os.environ:<N>        return os.environ["_PYTHON_HOST_PLATFORM"]<N><N>    if os.name != "posix" or not hasattr(os, 'uname'):<N>        # XXX what about the architecture? NT is Intel or Alpha,<N>        # Mac OS is M68k or PPC, etc.<N>        return sys.platform<N><N>
    # Try to distinguish various flavours of Unix<N><N>    (osname, host, release, version, machine) = os.uname()<N><N>    # Convert the OS name to lowercase, remove '/' characters, and translate<N>    # spaces (for "Power Macintosh")<N>    osname = osname.lower().replace('/', '')<N>    machine = machine.replace(' ', '_')<N>    machine = machine.replace('/', '-')<N><N>
"""distutils.ccompiler<N><N>Contains CCompiler, an abstract base class that defines the interface<N>for the Distutils compiler abstraction model."""<N><N>import sys, os, re<N>from distutils.errors import *<N>from distutils.spawn import spawn<N>from distutils.file_util import move_file<N>from distutils.dir_util import mkpath<N>from distutils.dep_util import newer_group<N>from distutils.util import split_quoted, execute<N>from distutils import log<N><N>
"""distutils.command.clean<N><N>Implements the Distutils 'clean' command."""<N><N># contributed by Bastian Kleineidam <calvin@cs.uni-sb.de>, added 2000-03-18<N><N>import os<N>from distutils.core import Command<N>from distutils.dir_util import remove_tree<N>from distutils import log<N><N>
"""distutils.command.install_scripts<N><N>Implements the Distutils 'install_scripts' command, for installing<N>Python scripts."""<N><N># contributed by Bastian Kleineidam<N><N>import os<N>from distutils.core import Command<N>from distutils import log<N>from stat import ST_MODE<N><N>
<N>class install_scripts(Command):<N><N>    description = "install scripts (Python or otherwise)"<N><N>    user_options = [<N>        ('install-dir=', 'd', "directory to install scripts to"),<N>        ('build-dir=','b', "build directory (where to install from)"),<N>        ('force', 'f', "force installation (overwrite existing files)"),<N>        ('skip-build', None, "skip the build steps"),<N>    ]<N><N>
"""distutils.command.bdist_dumb<N><N>Implements the Distutils 'bdist_dumb' command (create a "dumb" built<N>distribution -- i.e., just an archive to be unpacked under $prefix or<N>$exec_prefix)."""<N><N>import os<N>from distutils.core import Command<N>from distutils.util import get_platform<N>from distutils.dir_util import remove_tree, ensure_relative<N>from distutils.errors import *<N>from distutils.sysconfig import get_python_version<N>from distutils import log<N><N>
"""distutils.command.install_data<N><N>Implements the Distutils 'install_data' command, for installing<N>platform-independent data files."""<N><N># contributed by Bastian Kleineidam<N><N>import os<N>from distutils.core import Command<N>from distutils.util import change_root, convert_path<N><N>
class install_data(Command):<N><N>    description = "install data files"<N><N>    user_options = [<N>        ('install-dir=', 'd',<N>         "base directory for installing data files "<N>         "(default: installation base dir)"),<N>        ('root=', None,<N>         "install everything relative to this alternate root directory"),<N>        ('force', 'f', "force installation (overwrite existing files)"),<N>        ]<N><N>
    boolean_options = ['force']<N><N>    def initialize_options(self):<N>        self.install_dir = None<N>        self.outfiles = []<N>        self.root = None<N>        self.force = 0<N>        self.data_files = self.distribution.data_files<N>        self.warn_dir = 1<N><N>
    def finalize_options(self):<N>        self.set_undefined_options('install',<N>                                   ('install_data', 'install_dir'),<N>                                   ('root', 'root'),<N>                                   ('force', 'force'),<N>                                  )<N><N>
"""distutils.command.check<N><N>Implements the Distutils 'check' command.<N>"""<N>from distutils.core import Command<N>from distutils.errors import DistutilsSetupError<N><N>try:<N>    # docutils is installed<N>    from docutils.utils import Reporter<N>    from docutils.parsers.rst import Parser<N>    from docutils import frontend<N>    from docutils import nodes<N><N>
    class SilentReporter(Reporter):<N><N>        def __init__(self, source, report_level, halt_level, stream=None,<N>                     debug=0, encoding='ascii', error_handler='replace'):<N>            self.messages = []<N>            Reporter.__init__(self, source, report_level, halt_level, stream,<N>                              debug, encoding, error_handler)<N><N>
        def system_message(self, level, message, *children, **kwargs):<N>            self.messages.append((level, message, children, kwargs))<N>            return nodes.system_message(message, level=level,<N>                                        type=self.levels[level],<N>                                        *children, **kwargs)<N><N>
"""distutils.command.build<N><N>Implements the Distutils 'build' command."""<N><N>import sys, os<N>from distutils.core import Command<N>from distutils.errors import DistutilsOptionError<N>from distutils.util import get_platform<N><N><N>def show_compilers():<N>    from distutils.ccompiler import show_compilers<N>    show_compilers()<N><N>
"""distutils.command.register<N><N>Implements the Distutils 'register' command (register with the repository).<N>"""<N><N># created 2002/10/21, Richard Jones<N><N>import getpass<N>import io<N>import urllib.parse, urllib.request<N>from warnings import warn<N><N>
"""distutils.command.bdist_wininst<N><N>Implements the Distutils 'bdist_wininst' command: create a windows installer<N>exe-program."""<N><N>import os<N>import sys<N>import warnings<N>from distutils.core import Command<N>from distutils.util import get_platform<N>from distutils.dir_util import remove_tree<N>from distutils.errors import *<N>from distutils.sysconfig import get_python_version<N>from distutils import log<N><N>
"""distutils.command.build_scripts<N><N>Implements the Distutils 'build_scripts' command."""<N><N>import os, re<N>from stat import ST_MODE<N>from distutils import sysconfig<N>from distutils.core import Command<N>from distutils.dep_util import newer<N>from distutils.util import convert_path, Mixin2to3<N>from distutils import log<N>import tokenize<N><N>
# check if Python is called on the first line with this expression<N>first_line_re = re.compile(b'^#!.*python[0-9.]*([ \t].*)?$')<N><N>class build_scripts(Command):<N><N>    description = "\"build\" scripts (copy and fixup #! line)"<N><N>    user_options = [<N>        ('build-dir=', 'd', "directory to \"build\" (copy) to"),<N>        ('force', 'f', "forcibly build everything (ignore file timestamps"),<N>        ('executable=', 'e', "specify final destination interpreter path"),<N>        ]<N><N>
"""distutils.command.bdist_rpm<N><N>Implements the Distutils 'bdist_rpm' command (create RPM source and binary<N>distributions)."""<N><N>import subprocess, sys, os<N>from distutils.core import Command<N>from distutils.debug import DEBUG<N>from distutils.file_util import write_file<N>from distutils.errors import *<N>from distutils.sysconfig import get_python_version<N>from distutils import log<N><N>
import sys<N><N><N>def _pythonlib_compat():<N>    """<N>    On Python 3.7 and earlier, distutils would include the Python<N>    library. See pypa/distutils#9.<N>    """<N>    from distutils import sysconfig<N>    if not sysconfig.get_config_var('Py_ENABLED_SHARED'):<N>        return<N><N>
    yield 'python{}.{}{}'.format(<N>        sys.hexversion >> 24,<N>        (sys.hexversion >> 16) & 0xff,<N>        sysconfig.get_config_var('ABIFLAGS'),<N>    )<N><N><N>def compose(f1, f2):<N>    return lambda *args, **kwargs: f1(f2(*args, **kwargs))<N><N>
"""<N>distutils.command.upload<N><N>Implements the Distutils 'upload' subcommand (upload package to a package<N>index).<N>"""<N><N>import os<N>import io<N>import hashlib<N>from base64 import standard_b64encode<N>from urllib.request import urlopen, Request, HTTPError<N>from urllib.parse import urlparse<N>from distutils.errors import DistutilsError, DistutilsOptionError<N>from distutils.core import PyPIRCCommand<N>from distutils.spawn import spawn<N>from distutils import log<N><N>
<N># PyPI Warehouse supports MD5, SHA256, and Blake2 (blake2-256)<N># https://bugs.python.org/issue40698<N>_FILE_CONTENT_DIGESTS = {<N>    "md5_digest": getattr(hashlib, "md5", None),<N>    "sha256_digest": getattr(hashlib, "sha256", None),<N>    "blake2_256_digest": getattr(hashlib, "blake2b", None),<N>}<N><N>
<N>class upload(PyPIRCCommand):<N><N>    description = "upload binary package to PyPI"<N><N>    user_options = PyPIRCCommand.user_options + [<N>        ('sign', 's',<N>         'sign files to upload using gpg'),<N>        ('identity=', 'i', 'GPG identity used to sign files'),<N>        ]<N><N>
    boolean_options = PyPIRCCommand.boolean_options + ['sign']<N><N>    def initialize_options(self):<N>        PyPIRCCommand.initialize_options(self)<N>        self.username = ''<N>        self.password = ''<N>        self.show_response = 0<N>        self.sign = False<N>        self.identity = None<N><N>
"""distutils.command.install_lib<N><N>Implements the Distutils 'install_lib' command<N>(install all Python modules)."""<N><N>import os<N>import importlib.util<N>import sys<N><N>from distutils.core import Command<N>from distutils.errors import DistutilsOptionError<N><N>
"""distutils.command.build_py<N><N>Implements the Distutils 'build_py' command."""<N><N>import os<N>import importlib.util<N>import sys<N>import glob<N><N>from distutils.core import Command<N>from distutils.errors import *<N>from distutils.util import convert_path, Mixin2to3<N>from distutils import log<N><N>
"""distutils.command.install_egg_info<N><N>Implements the Distutils 'install_egg_info' command, for installing<N>a package's PKG-INFO metadata."""<N><N><N>from distutils.cmd import Command<N>from distutils import log, dir_util<N>import os, sys, re<N><N>class install_egg_info(Command):<N>    """Install an .egg-info file for the package"""<N><N>
"""distutils.command.install_headers<N><N>Implements the Distutils 'install_headers' command, to install C/C++ header<N>files to the Python include directory."""<N><N>from distutils.core import Command<N><N><N># XXX force is never used<N>class install_headers(Command):<N><N>
    description = "install C/C++ header files"<N><N>    user_options = [('install-dir=', 'd',<N>                     "directory to install header files to"),<N>                    ('force', 'f',<N>                     "force installation (overwrite existing files)"),<N>                   ]<N><N>
    boolean_options = ['force']<N><N>    def initialize_options(self):<N>        self.install_dir = None<N>        self.force = 0<N>        self.outfiles = []<N><N>    def finalize_options(self):<N>        self.set_undefined_options('install',<N>                                   ('install_headers', 'install_dir'),<N>                                   ('force', 'force'))<N><N>
<N>    def run(self):<N>        headers = self.distribution.headers<N>        if not headers:<N>            return<N><N>        self.mkpath(self.install_dir)<N>        for header in headers:<N>            (out, _) = self.copy_file(header, self.install_dir)<N>            self.outfiles.append(out)<N><N>
import importlib.util<N>import sys<N><N><N>class VendorImporter:<N>    """<N>    A PEP 302 meta path importer for finding optionally-vendored<N>    or otherwise naturally-installed packages from root_name.<N>    """<N><N>    def __init__(self, root_name, vendored_names=(), vendor_pkg=None):<N>        self.root_name = root_name<N>        self.vendored_names = set(vendored_names)<N>        self.vendor_pkg = vendor_pkg or root_name.replace('extern', '_vendor')<N><N>
    @property<N>    def search_path(self):<N>        """<N>        Search first the vendor package then as a natural package.<N>        """<N>        yield self.vendor_pkg + '.'<N>        yield ''<N><N>    def _module_matches_namespace(self, fullname):<N>        """Figure out if the target module is vendored."""<N>        root, base, target = fullname.partition(self.root_name + '.')<N>        return not root and any(map(target.startswith, self.vendored_names))<N><N>
"""setuptools.command.bdist_egg<N><N>Build .egg distributions"""<N><N>from distutils.dir_util import remove_tree, mkpath<N>from distutils import log<N>from types import CodeType<N>import sys<N>import os<N>import re<N>import textwrap<N>import marshal<N><N>from pkg_resources import get_build_platform, Distribution, ensure_directory<N>from setuptools.extension import Library<N>from setuptools import Command<N><N>
from sysconfig import get_path, get_python_version<N><N><N>def _get_purelib():<N>    return get_path("purelib")<N><N><N>def strip_module(filename):<N>    if '.' in filename:<N>        filename = os.path.splitext(filename)[0]<N>    if filename.endswith('module'):<N>        filename = filename[:-6]<N>    return filename<N><N>
<N>def sorted_walk(dir):<N>    """Do os.walk in a reproducible way,<N>    independent of indeterministic filesystem readdir order<N>    """<N>    for base, dirs, files in os.walk(dir):<N>        dirs.sort()<N>        files.sort()<N>        yield base, dirs, files<N><N>
from distutils.util import convert_path<N>from distutils import log<N>from distutils.errors import DistutilsOptionError<N>import os<N>import shutil<N><N>from setuptools import Command<N><N><N>class rotate(Command):<N>    """Delete older distributions"""<N><N>
    description = "delete older distributions, keeping N newest files"<N>    user_options = [<N>        ('match=', 'm', "patterns to match (required)"),<N>        ('dist-dir=', 'd', "directory where the distributions are"),<N>        ('keep=', 'k', "number of matching distributions to keep"),<N>    ]<N><N>
__all__ = [<N>    'alias', 'bdist_egg', 'bdist_rpm', 'build_ext', 'build_py', 'develop',<N>    'easy_install', 'egg_info', 'install', 'install_lib', 'rotate', 'saveopts',<N>    'sdist', 'setopt', 'test', 'install_egg_info', 'install_scripts',<N>    'upload_docs', 'build_clib', 'dist_info',<N>]<N><N>
from distutils.command.bdist import bdist<N>import sys<N><N>from setuptools.command import install_scripts<N><N>if 'egg' not in bdist.format_commands:<N>    bdist.format_command['egg'] = ('bdist_egg', "Python .egg file")<N>    bdist.format_commands.append('egg')<N><N>
import distutils.command.build_clib as orig<N>from distutils.errors import DistutilsSetupError<N>from distutils import log<N>from setuptools.dep_util import newer_pairwise_group<N><N><N>class build_clib(orig.build_clib):<N>    """<N>    Override the default build_clib behaviour to do the following:<N><N>
"""<N>Easy Install<N>------------<N><N>A tool for doing automatic download/extract/build of distutils-based Python<N>packages.  For detailed documentation, see the accompanying EasyInstall.txt<N>file, or visit the `EasyInstall home page`__.<N><N>__ https://setuptools.readthedocs.io/en/latest/easy_install.html<N><N>
from distutils import log<N>import distutils.command.sdist as orig<N>import os<N>import sys<N>import io<N>import contextlib<N>from glob import iglob<N><N>from setuptools.extern import ordered_set<N><N>from .py36compat import sdist_add_defaults<N><N>import pkg_resources<N><N>
_default_revctrl = list<N><N><N>def walk_revctrl(dirname=''):<N>    """Find all files under revision control"""<N>    for ep in pkg_resources.iter_entry_points('setuptools.file_finders'):<N>        for item in ep.load()(dirname):<N>            yield item<N><N>
from distutils import log<N>import distutils.command.install_scripts as orig<N>from distutils.errors import DistutilsModuleError<N>import os<N>import sys<N><N>from pkg_resources import Distribution, PathMetadata, ensure_directory<N><N><N>class install_scripts(orig.install_scripts):<N>    """Do normal script install, plus any egg_info wrapper scripts"""<N><N>
import os<N>from glob import glob<N>from distutils.util import convert_path<N>from distutils.command import sdist<N><N><N>class sdist_add_defaults:<N>    """<N>    Mix-in providing forward-compatibility for functionality as found in<N>    distutils on Python 3.7.<N><N>
import os<N>import sys<N>import itertools<N>from importlib.machinery import EXTENSION_SUFFIXES<N>from distutils.command.build_ext import build_ext as _du_build_ext<N>from distutils.file_util import copy_file<N>from distutils.ccompiler import new_compiler<N>from distutils.sysconfig import customize_compiler, get_config_var<N>from distutils.errors import DistutilsError<N>from distutils import log<N><N>
from setuptools.extension import Library<N><N>try:<N>    # Attempt to use Cython for building extensions, if available<N>    from Cython.Distutils.build_ext import build_ext as _build_ext<N>    # Additionally, assert that the compiler module will load<N>    # also. Ref #1229.<N>    __import__('Cython.Compiler.Main')<N>except ImportError:<N>    _build_ext = _du_build_ext<N><N>
# -*- coding: utf-8 -*-<N>"""upload_docs<N><N>Implements a Distutils 'upload_docs' subcommand (upload documentation to<N>sites other than PyPi such as devpi).<N>"""<N><N>from base64 import standard_b64encode<N>from distutils import log<N>from distutils.errors import DistutilsOptionError<N>import os<N>import socket<N>import zipfile<N>import tempfile<N>import shutil<N>import itertools<N>import functools<N>import http.client<N>import urllib.parse<N><N>
from pkg_resources import iter_entry_points<N>from .upload import upload<N><N><N>def _encode(s):<N>    return s.encode('utf-8', 'surrogateescape')<N><N><N>class upload_docs(upload):<N>    # override the default repository as upload_docs isn't<N>    # supported by Warehouse (and won't be).<N>    DEFAULT_REPOSITORY = 'https://pypi.python.org/pypi/'<N><N>
    description = 'Upload documentation to sites other than PyPi such as devpi'<N><N>    user_options = [<N>        ('repository=', 'r',<N>         "url of repository [default: %s]" % upload.DEFAULT_REPOSITORY),<N>        ('show-response', None,<N>         'display full response text from server'),<N>        ('upload-dir=', None, 'directory to upload'),<N>    ]<N>    boolean_options = upload.boolean_options<N><N>
    def has_sphinx(self):<N>        if self.upload_dir is None:<N>            for ep in iter_entry_points('distutils.commands', 'build_sphinx'):<N>                return True<N><N>    sub_commands = [('build_sphinx', has_sphinx)]<N><N>    def initialize_options(self):<N>        upload.initialize_options(self)<N>        self.upload_dir = None<N>        self.target_dir = None<N><N>
from distutils.util import convert_path<N>from distutils import log<N>from distutils.errors import DistutilsError, DistutilsOptionError<N>import os<N>import glob<N>import io<N><N>import pkg_resources<N>from setuptools.command.easy_install import easy_install<N>from setuptools import namespaces<N>import setuptools<N><N>
<N>class develop(namespaces.DevelopInstaller, easy_install):<N>    """Set up package for development"""<N><N>    description = "install package in 'development mode'"<N><N>    user_options = easy_install.user_options + [<N>        ("uninstall", "u", "Uninstall this source package"),<N>        ("egg-path=", None, "Set the path to be used in the .egg-link file"),<N>    ]<N><N>
    boolean_options = easy_install.boolean_options + ['uninstall']<N><N>    command_consumes_arguments = False  # override base<N><N>    def run(self):<N>        if self.uninstall:<N>            self.multi_version = True<N>            self.uninstall_link()<N>            self.uninstall_namespaces()<N>        else:<N>            self.install_for_development()<N>        self.warn_deprecated_options()<N><N>
    def initialize_options(self):<N>        self.uninstall = None<N>        self.egg_path = None<N>        easy_install.initialize_options(self)<N>        self.setup_path = None<N>        self.always_copy_from = '.'  # always copy eggs installed in curdir<N><N>
    def finalize_options(self):<N>        ei = self.get_finalized_command("egg_info")<N>        if ei.broken_egg_info:<N>            template = "Please rename %r to %r before using 'develop'"<N>            args = ei.egg_info, ei.broken_egg_info<N>            raise DistutilsError(template % args)<N>        self.args = [ei.egg_name]<N><N>
        easy_install.finalize_options(self)<N>        self.expand_basedirs()<N>        self.expand_dirs()<N>        # pick up setup-dir .egg files only: no .egg-info<N>        self.package_index.scan(glob.glob('*.egg'))<N><N>        egg_link_fn = ei.egg_name + '.egg-link'<N>        self.egg_link = os.path.join(self.install_dir, egg_link_fn)<N>        self.egg_base = ei.egg_base<N>        if self.egg_path is None:<N>            self.egg_path = os.path.abspath(ei.egg_base)<N><N>
        target = pkg_resources.normalize_path(self.egg_base)<N>        egg_path = pkg_resources.normalize_path(<N>            os.path.join(self.install_dir, self.egg_path))<N>        if egg_path != target:<N>            raise DistutilsOptionError(<N>                "--egg-path must be a relative path from the install"<N>                " directory to " + target<N>            )<N><N>
        # Make a distribution for the package's source<N>        self.dist = pkg_resources.Distribution(<N>            target,<N>            pkg_resources.PathMetadata(target, os.path.abspath(ei.egg_info)),<N>            project_name=ei.egg_name<N>        )<N><N>
from distutils import log<N>import distutils.command.register as orig<N><N>from setuptools.errors import RemovedCommandError<N><N><N>class register(orig.register):<N>    """Formerly used to register packages on PyPI."""<N><N>    def run(self):<N>        msg = (<N>            "The register command has been removed, use twine to upload "<N>            + "instead (https://pypi.org/p/twine)"<N>        )<N><N>        self.announce("ERROR: " + msg, log.ERROR)<N><N>        raise RemovedCommandError(msg)<N>
"""setuptools.command.egg_info<N><N>Create a distribution's .egg-info directory and contents"""<N><N>from distutils.filelist import FileList as _FileList<N>from distutils.errors import DistutilsInternalError<N>from distutils.util import convert_path<N>from distutils import log<N>import distutils.errors<N>import distutils.filelist<N>import functools<N>import os<N>import re<N>import sys<N>import io<N>import warnings<N>import time<N>import collections<N><N>
from setuptools import Command<N>from setuptools.command.sdist import sdist<N>from setuptools.command.sdist import walk_revctrl<N>from setuptools.command.setopt import edit_config<N>from setuptools.command import bdist_egg<N>from pkg_resources import (<N>    parse_requirements, safe_name, parse_version,<N>    safe_version, yield_lines, EntryPoint, iter_entry_points, to_filename)<N>import setuptools.unicode_utils as unicode_utils<N>from setuptools.glob import glob<N><N>
from setuptools.extern import packaging<N>from setuptools import SetuptoolsDeprecationWarning<N><N><N>def translate_pattern(glob):  # noqa: C901  # is too complex (14)  # FIXME<N>    """<N>    Translate a file path glob like '*.txt' in to a regular expression.<N>    This differs from fnmatch.translate which allows wildcards to match<N>    directory separators. It also knows about '**/' which matches any number of<N>    directories.<N>    """<N>    pat = ''<N><N>
    # This will split on '/' within [character classes]. This is deliberate.<N>    chunks = glob.split(os.path.sep)<N><N>    sep = re.escape(os.sep)<N>    valid_char = '[^%s]' % (sep,)<N><N>    for c, chunk in enumerate(chunks):<N>        last_chunk = c == len(chunks) - 1<N><N>
        # Chunks that are a literal ** are globstars. They match anything.<N>        if chunk == '**':<N>            if last_chunk:<N>                # Match anything if this is the last component<N>                pat += '.*'<N>            else:<N>                # Match '(name/)*'<N>                pat += '(?:%s+%s)*' % (valid_char, sep)<N>            continue  # Break here as the whole path component has been handled<N><N>
import distutils.command.bdist_rpm as orig<N><N><N>class bdist_rpm(orig.bdist_rpm):<N>    """<N>    Override the default bdist_rpm behavior to do the following:<N><N>    1. Run egg_info to ensure the name and version are properly calculated.<N>    2. Always run 'install' using --single-version-externally-managed to<N>       disable eggs in RPM distributions.<N>    """<N><N>
from distutils.util import convert_path<N>from distutils import log<N>from distutils.errors import DistutilsOptionError<N>import distutils<N>import os<N>import configparser<N><N>from setuptools import Command<N><N>__all__ = ['config_file', 'edit_config', 'option_base', 'setopt']<N><N>
from distutils import log<N>from distutils.command import upload as orig<N><N>from setuptools.errors import RemovedCommandError<N><N><N>class upload(orig.upload):<N>    """Formerly used to upload packages to PyPI."""<N><N>    def run(self):<N>        msg = (<N>            "The upload command has been removed, use twine to upload "<N>            + "instead (https://pypi.org/p/twine)"<N>        )<N><N>        self.announce("ERROR: " + msg, log.ERROR)<N>        raise RemovedCommandError(msg)<N>
import os<N>import sys<N>from itertools import product, starmap<N>import distutils.command.install_lib as orig<N><N><N>class install_lib(orig.install_lib):<N>    """Don't add compiled flags to filenames of non-Python files"""<N><N>    def run(self):<N>        self.build()<N>        outfiles = self.install()<N>        if outfiles is not None:<N>            # always compile, in case we have any extension stubs to deal with<N>            self.byte_compile(outfiles)<N><N>
    def get_exclusions(self):<N>        """<N>        Return a collections.Sized collections.Container of paths to be<N>        excluded for single_version_externally_managed installations.<N>        """<N>        all_packages = (<N>            pkg<N>            for ns_pkg in self._get_SVEM_NSPs()<N>            for pkg in self._all_packages(ns_pkg)<N>        )<N><N>
        excl_specs = product(all_packages, self._gen_exclusion_paths())<N>        return set(starmap(self._exclude_pkg_path, excl_specs))<N><N>    def _exclude_pkg_path(self, pkg, exclusion_path):<N>        """<N>        Given a package name and exclusion path within that package,<N>        compute the full exclusion path.<N>        """<N>        parts = pkg.split('.') + [exclusion_path]<N>        return os.path.join(self.install_dir, *parts)<N><N>
    @staticmethod<N>    def _all_packages(pkg_name):<N>        """<N>        >>> list(install_lib._all_packages('foo.bar.baz'))<N>        ['foo.bar.baz', 'foo.bar', 'foo']<N>        """<N>        while pkg_name:<N>            yield pkg_name<N>            pkg_name, sep, child = pkg_name.rpartition('.')<N><N>
    def _get_SVEM_NSPs(self):<N>        """<N>        Get namespace packages (list) but only for<N>        single_version_externally_managed installations and empty otherwise.<N>        """<N>        # TODO: is it necessary to short-circuit here? i.e. what's the cost<N>        # if get_finalized_command is called even when namespace_packages is<N>        # False?<N>        if not self.distribution.namespace_packages:<N>            return []<N><N>
        install_cmd = self.get_finalized_command('install')<N>        svem = install_cmd.single_version_externally_managed<N><N>        return self.distribution.namespace_packages if svem else []<N><N>    @staticmethod<N>    def _gen_exclusion_paths():<N>        """<N>        Generate file paths to be excluded for namespace packages (bytecode<N>        cache files).<N>        """<N>        # always exclude the package module itself<N>        yield '__init__.py'<N><N>
        yield '__init__.pyc'<N>        yield '__init__.pyo'<N><N>        if not hasattr(sys, 'implementation'):<N>            return<N><N>        base = os.path.join(<N>            '__pycache__', '__init__.' + sys.implementation.cache_tag)<N>        yield base + '.pyc'<N>        yield base + '.pyo'<N>        yield base + '.opt-1.pyc'<N>        yield base + '.opt-2.pyc'<N><N>
    def copy_tree(<N>            self, infile, outfile,<N>            preserve_mode=1, preserve_times=1, preserve_symlinks=0, level=1<N>    ):<N>        assert preserve_mode and preserve_times and not preserve_symlinks<N>        exclude = self.get_exclusions()<N><N>
        if not exclude:<N>            return orig.install_lib.copy_tree(self, infile, outfile)<N><N>        # Exclude namespace package __init__.py* files from the output<N><N>        from setuptools.archive_util import unpack_directory<N>        from distutils import log<N><N>
        outfiles = []<N><N>        def pf(src, dst):<N>            if dst in exclude:<N>                log.warn("Skipping installation of %s (namespace package)",<N>                         dst)<N>                return False<N><N>            log.info("copying %s -> %s", src, os.path.dirname(dst))<N>            outfiles.append(dst)<N>            return dst<N><N>
        unpack_directory(infile, outfile, pf)<N>        return outfiles<N><N>    def get_outputs(self):<N>        outputs = orig.install_lib.get_outputs(self)<N>        exclude = self.get_exclusions()<N>        if exclude:<N>            return [f for f in outputs if f not in exclude]<N>        return outputs<N><N><N>
from glob import glob<N>from distutils.util import convert_path<N>import distutils.command.build_py as orig<N>import os<N>import fnmatch<N>import textwrap<N>import io<N>import distutils.errors<N>import itertools<N>import stat<N><N>try:<N>    from setuptools.lib2to3_ex import Mixin2to3<N>except Exception:<N><N>
    class Mixin2to3:<N>        def run_2to3(self, files, doctests=True):<N>            "do nothing"<N><N><N>def make_writable(target):<N>    os.chmod(target, os.stat(target).st_mode | stat.S_IWRITE)<N><N><N>class build_py(orig.build_py, Mixin2to3):<N>    """Enhanced 'build_py' command that includes data files with packages<N><N>
    The data files are specified via a 'package_data' argument to 'setup()'.<N>    See 'setuptools.dist.Distribution' for more details.<N><N>    Also, this version of the 'build_py' command allows you to specify both<N>    'py_modules' and 'packages' in the same setup operation.<N>    """<N><N>
    def finalize_options(self):<N>        orig.build_py.finalize_options(self)<N>        self.package_data = self.distribution.package_data<N>        self.exclude_package_data = (self.distribution.exclude_package_data or<N>                                     {})<N>        if 'data_files' in self.__dict__:<N>            del self.__dict__['data_files']<N>        self.__updated_files = []<N>        self.__doctests_2to3 = []<N><N>
    def run(self):<N>        """Build modules, packages, and copy data files to build directory"""<N>        if not self.py_modules and not self.packages:<N>            return<N><N>        if self.py_modules:<N>            self.build_modules()<N><N>        if self.packages:<N>            self.build_packages()<N>            self.build_package_data()<N><N>
        self.run_2to3(self.__updated_files, False)<N>        self.run_2to3(self.__updated_files, True)<N>        self.run_2to3(self.__doctests_2to3, True)<N><N>        # Only compile actual .py files, using our base class' idea of what our<N>        # output files are.<N>        self.byte_compile(orig.build_py.get_outputs(self, include_bytecode=0))<N><N>
    def __getattr__(self, attr):<N>        "lazily compute data files"<N>        if attr == 'data_files':<N>            self.data_files = self._get_data_files()<N>            return self.data_files<N>        return orig.build_py.__getattr__(self, attr)<N><N>
    def build_module(self, module, module_file, package):<N>        outfile, copied = orig.build_py.build_module(self, module, module_file,<N>                                                     package)<N>        if copied:<N>            self.__updated_files.append(outfile)<N>        return outfile, copied<N><N>
    def _get_data_files(self):<N>        """Generate list of '(package,src_dir,build_dir,filenames)' tuples"""<N>        self.analyze_manifest()<N>        return list(map(self._get_pkg_data_files, self.packages or ()))<N><N>    def _get_pkg_data_files(self, package):<N>        # Locate package source directory<N>        src_dir = self.get_package_dir(package)<N><N>
        # Compute package build directory<N>        build_dir = os.path.join(*([self.build_lib] + package.split('.')))<N><N>        # Strip directory from globbed filenames<N>        filenames = [<N>            os.path.relpath(file, src_dir)<N>            for file in self.find_data_files(package, src_dir)<N>        ]<N>        return package, src_dir, build_dir, filenames<N><N>
from distutils import log, dir_util<N>import os<N><N>from setuptools import Command<N>from setuptools import namespaces<N>from setuptools.archive_util import unpack_archive<N>import pkg_resources<N><N><N>class install_egg_info(namespaces.Installer, Command):<N>    """Install an .egg-info directory for the package"""<N><N>
from distutils.errors import DistutilsOptionError<N><N>from setuptools.command.setopt import edit_config, option_base, config_file<N><N><N>def shquote(arg):<N>    """Quote an argument for later parsing by shlex.split()"""<N>    for c in '"', "'", "\\", "#":<N>        if c in arg:<N>            return repr(arg)<N>    if arg.split() != [arg]:<N>        return repr(arg)<N>    return arg<N><N>
<N>class alias(option_base):<N>    """Define a shortcut that invokes one or more commands"""<N><N>    description = "define a shortcut to invoke one or more commands"<N>    command_consumes_arguments = True<N><N>    user_options = [<N>        ('remove', 'r', 'remove (unset) the alias'),<N>    ] + option_base.user_options<N><N>
    boolean_options = option_base.boolean_options + ['remove']<N><N>    def initialize_options(self):<N>        option_base.initialize_options(self)<N>        self.args = None<N>        self.remove = None<N><N>    def finalize_options(self):<N>        option_base.finalize_options(self)<N>        if self.remove and len(self.args) != 1:<N>            raise DistutilsOptionError(<N>                "Must specify exactly one argument (the alias name) when "<N>                "using --remove"<N>            )<N><N>
    def run(self):<N>        aliases = self.distribution.get_option_dict('aliases')<N><N>        if not self.args:<N>            print("Command Aliases")<N>            print("---------------")<N>            for alias in aliases:<N>                print("setup.py alias", format_alias(alias, aliases))<N>            return<N><N>
        elif len(self.args) == 1:<N>            alias, = self.args<N>            if self.remove:<N>                command = None<N>            elif alias in aliases:<N>                print("setup.py alias", format_alias(alias, aliases))<N>                return<N>            else:<N>                print("No alias definition found for %r" % alias)<N>                return<N>        else:<N>            alias = self.args[0]<N>            command = ' '.join(map(shquote, self.args[1:]))<N><N>
        edit_config(self.filename, {'aliases': {alias: command}}, self.dry_run)<N><N><N>def format_alias(name, aliases):<N>    source, command = aliases[name]<N>    if source == config_file('global'):<N>        source = '--global-config '<N>    elif source == config_file('user'):<N>        source = '--user-config '<N>    elif source == config_file('local'):<N>        source = ''<N>    else:<N>        source = '--filename=%r' % source<N>    return source + name + ' ' + command<N><N><N>
from setuptools.command.setopt import edit_config, option_base<N><N><N>class saveopts(option_base):<N>    """Save command-line options to a file"""<N><N>    description = "save supplied options to setup.cfg or other config file"<N><N>    def run(self):<N>        dist = self.distribution<N>        settings = {}<N><N>
        for cmd in dist.command_options:<N><N>            if cmd == 'saveopts':<N>                continue  # don't save our own options!<N><N>            for opt, (src, val) in dist.get_option_dict(cmd).items():<N>                if src == "command line":<N>                    settings.setdefault(cmd, {})[opt] = val<N><N>
"""<N>Create a dist_info directory<N>As defined in the wheel specification<N>"""<N><N>import os<N><N>from distutils.core import Command<N>from distutils import log<N><N><N>class dist_info(Command):<N><N>    description = 'create a .dist-info directory'<N><N>
    user_options = [<N>        ('egg-base=', 'e', "directory containing .egg-info directories"<N>                           " (default: top of the source tree)"),<N>    ]<N><N>    def initialize_options(self):<N>        self.egg_base = None<N><N>    def finalize_options(self):<N>        pass<N><N>
    def run(self):<N>        egg_info = self.get_finalized_command('egg_info')<N>        egg_info.egg_base = self.egg_base<N>        egg_info.finalize_options()<N>        egg_info.run()<N>        dist_info_dir = egg_info.egg_info[:-len('.egg-info')] + '.dist-info'<N>        log.info("creating '{}'".format(os.path.abspath(dist_info_dir)))<N><N>
from distutils.errors import DistutilsArgError<N>import inspect<N>import glob<N>import warnings<N>import platform<N>import distutils.command.install as orig<N><N>import setuptools<N><N># Prior to numpy 1.9, NumPy relies on the '_install' name, so provide it for<N># now. See https://github.com/pypa/setuptools/issues/199/<N>_install = orig.install<N><N>
"""<N>An OrderedSet is a custom MutableSet that remembers its order, so that every<N>entry has an index that can be looked up.<N><N>Based on a recipe originally posted to ActiveState Recipes by Raymond Hettiger,<N>and released under the MIT license.<N>"""<N>import itertools as it<N>from collections import deque<N><N>
try:<N>    # Python 3<N>    from collections.abc import MutableSet, Sequence<N>except ImportError:<N>    # Python 2.7<N>    from collections import MutableSet, Sequence<N><N>SLICE_ALL = slice(None)<N>__version__ = "3.1"<N><N><N>def is_iterable(obj):<N>    """<N>    Are we being asked to look up a list of things, instead of a single thing?<N>    We check for the `__iter__` attribute so that this can cover types that<N>    don't have to be known by this module, such as NumPy arrays.<N><N>
    Strings, however, should be considered as atomic values to look up, not<N>    iterables. The same goes for tuples, since they are immutable and therefore<N>    valid entries.<N><N>    We don't need to check for the Python 2 `unicode` type, because it doesn't<N>    have an `__iter__` attribute anyway.<N>    """<N>    return (<N>        hasattr(obj, "__iter__")<N>        and not isinstance(obj, str)<N>        and not isinstance(obj, tuple)<N>    )<N><N>
<N>class OrderedSet(MutableSet, Sequence):<N>    """<N>    An OrderedSet is a custom MutableSet that remembers its order, so that<N>    every entry has an index that can be looked up.<N><N>    Example:<N>        >>> OrderedSet([1, 1, 2, 3, 2])<N>        OrderedSet([1, 2, 3])<N>    """<N><N>
    def __init__(self, iterable=None):<N>        self.items = []<N>        self.map = {}<N>        if iterable is not None:<N>            self |= iterable<N><N>    def __len__(self):<N>        """<N>        Returns the number of unique elements in the ordered set<N><N>
        Example:<N>            >>> len(OrderedSet([]))<N>            0<N>            >>> len(OrderedSet([1, 2]))<N>            2<N>        """<N>        return len(self.items)<N><N>    def __getitem__(self, index):<N>        """<N>        Get the item at a given index.<N><N>
        If `index` is a slice, you will get back that slice of items, as a<N>        new OrderedSet.<N><N>        If `index` is a list or a similar iterable, you'll get a list of<N>        items corresponding to those indices. This is similar to NumPy's<N>        "fancy indexing". The result is not an OrderedSet because you may ask<N>        for duplicate indices, and the number of elements returned should be<N>        the number of elements asked for.<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import sys<N><N>from ._typing import TYPE_CHECKING<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Any, Dict, Tuple, Type<N><N><N>PY2 = sys.version_info[0] == 2<N>PY3 = sys.version_info[0] == 3<N><N># flake8: noqa<N><N>if PY3:<N>    string_types = (str,)<N>else:<N>    string_types = (basestring,)<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import string<N>import re<N><N>from setuptools.extern.pyparsing import stringStart, stringEnd, originalTextFor, ParseException<N>from setuptools.extern.pyparsing import ZeroOrMore, Word, Optional, Regex, Combine<N>from setuptools.extern.pyparsing import Literal as L  # noqa<N>from urllib import parse as urlparse<N><N>
from ._typing import TYPE_CHECKING<N>from .markers import MARKER_EXPR, Marker<N>from .specifiers import LegacySpecifier, Specifier, SpecifierSet<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import List<N><N><N>class InvalidRequirement(ValueError):<N>    """<N>    An invalid requirement was found, users should refer to PEP 508.<N>    """<N><N>
<N>ALPHANUM = Word(string.ascii_letters + string.digits)<N><N>LBRACKET = L("[").suppress()<N>RBRACKET = L("]").suppress()<N>LPAREN = L("(").suppress()<N>RPAREN = L(")").suppress()<N>COMMA = L(",").suppress()<N>SEMICOLON = L(";").suppress()<N>AT = L("@").suppress()<N><N>
PUNCTUATION = Word("-_.")<N>IDENTIFIER_END = ALPHANUM | (ZeroOrMore(PUNCTUATION) + ALPHANUM)<N>IDENTIFIER = Combine(ALPHANUM + ZeroOrMore(IDENTIFIER_END))<N><N>NAME = IDENTIFIER("name")<N>EXTRA = IDENTIFIER<N><N>URI = Regex(r"[^ ]+")("url")<N>URL = AT + URI<N><N>
EXTRAS_LIST = EXTRA + ZeroOrMore(COMMA + EXTRA)<N>EXTRAS = (LBRACKET + Optional(EXTRAS_LIST) + RBRACKET)("extras")<N><N>VERSION_PEP440 = Regex(Specifier._regex_str, re.VERBOSE | re.IGNORECASE)<N>VERSION_LEGACY = Regex(LegacySpecifier._regex_str, re.VERBOSE | re.IGNORECASE)<N><N>
VERSION_ONE = VERSION_PEP440 ^ VERSION_LEGACY<N>VERSION_MANY = Combine(<N>    VERSION_ONE + ZeroOrMore(COMMA + VERSION_ONE), joinString=",", adjacent=False<N>)("_raw_spec")<N>_VERSION_SPEC = Optional(((LPAREN + VERSION_MANY + RPAREN) | VERSION_MANY))<N>_VERSION_SPEC.setParseAction(lambda s, l, t: t._raw_spec or "")<N><N>
VERSION_SPEC = originalTextFor(_VERSION_SPEC)("specifier")<N>VERSION_SPEC.setParseAction(lambda s, l, t: t[1])<N><N>MARKER_EXPR = originalTextFor(MARKER_EXPR())("marker")<N>MARKER_EXPR.setParseAction(<N>    lambda s, l, t: Marker(s[t._original_start : t._original_end])<N>)<N>MARKER_SEPARATOR = SEMICOLON<N>MARKER = MARKER_SEPARATOR + MARKER_EXPR<N><N>
VERSION_AND_MARKER = VERSION_SPEC + Optional(MARKER)<N>URL_AND_MARKER = URL + Optional(MARKER)<N><N>NAMED_REQUIREMENT = NAME + Optional(EXTRAS) + (URL_AND_MARKER | VERSION_AND_MARKER)<N><N>REQUIREMENT = stringStart + NAMED_REQUIREMENT + stringEnd<N># setuptools.extern.pyparsing isn't thread safe during initialization, so we do it eagerly, see<N># issue #104<N>REQUIREMENT.parseString("x[]")<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
from .__about__ import (<N>    __author__,<N>    __copyright__,<N>    __email__,<N>    __license__,<N>    __summary__,<N>    __title__,<N>    __uri__,<N>    __version__,<N>)<N><N>__all__ = [<N>    "__title__",<N>    "__summary__",<N>    "__uri__",<N>    "__version__",<N>    "__author__",<N>    "__email__",<N>    "__license__",<N>    "__copyright__",<N>]<N><N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import abc<N>import functools<N>import itertools<N>import re<N><N>from ._compat import string_types, with_metaclass<N>from ._typing import TYPE_CHECKING<N>from .utils import canonicalize_version<N>from .version import Version, LegacyVersion, parse<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import (<N>        List,<N>        Dict,<N>        Union,<N>        Iterable,<N>        Iterator,<N>        Optional,<N>        Callable,<N>        Tuple,<N>        FrozenSet,<N>    )<N><N>
    ParsedVersion = Union[Version, LegacyVersion]<N>    UnparsedVersion = Union[Version, LegacyVersion, str]<N>    CallableOperator = Callable[[ParsedVersion, str], bool]<N><N><N>class InvalidSpecifier(ValueError):<N>    """<N>    An invalid specifier was found, users should refer to PEP 440.<N>    """<N><N>
<N>class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):  # type: ignore<N>    @abc.abstractmethod<N>    def __str__(self):<N>        # type: () -> str<N>        """<N>        Returns the str representation of this Specifier like object. This<N>        should be representative of the Specifier itself.<N>        """<N><N>
    @abc.abstractmethod<N>    def __hash__(self):<N>        # type: () -> int<N>        """<N>        Returns a hash value for this Specifier like object.<N>        """<N><N>    @abc.abstractmethod<N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        """<N>        Returns a boolean representing whether or not the two Specifier like<N>        objects are equal.<N>        """<N><N>
    @abc.abstractmethod<N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        """<N>        Returns a boolean representing whether or not the two Specifier like<N>        objects are not equal.<N>        """<N><N>    @abc.abstractproperty<N>    def prereleases(self):<N>        # type: () -> Optional[bool]<N>        """<N>        Returns whether or not pre-releases as a whole are allowed by this<N>        specifier.<N>        """<N><N>
    @prereleases.setter<N>    def prereleases(self, value):<N>        # type: (bool) -> None<N>        """<N>        Sets whether or not pre-releases as a whole are allowed by this<N>        specifier.<N>        """<N><N>    @abc.abstractmethod<N>    def contains(self, item, prereleases=None):<N>        # type: (str, Optional[bool]) -> bool<N>        """<N>        Determines if the given item is contained within this specifier.<N>        """<N><N>
    @abc.abstractmethod<N>    def filter(self, iterable, prereleases=None):<N>        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]<N>        """<N>        Takes an iterable of items and filters them so that only items which<N>        are contained within this specifier are allowed in it.<N>        """<N><N>
<N>class _IndividualSpecifier(BaseSpecifier):<N><N>    _operators = {}  # type: Dict[str, str]<N><N>    def __init__(self, spec="", prereleases=None):<N>        # type: (str, Optional[bool]) -> None<N>        match = self._regex.search(spec)<N>        if not match:<N>            raise InvalidSpecifier("Invalid specifier: '{0}'".format(spec))<N><N>
        self._spec = (<N>            match.group("operator").strip(),<N>            match.group("version").strip(),<N>        )  # type: Tuple[str, str]<N><N>        # Store whether or not this Specifier should accept prereleases<N>        self._prereleases = prereleases<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        pre = (<N>            ", prereleases={0!r}".format(self.prereleases)<N>            if self._prereleases is not None<N>            else ""<N>        )<N><N>        return "<{0}({1!r}{2})>".format(self.__class__.__name__, str(self), pre)<N><N>
    def __str__(self):<N>        # type: () -> str<N>        return "{0}{1}".format(*self._spec)<N><N>    @property<N>    def _canonical_spec(self):<N>        # type: () -> Tuple[str, Union[Version, str]]<N>        return self._spec[0], canonicalize_version(self._spec[1])<N><N>
    def __hash__(self):<N>        # type: () -> int<N>        return hash(self._canonical_spec)<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        if isinstance(other, string_types):<N>            try:<N>                other = self.__class__(str(other))<N>            except InvalidSpecifier:<N>                return NotImplemented<N>        elif not isinstance(other, self.__class__):<N>            return NotImplemented<N><N>
        return self._canonical_spec == other._canonical_spec<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        if isinstance(other, string_types):<N>            try:<N>                other = self.__class__(str(other))<N>            except InvalidSpecifier:<N>                return NotImplemented<N>        elif not isinstance(other, self.__class__):<N>            return NotImplemented<N><N>
        return self._spec != other._spec<N><N>    def _get_operator(self, op):<N>        # type: (str) -> CallableOperator<N>        operator_callable = getattr(<N>            self, "_compare_{0}".format(self._operators[op])<N>        )  # type: CallableOperator<N>        return operator_callable<N><N>
    def _coerce_version(self, version):<N>        # type: (UnparsedVersion) -> ParsedVersion<N>        if not isinstance(version, (LegacyVersion, Version)):<N>            version = parse(version)<N>        return version<N><N>    @property<N>    def operator(self):<N>        # type: () -> str<N>        return self._spec[0]<N><N>
    @property<N>    def version(self):<N>        # type: () -> str<N>        return self._spec[1]<N><N>    @property<N>    def prereleases(self):<N>        # type: () -> Optional[bool]<N>        return self._prereleases<N><N>    @prereleases.setter<N>    def prereleases(self, value):<N>        # type: (bool) -> None<N>        self._prereleases = value<N><N>
    def __contains__(self, item):<N>        # type: (str) -> bool<N>        return self.contains(item)<N><N>    def contains(self, item, prereleases=None):<N>        # type: (UnparsedVersion, Optional[bool]) -> bool<N><N>        # Determine if prereleases are to be allowed or not.<N>        if prereleases is None:<N>            prereleases = self.prereleases<N><N>
        # Normalize item to a Version or LegacyVersion, this allows us to have<N>        # a shortcut for ``"2.0" in Specifier(">=2")<N>        normalized_item = self._coerce_version(item)<N><N>        # Determine if we should be supporting prereleases in this specifier<N>        # or not, if we do not support prereleases than we can short circuit<N>        # logic if this version is a prereleases.<N>        if normalized_item.is_prerelease and not prereleases:<N>            return False<N><N>
        # Actually do the comparison to determine if this item is contained<N>        # within this Specifier or not.<N>        operator_callable = self._get_operator(self.operator)  # type: CallableOperator<N>        return operator_callable(normalized_item, self.version)<N><N>
    def filter(self, iterable, prereleases=None):<N>        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]<N><N>        yielded = False<N>        found_prereleases = []<N><N>        kw = {"prereleases": prereleases if prereleases is not None else True}<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N><N>from __future__ import absolute_import<N><N>import distutils.util<N><N>
try:<N>    from importlib.machinery import EXTENSION_SUFFIXES<N>except ImportError:  # pragma: no cover<N>    import imp<N><N>    EXTENSION_SUFFIXES = [x[0] for x in imp.get_suffixes()]<N>    del imp<N>import logging<N>import os<N>import platform<N>import re<N>import struct<N>import sys<N>import sysconfig<N>import warnings<N><N>
from ._typing import TYPE_CHECKING, cast<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import (<N>        Dict,<N>        FrozenSet,<N>        IO,<N>        Iterable,<N>        Iterator,<N>        List,<N>        Optional,<N>        Sequence,<N>        Tuple,<N>        Union,<N>    )<N><N>
    PythonVersion = Sequence[int]<N>    MacVersion = Tuple[int, int]<N>    GlibcVersion = Tuple[int, int]<N><N><N>logger = logging.getLogger(__name__)<N><N>INTERPRETER_SHORT_NAMES = {<N>    "python": "py",  # Generic.<N>    "cpython": "cp",<N>    "pypy": "pp",<N>    "ironpython": "ip",<N>    "jython": "jy",<N>}  # type: Dict[str, str]<N><N>
<N>_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32<N><N><N>class Tag(object):<N>    """<N>    A representation of the tag triple for a wheel.<N><N>    Instances are considered immutable and thus are hashable. Equality checking<N>    is also supported.<N>    """<N><N>
    __slots__ = ["_interpreter", "_abi", "_platform"]<N><N>    def __init__(self, interpreter, abi, platform):<N>        # type: (str, str, str) -> None<N>        self._interpreter = interpreter.lower()<N>        self._abi = abi.lower()<N>        self._platform = platform.lower()<N><N>
    @property<N>    def interpreter(self):<N>        # type: () -> str<N>        return self._interpreter<N><N>    @property<N>    def abi(self):<N>        # type: () -> str<N>        return self._abi<N><N>    @property<N>    def platform(self):<N>        # type: () -> str<N>        return self._platform<N><N>
    def __eq__(self, other):<N>        # type: (object) -> bool<N>        if not isinstance(other, Tag):<N>            return NotImplemented<N><N>        return (<N>            (self.platform == other.platform)<N>            and (self.abi == other.abi)<N>            and (self.interpreter == other.interpreter)<N>        )<N><N>
    def __hash__(self):<N>        # type: () -> int<N>        return hash((self._interpreter, self._abi, self._platform))<N><N>    def __str__(self):<N>        # type: () -> str<N>        return "{}-{}-{}".format(self._interpreter, self._abi, self._platform)<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        return "<{self} @ {self_id}>".format(self=self, self_id=id(self))<N><N><N>def parse_tag(tag):<N>    # type: (str) -> FrozenSet[Tag]<N>    """<N>    Parses the provided tag (e.g. `py3-none-any`) into a frozenset of Tag instances.<N><N>
    Returning a set is required due to the possibility that the tag is a<N>    compressed tag set.<N>    """<N>    tags = set()<N>    interpreters, abis, platforms = tag.split("-")<N>    for interpreter in interpreters.split("."):<N>        for abi in abis.split("."):<N>            for platform_ in platforms.split("."):<N>                tags.add(Tag(interpreter, abi, platform_))<N>    return frozenset(tags)<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import collections<N>import itertools<N>import re<N><N>from ._structures import Infinity, NegativeInfinity<N>from ._typing import TYPE_CHECKING<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
<N>class InfinityType(object):<N>    def __repr__(self):<N>        # type: () -> str<N>        return "Infinity"<N><N>    def __hash__(self):<N>        # type: () -> int<N>        return hash(repr(self))<N><N>    def __lt__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>
    def __le__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        return isinstance(other, self.__class__)<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        return not isinstance(other, self.__class__)<N><N>
    def __gt__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __ge__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __neg__(self):<N>        # type: (object) -> NegativeInfinityType<N>        return NegativeInfinity<N><N>
<N>Infinity = InfinityType()<N><N><N>class NegativeInfinityType(object):<N>    def __repr__(self):<N>        # type: () -> str<N>        return "-Infinity"<N><N>    def __hash__(self):<N>        # type: () -> int<N>        return hash(repr(self))<N><N>    def __lt__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>
    def __le__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        return isinstance(other, self.__class__)<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        return not isinstance(other, self.__class__)<N><N>
    def __gt__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __ge__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __neg__(self):<N>        # type: (object) -> InfinityType<N>        return Infinity<N><N>
"""For neatly implementing static typing in packaging.<N><N>`mypy` - the static type analysis tool we use - uses the `typing` module, which<N>provides core functionality fundamental to mypy's functioning.<N><N>Generally, `typing` would be imported at runtime and used in that fashion -<N>it acts as a no-op at runtime and does not have any run-time overhead by<N>design.<N><N>
As it turns out, `typing` is not vendorable - it uses separate sources for<N>Python 2/Python 3. Thus, this codebase can not expect it to be present.<N>To work around this, mypy allows the typing import to be behind a False-y<N>optional to prevent it from running at runtime and type-comments can be used<N>to remove the need for the types to be accessible directly during runtime.<N><N>
This module provides the False-y guard in a nicely named fashion so that a<N>curious maintainer can reach here to read this.<N><N>In packaging, all static-typing related imports should be guarded as follows:<N><N>    from packaging._typing import TYPE_CHECKING<N><N>
    if TYPE_CHECKING:<N>        from typing import ...<N><N>Ref: https://github.com/python/mypy/issues/3216<N>"""<N><N>__all__ = ["TYPE_CHECKING", "cast"]<N><N># The TYPE_CHECKING constant defined by the typing module is False at runtime<N># but True while type checking.<N>if False:  # pragma: no cover<N>    from typing import TYPE_CHECKING<N>else:<N>    TYPE_CHECKING = False<N><N>
# typing's cast syntax requires calling typing.cast at runtime, but we don't<N># want to import typing at runtime. Here, we inform the type checkers that<N># we're importing `typing.cast` as `cast` and re-implement typing.cast's<N># runtime behavior in a block that is ignored by type checkers.<N>if TYPE_CHECKING:  # pragma: no cover<N>    # not executed at runtime<N>    from typing import cast<N>else:<N>    # executed at runtime<N>    def cast(type_, value):  # noqa<N>        return value<N><N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
__all__ = [<N>    "__title__",<N>    "__summary__",<N>    "__uri__",<N>    "__version__",<N>    "__author__",<N>    "__email__",<N>    "__license__",<N>    "__copyright__",<N>]<N><N>__title__ = "packaging"<N>__summary__ = "Core utilities for Python packages"<N>__uri__ = "https://github.com/pypa/packaging"<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import operator<N>import os<N>import platform<N>import sys<N><N>from setuptools.extern.pyparsing import ParseException, ParseResults, stringStart, stringEnd<N>from setuptools.extern.pyparsing import ZeroOrMore, Group, Forward, QuotedString<N>from setuptools.extern.pyparsing import Literal as L  # noqa<N><N>
from ._compat import string_types<N>from ._typing import TYPE_CHECKING<N>from .specifiers import Specifier, InvalidSpecifier<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Any, Callable, Dict, List, Optional, Tuple, Union<N><N>    Operator = Callable[[str, str], bool]<N><N>
<N>__all__ = [<N>    "InvalidMarker",<N>    "UndefinedComparison",<N>    "UndefinedEnvironmentName",<N>    "Marker",<N>    "default_environment",<N>]<N><N><N>class InvalidMarker(ValueError):<N>    """<N>    An invalid marker was found, users should refer to PEP 508.<N>    """<N><N>
<N>class UndefinedComparison(ValueError):<N>    """<N>    An invalid operation was attempted on a value that doesn't support it.<N>    """<N><N><N>class UndefinedEnvironmentName(ValueError):<N>    """<N>    A name was attempted to be used that does not exist inside of the<N>    environment.<N>    """<N><N>
<N>class Node(object):<N>    def __init__(self, value):<N>        # type: (Any) -> None<N>        self.value = value<N><N>    def __str__(self):<N>        # type: () -> str<N>        return str(self.value)<N><N>    def __repr__(self):<N>        # type: () -> str<N>        return "<{0}({1!r})>".format(self.__class__.__name__, str(self))<N><N>
    def serialize(self):<N>        # type: () -> str<N>        raise NotImplementedError<N><N><N>class Variable(Node):<N>    def serialize(self):<N>        # type: () -> str<N>        return str(self)<N><N><N>class Value(Node):<N>    def serialize(self):<N>        # type: () -> str<N>        return '"{0}"'.format(self)<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import re<N><N>from ._typing import TYPE_CHECKING, cast<N>from .version import InvalidVersion, Version<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import NewType, Union<N><N>    NormalizedName = NewType("NormalizedName", str)<N><N>_canonicalize_regex = re.compile(r"[-_.]+")<N><N>
<N>def canonicalize_name(name):<N>    # type: (str) -> NormalizedName<N>    # This is taken from PEP 503.<N>    value = _canonicalize_regex.sub("-", name).lower()<N>    return cast("NormalizedName", value)<N><N><N>def canonicalize_version(_version):<N>    # type: (str) -> Union[Version, str]<N>    """<N>    This is very similar to Version.__str__, but has one subtle difference<N>    with the way it handles the release segment.<N>    """<N><N>
    try:<N>        version = Version(_version)<N>    except InvalidVersion:<N>        # Legacy versions cannot be normalized<N>        return _version<N><N>    parts = []<N><N>    # Epoch<N>    if version.epoch != 0:<N>        parts.append("{0}!".format(version.epoch))<N><N>
    # Release segment<N>    # NB: This strips trailing '.0's to normalize<N>    parts.append(re.sub(r"(\.0)+$", "", ".".join(str(x) for x in version.release)))<N><N>    # Pre-release<N>    if version.pre is not None:<N>        parts.append("".join(str(x) for x in version.pre))<N><N>
    # Post-release<N>    if version.post is not None:<N>        parts.append(".post{0}".format(version.post))<N><N>    # Development release<N>    if version.dev is not None:<N>        parts.append(".dev{0}".format(version.dev))<N><N>    # Local version segment<N>    if version.local is not None:<N>        parts.append("+{0}".format(version.local))<N><N>
import win32gui, win32con, os<N><N>filter='Python Scripts\0*.py;*.pyw;*.pys\0Text files\0*.txt\0'<N>customfilter='Other file types\0*.*\0'<N><N>fname, customfilter, flags=win32gui.GetSaveFileNameW(<N>    InitialDir=os.environ['temp'],<N>    Flags=win32con.OFN_ALLOWMULTISELECT|win32con.OFN_EXPLORER,<N>    File='somefilename', DefExt='py',<N>    Title='GetSaveFileNameW',<N>    Filter=filter,<N>    CustomFilter=customfilter,<N>    FilterIndex=1)<N><N>
## demonstrates using BackupRead and BackupWrite to copy all of a file's data streams<N><N>import win32file, win32api, win32con, win32security, ntsecuritycon<N>from win32com import storagecon<N>import pythoncom, pywintypes<N>import struct, traceback<N>from pywin32_testutil import str2bytes, ob2memory<N><N>
all_sd_info=win32security.DACL_SECURITY_INFORMATION|win32security.DACL_SECURITY_INFORMATION|   \<N>            win32security.OWNER_SECURITY_INFORMATION|win32security.GROUP_SECURITY_INFORMATION<N><N>tempdir=win32api.GetTempPath()<N>tempfile=win32api.GetTempFileName(tempdir,'bkr')[0]<N>outfile=win32api.GetTempFileName(tempdir,'out')[0]<N>print('Filename:',tempfile,'Output file:',outfile)<N><N>
f=open(tempfile,'w')<N>f.write('some random junk'+'x'*100)<N>f.close()<N><N>## add a couple of alternate data streams<N>f=open(tempfile+':streamdata','w')<N>f.write('data written to alternate stream'+'y'*100)<N>f.close()<N><N>f=open(tempfile+':anotherstream','w')<N>f.write('z'*100)<N>f.close()<N><N>
import sys<N>import win32api<N>import win32net<N>import win32netcon<N>import win32security<N>import getopt<N>import traceback<N><N>verbose_level = 0<N><N>server = None # Run on local machine.<N><N>def verbose(msg):<N>    if verbose_level:<N>        print(msg)<N><N>
def CreateUser():<N>    "Creates a new test user, then deletes the user"<N>    testName = "PyNetTestUser"<N>    try:<N>        win32net.NetUserDel(server, testName)<N>        print("Warning - deleted user before creating it!")<N>    except win32net.error:<N>        pass<N><N>
# -*- Mode: Python; tab-width: 4 -*-<N>#<N><N># This module, and the timer.pyd core timer support, were written by<N># Sam Rushing (rushing@nightmare.com)<N><N>import timer<N>import time<N><N># Timers are based on Windows messages.  So we need<N># to do the event-loop thing!<N>import win32event, win32gui<N><N>
# glork holds a simple counter for us.<N><N>class glork:<N><N>    def __init__ (self, delay=1000, max=10):<N>        self.x = 0<N>        self.max = max<N>        self.id = timer.set_timer (delay, self.increment)<N>        # Could use the threading module, but this is<N>        # a win32 extension test after all! :-)<N>        self.event = win32event.CreateEvent(None, 0, 0, None)<N><N>
    def increment (self, id, time):<N>        print('x = %d' % self.x)<N>        self.x = self.x + 1<N>        # if we've reached the max count,<N>        # kill off the timer.<N>        if self.x > self.max:<N>            # we could have used 'self.id' here, too<N>            timer.kill_timer (id)<N>            win32event.SetEvent(self.event)<N><N>
# win32clipboardDemo.py<N>#<N># Demo/test of the win32clipboard module.<N>from win32clipboard import *<N>from pywin32_testutil import str2bytes # py3k-friendly helper<N>import win32con<N>import types<N><N>if not __debug__:<N>    print("WARNING: The test code in this module uses assert")<N>    print("This instance of Python has asserts disabled, so many tests will be skipped")<N><N>
cf_names = {}<N># Build map of CF_* constants to names.<N>for name, val in list(win32con.__dict__.items()):<N>    if name[:3]=="CF_" and name != "CF_SCREENFONTS": # CF_SCREEN_FONTS==CF_TEXT!?!?<N>        cf_names[val] = name<N><N>def TestEmptyClipboard():<N>    OpenClipboard()<N>    try:<N>        EmptyClipboard()<N>        assert EnumClipboardFormats(0)==0, "Clipboard formats were available after emptying it!"<N>    finally:<N>        CloseClipboard()<N><N>
def TestText():<N>    OpenClipboard()<N>    try:<N>        text = "Hello from Python"<N>        text_bytes = str2bytes(text)<N>        SetClipboardText(text)<N>        got = GetClipboardData(win32con.CF_TEXT)<N>        # CF_TEXT always gives us 'bytes' back .<N>        assert  got == text_bytes, "Didnt get the correct result back - '%r'." % (got,)<N>    finally:<N>        CloseClipboard()<N><N>
    OpenClipboard()<N>    try:<N>        # CF_UNICODE text always gives unicode objects back.<N>        got = GetClipboardData(win32con.CF_UNICODETEXT)<N>        assert  got == text, "Didnt get the correct result back - '%r'." % (got,)<N>        assert type(got)==str, "Didnt get the correct result back - '%r'." % (got,)<N><N>
## Demonstrates how to create a "pull" subscription<N>import win32evtlog, win32event, win32con<N>query_text='*[System[Provider[@Name="Microsoft-Windows-Winlogon"]]]'<N><N>h=win32event.CreateEvent(None, 0, 0, None)<N>s=win32evtlog.EvtSubscribe('System', win32evtlog.EvtSubscribeStartAtOldestRecord, SignalEvent=h, Query=query_text)<N><N>
while 1:<N>	while 1:<N>		events=win32evtlog.EvtNext(s, 10)<N>		if len(events)==0:<N>			break<N>		##for event in events:<N>		##	print(win32evtlog.EvtRender(event, win32evtlog.EvtRenderEventXml))<N>		print('retrieved %s events' %len(events))<N>	while 1:<N>		print ('waiting...')<N>		w=win32event.WaitForSingleObjectEx(h, 2000, True)<N>		if w==win32con.WAIT_OBJECT_0:<N>			break<N><N>
"""<N>Windows Process Control<N><N>winprocess.run launches a child process and returns the exit code.<N>Optionally, it can:<N>  redirect stdin, stdout & stderr to files<N>  run the command as another user<N>  limit the process's running time<N>  control the process window (location, size, window state, desktop)<N>Works on Windows NT, 2000 & XP. Requires Mark Hammond's win32<N>extensions.<N><N>
import win32service<N>import win32con<N><N><N>def EnumServices():<N>    resume = 0<N>    accessSCM = win32con.GENERIC_READ<N>    accessSrv = win32service.SC_MANAGER_ALL_ACCESS<N><N>    #Open Service Control Manager<N>    hscm = win32service.OpenSCManager(None, None, accessSCM)<N><N>
    #Enumerate Service Control Manager DB<N><N>    typeFilter = win32service.SERVICE_WIN32<N>    stateFilter = win32service.SERVICE_STATE_ALL<N><N>    statuses = win32service.EnumServicesStatus(hscm, typeFilter, stateFilter)<N>    for (short_name, desc, status) in statuses:<N>        print(short_name, desc, status)<N><N>
import win32evtlog<N>import win32api<N>import win32con<N>import win32security # To translate NT Sids to account names.<N><N>import win32evtlogutil<N><N>def ReadLog(computer, logType="Application", dumpEachRecord = 0):<N>    # read the entire log back.<N>    h=win32evtlog.OpenEventLog(computer, logType)<N>    numRecords = win32evtlog.GetNumberOfEventLogRecords(h)<N>#       print "There are %d records" % numRecords<N><N>
# A demo of the win32rcparser module and using win32gui<N><N>import win32gui<N>import win32api<N>import win32con<N>import win32rcparser<N>import commctrl<N>import sys, os<N><N>this_dir = os.path.abspath(os.path.dirname(__file__))<N>g_rcname = os.path.abspath(<N>        os.path.join( this_dir, "..", "test", "win32rcparser", "test.rc"))<N><N>
if not os.path.isfile(g_rcname):<N>    raise RuntimeError("Can't locate test.rc (should be at '%s')" % (g_rcname,))<N><N>class DemoWindow:<N>    def __init__(self, dlg_template):<N>        self.dlg_template = dlg_template<N><N>    def CreateWindow(self):<N>        self._DoCreate(win32gui.CreateDialogIndirect)<N><N>
    def DoModal(self):<N>        return self._DoCreate(win32gui.DialogBoxIndirect)<N><N>    def _DoCreate(self, fn):<N>        message_map = {<N>            win32con.WM_INITDIALOG: self.OnInitDialog,<N>            win32con.WM_CLOSE: self.OnClose,<N>            win32con.WM_DESTROY: self.OnDestroy,<N>            win32con.WM_COMMAND: self.OnCommand,<N>        }<N>        return fn(0, self.dlg_template, 0, message_map)<N><N>
    def OnInitDialog(self, hwnd, msg, wparam, lparam):<N>        self.hwnd = hwnd<N>        # centre the dialog<N>        desktop = win32gui.GetDesktopWindow()<N>        l,t,r,b = win32gui.GetWindowRect(self.hwnd)<N>        dt_l, dt_t, dt_r, dt_b = win32gui.GetWindowRect(desktop)<N>        centre_x, centre_y = win32gui.ClientToScreen( desktop, ( (dt_r-dt_l)//2, (dt_b-dt_t)//2) )<N>        win32gui.MoveWindow(hwnd, centre_x-(r//2), centre_y-(b//2), r-l, b-t, 0)<N><N>
    def OnCommand(self, hwnd, msg, wparam, lparam):<N>        # Needed to make OK/Cancel work - no other controls are handled.<N>        id = win32api.LOWORD(wparam)<N>        if id in [win32con.IDOK, win32con.IDCANCEL]:<N>            win32gui.EndDialog(hwnd, id)<N><N>
    def OnClose(self, hwnd, msg, wparam, lparam):<N>        win32gui.EndDialog(hwnd, 0)<N><N>    def OnDestroy(self, hwnd, msg, wparam, lparam):<N>        pass<N><N>def DemoModal():<N>    # Load the .rc file.<N>    resources = win32rcparser.Parse(g_rcname)<N>    for id, ddef in resources.dialogs.items():<N>        print("Displaying dialog", id)<N>        w=DemoWindow(ddef)<N>        w.DoModal()<N><N>
# Demo RegisterDeviceNotification etc.  Creates a hidden window to receive<N># notifications.  See serviceEvents.py for an example of a service doing<N># that.<N>import sys, time<N>import win32gui, win32con, win32api, win32file<N>import win32gui_struct, winnt<N><N>
# A demo of a fairly complex dialog.<N>#<N># Features:<N># * Uses a "dynamic dialog resource" to build the dialog.<N># * Uses a ListView control.<N># * Dynamically resizes content.<N># * Uses a second worker thread to fill the list.<N># * Demostrates support for windows XP themes.<N><N>
# The start of a win32gui generic demo.<N># Feel free to contribute more demos back ;-)<N><N>import win32gui, win32con, win32api<N>import time, math, random<N><N>def _MyCallback( hwnd, extra ):<N>    hwnds, classes = extra<N>    hwnds.append(hwnd)<N>    classes[win32gui.GetClassName(hwnd)] = 1<N><N>
def TestEnumWindows():<N>    windows = []<N>    classes = {}<N>    win32gui.EnumWindows(_MyCallback, (windows, classes))<N>    print("Enumerated a total of %d windows with %d classes" % (len(windows),len(classes)))<N>    if "tooltips_class32" not in classes:<N>        print("Hrmmmm - I'm very surprised to not find a 'tooltips_class32' class.")<N><N>
# Demonstrates using a taskbar icon to create and navigate between desktops<N><N>import win32api, win32con, win32gui, win32service, win32process<N>import pywintypes<N>import traceback, _thread, time<N>import io<N><N>## "Shell_TrayWnd" is class of system tray window, broadcasts "TaskbarCreated" when initialized<N><N>
# Contributed by Kelly Kranabetter.<N>import os, sys<N>import win32security, ntsecuritycon, pywintypes, winerror<N><N># get security information<N>#name=r"c:\autoexec.bat"<N>#name= r"g:\!workgrp\lim"<N>name=sys.argv[0]<N><N>if not os.path.exists(name):<N>    print(name, "does not exist!")<N>    sys.exit()<N><N>
import win32api, mmapfile<N>import winerror<N>import tempfile, os<N>from pywin32_testutil import str2bytes<N><N>system_info=win32api.GetSystemInfo()<N>page_size=system_info[1]<N>alloc_size=system_info[7]<N><N>fname=tempfile.mktemp()<N>mapping_name=os.path.split(fname)[1]<N>fsize=8*page_size<N>print(fname, fsize, mapping_name)<N><N>
m1=mmapfile.mmapfile(File=fname, Name=mapping_name, MaximumSize=fsize)<N>m1.seek(100)<N>m1.write_byte(str2bytes('?'))<N>m1.seek(-1,1)<N>assert m1.read_byte()==str2bytes('?')<N><N>## A reopened named mapping should have exact same size as original mapping<N>m2=mmapfile.mmapfile(Name=mapping_name, File=None, MaximumSize=fsize*2)<N>assert m2.size()==m1.size()<N>m1.seek(0,0)<N>m1.write(fsize*str2bytes('s'))<N>assert m2.read(fsize)==fsize*str2bytes('s')<N><N>
move_src=100<N>move_dest=500<N>move_size=150<N><N>m2.seek(move_src,0)<N>assert m2.tell()==move_src<N>m2.write(str2bytes('m')*move_size)<N>m2.move(move_dest, move_src, move_size)<N>m2.seek(move_dest, 0)<N>assert m2.read(move_size) ==  str2bytes('m') * move_size<N>##    m2.write('x'* (fsize+1))<N><N>
m2.close()<N>m1.resize(fsize*2)<N>assert m1.size()==fsize * 2<N>m1.seek(fsize)<N>m1.write(str2bytes('w') * fsize)<N>m1.flush()<N>m1.close()<N>os.remove(fname)<N><N><N><N>## Test a file with size larger than 32 bits<N>## need 10 GB free on drive where your temp folder lives<N>fname_large=tempfile.mktemp()<N>mapping_name='Pywin32_large_mmap'<N>offsetdata=str2bytes('This is start of offset')<N><N>
## Deliberately use odd numbers to test rounding logic<N>fsize = (1024*1024*1024*10) + 333<N>offset = (1024*1024*32) + 42<N>view_size = (1024*1024*16) + 111<N><N>## round mapping size and view size up to multiple of system page size<N>if fsize%page_size:<N>    fsize += page_size - (fsize%page_size)<N>if view_size%page_size:<N>    view_size += page_size - (view_size%page_size)<N>## round offset down to multiple of allocation granularity<N>offset -= offset%alloc_size<N><N>
# rastest.py - test/demonstrate the win32ras module.<N># Much of the code here contributed by Jethro Wright.<N><N>import sys<N>import os<N>import win32ras<N><N># Build a little dictionary of RAS states to decent strings.<N># eg win32ras.RASCS_OpenPort -> "OpenPort"<N>stateMap = {}<N>for name, val in list(win32ras.__dict__.items()):<N>    if name[:6]=="RASCS_":<N>        stateMap[val] = name[6:]<N><N>
# Demonstrates some advanced menu concepts using win32gui.<N># This creates a taskbar icon which has some fancy menus (but note that<N># selecting the menu items does nothing useful - see win32gui_taskbar.py<N># for examples of this.<N><N># NOTE: This is a work in progress.  Todo:<N># * The "Checked" menu items don't work correctly - I'm not sure why.<N># * No support for GetMenuItemInfo.<N><N>
# Based on Andy McKay's demo code.<N>from win32api import *<N># Try and use XP features, so we get alpha-blending etc.<N>try:<N>    from winxpgui import *<N>except ImportError:<N>    from win32gui import *<N>from win32gui_struct import *<N>import win32con<N>import sys, os<N>import struct<N>import array<N><N>
import os, win32api<N><N>ver_strings=('Comments','InternalName','ProductName', <N>    'CompanyName','LegalCopyright','ProductVersion', <N>    'FileDescription','LegalTrademarks','PrivateBuild', <N>    'FileVersion','OriginalFilename','SpecialBuild')<N>fname = os.environ["comspec"]<N>d=win32api.GetFileVersionInfo(fname, '\\')<N>## backslash as parm returns dictionary of numeric info corresponding to VS_FIXEDFILEINFO struc<N>for n, v in d.items():<N>    print(n, v)<N><N>
import win32console, win32con<N>import traceback, time<N><N>virtual_keys={}<N>for k,v in list(win32con.__dict__.items()):<N>    if k.startswith('VK_'):<N>        virtual_keys[v]=k <N><N>free_console=True<N>try:<N>    win32console.AllocConsole()<N>except win32console.error as exc:<N>    if exc.winerror!=5:<N>        raise<N>    ## only free console if one was created successfully<N>    free_console=False<N><N>
stdout=win32console.GetStdHandle(win32console.STD_OUTPUT_HANDLE)<N>stdin=win32console.GetStdHandle(win32console.STD_INPUT_HANDLE)<N>newbuffer=win32console.CreateConsoleScreenBuffer()<N>newbuffer.SetConsoleActiveScreenBuffer()<N>newbuffer.SetConsoleTextAttribute(win32console.FOREGROUND_RED|win32console.FOREGROUND_INTENSITY<N>        |win32console.BACKGROUND_GREEN|win32console.BACKGROUND_INTENSITY)<N>newbuffer.WriteConsole('This is a new screen buffer\n')<N><N>
## test setting screen buffer and window size<N>## screen buffer size cannot be smaller than window size<N>window_size=newbuffer.GetConsoleScreenBufferInfo()['Window']<N>coord=win32console.PyCOORDType(X=window_size.Right+20, Y=window_size.Bottom+20)<N>newbuffer.SetConsoleScreenBufferSize(coord)<N><N>
window_size.Right+=10<N>window_size.Bottom+=10<N>newbuffer.SetConsoleWindowInfo(Absolute=True,ConsoleWindow=window_size)<N><N>## write some records to the input queue <N>x=win32console.PyINPUT_RECORDType(win32console.KEY_EVENT)<N>x.Char='X'<N>x.KeyDown=True<N>x.RepeatCount=1<N>x.VirtualKeyCode=0x58<N>x.ControlKeyState=win32con.SHIFT_PRESSED<N><N>
z=win32console.PyINPUT_RECORDType(win32console.KEY_EVENT)<N>z.Char='Z'<N>z.KeyDown=True<N>z.RepeatCount=1<N>z.VirtualKeyCode=0x5a<N>z.ControlKeyState=win32con.SHIFT_PRESSED<N><N>stdin.WriteConsoleInput([x,z,x])<N><N>newbuffer.SetConsoleTextAttribute(win32console.FOREGROUND_RED|win32console.FOREGROUND_INTENSITY<N>        |win32console.BACKGROUND_GREEN|win32console.BACKGROUND_INTENSITY)<N>newbuffer.WriteConsole('Press some keys, click some characters with the mouse\n')<N><N>
"""<N>This demonstrates the creation of miniversions of a file during a transaction.<N>The FSCTL_TXFS_CREATE_MINIVERSION control code saves any changes to a new<N>miniversion (effectively a savepoint within a transaction).<N>"""<N><N>import win32file, win32api, win32transaction, winerror<N>import win32con, winioctlcon<N>import struct<N>import os<N>from pywin32_testutil import str2bytes # py3k-friendly helper<N><N>
def demo():<N>    """<N>    Definition of buffer used with FSCTL_TXFS_CREATE_MINIVERSION:<N>    typedef struct _TXFS_CREATE_MINIVERSION_INFO{<N>        USHORT StructureVersion;<N>        USHORT StructureLength;<N>        ULONG BaseVersion;<N>        USHORT MiniVersion;}<N>    """<N>    buf_fmt='HHLH0L'   ## buffer size must include struct padding<N>    buf_size=struct.calcsize(buf_fmt)<N><N>
import win32file, win32api<N>import os<N><N><N>def ProgressRoutine(TotalFileSize, TotalBytesTransferred, StreamSize, StreamBytesTransferred,<N>    StreamNumber, CallbackReason, SourceFile, DestinationFile, Data):<N>    print(Data)<N>    print(TotalFileSize, TotalBytesTransferred, StreamSize, StreamBytesTransferred, StreamNumber, CallbackReason, SourceFile, DestinationFile)<N>    ##if TotalBytesTransferred > 100000:<N>    ##    return win32file.PROGRESS_STOP<N>    return win32file.PROGRESS_CONTINUE<N><N>
temp_dir=win32api.GetTempPath()<N>fsrc=win32api.GetTempFileName(temp_dir,'cfe')[0]<N>fdst=win32api.GetTempFileName(temp_dir,'cfe')[0]<N>print(fsrc, fdst)<N><N>f=open(fsrc,'w')<N>f.write('xxxxxxxxxxxxxxxx\n'*32768)<N>f.close()<N>## add a couple of extra data streams<N>f=open(fsrc+':stream_y','w')<N>f.write('yyyyyyyyyyyyyyyy\n'*32768)<N>f.close()<N>f=open(fsrc+':stream_z','w')<N>f.write('zzzzzzzzzzzzzzzz\n'*32768)<N>f.close()<N><N>
"""A demo of using win32net.NetValidatePasswordPolicy.<N><N>Example usage:<N><N>% NetValidatePasswordPolicy.py --password=foo change<N>which might return:<N><N>> Result of 'change' validation is 0: The operation completed successfully.<N><N>or depending on the policy:<N><N>
> Result of 'change' validation is 2245: The password does not meet the<N>> password policy requirements. Check the minimum password length,<N>> password complexity and password history requirements.<N><N>Adding --user doesn't seem to change the output (even the PasswordLastSet seen<N>when '-f' is used doesn't depend on the username), but theoretically it will<N>also check the password history for the specified user.<N><N>
% NetValidatePasswordPolicy.py auth<N><N>which always (with and without '-m') seems to return:<N><N>> Result of 'auth' validation is 2701: Password must change at next logon<N>"""<N><N>import sys<N>import win32api<N>import win32net, win32netcon<N><N>import optparse<N>from pprint import pprint<N><N>
def main():<N>    parser = optparse.OptionParser("%prog [options] auth|change ...",<N>                                   description="A win32net.NetValidatePasswordPolicy demo.")<N><N>    parser.add_option("-u", "--username",<N>                      action="store",<N>                      help="The username to pass to the function (only for the "<N>                           "change command")<N><N>
import sys<N><N>import win32evtlog<N><N><N>def main():<N>    path = 'System'<N>    num_events = 5<N>    if len(sys.argv) > 2:<N>        path = sys.argv[1]<N>        num_events = int(sys.argv[2])<N>    elif len(sys.argv) > 1:<N>        path = sys.argv[1]<N><N>
    query = win32evtlog.EvtQuery(path, win32evtlog.EvtQueryForwardDirection)<N>    events = win32evtlog.EvtNext(query, num_events)<N>    context = win32evtlog.EvtCreateRenderContext(win32evtlog.EvtRenderContextSystem)<N><N>    for i, event in enumerate(events, 1):<N>        result = win32evtlog.EvtRender(event, win32evtlog.EvtRenderEventValues, Context=context)<N><N>
import win32file, win32api, winerror<N>import os<N><N>def ReadCallback(input_buffer, data, buflen):<N>    fnamein, fnameout, f = data<N>    ## print fnamein, fnameout, buflen<N>    f.write(input_buffer)<N>    ## python 2.3 throws an error if return value is a plain int<N>    return winerror.ERROR_SUCCESS<N><N>
def WriteCallback(output_buffer, data, buflen):<N>    fnamebackup, fnameout, f = data<N>    file_data=f.read(buflen)<N>    ## returning 0 as len terminates WriteEncryptedFileRaw<N>    output_len=len(file_data)<N>    output_buffer[:output_len]=file_data<N>    return winerror.ERROR_SUCCESS, output_len<N><N>
# A sample distutils script to show to build your own<N># extension module which extends pywintypes or pythoncom.<N>#<N># Use 'python setup.py build' to build this extension.<N>import os<N>from distutils.core import setup, Extension<N>from distutils.sysconfig import get_python_lib<N><N>
sources = ["win32_extension.cpp"]<N><N># Specify the directory where the PyWin32 .h and .lib files are installed.<N># If you are doing a win32com extension, you will also need to add<N># win32com\Include and win32com\Libs.<N>ext = Extension("win32_extension", sources,<N>                include_dirs = [os.path.join(get_python_lib(), "win32", "Include")],<N>                library_dirs = [os.path.join(get_python_lib(), "win32", "Libs")],<N>                )<N><N>
# 'Request' example added jjk  11/20/98<N><N>import win32ui<N>from pywin.mfc import object<N>import dde<N><N>class MySystemTopic(object.Object):<N>	def __init__(self):<N>		object.Object.__init__(self, dde.CreateServerSystemTopic())<N><N>	def Exec(self, cmd):<N>		print("System Topic asked to exec", cmd)<N><N>
class MyOtherTopic(object.Object):<N>	def __init__(self, topicName):<N>		object.Object.__init__(self, dde.CreateTopic(topicName))<N><N>	def Exec(self, cmd):<N>		print("Other Topic asked to exec", cmd)<N><N>class MyRequestTopic(object.Object):<N>	def __init__(self, topicName):<N>		topic = dde.CreateTopic(topicName)<N>		topic.AddItem(dde.CreateStringItem(""))<N>		object.Object.__init__(self, topic)<N><N>
	def Request(self, aString):<N>		print("Request Topic asked to compute length of:", aString)<N>		return(str(len(aString)))<N><N>server = dde.CreateServer()<N>server.AddTopic(MySystemTopic())<N>server.AddTopic(MyOtherTopic("RunAnyCommand"))<N>server.AddTopic(MyRequestTopic("ComputeStringLength"))<N>server.Create('RunAny')<N><N>
# 'Request' example added jjk  11/20/98<N><N>import win32ui<N>import dde<N><N>server = dde.CreateServer()<N>server.Create("TestClient")<N><N>conversation = dde.CreateConversation(server)<N><N>conversation.ConnectTo("RunAny", "RunAnyCommand")<N>conversation.Exec("DoSomething")<N>conversation.Exec("DoSomethingElse")<N><N>conversation.ConnectTo("RunAny", "ComputeStringLength")<N>s = 'abcdefghi'<N>sl = conversation.Request(s)<N>print('length of "%s" is %s'%(s,sl))<N><N>
import win32security,win32file,win32api,ntsecuritycon,win32con<N>policy_handle = win32security.GetPolicyHandle('rupole',win32security.POLICY_ALL_ACCESS)<N><N>event_audit_info=win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyAuditEventsInformation)<N>print(event_audit_info)<N><N>
new_audit_info=list(event_audit_info[1])<N>new_audit_info[win32security.AuditCategoryPolicyChange]= \<N>            win32security.POLICY_AUDIT_EVENT_SUCCESS|win32security.POLICY_AUDIT_EVENT_FAILURE<N>new_audit_info[win32security.AuditCategoryAccountLogon]= \<N>            win32security.POLICY_AUDIT_EVENT_SUCCESS|win32security.POLICY_AUDIT_EVENT_FAILURE<N>new_audit_info[win32security.AuditCategoryLogon]= \<N>            win32security.POLICY_AUDIT_EVENT_SUCCESS|win32security.POLICY_AUDIT_EVENT_FAILURE<N><N>
import os<N>import win32security,win32file,win32api,ntsecuritycon,win32con<N>from security_enums import TRUSTEE_TYPE,TRUSTEE_FORM,ACE_FLAGS,ACCESS_MODE<N><N>fname = os.path.join(win32api.GetTempPath(), "win32security_test.txt")<N>f=open(fname, "w")<N>f.write("Hello from Python\n");<N>f.close()<N>print("Testing on file", fname)<N><N>
import win32security,win32file,win32api,ntsecuritycon,win32con<N>policy_handle = win32security.GetPolicyHandle('rupole',win32security.POLICY_ALL_ACCESS)<N><N>## mod_nbr, mod_time = win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyModificationInformation)<N>## print mod_nbr, mod_time<N><N>
domain_name,dns_domain_name, dns_forest_name, domain_guid, domain_sid = \<N>        win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyDnsDomainInformation)<N>print(domain_name, dns_domain_name, dns_forest_name, domain_guid, domain_sid)<N><N>
event_audit_info=win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyAuditEventsInformation)<N>print(event_audit_info)<N><N>domain_name,sid =win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyPrimaryDomainInformation)<N>print(domain_name, sid)<N><N>
domain_name,sid =win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyAccountDomainInformation)<N>print(domain_name, sid)<N><N>server_role = win32security.LsaQueryInformationPolicy(policy_handle,win32security.PolicyLsaServerRoleInformation)<N>print('server role: ',server_role)<N><N>
# A Python port of the MS knowledge base article Q157234<N># "How to deal with localized and renamed user and group names"<N># http://support.microsoft.com/default.aspx?kbid=157234<N><N>import sys<N>from win32net import NetUserModalsGet<N>from win32security import LookupAccountSid<N>import pywintypes<N>from ntsecuritycon import *<N><N>
def LookupAliasFromRid(TargetComputer, Rid):<N>    # Sid is the same regardless of machine, since the well-known<N>    # BUILTIN domain is referenced.<N>    sid = pywintypes.SID()<N>    sid.Initialize(SECURITY_NT_AUTHORITY, 2)<N><N>    for i, r in enumerate((SECURITY_BUILTIN_DOMAIN_RID, Rid)):<N>        sid.SetSubAuthority(i, r)<N><N>
import win32security, win32event<N>evt = win32event.CreateEvent(None,0,0,None)<N>win32security.LsaRegisterPolicyChangeNotification(win32security.PolicyNotifyAuditEventsInformation, evt)<N>print("Waiting for you change Audit policy in Management console ...")<N>ret_code=win32event.WaitForSingleObject(evt,1000000000)<N>## should come back when you change Audit policy in Management console ...<N>print(ret_code)<N>win32security.LsaUnregisterPolicyChangeNotification(win32security.PolicyNotifyAuditEventsInformation, evt)<N>
import win32security<N>policy_handle = win32security.GetPolicyHandle('',win32security.POLICY_ALL_ACCESS)<N>privatedata='some sensitive data'<N>keyname='tmp'<N>win32security.LsaStorePrivateData(policy_handle,keyname,privatedata)<N>retrieveddata=win32security.LsaRetrievePrivateData(policy_handle,keyname)<N>assert retrieveddata==privatedata<N><N>## passing None deletes key<N>win32security.LsaStorePrivateData(policy_handle,keyname,None)<N>win32security.LsaClose(policy_handle)<N>
import win32security,win32file,win32api,ntsecuritycon,win32con, os<N>from win32security import ACL_REVISION_DS, CONTAINER_INHERIT_ACE, OBJECT_INHERIT_ACE, \<N>     PROTECTED_DACL_SECURITY_INFORMATION, DACL_SECURITY_INFORMATION, SACL_SECURITY_INFORMATION, \<N>     OWNER_SECURITY_INFORMATION, GROUP_SECURITY_INFORMATION, SE_FILE_OBJECT<N><N>
import pywintypes, win32security<N>sa=pywintypes.SECURITY_ATTRIBUTES()<N>tmp_sid=win32security.LookupAccountName('','tmp')[0]<N>sa.SetSecurityDescriptorOwner(tmp_sid,0)<N>sid=sa.SECURITY_DESCRIPTOR.GetSecurityDescriptorOwner()<N>print(win32security.LookupAccountSid('',sid))<N><N>
""" Lists various types of information about current user's access token,<N>    including UAC status on Vista<N>"""<N><N>import pywintypes, win32api, win32security<N>import win32con, winerror<N>from security_enums import TOKEN_GROUP_ATTRIBUTES, TOKEN_PRIVILEGE_ATTRIBUTES, \<N>     SECURITY_IMPERSONATION_LEVEL, TOKEN_TYPE, TOKEN_ELEVATION_TYPE<N><N>
<N>def dump_token(th):<N>    token_type=win32security.GetTokenInformation(th, win32security.TokenType)<N>    print('TokenType:', token_type, TOKEN_TYPE.lookup_name(token_type))<N>    if token_type==win32security.TokenImpersonation:<N>        imp_lvl=win32security.GetTokenInformation(th, win32security.TokenImpersonationLevel)<N>        print('TokenImpersonationLevel:', imp_lvl, SECURITY_IMPERSONATION_LEVEL.lookup_name(imp_lvl))<N><N>
    print('TokenSessionId:', win32security.GetTokenInformation(th, win32security.TokenSessionId))<N><N>    privs=win32security.GetTokenInformation(th,win32security.TokenPrivileges)<N>    print('TokenPrivileges:')<N>    for priv_luid, priv_flags in privs:<N>        flag_names, unk=TOKEN_PRIVILEGE_ATTRIBUTES.lookup_flags(priv_flags)<N>        flag_desc = ' '.join(flag_names)<N>        if (unk):<N>            flag_desc += '(' + str(unk) + ')'<N><N>
import win32api, win32con, win32security, ntsecuritycon<N><N>new_privs = ((win32security.LookupPrivilegeValue('',ntsecuritycon.SE_SECURITY_NAME),win32con.SE_PRIVILEGE_ENABLED),<N>             (win32security.LookupPrivilegeValue('',ntsecuritycon.SE_TCB_NAME),win32con.SE_PRIVILEGE_ENABLED)<N>            )<N>ph = win32api.GetCurrentProcess()<N>th = win32security.OpenProcessToken(ph,win32security.TOKEN_ALL_ACCESS|win32con.TOKEN_ADJUST_PRIVILEGES)<N><N>
win32security.AdjustTokenPrivileges(th,0,new_privs)<N>hkey=win32api.RegOpenKey(win32con.HKEY_LOCAL_MACHINE,None,0,win32con.KEY_ALL_ACCESS)<N>win32api.RegCreateKey(hkey,'SYSTEM\\NOTMP')<N>notmpkey=win32api.RegOpenKey(hkey,'SYSTEM\\notmp',0,win32con.ACCESS_SYSTEM_SECURITY)<N><N>
tmp_sid = win32security.LookupAccountName('','tmp')[0]<N>sacl=win32security.ACL()<N>sacl.AddAuditAccessAce(win32security.ACL_REVISION,win32con.GENERIC_ALL,tmp_sid,1,1)<N><N>sd=win32security.SECURITY_DESCRIPTOR()<N>sd.SetSecurityDescriptorSacl(1,sacl,1)<N>win32api.RegSetKeySecurity(notmpkey,win32con.SACL_SECURITY_INFORMATION,sd)<N><N><N>
"""A sample socket server and client using SSPI authentication and encryption.<N><N>You must run with either 'client' or 'server' as arguments.  A server must be<N>running before a client can connect.<N><N>To use with Kerberos you should include in the client options<N>--target-spn=username, where 'username' is the user under which the server is<N>being run.<N><N>
Running either the client or server as a different user can be informative.<N>A command-line such as the following may be useful:<N>`runas /user:{user} {fqp}\python.exe {fqp}\socket_server.py --wait client|server`<N><N>{fqp} should specify the relevant fully-qualified path names.<N><N>
To use 'runas' with Kerberos, the client program will need to<N>specify --target-spn with the username under which the *server* is running.<N><N>See the SSPI documentation for more details.<N>"""<N><N><N>import sys<N>import struct<N>import socketserver<N>import win32api<N>import http.client<N>import traceback<N><N>
# A demo of basic SSPI authentication.<N># There is a 'client' context and a 'server' context - typically these will<N># be on different machines (here they are in the same process, but the same<N># concepts apply)<N>import sspi<N>import win32security, sspicon, win32api<N><N>
"""<N>Fetches a URL from a web-server supporting NTLM authentication<N>eg, IIS.<N><N>If no arguments are specified, a default of http://localhost/localstart.asp<N>is used.  This script does follow simple 302 redirections, so pointing at the<N>root of an IIS server is should work.<N>"""<N><N>
import sys<N>import urllib.request, urllib.parse, urllib.error<N>import http.client<N>import urllib.parse<N>from base64 import encodestring, decodestring<N><N>from sspi import ClientAuth<N><N>import optparse # sorry, this demo needs 2.3+<N><N>options = None # set to optparse options object<N><N>
'''runproc.py<N><N>start a process with three inherited pipes.<N>Try to write to and read from those.<N>'''<N><N>import win32api<N>import win32pipe<N>import win32file<N>import win32process<N>import win32security<N>import win32con<N>import msvcrt<N>import os<N><N>
class Process:<N>    def run(self, cmdline):<N>        # security attributes for pipes<N>        sAttrs = win32security.SECURITY_ATTRIBUTES()<N>        sAttrs.bInheritHandle = 1<N><N>        # create pipes<N>        hStdin_r,  self.hStdin_w  = win32pipe.CreatePipe(sAttrs, 0)<N>        self.hStdout_r, hStdout_w = win32pipe.CreatePipe(sAttrs, 0)<N>        self.hStderr_r, hStderr_w = win32pipe.CreatePipe(sAttrs, 0)<N><N>
'''cat.py<N>a version of unix cat, tweaked to show off runproc.py<N>'''<N><N>import sys<N>data = sys.stdin.read(1)<N>sys.stdout.write(data)<N>sys.stdout.flush()<N>while data:<N>    data = sys.stdin.read(1)<N>    sys.stdout.write(data)<N>    sys.stdout.flush()<N># Just here to have something to read from stderr.<N>sys.stderr.write("Blah...")<N><N># end of cat.py<N>
# A Test Program for pipeTestService.py<N>#<N># Install and start the Pipe Test service, then run this test<N># either from the same machine, or from another using the "-s" param.<N>#<N># Eg: pipeTestServiceClient.py -s server_name Hi There<N># Should work.<N><N>
# A Demo of a service that takes advantage of the additional notifications<N># available in later Windows versions.<N><N># Note that all output is written as event log entries - so you must install<N># and start the service, then look at the event log for messages as events<N># are generated.<N><N>
# Events are generated for USB device insertion and removal, power state<N># changes and hardware profile events - so try putting your computer to<N># sleep and waking it, inserting a memory stick, etc then check the event log<N><N>import win32serviceutil, win32service<N>import win32event<N>import servicemanager<N><N>
# Most event notification support lives around win32gui<N>import win32gui, win32gui_struct, win32con<N>GUID_DEVINTERFACE_USB_DEVICE = "{A5DCBF10-6530-11D2-901F-00C04FB951ED}"<N><N>class EventDemoService(win32serviceutil.ServiceFramework):<N>    _svc_name_ = "PyServiceEventDemo"<N>    _svc_display_name_ = "Python Service Event Demo"<N>    _svc_description_ = "Demonstrates a Python service which takes advantage of the extra notifications"<N><N>
# A Demo of services and named pipes.<N><N># A multi-threaded service that simply echos back its input.<N><N># * Install as a service using "pipeTestService.py install"<N># * Use Control Panel to change the user name of the service<N>#   to a real user name (ie, NOT the SystemAccount)<N># * Start the service.<N># * Run the "pipeTestServiceClient.py" program as the client pipe side.<N><N>
import win32serviceutil, win32service<N>import pywintypes, win32con, winerror<N># Use "import *" to keep this looking as much as a "normal" service<N># as possible.  Real code shouldn't do this.<N>from win32event import *<N>from win32file import *<N>from win32pipe import *<N>from win32api import *<N>from ntsecuritycon import *<N><N>
# Old versions of the service framework would not let you import this<N># module at the top-level.  Now you can, and can check 'Debugging()' and<N># 'RunningAsService()' to check your context.<N>import servicemanager<N><N>import traceback<N>import _thread<N><N>
def ApplyIgnoreError(fn, args):<N>    try:<N>        return fn(*args)<N>    except error: # Ignore win32api errors.<N>        return None<N><N>class TestPipeService(win32serviceutil.ServiceFramework):<N>    _svc_name_ = "PyPipeTestService"<N>    _svc_display_name_ = "Python Pipe Test Service"<N>    _svc_description_ = "Tests Python service framework by receiving and echoing messages over a named pipe"<N><N>
    def __init__(self, args):<N>        win32serviceutil.ServiceFramework.__init__(self, args)<N>        self.hWaitStop = CreateEvent(None, 0, 0, None)<N>        self.overlapped = pywintypes.OVERLAPPED()<N>        self.overlapped.hEvent = CreateEvent(None,0,0,None)<N>        self.thread_handles = []<N><N>
# A tool to setup the Python registry.<N><N>class error(Exception):<N>    pass<N><N>import sys # at least we can count on this!<N><N>def FileExists(fname):<N>    """Check if a file exists.  Returns true or false.<N>    """<N>    import os<N>    try:<N>        os.stat(fname)<N>        return 1<N>    except os.error as details:<N>        return 0<N><N>
def IsPackageDir(path, packageName, knownFileName):<N>    """Given a path, a ni package name, and possibly a known file name in<N>       the root of the package, see if this path is good.<N>    """<N>    import os<N>    if knownFileName is None:<N>        knownFileName = "."<N>    return FileExists(os.path.join(os.path.join(path, packageName),knownFileName))<N><N>
def IsDebug():<N>    """Return "_d" if we're running a debug version.<N><N>    This is to be used within DLL names when locating them.<N>    """<N>    import importlib.machinery<N>    return '_d' if '_d.pyd' in importlib.machinery.EXTENSION_SUFFIXES else ''<N><N>
# Kills a process by process name<N>#<N># Uses the Performance Data Helper to locate the PID, then kills it.<N># Will only kill the process if there is only one process of that name<N># (eg, attempting to kill "Python.exe" will only work if there is only<N># one Python.exe running.  (Note that the current process does not<N># count - ie, if Python.exe is hosting this script, you can still kill<N># another Python.exe (as long as there is only one other Python.exe)<N><N>
# Install and register pythonxx_d.dll, pywintypesxx_d.dll and pythoncomxx_d.dll<N>#<N># Assumes the _d files can be found in the same directory as this script<N># or in the cwd.<N><N>import win32api<N>import winreg<N>import sys<N>import shutil<N>import os<N><N>
import win32con, string, traceback<N>import win32com.client, win32com.client.gencache<N>import pythoncom<N>import time<N>import os<N><N>constants = win32com.client.constants<N><N>win32com.client.gencache.EnsureModule('{783CD4E0-9D54-11CF-B8EE-00608CC9A71F}', 0, 5, 0)<N><N>
error = "vssutil error"<N><N>def GetSS():<N>	ss=win32com.client.Dispatch("SourceSafe")<N>	# SS seems a bit weird.  It defaults the arguments as empty strings, but<N>	# then complains when they are used - so we pass "Missing"<N>	ss.Open(pythoncom.Missing, pythoncom.Missing, pythoncom.Missing)<N>	return ss<N><N>
def test(projectName):<N>	ss=GetSS()<N>	project = ss.VSSItem(projectName)<N><N>	for item in project.GetVersions(constants.VSSFLAG_RECURSYES):<N>		print(item.VSSItem.Name, item.VersionNumber, item.Action)<N>		<N><N>#	item=i.Versions[0].VSSItem<N>#	for h in i.Versions:<N>#		print `h.Comment`, h.Action, h.VSSItem.Name<N>	<N><N>
def SubstituteInString(inString, evalEnv):<N>	substChar = "$"<N>	fields = string.split(inString, substChar)<N>	newFields = []<N>	for i in range(len(fields)):<N>		didSubst = 0<N>		strVal = fields[i]<N>		if i%2!=0:<N>			try:<N>				strVal = eval(strVal,evalEnv[0], evalEnv[1])<N>				newFields.append(strVal)<N>				didSubst = 1<N>			except:<N>				traceback.print_exc()<N>				print("Could not substitute", strVal)<N>		if not didSubst:<N>			newFields.append(strVal)<N>	return string.join(map(str, newFields), "")<N><N>
def SubstituteInFile(inName, outName, evalEnv):<N>	inFile = open(inName, "r")<N>	try:<N>		outFile = open(outName, "w")<N>		try:<N>			while 1:<N>				line = inFile.read()<N>				if not line: break<N>				outFile.write(SubstituteInString(line, evalEnv))<N>		finally:<N>			outFile.close()<N>	finally:<N>		inFile.close()<N><N>
# Simple CE synchronisation utility with Python features.<N><N>import wincerapi<N>import win32api<N>import win32file<N>import getopt<N>import sys<N>import os<N>import string<N>import win32con<N>import fnmatch<N><N>class InvalidUsage(Exception): pass<N><N>def print_error(api_exc, msg):<N>    hr, fn, errmsg = api_exc<N>    print("%s - %s(%d)" % (msg, errmsg, hr))<N><N>
def GetFileAttributes(file, local=1):<N>    if local: return win32api.GetFileAttributes(file)<N>    else: return wincerapi.CeGetFileAttributes(file)<N><N>def FindFiles(spec, local=1):<N>    if local: return win32api.FindFiles(spec)<N>    else: return wincerapi.CeFindFiles(spec)<N><N>
import sys<N>import unittest<N>import pywintypes<N>import win32api<N>from pywin32_testutil import int2long<N><N># A class that will never die vie refcounting, but will die via GC.<N>class Cycle:<N>    def __init__(self, handle):<N>        self.cycle = self<N>        self.handle = handle<N><N>
import unittest<N>from pywin32_testutil import str2bytes, TestSkipped, testmain<N>import win32api, win32file, win32pipe, pywintypes, winerror, win32event<N>import win32con, ntsecuritycon<N>import sys<N>import os<N>import tempfile<N>import threading<N>import time<N>import shutil<N>import socket<N>import datetime<N>import random<N>import win32timezone<N><N>
try:<N>    set<N>except NameError:<N>    from sets import Set as set<N><N>class TestReadBuffer(unittest.TestCase):<N>    def testLen(self):<N>        buffer = win32file.AllocateReadBuffer(1)<N>        self.failUnlessEqual(len(buffer), 1)<N><N>    def testSimpleIndex(self):<N>        buffer = win32file.AllocateReadBuffer(1)<N>        buffer[0] = 0xFF<N>        self.assertEqual(buffer[0], 0xFF)<N><N>
# tests for win32gui<N>import unittest<N>import win32gui<N>import pywin32_testutil<N>import operator<N>import array<N>import sys<N><N>class TestPyGetString(unittest.TestCase):<N>    def test_get_string(self):<N>        # test invalid addresses cause a ValueError rather than crash!<N>        self.assertRaises(ValueError, win32gui.PyGetString, 0)<N>        self.assertRaises(ValueError, win32gui.PyGetString, 1)<N>        self.assertRaises(ValueError, win32gui.PyGetString, 1,1)<N><N>
class TestPyGetMemory(unittest.TestCase):<N>    def test_ob(self):<N>        # Check the PyGetMemory result and a bytes string can be compared<N>        test_data = b"\0\1\2\3\4\5\6"<N>        c = array.array("b", test_data)<N>        addr, buflen = c.buffer_info()<N>        got = win32gui.PyGetMemory(addr, buflen)<N>        self.assertEqual(len(got), len(test_data))<N>        self.assertEqual(bytes(got), test_data)<N><N>
    def test_memory_index(self):<N>        # Check we can index into the buffer object returned by PyGetMemory<N>        test_data = b"\0\1\2\3\4\5\6"<N>        c = array.array("b", test_data)<N>        addr, buflen = c.buffer_info()<N>        got = win32gui.PyGetMemory(addr, buflen)<N>        self.assertEqual(got[0], 0)<N><N>
    def test_memory_slice(self):<N>        # Check we can slice the buffer object returned by PyGetMemory<N>        test_data = b"\0\1\2\3\4\5\6"<N>        c = array.array("b", test_data)<N>        addr, buflen = c.buffer_info()<N>        got = win32gui.PyGetMemory(addr, buflen)<N>        self.assertEqual(list(got[0:3]), [0, 1, 2])<N><N>
    def test_real_view(self):<N>        # Do the PyGetMemory, then change the original memory, then ensure<N>        # the initial object we fetched sees the new value.<N>        test_data = b"\0\1\2\3\4\5\6"<N>        c = array.array("b", test_data)<N>        addr, buflen = c.buffer_info()<N>        got = win32gui.PyGetMemory(addr, buflen)<N>        self.assertEqual(got[0], 0)<N>        c[0] = 1<N>        self.assertEqual(got[0], 1)<N><N>
    def test_memory_not_writable(self):<N>        # Check the buffer object fetched by PyGetMemory isn't writable.<N>        test_data = b"\0\1\2\3\4\5\6"<N>        c = array.array("b", test_data)<N>        addr, buflen = c.buffer_info()<N>        got = win32gui.PyGetMemory(addr, buflen)<N>        self.assertRaises(TypeError, operator.setitem, got, 0, 1)<N><N>
import unittest<N>import win32event<N>import pywintypes<N>import time<N>import os<N>import sys<N>from pywin32_testutil import int2long<N><N>class TestWaitableTimer(unittest.TestCase):<N>    def testWaitableFireLong(self):<N>        h = win32event.CreateWaitableTimer(None, 0, None)<N>        dt = int2long(-160) # 160 ns.<N>        win32event.SetWaitableTimer(h, dt, 0, None, None, 0)<N>        rc = win32event.WaitForSingleObject(h, 1000)<N>        self.failUnlessEqual(rc, win32event.WAIT_OBJECT_0)<N><N>
    def testWaitableFire(self):<N>        h = win32event.CreateWaitableTimer(None, 0, None)<N>        dt = -160 # 160 ns.<N>        win32event.SetWaitableTimer(h, dt, 0, None, None, 0)<N>        rc = win32event.WaitForSingleObject(h, 1000)<N>        self.failUnlessEqual(rc, win32event.WAIT_OBJECT_0)<N><N>
    def testWaitableTrigger(self):<N>        h = win32event.CreateWaitableTimer(None, 0, None)<N>        # for the sake of this, pass a long that doesn't fit in an int.<N>        dt = -2000000000<N>        win32event.SetWaitableTimer(h, dt, 0, None, None, 0)<N>        rc = win32event.WaitForSingleObject(h, 10) # 10 ms.<N>        self.failUnlessEqual(rc, win32event.WAIT_TIMEOUT)<N><N>
# odbc test suite kindly contributed by Frank Millman.<N>import sys<N>import os<N>import unittest<N>import odbc<N>import tempfile<N><N>from pywin32_testutil import str2bytes, str2memory, TestSkipped<N><N># We use the DAO ODBC driver<N>from win32com.client.gencache import EnsureDispatch<N>from win32com.client import constants<N>import pythoncom<N><N>
# General test module for win32api - please add some :)<N><N>import unittest<N>from pywin32_testutil import str2bytes<N><N>import win32api, win32con, win32event, winerror<N>import sys, os<N>import tempfile<N>import datetime<N><N>class CurrentUserTestCase(unittest.TestCase):<N>    def testGetCurrentUser(self):<N>        name = "%s\\%s" % (win32api.GetDomainName(), win32api.GetUserName())<N>        self.failUnless(name == win32api.GetUserNameEx(win32api.NameSamCompatible))<N><N>
import unittest<N>import time<N>import threading<N>from pywin32_testutil import str2bytes # py3k-friendly helper<N><N><N>import win32pipe<N>import win32file<N>import win32event<N>import pywintypes<N>import winerror<N>import win32con<N><N>class PipeTests(unittest.TestCase):<N>    pipename = "\\\\.\\pipe\\python_test_pipe"<N><N>
import sys, os<N>import unittest<N>import win32rcparser<N>import win32con<N>import tempfile<N><N>class TestParser(unittest.TestCase):<N>    def setUp(self):<N>        rc_file = os.path.join(os.path.dirname(__file__), "win32rcparser", "test.rc")<N>        self.resources = win32rcparser.Parse(rc_file)<N><N>
    def testStrings(self):<N>        for sid, expected in [<N>            ("IDS_TEST_STRING4", "Test 'single quoted' string"),<N>            ("IDS_TEST_STRING1", 'Test "quoted" string'),<N>            ("IDS_TEST_STRING3", 'String with single " quote'),<N>            ("IDS_TEST_STRING2", 'Test string'),<N>                             ]:<N>            got = self.resources.stringTable[sid].value<N>            self.assertEqual(got, expected)<N><N>
    def testStandardIds(self):<N>        for idc in "IDOK IDCANCEL".split():<N>            correct = getattr(win32con, idc)<N>            self.assertEqual(self.resources.names[correct], idc)<N>            self.assertEqual(self.resources.ids[idc], correct)<N><N>
# General test module for win32api - please add some :)<N>import sys, os<N>import unittest<N><N>from win32clipboard import *<N>import win32gui, win32con<N>import pywintypes<N>import array<N><N>from pywin32_testutil import str2bytes<N><N>custom_format_name = "PythonClipboardTestFormat"<N><N>
class CrashingTestCase(unittest.TestCase):<N>    def test_722082(self):<N>        class crasher(object):<N>            pass<N><N>        obj = crasher()<N>        OpenClipboard()<N>        try:<N>            EmptyClipboard()<N>            # This used to crash - now correctly raises type error.<N>            self.assertRaises(TypeError, SetClipboardData, 0, obj )<N>        finally:<N>            CloseClipboard()<N><N>
import unittest<N>import win32net, win32netcon<N><N>class TestCase(unittest.TestCase):<N>    def testGroupsGoodResume(self, server=None):<N>        res=0<N>        level=0 #setting it to 1 will provide more detailed info<N>        while True:<N>            (user_list,total,res)=win32net.NetGroupEnum(server,level,res)<N>            for i in user_list:<N>                pass<N>            if not res:<N>                break<N><N>
from win32inet import *<N>from win32inetcon import *<N>import winerror<N>from pywin32_testutil import str2bytes # py3k-friendly helper<N>from pywin32_testutil import TestSkipped<N><N>import unittest<N><N>class CookieTests(unittest.TestCase):<N>    def testCookies(self):<N>        data = "TestData=Test"<N>        InternetSetCookie("http://www.python.org", None, data)<N>        got = InternetGetCookie("http://www.python.org", None)<N>        self.assertEqual(got, data)<N><N>
    def testCookiesEmpty(self):<N>        try:<N>            InternetGetCookie("http://site-with-no-cookie.python.org", None)<N>            self.fail("expected win32 exception")<N>        except error as exc:<N>            self.failUnlessEqual(exc.winerror, winerror.ERROR_NO_MORE_ITEMS)<N><N>
class UrlTests(unittest.TestCase):<N>    def testSimpleCanonicalize(self):<N>        ret = InternetCanonicalizeUrl("foo bar")<N>        self.assertEqual(ret, "foo%20bar")<N><N>    def testLongCanonicalize(self):<N>        # a 4k URL causes the underlying API to request a bigger buffer"<N>        big = "x" * 2048<N>        ret = InternetCanonicalizeUrl(big + " " + big)<N>        self.assertEqual(ret, big + "%20" + big)<N><N>
# Some tests of the win32security sspi functions.<N># Stolen from Roger's original test_sspi.c, a version of which is in "Demos"<N># See also the other SSPI demos.<N>import re<N>import win32security, sspi, sspicon, win32api<N>from pywin32_testutil import TestSkipped, testmain, str2bytes<N>import unittest<N><N>
# It is quite likely that the Kerberos tests will fail due to not being<N># installed.  The NTLM tests do *not* get the same behaviour as they should<N># always be there.<N>def applyHandlingSkips(func, *args):<N>    try:<N>        return func(*args)<N>    except win32api.error as exc:<N>        if exc.winerror == sspicon.SEC_E_NO_CREDENTIALS:<N>            raise TestSkipped(exc)<N>        raise<N><N>
<N>class TestSSPI(unittest.TestCase):<N><N>    def assertRaisesHRESULT(self, hr, func, *args):<N>        try:<N>            return func(*args)<N>            raise RuntimeError("expecting %s failure" % (hr,))<N>        except win32security.error as exc:<N>            self.failUnlessEqual(exc.winerror, hr)<N><N>
    def _doAuth(self, pkg_name):<N>        sspiclient=sspi.ClientAuth(pkg_name,targetspn=win32api.GetUserName())<N>        sspiserver=sspi.ServerAuth(pkg_name)<N><N>        sec_buffer=None<N>        err = 1<N>        while err != 0:<N>            err, sec_buffer = sspiclient.authorize(sec_buffer)<N>            err, sec_buffer = sspiserver.authorize(sec_buffer)<N>        return sspiclient, sspiserver<N><N>
    def _doTestImpersonate(self, pkg_name):<N>        # Just for the sake of code exercising!<N>        sspiclient, sspiserver = self._doAuth(pkg_name)<N>        sspiserver.ctxt.ImpersonateSecurityContext()<N>        sspiserver.ctxt.RevertSecurityContext()<N><N>
    def testImpersonateKerberos(self):<N>        applyHandlingSkips(self._doTestImpersonate, "Kerberos")<N><N>    def testImpersonateNTLM(self):<N>        self._doTestImpersonate("NTLM")<N><N>    def _doTestEncrypt(self, pkg_name):<N><N>        sspiclient, sspiserver = self._doAuth(pkg_name)<N><N>
"""A useful wrapper around the "_winxptheme" module.<N>Unlike _winxptheme, this module will load on any version of Windows.<N><N>If _winxptheme is not available, then this module will have only 2 functions -<N>IsAppThemed() and IsThemeActive, which will both always return False.<N><N>
If _winxptheme is available, this module will have all methods in that module,<N>including real implementations of IsAppThemed() and IsThemeActive().<N>"""<N><N>import win32api<N>try:<N>    win32api.FreeLibrary(win32api.LoadLibrary("Uxtheme.dll"))<N>    # Life is good, everything is available.<N>    from _winxptheme import *<N>except win32api.error:<N>    # Probably not running XP.<N>    def IsAppThemed():<N>        return False<N>    def IsThemeActive():<N>        return False<N><N>
# Imported by pywin32.pth to bootstrap the pywin32 environment in "portable"<N># environments or any other case where the post-install script isn't run.<N>#<N># In short, there's a directory installed by pywin32 named 'pywin32_system32'<N># with some important DLLs which need to be found by Python when some pywin32<N># modules are imported.<N># If Python has `os.add_dll_directory()`, we need to call it with this path.<N># Otherwise, we add this path to PATH.<N>import os<N>import site<N><N>
# The directory should be installed under site-packages.<N><N>dirname = os.path.dirname<N># This is to get the "...\Lib\site-packages" directory<N># out of this file name: "...\Lib\site-packages\win32\Lib\pywin32_bootstrap.py".<N># It needs to be searched when installed in virtual environments.<N>level3_up_dir = dirname(dirname(dirname(__file__)))<N><N>
"""Event Log Utilities - helper for win32evtlog.pyd<N>"""<N><N>import win32api, win32con, winerror, win32evtlog<N><N>error = win32api.error # The error the evtlog module raises.<N><N>langid = win32api.MAKELANGID(win32con.LANG_NEUTRAL, win32con.SUBLANG_NEUTRAL)<N><N>
def AddSourceToRegistry(appName, msgDLL = None, eventLogType = "Application", eventLogFlags = None):<N>    """Add a source of messages to the event log.<N><N>    Allows Python program to register a custom source of messages in the<N>    registry.  You must also provide the DLL name that has the message table, so the<N>    full message text appears in the event log.<N><N>
    Note that the win32evtlog.pyd file has a number of string entries with just "%1"<N>    built in, so many Python programs can simply use this DLL.  Disadvantages are that<N>    you do not get language translation, and the full text is stored in the event log,<N>    blowing the size of the log up.<N>    """<N><N>
    # When an application uses the RegisterEventSource or OpenEventLog<N>    # function to get a handle of an event log, the event loggging service<N>    # searches for the specified source name in the registry. You can add a<N>    # new source name to the registry by opening a new registry subkey<N>    # under the Application key and adding registry values to the new<N>    # subkey.<N><N>
    if msgDLL is None:<N>        msgDLL = win32evtlog.__file__<N><N>    # Create a new key for our application<N>    hkey = win32api.RegCreateKey(win32con.HKEY_LOCAL_MACHINE, \<N>        "SYSTEM\\CurrentControlSet\\Services\\EventLog\\%s\\%s" % (eventLogType, appName))<N><N>
    # Add the Event-ID message-file name to the subkey.<N>    win32api.RegSetValueEx(hkey,<N>        "EventMessageFile",    # value name \<N>        0,                     # reserved \<N>        win32con.REG_EXPAND_SZ,# value type \<N>        msgDLL)<N><N>
    # Set the supported types flags and add it to the subkey.<N>    if eventLogFlags is None:<N>        eventLogFlags = win32evtlog.EVENTLOG_ERROR_TYPE | win32evtlog.EVENTLOG_WARNING_TYPE | win32evtlog.EVENTLOG_INFORMATION_TYPE<N>    win32api.RegSetValueEx(hkey, # subkey handle \<N>        "TypesSupported",        # value name \<N>        0,                       # reserved \<N>        win32con.REG_DWORD,      # value type \<N>        eventLogFlags)<N>    win32api.RegCloseKey(hkey)<N><N>
def RemoveSourceFromRegistry(appName, eventLogType = "Application"):<N>    """Removes a source of messages from the event log.<N>    """<N><N>    # Delete our key<N>    try:<N>        win32api.RegDeleteKey(win32con.HKEY_LOCAL_MACHINE, \<N>                     "SYSTEM\\CurrentControlSet\\Services\\EventLog\\%s\\%s" % (eventLogType, appName))<N>    except win32api.error as exc:<N>        if exc.winerror != winerror.ERROR_FILE_NOT_FOUND:<N>            raise<N><N>
<N>def ReportEvent(appName, eventID, eventCategory = 0, eventType=win32evtlog.EVENTLOG_ERROR_TYPE, strings = None, data = None, sid=None):<N>    """Report an event for a previously added event source.<N>    """<N>    # Get a handle to the Application event log<N>    hAppLog = win32evtlog.RegisterEventSource(None, appName)<N><N>
    # Now report the event, which will add this event to the event log */<N>    win32evtlog.ReportEvent(hAppLog, # event-log handle \<N>        eventType,<N>        eventCategory,<N>        eventID,<N>        sid,<N>        strings,<N>        data)<N><N>    win32evtlog.DeregisterEventSource(hAppLog);<N><N>
def FormatMessage( eventLogRecord, logType="Application" ):<N>    """Given a tuple from ReadEventLog, and optionally where the event<N>    record came from, load the message, and process message inserts.<N><N>    Note that this function may raise win32api.error.  See also the<N>    function SafeFormatMessage which will return None if the message can<N>    not be processed.<N>    """<N><N>
    # From the event log source name, we know the name of the registry<N>    # key to look under for the name of the message DLL that contains<N>    # the messages we need to extract with FormatMessage. So first get<N>    # the event log source name...<N>    keyName = "SYSTEM\\CurrentControlSet\\Services\\EventLog\\%s\\%s" % (logType, eventLogRecord.SourceName)<N><N>
## flags, enums, guids used with DeviceIoControl from WinIoCtl.h<N><N>import pywintypes<N>from ntsecuritycon import FILE_READ_DATA,FILE_WRITE_DATA<N>def CTL_CODE(DeviceType, Function, Method, Access):<N>    return (DeviceType << 16) | (Access << 14) | (Function << 2) | Method<N><N>
"""Error related constants for win32<N><N>Generated by h2py from winerror.h<N>"""<N># Few extras added manually...<N>TRUST_E_PROVIDER_UNKNOWN = -2146762751<N>TRUST_E_ACTION_UNKNOWN = -2146762750<N>TRUST_E_SUBJECT_FORM_UNKNOWN = -2146762749<N>TRUST_E_SUBJECT_NOT_TRUSTED = -2146762748<N># up to here...<N><N>
# This module is very old and useless in this day and age!  It will be<N># removed in a few years (ie, 2009 or so...)<N><N>import warnings<N>warnings.warn("The regcheck module has been pending deprecation since build 210",<N>	      category=PendingDeprecationWarning)<N><N>
import win32con<N>import regutil<N>import win32api<N>import os<N>import sys<N><N><N>def CheckRegisteredExe(exename):<N>	try:<N>		os.stat(win32api.RegQueryValue(regutil.GetRootKey()  , regutil.GetAppPathsKey() + "\\" + exename))<N>#	except SystemError:<N>	except (os.error,win32api.error):<N>		print("Registration of %s - Not registered correctly" % exename)<N><N>
"""Utilities for the win32 Performance Data Helper module<N><N>Example:<N>  To get a single bit of data:<N>  >>> import win32pdhutil<N>  >>> win32pdhutil.GetPerformanceAttributes("Memory", "Available Bytes")<N>  6053888<N>  >>> win32pdhutil.FindPerformanceAttributesByName("python", counter="Virtual Bytes")<N>  [22278144]<N><N>
  First example returns data which is not associated with any specific instance.<N><N>  The second example reads data for a specific instance - hence the list return -<N>  it would return one result for each instance of Python running.<N><N>  In general, it can be tricky finding exactly the "name" of the data you wish to query.<N>  Although you can use <om win32pdh.EnumObjectItems>(None,None,(eg)"Memory", -1) to do this,<N>  the easiest way is often to simply use PerfMon to find out the names.<N>"""<N><N>
import win32pdh, time<N><N>error = win32pdh.error<N><N># Handle some localization issues.<N># see http://support.microsoft.com/default.aspx?scid=http://support.microsoft.com:80/support/kb/articles/Q287/1/59.asp&NoWebContent=1<N># Build a map of english_counter_name: counter_id<N>counter_english_map = {}<N><N>
# General purpose service utilities, both for standard Python scripts,<N># and for for Python programs which run as services...<N>#<N># Note that most utility functions here will raise win32api.error's<N># (which is == win32service.error, pywintypes.error, etc)<N># when things go wrong - eg, not enough permissions to hit the<N># registry etc.<N><N>
import win32service, win32api, win32con, winerror<N>import sys, pywintypes, os, warnings<N>error = RuntimeError<N><N>def LocatePythonServiceExe(exeName = None):<N>    if not exeName and hasattr(sys, "frozen"):<N>        # If py2exe etc calls this with no exeName, default is current exe.<N>        return sys.executable<N><N>
# Windows dialog .RC file parser, by Adam Walker.<N><N># This module was adapted from the spambayes project, and is Copyright<N># 2003/2004 The Python Software Foundation and is covered by the Python<N># Software Foundation license.<N>"""<N>This is a parser for Windows .rc files, which are text files which define<N>dialogs and other Windows UI resources.<N>"""<N>__author__="Adam Walker"<N>__version__="0.11"<N><N>
# -*- coding: UTF-8 -*-<N><N>"""<N>win32timezone:<N>    Module for handling datetime.tzinfo time zones using the windows<N>registry for time zone information.  The time zone names are dependent<N>on the registry entries defined by the operating system.<N><N>
    This module may be tested using the doctest module.<N><N>    Written by Jason R. Coombs (jaraco@jaraco.com).<N>    Copyright Â© 2003-2012.<N>    All Rights Reserved.<N><N>    This module is licenced for use in Mark Hammond's pywin32<N>library under the same terms as the pywin32 library.<N><N>
    To use this time zone module with the datetime module, simply pass<N>the TimeZoneInfo object to the datetime constructor.  For example,<N><N>>>> import win32timezone, datetime<N>>>> assert 'Mountain Standard Time' in win32timezone.TimeZoneInfo.get_sorted_time_zone_names()<N>>>> MST = win32timezone.TimeZoneInfo('Mountain Standard Time')<N>>>> now = datetime.datetime.now(MST)<N><N>
    The now object is now a time-zone aware object, and daylight savings-<N>aware methods may be called on it.<N><N>>>> now.utcoffset() in (datetime.timedelta(-1, 61200), datetime.timedelta(-1, 64800))<N>True<N><N>(note that the result of utcoffset call will be different based on when now was<N>generated, unless standard time is always used)<N><N>
>>> now = datetime.datetime.now(TimeZoneInfo('Mountain Standard Time', True))<N>>>> now.utcoffset()<N>datetime.timedelta(days=-1, seconds=61200)<N><N>>>> aug2 = datetime.datetime(2003, 8, 2, tzinfo = MST)<N>>>> tuple(aug2.utctimetuple())<N>(2003, 8, 2, 6, 0, 0, 5, 214, 0)<N>>>> nov2 = datetime.datetime(2003, 11, 25, tzinfo = MST)<N>>>> tuple(nov2.utctimetuple())<N>(2003, 11, 25, 7, 0, 0, 1, 329, 0)<N><N>
To convert from one timezone to another, just use the astimezone method.<N><N>>>> aug2.isoformat()<N>'2003-08-02T00:00:00-06:00'<N>>>> aug2est = aug2.astimezone(win32timezone.TimeZoneInfo('Eastern Standard Time'))<N>>>> aug2est.isoformat()<N>'2003-08-02T02:00:00-04:00'<N><N>
calling the displayName member will return the display name as set in the<N>registry.<N><N>>>> est = win32timezone.TimeZoneInfo('Eastern Standard Time')<N>>>> str(est.displayName)<N>'(UTC-05:00) Eastern Time (US & Canada)'<N><N>>>> gmt = win32timezone.TimeZoneInfo('GMT Standard Time', True)<N>>>> str(gmt.displayName)<N>'(UTC+00:00) Dublin, Edinburgh, Lisbon, London'<N><N>
To get the complete list of available time zone keys,<N>>>> zones = win32timezone.TimeZoneInfo.get_all_time_zones()<N><N>If you want to get them in an order that's sorted longitudinally<N>>>> zones = win32timezone.TimeZoneInfo.get_sorted_time_zones()<N><N>
TimeZoneInfo now supports being pickled and comparison<N>>>> import pickle<N>>>> tz = win32timezone.TimeZoneInfo('China Standard Time')<N>>>> tz == pickle.loads(pickle.dumps(tz))<N>True<N><N>It's possible to construct a TimeZoneInfo from a TimeZoneDescription<N>including the currently-defined zone.<N>>>> tz = win32timezone.TimeZoneInfo(TimeZoneDefinition.current())<N>>>> tz == pickle.loads(pickle.dumps(tz))<N>True<N><N>
>>> aest = win32timezone.TimeZoneInfo('AUS Eastern Standard Time')<N>>>> est = win32timezone.TimeZoneInfo('E. Australia Standard Time')<N>>>> dt = datetime.datetime(2006, 11, 11, 1, 0, 0, tzinfo = aest)<N>>>> estdt = dt.astimezone(est)<N>>>> estdt.strftime('%Y-%m-%d %H:%M:%S')<N>'2006-11-11 00:00:00'<N><N>
>>> dt = datetime.datetime(2007, 1, 12, 1, 0, 0, tzinfo = aest)<N>>>> estdt = dt.astimezone(est)<N>>>> estdt.strftime('%Y-%m-%d %H:%M:%S')<N>'2007-01-12 00:00:00'<N><N>>>> dt = datetime.datetime(2007, 6, 13, 1, 0, 0, tzinfo = aest)<N>>>> estdt = dt.astimezone(est)<N>>>> estdt.strftime('%Y-%m-%d %H:%M:%S')<N>'2007-06-13 01:00:00'<N><N>
# Some registry helpers.<N>import win32api<N>import win32con<N>import sys<N>import os<N><N>error = "Registry utility error"<N><N># A .py file has a CLSID associated with it (why? - dunno!)<N>CLSIDPyFile = "{b51df050-06ae-11cf-ad3b-524153480001}"<N><N>RegistryIDPyFile = "Python.File" # The registry "file type" of a .py file<N>RegistryIDPycFile = "Python.CompiledFile" # The registry "file type" of a .pyc file<N><N>
def BuildDefaultPythonKey():<N>	"""Builds a string containing the path to the current registry key.<N><N>	   The Python registry key contains the Python version.  This function<N>	   uses the version of the DLL used by the current process to get the<N>	   registry key currently in use.<N>        """<N>	return "Software\\Python\\PythonCore\\" + sys.winver<N><N>
def GetRootKey():<N>	"""Retrieves the Registry root in use by Python.<N>	"""<N>	keyname = BuildDefaultPythonKey()<N>	try:<N>		k = win32api.RegOpenKey(win32con.HKEY_CURRENT_USER, keyname)<N>		k.close()<N>		return win32con.HKEY_CURRENT_USER<N>	except win32api.error:<N>		return win32con.HKEY_LOCAL_MACHINE<N><N>
"""<N>Helper classes for SSPI authentication via the win32security module.<N><N>SSPI authentication involves a token-exchange "dance", the exact details<N>of which depends on the authentication provider used.  There are also<N>a number of complex flags and constants that need to be used - in most<N>cases, there are reasonable defaults.<N><N>
These classes attempt to hide these details from you until you really need<N>to know.  They are not designed to handle all cases, just the common ones.<N>If you need finer control than offered here, just use the win32security<N>functions directly.<N>"""<N># Based on Roger Upole's sspi demos.<N># $Id$<N>import win32security, sspicon<N><N>
error = win32security.error<N><N>class _BaseAuth(object):<N>    def __init__(self):<N>        self.reset()<N><N>    def reset(self):<N>        """Reset everything to an unauthorized state"""<N>        self.ctxt = None<N>        self.authenticated = False<N>        # The next seq_num for an encrypt/sign operation<N>        self.next_seq_num = 0<N><N>
    def _get_next_seq_num(self):<N>        """Get the next sequence number for a transmission.  Default<N>        implementation is to increment a counter<N>        """<N>        ret = self.next_seq_num<N>        self.next_seq_num = self.next_seq_num + 1<N>        return ret<N><N>
    def encrypt(self, data):<N>        """Encrypt a string, returning a tuple of (encrypted_data, encryption_data).<N>        These can be passed to decrypt to get back the original string.<N>        """<N>        pkg_size_info=self.ctxt.QueryContextAttributes(sspicon.SECPKG_ATTR_SIZES)<N>        trailersize=pkg_size_info['SecurityTrailer']<N><N>
        encbuf=win32security.PySecBufferDescType()<N>        encbuf.append(win32security.PySecBufferType(len(data), sspicon.SECBUFFER_DATA))<N>        encbuf.append(win32security.PySecBufferType(trailersize, sspicon.SECBUFFER_TOKEN))<N>        encbuf[0].Buffer=data<N>        self.ctxt.EncryptMessage(0,encbuf,self._get_next_seq_num())<N>        return encbuf[0].Buffer, encbuf[1].Buffer<N><N>
""" Stamp a Win32 binary with version information.<N>"""<N><N>from win32api import BeginUpdateResource, UpdateResource, EndUpdateResource<N><N>import os<N>import struct<N>import glob<N>import sys<N><N>import optparse<N><N>VS_FFI_SIGNATURE = -17890115 # 0xFEEF04BD<N>VS_FFI_STRUCVERSION = 0x00010000<N>VS_FFI_FILEFLAGSMASK = 0x0000003f<N>VOS_NT_WINDOWS32 = 0x00040004<N><N>
null_byte = "\0".encode("ascii") # str in py2k, bytes in py3k<N>#<N># Set VS_FF_PRERELEASE and DEBUG if Debug<N>#<N>def file_flags(debug):<N>  if debug:<N>    return 3	# VS_FF_DEBUG | VS_FF_PRERELEASE<N>  return 0<N><N>def file_type(is_dll):<N>  if is_dll:<N>    return 2	# VFT_DLL<N>  return 1	# VFT_APP<N><N>
# Utilities for the pywin32 tests<N>import sys<N>import unittest<N>import gc<N>import winerror<N><N>##<N>## General purpose utilities for the test suite.<N>##<N><N>def int2long(val):<N>    """return a long on py2k"""<N>    return val + 0x100000000 - 0x100000000<N><N>
# The test suite has lots of string constants containing binary data, but<N># the strings are used in various "bytes" contexts.<N>def str2bytes(sval):<N>    if sys.version_info < (3,0) and isinstance(sval, str):<N>        sval = sval.decode("latin1")<N>    return sval.encode("latin1")<N><N>
<N># Sometimes we want to pass a string that should explicitly be treated as<N># a memory blob.<N>def str2memory(sval):<N>    if sys.version_info < (3,0):<N>        return buffer(sval)<N>    # py3k.<N>    return memoryview(sval.encode("latin1"))<N><N><N># Sometimes we want to pass an object that exposes its memory<N>def ob2memory(ob):<N>    if sys.version_info < (3,0):<N>        return buffer(ob)<N>    # py3k.<N>    return memoryview(ob)<N><N>
'''<N>Performance Data Helper (PDH) Query Classes<N><N>Wrapper classes for end-users and high-level access to the PDH query<N>mechanisms.  PDH is a win32-specific mechanism for accessing the<N>performance data made available by the system.  The Python for Windows<N>PDH module does not implement the "Registry" interface, implementing<N>the more straightforward Query-based mechanism.<N><N>
"""<N>Skeleton replacement for removed dbi module.<N>Use of objects created by this module should be replaced with native Python objects.<N>Dates are now returned as datetime.datetime objects, but will still accept PyTime<N>objects also.<N>Raw data for binary fields should be passed as buffer objects for Python 2.x,<N>and memoryview objects in Py3k.<N>"""<N><N>
import warnings<N>warnings.warn(<N>	"dbi module is obsolete, code should now use native python datetime and buffer/memoryview objects",<N>	DeprecationWarning)<N><N>import datetime<N>dbDate = dbiDate = datetime.datetime<N>	  <N>try:<N>	dbRaw = dbiRaw = buffer<N>except NameError:<N>	dbRaw = dbiRaw = memoryview<N><N>
import argparse<N><N>from certifi import contents, where<N><N>parser = argparse.ArgumentParser()<N>parser.add_argument("-c", "--contents", action="store_true")<N>args = parser.parse_args()<N><N>if args.contents:<N>    print(contents())<N>else:<N>    print(where())<N>
# -*- coding: utf-8 -*-<N><N>"""<N>certifi.py<N>~~~~~~~~~~<N><N>This module returns the installation location of cacert.pem or its contents.<N>"""<N>import os<N><N>try:<N>    from importlib.resources import path as get_path, read_text<N><N>    _CACERT_CTX = None<N>    _CACERT_PATH = None<N><N>
# $Id: __init__.py 8705 2021-04-17 12:41:26Z grubert $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This is the Docutils (Python Documentation Utilities) package.<N><N>Package Structure<N>=================<N><N>
Modules:<N><N>- __init__.py: Contains component base classes, exception classes, and<N>  Docutils version information.<N><N>- core.py: Contains the ``Publisher`` class and ``publish_*()`` convenience<N>  functions.<N><N>- frontend.py: Runtime settings (command-line interface, configuration files)<N>  processing, for Docutils front-ends.<N><N>
- io.py: Provides a uniform API for low-level input and output.<N><N>- nodes.py: Docutils document tree (doctree) node class library.<N><N>- statemachine.py: A finite state machine specialized for<N>  regular-expression-based text filters.<N><N>Subpackages:<N><N>
- languages: Language-specific mappings of terms.<N><N>- parsers: Syntax-specific input parser modules or packages.<N><N>- readers: Context-specific input handlers which understand the data<N>  source and manage a parser.<N><N>- transforms: Modules used by readers and writers to modify DPS<N>  doctrees.<N><N>
- utils: Contains the ``Reporter`` system warning class and miscellaneous<N>  utilities used by readers, writers, and transforms.<N><N>  utils/urischemes.py: Contains a complete mapping of known URI addressing<N>  scheme names to descriptions.<N><N>- utils/math: Contains functions for conversion of mathematical notation<N>  between different formats (LaTeX, MathML, text, ...).<N><N>
- writers: Format-specific output translators.<N>"""<N><N>import sys<N>from collections import namedtuple<N><N><N>__docformat__ = 'reStructuredText'<N><N>__version__ = '0.17.1'<N>"""Docutils version identifier (complies with PEP 440)::<N><N>    major.minor[.micro][releaselevel[serial]][.dev]<N><N>
For version comparison operations, use `__version_info__` (see, below)<N>rather than parsing the text of `__version__`.<N><N>See 'Version Numbering' in docs/dev/policies.txt.<N>"""<N><N># from functools import total_ordering<N># @total_ordering<N>class VersionInfo(namedtuple('VersionInfo',<N>                             'major minor micro releaselevel serial release')):<N><N>
# $Id: nodes.py 8592 2020-12-15 23:06:26Z milde $<N># Author: David Goodger <goodger@python.org><N># Maintainer: docutils-develop@lists.sourceforge.net<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Docutils document tree element class library.<N><N>
Classes in CamelCase are abstract base classes or auxiliary classes. The one<N>exception is `Text`, for a text (PCDATA) node; uppercase is used to<N>differentiate from element classes.  Classes in lower_case_with_underscores<N>are element classes, matching the XML element generic identifiers in the DTD_.<N><N>
The position of each node (the level at which it can occur) is significant and<N>is represented by abstract base classes (`Root`, `Structural`, `Body`,<N>`Inline`, etc.).  Certain transformations will be easier because we can use<N>``isinstance(node, base_class)`` to determine the position of the node in the<N>hierarchy.<N><N>
.. _DTD: http://docutils.sourceforge.net/docs/ref/docutils.dtd<N>"""<N>from __future__ import print_function<N>from collections import Counter<N><N>__docformat__ = 'reStructuredText'<N><N>import sys<N>import os<N>import re<N>import warnings<N>import unicodedata<N><N>
# $Id: examples.py 7320 2012-01-19 22:33:02Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This module contains practical examples of Docutils client code.<N><N>Importing this module from client code is not recommended; its contents are<N>subject to change in future Docutils releases.  Instead, it is recommended<N>that you copy and paste the parts you need into your own code, modifying as<N>necessary.<N>"""<N><N>
from docutils import core, io<N><N><N>def html_parts(input_string, source_path=None, destination_path=None,<N>               input_encoding='unicode', doctitle=True,<N>               initial_header_level=1):<N>    """<N>    Given an input string, returns a dictionary of HTML document parts.<N><N>
 # $Id: statemachine.py 8565 2020-09-14 10:26:03Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>A finite state machine specialized for regular-expression-based text filters,<N>this module defines the following classes:<N><N>
- `StateMachine`, a state machine<N>- `State`, a state superclass<N>- `StateMachineWS`, a whitespace-sensitive version of `StateMachine`<N>- `StateWS`, a state superclass for use with `StateMachineWS`<N>- `SearchStateMachine`, uses `re.search()` instead of `re.match()`<N>- `SearchStateMachineWS`, uses `re.search()` instead of `re.match()`<N>- `ViewList`, extends standard Python lists.<N>- `StringList`, string-specific ViewList.<N><N>
Exception classes:<N><N>- `StateMachineError`<N>- `UnknownStateError`<N>- `DuplicateStateError`<N>- `UnknownTransitionError`<N>- `DuplicateTransitionError`<N>- `TransitionPatternNotFound`<N>- `TransitionMethodNotFound`<N>- `UnexpectedIndentationError`<N>- `TransitionCorrection`: Raised to switch to another transition.<N>- `StateCorrection`: Raised to switch to another state & transition.<N><N>
Functions:<N><N>- `string2lines()`: split a multi-line string into a list of one-line strings<N><N><N>How To Use This Module<N>======================<N>(See the individual classes, methods, and attributes for details.)<N><N>1. Import it: ``import statemachine`` or ``from statemachine import ...``.<N>   You will also need to ``import re``.<N><N>
2. Derive a subclass of `State` (or `StateWS`) for each state in your state<N>   machine::<N><N>       class MyState(statemachine.State):<N><N>   Within the state's class definition:<N><N>   a) Include a pattern for each transition, in `State.patterns`::<N><N>
          patterns = {'atransition': r'pattern', ...}<N><N>   b) Include a list of initial transitions to be set up automatically, in<N>      `State.initial_transitions`::<N><N>          initial_transitions = ['atransition', ...]<N><N>   c) Define a method for each transition, with the same name as the<N>      transition pattern::<N><N>
          def atransition(self, match, context, next_state):<N>              # do something<N>              result = [...]  # a list<N>              return context, next_state, result<N>              # context, next_state may be altered<N><N>      Transition methods may raise an `EOFError` to cut processing short.<N><N>
   d) You may wish to override the `State.bof()` and/or `State.eof()` implicit<N>      transition methods, which handle the beginning- and end-of-file.<N><N>   e) In order to handle nested processing, you may wish to override the<N>      attributes `State.nested_sm` and/or `State.nested_sm_kwargs`.<N><N>
      If you are using `StateWS` as a base class, in order to handle nested<N>      indented blocks, you may wish to:<N><N>      - override the attributes `StateWS.indent_sm`,<N>        `StateWS.indent_sm_kwargs`, `StateWS.known_indent_sm`, and/or<N>        `StateWS.known_indent_sm_kwargs`;<N>      - override the `StateWS.blank()` method; and/or<N>      - override or extend the `StateWS.indent()`, `StateWS.known_indent()`,<N>        and/or `StateWS.firstknown_indent()` methods.<N><N>
3. Create a state machine object::<N><N>       sm = StateMachine(state_classes=[MyState, ...],<N>                         initial_state='MyState')<N><N>4. Obtain the input text, which needs to be converted into a tab-free list of<N>   one-line strings. For example, to read text from a file called<N>   'inputfile'::<N><N>
       input_string = open('inputfile').read()<N>       input_lines = statemachine.string2lines(input_string)<N><N>5. Run the state machine on the input text and collect the results, a list::<N><N>       results = sm.run(input_lines)<N><N>6. Remove any lingering circular references::<N><N>
       sm.unlink()<N>"""<N>from __future__ import print_function<N><N>__docformat__ = 'restructuredtext'<N><N>import sys<N>import re<N>import unicodedata<N>from docutils import utils<N>from docutils.utils.error_reporting import ErrorOutput<N><N>if sys.version_info >= (3, 0):<N>    unicode = str  # noqa<N><N>
<N>class StateMachine(object):<N><N>    """<N>    A finite state machine for text filters using regular expressions.<N><N>    The input is provided in the form of a list of one-line strings (no<N>    newlines). States are subclasses of the `State` class. Transitions consist<N>    of regular expression patterns and transition methods, and are defined in<N>    each state.<N><N>
    The state machine is started with the `run()` method, which returns the<N>    results of processing in a list.<N>    """<N><N>    def __init__(self, state_classes, initial_state, debug=False):<N>        """<N>        Initialize a `StateMachine` object; add state objects.<N><N>
        Parameters:<N><N>        - `state_classes`: a list of `State` (sub)classes.<N>        - `initial_state`: a string, the class name of the initial state.<N>        - `debug`: a boolean; produce verbose output if true (nonzero).<N>        """<N><N>        self.input_lines = None<N>        """`StringList` of input lines (without newlines).<N>        Filled by `self.run()`."""<N><N>
        self.input_offset = 0<N>        """Offset of `self.input_lines` from the beginning of the file."""<N><N>        self.line = None<N>        """Current input line."""<N><N>        self.line_offset = -1<N>        """Current input line offset from beginning of `self.input_lines`."""<N><N>
        self.debug = debug<N>        """Debugging mode on/off."""<N><N>        self.initial_state = initial_state<N>        """The name of the initial state (key to `self.states`)."""<N><N>        self.current_state = initial_state<N>        """The name of the current state (key to `self.states`)."""<N><N>
        self.states = {}<N>        """Mapping of {state_name: State_object}."""<N><N>        self.add_states(state_classes)<N><N>        self.observers = []<N>        """List of bound methods or functions to call whenever the current<N>        line changes.  Observers are called with one argument, ``self``.<N>        Cleared at the end of `run()`."""<N><N>
        self._stderr = ErrorOutput()<N>        """Wrapper around sys.stderr catching en-/decoding errors"""<N><N><N>    def unlink(self):<N>        """Remove circular references to objects no longer required."""<N>        for state in self.states.values():<N>            state.unlink()<N>        self.states = None<N><N>
# $Id: core.py 8367 2019-08-27 12:09:56Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Calling the ``publish_*`` convenience functions (or instantiating a<N>`Publisher` object) with component names will result in default<N>behavior.  For custom behavior (setting component options), create<N>custom component objects first, and pass *them* to<N>``publish_*``/`Publisher`.  See `The Docutils Publisher`_.<N><N>
# $Id: frontend.py 8676 2021-04-08 16:36:09Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Command-line and common processing for Docutils front-end tools.<N><N>Exports the following classes:<N><N>
* `OptionParser`: Standard Docutils command-line processing.<N>* `Option`: Customized version of `optparse.Option`; validation support.<N>* `Values`: Runtime settings; objects are simple structs<N>  (``object.attribute``).  Supports cumulative list settings (attributes).<N>* `ConfigParser`: Standard Docutils config file processing.<N><N>
Also exports the following functions:<N><N>* Option callbacks: `store_multiple`, `read_config_file`.<N>* Setting validators: `validate_encoding`,<N>  `validate_encoding_error_handler`,<N>  `validate_encoding_and_error_handler`,<N>  `validate_boolean`, `validate_ternary`, `validate_threshold`,<N>  `validate_colon_separated_list`,<N>  `validate_comma_separated_list`,<N>  `validate_dependency_file`.<N>* `make_paths_absolute`.<N>* SettingSpec manipulation: `filter_settings_spec`.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import os<N>import os.path<N>import sys<N>import warnings<N>import codecs<N>import optparse<N>from optparse import SUPPRESS_HELP<N>if sys.version_info >= (3, 0):<N>    from configparser import RawConfigParser<N>    from os import getcwd<N>else:<N>    from ConfigParser import RawConfigParser<N>    from os import getcwdu as getcwd<N><N>
import docutils<N>import docutils.utils<N>import docutils.nodes<N>from docutils.utils.error_reporting import (locale_encoding, SafeString,<N>                                            ErrorOutput, ErrorString)<N><N>if sys.version_info >= (3, 0):<N>    unicode = str  # noqa<N><N>
<N>def store_multiple(option, opt, value, parser, *args, **kwargs):<N>    """<N>    Store multiple values in `parser.values`.  (Option callback.)<N><N>    Store `None` for each attribute named in `args`, and store the value for<N>    each key (attribute name) in `kwargs`.<N>    """<N>    for attribute in args:<N>        setattr(parser.values, attribute, None)<N>    for key, value in kwargs.items():<N>        setattr(parser.values, key, value)<N><N>
def read_config_file(option, opt, value, parser):<N>    """<N>    Read a configuration file during option processing.  (Option callback.)<N>    """<N>    try:<N>        new_settings = parser.get_config_file_settings(value)<N>    except ValueError as error:<N>        parser.error(error)<N>    parser.values.update(new_settings, parser)<N><N>
def validate_encoding(setting, value, option_parser,<N>                      config_parser=None, config_section=None):<N>    try:<N>        codecs.lookup(value)<N>    except LookupError:<N>        raise LookupError('setting "%s": unknown encoding: "%s"'<N>                          % (setting, value))<N>    return value<N><N>
# $Id: io.py 8676 2021-04-08 16:36:09Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>I/O classes provide a uniform API for low-level input and output.  Subclasses<N>exist for a variety of input/output mechanisms.<N>"""<N>from __future__ import print_function<N><N>
__docformat__ = 'reStructuredText'<N><N>import sys<N>import os<N>import re<N>import codecs<N>from docutils import TransformSpec<N>from docutils.utils.error_reporting import locale_encoding, ErrorString, ErrorOutput<N><N>if sys.version_info >= (3, 0):<N>    unicode = str  # noqa<N><N>
# -*- coding: utf-8 -*-<N># $Id: sv.py 8006 2016-12-22 23:02:44Z milde $<N># Author: Adam Chodorowski <chodorowski@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: zh_tw.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Joe YS Jaw <joeysj@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: fa.py 4564 2016-08-10 11:48:42Z<N># Author: Shahin <me@5hah.in><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: __init__.py 8467 2020-01-26 21:23:42Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># Internationalization details are documented in<N># <http://docutils.sf.net/docs/howto/i18n.html>.<N><N>
"""<N>This package contains modules for language-dependent features of Docutils.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>import sys<N>from importlib import import_module<N><N>from docutils.utils import normalize_language_tag<N><N><N>class LanguageImporter(object):<N>    """Import language modules.<N><N>
# $Id: ca.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Ivan Vilata i Balaguer <ivan@selidor.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: pt_br.py 5567 2008-06-03 01:11:03Z goodger $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: es.py 4572 2006-05-25 20:48:37Z richieadler $<N># Author: Marcelo Huerta San MartÃ­n <richieadler@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: it.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Nicola Larosa <docutils@tekNico.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: zh_cn.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Pan Junyong <panjy@zopechina.com><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ja.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Hisashi Morita <hisashim@kt.rim.or.jp><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# Author: Meir Kriheli<N># Id: $Id: he.py 4837 2006-12-26 09:59:41Z sfcben $<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: eo.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Marcelo Huerta San Martin <richieadler@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: sk.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Miroslav Vasko <zemiak@zoznam.sk><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: da.py 7678 2013-07-03 09:57:36Z milde $<N># Author: E D<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: fi.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Asko Soukka <asko.soukka@iki.fi><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: nl.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Martijn Pieters <mjpieters@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># Author: David Goodger<N># Contact: goodger@users.sourceforge.net<N># Revision: $Revision: 2224 $<N># Date: $Date: 2004-06-05 21:40:46 +0200 (Sat, 05 Jun 2004) $<N># Copyright: This module has been placed in the public domain.<N><N>
# New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: lt.py 7911 2015-08-31 08:23:06Z milde $<N># Author: Dalius Dobravolskas <dalius.do...@gmail.com><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: de.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Gunnar Schwant <g.schwant@gmx.de><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: en.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: lv.py 7975 2016-10-20 20:00:19Z milde $<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: af.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Jannie Hofmeyr <jhsh@sun.ac.za><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id$<N># Author: Robert Wojciechowicz <rw@smsnet.pl><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: cs.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Marek Blaha <mb@dat.cz><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ru.py 7125 2011-09-16 18:36:18Z milde $<N># Author: Roman Suzi <rnd@onego.ru><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ko.py 8541 2020-08-22 22:16:25Z milde $<N># Author: Thomas SJ Kang <thomas.kangsj@ujuc.kr><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: fr.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Stefane Fermigier <sf@fermigier.com><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: fa.py 4564 2016-08-10 11:48:42Z<N># Author: Shahin <me@5hah.in><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# coding: utf-8<N># $Id: __init__.py 8672 2021-04-07 12:10:06Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Miscellaneous utilities for the documentation utilities.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import sys<N>import os<N>import os.path<N>import re<N>import itertools<N>import warnings<N>import unicodedata<N>from docutils import ApplicationError, DataError, __version_info__<N>from docutils import nodes<N>from docutils.nodes import unescape<N>import docutils.io<N>from docutils.utils.error_reporting import ErrorOutput, SafeString<N><N>
if sys.version_info >= (3, 0):<N>    unicode = str<N><N><N>class SystemMessage(ApplicationError):<N><N>    def __init__(self, system_message, level):<N>        Exception.__init__(self, system_message.astext())<N>        self.level = level<N><N><N>class SystemMessagePropagation(ApplicationError): pass<N><N>
<N>class Reporter(object):<N><N>    """<N>    Info/warning/error reporter and ``system_message`` element generator.<N><N>    Five levels of system messages are defined, along with corresponding<N>    methods: `debug()`, `info()`, `warning()`, `error()`, and `severe()`.<N><N>
    There is typically one Reporter object per process.  A Reporter object is<N>    instantiated with thresholds for reporting (generating warnings) and<N>    halting processing (raising exceptions), a switch to turn debug output on<N>    or off, and an I/O stream for warnings.  These are stored as instance<N>    attributes.<N><N>
    When a system message is generated, its level is compared to the stored<N>    thresholds, and a warning or error is generated as appropriate.  Debug<N>    messages are produced if the stored debug switch is on, independently of<N>    other thresholds.  Message output is sent to the stored warning stream if<N>    not set to ''.<N><N>
    The Reporter class also employs a modified form of the "Observer" pattern<N>    [GoF95]_ to track system messages generated.  The `attach_observer` method<N>    should be called before parsing, with a bound method or function which<N>    accepts system messages.  The observer can be removed with<N>    `detach_observer`, and another added in its place.<N><N>
    .. [GoF95] Gamma, Helm, Johnson, Vlissides. *Design Patterns: Elements of<N>       Reusable Object-Oriented Software*. Addison-Wesley, Reading, MA, USA,<N>       1995.<N>    """<N><N>    levels = 'DEBUG INFO WARNING ERROR SEVERE'.split()<N>    """List of names for system message levels, indexed by level."""<N><N>
"""Convert to and from Roman numerals"""<N><N>__author__ = "Mark Pilgrim (f8dy@diveintopython.org)"<N>__version__ = "1.4"<N>__date__ = "8 August 2001"<N>__copyright__ = """Copyright (c) 2001 Mark Pilgrim<N><N>This program is part of "Dive Into Python", a free Python tutorial for<N>experienced programmers.  Visit http://diveintopython.org/ for the<N>latest version.<N><N>
This program is free software; you can redistribute it and/or modify<N>it under the terms of the Python 2.1.1 license, available at<N>http://www.python.org/2.1.1/license.html<N>"""<N><N>import re<N><N>#Define exceptions<N>class RomanError(Exception): pass<N>class OutOfRangeError(RomanError): pass<N>class NotIntegerError(RomanError): pass<N>class InvalidRomanNumeralError(RomanError): pass<N><N>
#Define digit mapping<N>romanNumeralMap = (('M',  1000),<N>                   ('CM', 900),<N>                   ('D',  500),<N>                   ('CD', 400),<N>                   ('C',  100),<N>                   ('XC', 90),<N>                   ('L',  50),<N>                   ('XL', 40),<N>                   ('X',  10),<N>                   ('IX', 9),<N>                   ('V',  5),<N>                   ('IV', 4),<N>                   ('I',  1))<N><N>
def toRoman(n):<N>    """convert integer to Roman numeral"""<N>    if not (0 < n < 5000):<N>        raise OutOfRangeError("number out of range (must be 1..4999)")<N>    if int(n) != n:<N>        raise NotIntegerError("decimals can not be converted")<N><N>    result = ""<N>    for numeral, integer in romanNumeralMap:<N>        while n >= integer:<N>            result += numeral<N>            n -= integer<N>    return result<N><N>
#!/usr/bin/python<N># coding: utf-8<N><N>"""Lexical analysis of formal languages (i.e. code) using Pygments."""<N><N># :Author: Georg Brandl; Felix Wiemann; GÃ¼nter Milde<N># :Date: $Date: 2021-01-03 22:05:13 +0100 (So, 03. JÃ¤n 2021) $<N># :Copyright: This module has been placed in the public domain.<N><N>
from docutils import ApplicationError<N>try:<N>    import pygments<N>    from pygments.lexers import get_lexer_by_name<N>    from pygments.formatters.html import _get_ttype_class<N>    with_pygments = True<N>except ImportError:<N>    with_pygments = False<N><N>
# Filter the following token types from the list of class arguments:<N>unstyled_tokens = ['token', # Token (base token type)<N>                   'text',  # Token.Text<N>                   '']      # short name for Token and Text<N># (Add, e.g., Token.Punctuation with ``unstyled_tokens += 'punctuation'``.)<N><N>
class LexerError(ApplicationError):<N>    pass<N><N>class Lexer(object):<N>    """Parse `code` lines and yield "classified" tokens.<N><N>    Arguments<N><N>      code       -- string of source code to parse,<N>      language   -- formal language the code is written in,<N>      tokennames -- either 'long', 'short', or 'none' (see below).<N><N>
    Merge subsequent tokens of the same token-type.<N><N>    Iterating over an instance yields the tokens as ``(tokentype, value)``<N>    tuples. The value of `tokennames` configures the naming of the tokentype:<N><N>      'long':  downcased full token type name,<N>      'short': short name defined by pygments.token.STANDARD_TYPES<N>               (= class argument used in pygments html output),<N>      'none':  skip lexical analysis.<N>    """<N><N>
# $Id: urischemes.py 8376 2019-08-27 19:49:29Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>`schemes` is a dictionary with lowercase URI addressing schemes as<N>keys and descriptions as values. It was compiled from the index at<N>http://www.iana.org/assignments/uri-schemes (revised 2005-11-28)<N>and an older list at http://www.w3.org/Addressing/schemes.html.<N>"""<N><N>
# -*- coding: utf-8 -*-<N><N># LaTeX math to Unicode symbols translation dictionaries.<N># Generated with ``write_tex2unichar.py`` from the data in<N># http://milde.users.sourceforge.net/LUCR/Math/<N><N># Includes commands from: wasysym, stmaryrd, mathdots, mathabx, esint, bbold, amsxtra, amsmath, amssymb, standard LaTeX<N><N>
# :Id: $Id: __init__.py 8554 2020-09-04 16:52:11Z milde $<N># :Author: Guenter Milde.<N># :License: Released under the terms of the `2-Clause BSD license`_, in short:<N>#<N>#    Copying and distribution of this file, with or without modification,<N>#    are permitted in any medium without royalty provided the copyright<N>#    notice and this notice are preserved.<N>#    This file is offered as-is, without any warranty.<N>#<N># .. _2-Clause BSD license: https://opensource.org/licenses/BSD-2-Clause<N><N>
# LaTeX math to Unicode symbols translation table<N># for use with the translate() method of unicode objects.<N># Generated with ``write_unichar2tex.py`` from the data in<N># http://milde.users.sourceforge.net/LUCR/Math/<N><N># Includes commands from: standard LaTeX, amssymb, amsmath<N><N>
# $Id: __init__.py 8673 2021-04-07 17:57:27Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This package contains Docutils Writer modules.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import os.path<N>import sys<N>from importlib import import_module<N><N>import docutils<N>from docutils import languages, Component<N>from docutils.transforms import universal<N><N>class Writer(Component):<N><N>    """<N>    Abstract base class for docutils Writers.<N><N>
    Each writer module or package must export a subclass also called 'Writer'.<N>    Each writer must support all standard node types listed in<N>    `docutils.nodes.node_class_names`.<N><N>    The `write()` method is the main entry point.<N>    """<N><N>    component_type = 'writer'<N>    config_section = 'writers'<N><N>
    def get_transforms(self):<N>        return Component.get_transforms(self) + [<N>            universal.Messages,<N>            universal.FilterMessages,<N>            universal.StripClassesAndElements,]<N><N>    document = None<N>    """The document to write (Docutils doctree); set by `write`."""<N><N>
    output = None<N>    """Final translated form of `document` (Unicode string for text, binary<N>    string for other forms); set by `translate`."""<N><N>    language = None<N>    """Language module for the document; set by `write`."""<N><N>    destination = None<N>    """`docutils.io` Output object; where to write the document.<N>    Set by `write`."""<N><N>
    def __init__(self):<N><N>        # Used by HTML and LaTeX writer for output fragments:<N>        self.parts = {}<N>        """Mapping of document part names to fragments of `self.output`.<N>        Values are Unicode strings; encoding is up to the client.  The 'whole'<N>        key should contain the entire document output.<N>        """<N><N>
    def write(self, document, destination):<N>        """<N>        Process a document into its final form.<N><N>        Translate `document` (a Docutils document tree) into the Writer's<N>        native format, and write it out to its `destination` (a<N>        `docutils.io.Output` subclass object).<N><N>
        Normally not overridden or extended in subclasses.<N>        """<N>        self.document = document<N>        self.language = languages.get_language(<N>            document.settings.language_code,<N>            document.reporter)<N>        self.destination = destination<N>        self.translate()<N>        output = self.destination.write(self.output)<N>        return output<N><N>
# -*- coding: utf-8 -*-<N># $Id: manpage.py 8664 2021-04-04 18:48:10Z grubert $<N># Author: Engelbert Gruber <grubert@users.sourceforge.net><N># Copyright: This module is put into the public domain.<N><N>"""<N>Simple man page writer for reStructuredText.<N><N>
Man pages (short for "manual pages") contain system documentation on unix-like<N>systems. The pages are grouped in numbered sections:<N><N> 1 executable programs and shell commands<N> 2 system calls<N> 3 library functions<N> 4 special files<N> 5 file formats<N> 6 games<N> 7 miscellaneous<N> 8 system administration<N><N>
Man pages are written *troff*, a text file formatting system.<N><N>See http://www.tldp.org/HOWTO/Man-Page for a start.<N><N>Man pages have no subsection only parts.<N>Standard parts<N><N>  NAME ,<N>  SYNOPSIS ,<N>  DESCRIPTION ,<N>  OPTIONS ,<N>  FILES ,<N>  SEE ALSO ,<N>  BUGS ,<N><N>
and<N><N>  AUTHOR .<N><N>A unix-like system keeps an index of the DESCRIPTIONs, which is accessible<N>by the command whatis or apropos.<N><N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>import re<N>import sys<N><N>if sys.version_info < (3, 0):<N>    range = xrange  # NOQA: F821  # flake8 do not check undefined name<N><N>
import docutils<N>from docutils import nodes, writers, languages<N>try:<N>    import roman<N>except ImportError:<N>    import docutils.utils.roman as roman<N><N>FIELD_LIST_INDENT = 7<N>DEFINITION_LIST_INDENT = 7<N>OPTION_LIST_INDENT = 7<N>BLOCKQOUTE_INDENT = 3.5<N>LITERAL_BLOCK_INDENT = 3.5<N><N>
# $Id: docutils_xml.py 8368 2019-08-27 12:10:14Z milde $<N># Author: David Goodger, Paul Tremblay, Guenter Milde<N># Maintainer: docutils-develop@lists.sourceforge.net<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Simple document tree Writer, writes Docutils XML according to<N>http://docutils.sourceforge.net/docs/ref/docutils.dtd.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import sys<N>import xml.sax.saxutils<N><N>import docutils<N>from docutils import frontend, writers, nodes<N><N>if sys.version_info >= (3, 0):<N>    from io import StringIO  # noqa<N>else:<N>    from StringIO import StringIO  # noqa<N><N>
# $Id: pseudoxml.py 8592 2020-12-15 23:06:26Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Simple internal document tree Writer, writes indented pseudo-XML.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
<N>from docutils import writers, frontend<N><N><N>class Writer(writers.Writer):<N><N>    supported = ('pprint', 'pformat', 'pseudoxml')<N>    """Formats this writer supports."""<N>    <N>    settings_spec = (<N>        '"Docutils pseudo-XML" Writer Options',<N>        None,<N>        (('Pretty-print <#text> nodes.',<N>          ['--detailled'],<N>          {'action': 'store_true', 'validator': frontend.validate_boolean}),<N>        ))<N><N>
    config_section = 'pseudoxml writer'<N>    config_section_dependencies = ('writers',)<N><N>    output = None<N>    """Final translated form of `document`."""<N><N>    def translate(self):<N>        self.output = self.document.pformat()<N><N>    def supports(self, format):<N>        """This writer supports all format-specific elements."""<N>        return True<N><N><N>
# $Id: null.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>A do-nothing Writer.<N>"""<N><N>from docutils import writers<N><N><N>class Writer(writers.UnfilteredWriter):<N><N>    supported = ('null',)<N>    """Formats this writer supports."""<N><N>    config_section = 'null writer'<N>    config_section_dependencies = ('writers',)<N><N>    def translate(self):<N>        pass<N>
# $Id: __init__.py 8412 2019-11-06 18:15:21Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>PEP HTML Writer.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N><N>import sys<N>import os<N>import os.path<N>import codecs<N>import docutils<N>from docutils import frontend, nodes, utils, writers<N>from docutils.writers import html4css1<N><N>
<N>class Writer(html4css1.Writer):<N><N>    default_stylesheet = 'pep.css'<N><N>    default_stylesheet_path = utils.relative_path(<N>        os.path.join(os.getcwd(), 'dummy'),<N>        os.path.join(os.path.dirname(__file__), default_stylesheet))<N><N>    default_template = 'template.txt'<N><N>
# .. coding: utf-8<N># $Id: __init__.py 8676 2021-04-08 16:36:09Z milde $<N># Author: Engelbert Gruber, GÃ¼nter Milde<N># Maintainer: docutils-develop@lists.sourceforge.net<N># Copyright: This module has been placed in the public domain.<N><N>"""LaTeX2e document tree Writer."""<N><N>
__docformat__ = 'reStructuredText'<N><N># code contributions from several people included, thanks to all.<N># some named: David Abrahams, Julien Letessier, Lele Gaifax, and others.<N>#<N># convention deactivate code by two # i.e. ##.<N><N>import os<N>import re<N>import string<N>import sys<N><N>
if sys.version_info < (3, 0):<N>    from io import open<N>    from urllib import url2pathname<N>else:<N>    from urllib.request import url2pathname<N><N>try:<N>    import roman<N>except ImportError:<N>    import docutils.utils.roman as roman<N><N>import docutils<N>from docutils import frontend, nodes, languages, writers, utils<N>from docutils.utils.error_reporting import SafeString<N>from docutils.transforms import writer_aux<N>from docutils.utils.math import pick_math_environment, unichar2tex<N><N>
# $Id: __init__.py 8412 2019-11-06 18:15:21Z milde $<N># Authors: Chris Liechti <cliechti@gmx.net>;<N>#          David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>S5/HTML Slideshow Writer.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N><N>import sys<N>import os<N>import re<N>import docutils<N>from docutils import frontend, nodes, utils<N>from docutils.writers import html4css1<N>from docutils.parsers.rst import directives<N><N>themes_dir_path = utils.relative_path(<N>    os.path.join(os.getcwd(), 'dummy'),<N>    os.path.join(os.path.dirname(__file__), 'themes'))<N><N>
def find_theme(name):<N>    # Where else to look for a theme?<N>    # Check working dir?  Destination dir?  Config dir?  Plugins dir?<N>    path = os.path.join(themes_dir_path, name)<N>    if not os.path.isdir(path):<N>        raise docutils.ApplicationError(<N>            'Theme directory not found: %r (path: %r)' % (name, path))<N>    return path<N><N>
# $Id: __init__.py 8638 2021-03-20 23:47:07Z milde $<N># Author: David Goodger<N># Maintainer: docutils-develop@lists.sourceforge.net<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Simple HyperText Markup Language document tree Writer.<N><N>
The output conforms to the XHTML version 1.0 Transitional DTD<N>(*almost* strict).  The output contains a minimum of formatting<N>information.  The cascading style sheet "html4css1.css" is required<N>for proper viewing with a modern graphical browser.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import os.path<N>import re<N>import sys<N>import docutils<N>from docutils import frontend, nodes, writers, io<N>from docutils.transforms import writer_aux<N>from docutils.writers import _html_base<N>from docutils.writers._html_base import PIL, url2pathname<N><N>
class Writer(writers._html_base.Writer):<N><N>    supported = ('html', 'html4', 'html4css1', 'xhtml', 'xhtml10')<N>    """Formats this writer supports."""<N><N>    default_stylesheets = ['html4css1.css']<N>    default_stylesheet_dirs = ['.',<N>        os.path.abspath(os.path.dirname(__file__)),<N>        # for math.css<N>        os.path.abspath(os.path.join(<N>            os.path.dirname(os.path.dirname(__file__)), 'html5_polyglot'))<N>       ]<N><N>
# $Id: __init__.py 8605 2021-01-11 11:07:17Z milde $<N># Author: Dave Kuhlman <dkuhlman@davekuhlman.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Open Document Format (ODF) Writer.<N><N>"""<N>from __future__ import absolute_import<N><N>
__docformat__ = 'reStructuredText'<N><N><N>import sys<N>import os<N>import os.path<N>import tempfile<N>import zipfile<N>from xml.etree import ElementTree as etree<N>from xml.dom import minidom<N>import time<N>import re<N>import copy<N>import itertools<N>import weakref<N><N>
try:<N>    import locale   # module missing in Jython<N>except ImportError:<N>    pass<N><N>import docutils<N>from docutils import frontend, nodes, utils, writers, languages<N>from docutils.readers import standalone<N>from docutils.transforms import references<N><N>
if sys.version_info >= (3, 0):<N>    from configparser import ConfigParser<N>    from io import StringIO<N>    from urllib.request import urlopen<N>    from urllib.error import HTTPError<N>else:<N>    from ConfigParser import ConfigParser<N>    from StringIO import StringIO<N>    from urllib2 import HTTPError<N>    from urllib2 import urlopen<N><N>
<N>VERSION = '1.0a'<N><N>IMAGE_NAME_COUNTER = itertools.count()<N><N>#<N># Import pygments and odtwriter pygments formatters if possible.<N>try:<N>    import pygments<N>    import pygments.lexers<N>    from .pygmentsformatter import (OdtPygmentsProgFormatter,<N>                                    OdtPygmentsLaTeXFormatter)<N>except (ImportError, SyntaxError):<N>    pygments = None<N><N>
# check for the Python Imaging Library<N>try:<N>    import PIL.Image<N>except ImportError:<N>    try:  # sometimes PIL modules are put in PYTHONPATH's root<N>        import Image<N><N>        class PIL(object):<N>            pass  # dummy wrapper<N>        PIL.Image = Image<N>    except ImportError:<N>        PIL = None<N><N>
## import warnings<N>## warnings.warn('importing IPShellEmbed', UserWarning)<N>## from IPython.Shell import IPShellEmbed<N>## args = ['-pdb', '-pi1', 'In <\\#>: ', '-pi2', '   .\\D.: ',<N>##         '-po', 'Out<\\#>: ', '-nosep']<N>## ipshell = IPShellEmbed(args,<N>##                        banner = 'Entering IPython.  Press Ctrl-D to exit.',<N>##                        exit_msg = 'Leaving Interpreter, back to program.')<N><N>
<N>#<N># ElementTree does not support getparent method (lxml does).<N># This wrapper class and the following support functions provide<N>#   that support for the ability to get the parent of an element.<N>#<N>_parents = weakref.WeakKeyDictionary()<N>if isinstance(etree.Element, type):<N>    _ElementInterface = etree.Element<N>else:<N>    _ElementInterface = etree._ElementInterface<N><N>
<N>class _ElementInterfaceWrapper(_ElementInterface):<N>    def __init__(self, tag, attrib=None):<N>        _ElementInterface.__init__(self, tag, attrib)<N>        _parents[self] = None<N><N>    def setparent(self, parent):<N>        _parents[self] = parent<N><N>
    def getparent(self):<N>        return _parents[self]<N><N><N>#<N># Constants and globals<N><N>SPACES_PATTERN = re.compile(r'( +)')<N>TABS_PATTERN = re.compile(r'(\t+)')<N>FILL_PAT1 = re.compile(r'^ +')<N>FILL_PAT2 = re.compile(r' {2,}')<N><N>TABLESTYLEPREFIX = 'rststyle-table-'<N>TABLENAMEDEFAULT = '%s0' % TABLESTYLEPREFIX<N>TABLEPROPERTYNAMES = (<N>    'border', 'border-top', 'border-left',<N>    'border-right', 'border-bottom', )<N><N>
# $Id: pygmentsformatter.py 5853 2009-01-19 21:02:02Z dkuhlman $<N># Author: Dave Kuhlman <dkuhlman@rexx.com><N># Copyright: This module has been placed in the public domain.<N><N>"""<N><N>Additional support for Pygments formatter.<N><N>"""<N><N><N>import pygments<N>import pygments.formatter<N><N>
<N>class OdtPygmentsFormatter(pygments.formatter.Formatter):<N>    def __init__(self, rststyle_function, escape_function):<N>        pygments.formatter.Formatter.__init__(self)<N>        self.rststyle_function = rststyle_function<N>        self.escape_function = escape_function<N><N>
# $Id: __init__.py 8358 2019-08-26 16:45:09Z milde $<N># Authors: David Goodger <goodger@python.org>; Ueli Schlaepfer<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This package contains modules for standard tree transforms available<N>to Docutils components. Tree transforms serve a variety of purposes:<N><N>
- To tie up certain syntax-specific "loose ends" that remain after the<N>  initial parsing of the input plaintext. These transforms are used to<N>  supplement a limited syntax.<N><N>- To automate the internal linking of the document tree (hyperlink<N>  references, footnote references, etc.).<N><N>
- To extract useful information from the document tree. These<N>  transforms may be used to construct (for example) indexes and tables<N>  of contents.<N><N>Each transform is an optional step that a Docutils component may<N>choose to perform on the parsed document.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N><N>from docutils import languages, ApplicationError, TransformSpec<N><N><N>class TransformError(ApplicationError): pass<N><N><N>class Transform(object):<N><N>    """<N>    Docutils transform component abstract base class.<N>    """<N><N>
    default_priority = None<N>    """Numerical priority of this transform, 0 through 999 (override)."""<N><N>    def __init__(self, document, startnode=None):<N>        """<N>        Initial setup for in-place document transforms.<N>        """<N><N>        self.document = document<N>        """The document tree to transform."""<N><N>
        self.startnode = startnode<N>        """Node from which to begin the transform.  For many transforms which<N>        apply to the document as a whole, `startnode` is not set (i.e. its<N>        value is `None`)."""<N><N>        self.language = languages.get_language(<N>            document.settings.language_code, document.reporter)<N>        """Language module local to this document."""<N><N>
    def apply(self, **kwargs):<N>        """Override to apply the transform to the document tree."""<N>        raise NotImplementedError('subclass must override this method')<N><N><N>class Transformer(TransformSpec):<N><N>    """<N>    Stores transforms (`Transform` classes) and applies them to document<N>    trees.  Also keeps track of components by component type name.<N>    """<N><N>
    def __init__(self, document):<N>        self.transforms = []<N>        """List of transforms to apply.  Each item is a 4-tuple:<N>        ``(priority string, transform class, pending node or None, kwargs)``.<N>        """<N><N>        self.unknown_reference_resolvers = []<N>        """List of hook functions which assist in resolving references"""<N><N>
        self.document = document<N>        """The `nodes.document` object this Transformer is attached to."""<N><N>        self.applied = []<N>        """Transforms already applied, in order."""<N><N>        self.sorted = 0<N>        """Boolean: is `self.tranforms` sorted?"""<N><N>
        self.components = {}<N>        """Mapping of component type name to component object.  Set by<N>        `self.populate_from_components()`."""<N><N>        self.serialno = 0<N>        """Internal serial number to keep track of the add order of<N>        transforms."""<N><N>
# $Id: universal.py 8671 2021-04-07 12:09:51Z milde $<N># -*- coding: utf-8 -*-<N># Authors: David Goodger <goodger@python.org>; Ueli Schlaepfer; GÃ¼nter Milde<N># Maintainer: docutils-develop@lists.sourceforge.net<N># Copyright: This module has been placed in the public domain.<N><N>
"""<N>Transforms needed by most or all documents:<N><N>- `Decorations`: Generate a document's header & footer.<N>- `Messages`: Placement of system messages stored in<N>  `nodes.document.transform_messages`.<N>- `TestMessages`: Like `Messages`, used on test runs.<N>- `FinalReferences`: Resolve remaining references.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import re<N>import sys<N>import time<N>from docutils import nodes, utils<N>from docutils.transforms import TransformError, Transform<N>from docutils.utils import smartquotes<N><N><N>if sys.version_info >= (3, 0):<N>    unicode = str  # noqa<N><N>
# $Id: frontmatter.py 8671 2021-04-07 12:09:51Z milde $<N># Author: David Goodger, Ueli Schlaepfer <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Transforms related to the front matter of a document or a section<N>(information found before the main text):<N><N>
- `DocTitle`: Used to transform a lone top level section's title to<N>  the document title, promote a remaining lone top-level section's<N>  title to the document subtitle, and determine the document's title<N>  metadata (document['title']) based on the document title and/or the<N>  "title" setting.<N><N>
- `SectionSubTitle`: Used to transform a lone subsection into a<N>  subtitle.<N><N>- `DocInfo`: Used to transform a bibliographic field list into docinfo<N>  elements.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>import re<N>import sys<N><N>from docutils import nodes, utils<N>from docutils.transforms import TransformError, Transform<N><N>
<N>if sys.version_info >= (3, 0):<N>    unicode = str  # noqa<N><N><N>class TitlePromoter(Transform):<N><N>    """<N>    Abstract base class for DocTitle and SectionSubTitle transforms.<N>    """<N><N>    def promote_title(self, node):<N>        """<N>        Transform the following tree::<N><N>
            <node><N>                <section><N>                    <title><N>                    ...<N><N>        into ::<N><N>            <node><N>                <title><N>                ...<N><N>        `node` is normally a document.<N>        """<N>        # Type check<N>        if not isinstance(node, nodes.Element):<N>            raise TypeError('node must be of Element-derived type.')<N><N>
# $Id: references.py 8565 2020-09-14 10:26:03Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Transforms for resolving references.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import sys<N>import re<N>from docutils import nodes, utils<N>from docutils.transforms import TransformError, Transform<N><N><N>class PropagateTargets(Transform):<N><N>    """<N>    Propagate empty internal targets to the next element.<N><N>    Given the following nodes::<N><N>
        <target ids="internal1" names="internal1"><N>        <target anonymous="1" ids="id1"><N>        <target ids="internal2" names="internal2"><N>        <paragraph><N>            This is a test.<N><N>    PropagateTargets propagates the ids and names of the internal<N>    targets preceding the paragraph to the paragraph itself::<N><N>
        <target refid="internal1"><N>        <target anonymous="1" refid="id1"><N>        <target refid="internal2"><N>        <paragraph ids="internal2 id1 internal1" names="internal2 internal1"><N>            This is a test.<N>    """<N><N>    default_priority = 260<N><N>
# $Id: components.py 8603 2021-01-08 15:24:32Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Docutils component-related transforms.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import sys<N>import os<N>import re<N>import time<N>from docutils import nodes, utils<N>from docutils import ApplicationError, DataError<N>from docutils.transforms import Transform, TransformError<N><N><N>class Filter(Transform):<N><N>    """<N>    Include or exclude elements which depend on a specific Docutils component.<N><N>
# $Id: peps.py 8527 2020-07-14 16:41:15Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Transforms for PEP processing.<N><N>- `Headers`: Used to transform a PEP's initial RFC-2822 header.  It remains a<N>  field list, but some entries get processed.<N>- `Contents`: Auto-inserts a table of contents.<N>- `PEPZero`: Special processing for PEP 0.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N>import sys<N>import os<N>import re<N>import time<N>from docutils import nodes, utils, languages<N>from docutils import ApplicationError, DataError<N>from docutils.transforms import Transform, TransformError<N>from docutils.transforms import parts, references, misc<N><N>
<N>class Headers(Transform):<N><N>    """<N>    Process fields in a PEP's initial RFC-2822 header.<N>    """<N><N>    default_priority = 360<N><N>    pep_url = 'pep-%04d'<N>    pep_cvs_url = ('http://hg.python.org'<N>                   '/peps/file/default/pep-%04d.txt')<N>    rcs_keyword_substitutions = (<N>          (re.compile(r'\$' r'RCSfile: (.+),v \$$', re.IGNORECASE), r'\1'),<N>          (re.compile(r'\$[a-zA-Z]+: (.+) \$$'), r'\1'),)<N><N>
# $Id: misc.py 6314 2010-04-26 10:04:17Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Miscellaneous transforms.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>from docutils import nodes<N>from docutils.transforms import Transform, TransformError<N><N>
<N>class CallBack(Transform):<N><N>    """<N>    Inserts a callback into a document.  The callback is called when the<N>    transform is applied, which is determined by its priority.<N><N>    For use with `nodes.pending` elements.  Requires a ``details['callback']``<N>    entry, a bound method or function which takes one parameter: the pending<N>    node.  Other data can be stored in the ``details`` attribute or in the<N>    object hosting the callback method.<N>    """<N><N>
    default_priority = 990<N><N>    def apply(self):<N>        pending = self.startnode<N>        pending.details['callback'](pending)<N>        pending.parent.remove(pending)<N><N><N>class ClassAttribute(Transform):<N><N>    """<N>    Move the "class" attribute specified in the "pending" node into the<N>    immediately following non-comment element.<N>    """<N><N>
# $Id: parts.py 8671 2021-04-07 12:09:51Z milde $<N># Authors: David Goodger <goodger@python.org>; Ueli Schlaepfer; Dmitry Jemerov<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Transforms related to document parts.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N><N>import re<N>import sys<N>from docutils import nodes, utils<N>from docutils.transforms import TransformError, Transform<N><N><N>class SectNum(Transform):<N><N>    """<N>    Automatically assigns numbers to the titles of document sections.<N><N>
    It is possible to limit the maximum section level for which the numbers<N>    are added.  For those sections that are auto-numbered, the "autonum"<N>    attribute is set, informing the contents table generator that a different<N>    form of the TOC should be used.<N>    """<N><N>
# $Id: writer_aux.py 7808 2015-02-27 17:03:32Z milde $<N># Author: Lea Wiemann <LeWiemann@gmail.com><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Auxiliary transforms mainly to be used by Writer components.<N><N>This module is called "writer_aux" because otherwise there would be<N>conflicting imports like this one::<N><N>
    from docutils import writers<N>    from docutils.transforms import writers<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>from docutils import nodes, utils, languages<N>from docutils.transforms import Transform<N><N><N>class Compound(Transform):<N><N>
    """<N>    Flatten all compound paragraphs.  For example, transform ::<N><N>        <compound><N>            <paragraph><N>            <literal_block><N>            <paragraph><N><N>    into ::<N><N>        <paragraph><N>        <literal_block classes="continued"><N>        <paragraph classes="continued"><N>    """<N><N>
# $Id: __init__.py 8478 2020-01-30 12:29:29Z milde $<N># Authors: David Goodger <goodger@python.org>; Ueli Schlaepfer<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This package contains Docutils Reader modules.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import sys<N>from importlib import import_module<N><N>from docutils import utils, parsers, Component<N>from docutils.transforms import universal<N><N><N>class Reader(Component):<N><N>    """<N>    Abstract base class for docutils Readers.<N><N>    Each reader module or package must export a subclass also called 'Reader'.<N><N>
    The two steps of a Reader's responsibility are to read data from the<N>    source Input object and parse the data with the Parser object.<N>    Call `read()` to process a document.<N>    """<N><N>    component_type = 'reader'<N>    config_section = 'readers'<N><N>
    def get_transforms(self):<N>        return Component.get_transforms(self) + [<N>            universal.Decorations,<N>            universal.ExposeInternals,<N>            universal.StripComments,]<N><N>    def __init__(self, parser=None, parser_name=None):<N>        """<N>        Initialize the Reader instance.<N><N>
        Several instance attributes are defined with dummy initial values.<N>        Subclasses may use these attributes as they wish.<N>        """<N><N>        self.parser = parser<N>        """A `parsers.Parser` instance shared by all doctrees.  May be left<N>        unspecified if the document source determines the parser."""<N><N>
        if parser is None and parser_name:<N>            self.set_parser(parser_name)<N><N>        self.source = None<N>        """`docutils.io` IO object, source of input data."""<N><N>        self.input = None<N>        """Raw text input; either a single string or, for more complex cases,<N>        a collection of strings."""<N><N>
    def set_parser(self, parser_name):<N>        """Set `self.parser` by name."""<N>        parser_class = parsers.get_parser_class(parser_name)<N>        self.parser = parser_class()<N><N>    def read(self, source, parser, settings):<N>        self.source = source<N>        if not self.parser:<N>            self.parser = parser<N>        self.settings = settings<N>        self.input = self.source.read()<N>        self.parse()<N>        return self.document<N><N>
    def parse(self):<N>        """Parse `self.input` into a document tree."""<N>        self.document = document = self.new_document()<N>        self.parser.parse(self.input, document)<N>        document.current_source = document.current_line = None<N><N>    def new_document(self):<N>        """Create and return a new empty document tree (root node)."""<N>        document = utils.new_document(self.source.source_path, self.settings)<N>        return document<N><N>
<N>class ReReader(Reader):<N><N>    """<N>    A reader which rereads an existing document tree (e.g. a<N>    deserializer).<N><N>    Often used in conjunction with `writers.UnfilteredWriter`.<N>    """<N><N>    def get_transforms(self):<N>        # Do not add any transforms.  They have already been applied<N>        # by the reader which originally created the document.<N>        return Component.get_transforms(self)<N><N>
<N>_reader_aliases = {}<N><N>def get_reader_class(reader_name):<N>    """Return the Reader class from the `reader_name` module."""<N>    reader_name = reader_name.lower()<N>    if reader_name in _reader_aliases:<N>        reader_name = _reader_aliases[reader_name]<N>    try:<N>        module = import_module('docutils.readers.'+reader_name)<N>    except ImportError:<N>        module = import_module(reader_name)<N>    return module.Reader<N><N><N>
# $Id: pep.py 7320 2012-01-19 22:33:02Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Python Enhancement Proposal (PEP) Reader.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
<N>from docutils.readers import standalone<N>from docutils.transforms import peps, references, misc, frontmatter<N>from docutils.parsers import rst<N><N><N>class Reader(standalone.Reader):<N><N>    supported = ('pep',)<N>    """Contexts this reader supports."""<N><N>
    settings_spec = (<N>        'PEP Reader Option Defaults',<N>        'The --pep-references and --rfc-references options (for the '<N>        'reStructuredText parser) are on by default.',<N>        ())<N><N>    config_section = 'pep reader'<N>    config_section_dependencies = ('readers', 'standalone reader')<N><N>
    def get_transforms(self):<N>        transforms = standalone.Reader.get_transforms(self)<N>        # We have PEP-specific frontmatter handling.<N>        transforms.remove(frontmatter.DocTitle)<N>        transforms.remove(frontmatter.SectionSubTitle)<N>        transforms.remove(frontmatter.DocInfo)<N>        transforms.extend([peps.Headers, peps.Contents, peps.TargetNotes])<N>        return transforms<N><N>
    settings_default_overrides = {'pep_references': 1, 'rfc_references': 1}<N><N>    inliner_class = rst.states.Inliner<N><N>    def __init__(self, parser=None, parser_name=None):<N>        """`parser` should be ``None``."""<N>        if parser is None:<N>            parser = rst.Parser(rfc2822=True, inliner=self.inliner_class())<N>        standalone.Reader.__init__(self, parser, '')<N><N><N>
# $Id: doctree.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Martin Blais <blais@furius.ca><N># Copyright: This module has been placed in the public domain.<N><N>"""Reader for existing document trees."""<N><N>from docutils import readers, utils, transforms<N><N>
<N>class Reader(readers.ReReader):<N><N>    """<N>    Adapt the Reader API for an existing document tree.<N><N>    The existing document tree must be passed as the ``source`` parameter to<N>    the `docutils.core.Publisher` initializer, wrapped in a<N>    `docutils.io.DocTreeInput` object::<N><N>
        pub = docutils.core.Publisher(<N>            ..., source=docutils.io.DocTreeInput(document), ...)<N><N>    The original document settings are overridden; if you want to use the<N>    settings of the original document, pass ``settings=document.settings`` to<N>    the Publisher call above.<N>    """<N><N>
# $Id: standalone.py 4802 2006-11-12 18:02:17Z goodger $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Standalone file Reader for the reStructuredText markup syntax.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
<N>import sys<N>from docutils import frontend, readers<N>from docutils.transforms import frontmatter, references, misc<N><N><N>class Reader(readers.Reader):<N><N>    supported = ('standalone',)<N>    """Contexts this reader supports."""<N><N>    document = None<N>    """A single document tree."""<N><N>
# $Id: __init__.py 8671 2021-04-07 12:09:51Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This package contains Docutils parser modules.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
# $Id: null.py 4564 2006-05-21 20:44:42Z wiemann $<N># Author: Martin Blais <blais@furius.ca><N># Copyright: This module has been placed in the public domain.<N><N>"""A do-nothing parser."""<N><N>from docutils import parsers<N><N><N>class Parser(parsers.Parser):<N><N>    """A do-nothing parser."""<N><N>    supported = ('null',)<N><N>    config_section = 'null parser'<N>    config_section_dependencies = ('parsers',)<N><N>    def parse(self, inputstring, document):<N>        pass<N>
# $Id: __init__.py 8671 2021-04-07 12:09:51Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This is ``docutils.parsers.rst`` package. It exports a single class, `Parser`,<N>the reStructuredText parser.<N><N>
<N>Usage<N>=====<N><N>1. Create a parser::<N><N>       parser = docutils.parsers.rst.Parser()<N><N>   Several optional arguments may be passed to modify the parser's behavior.<N>   Please see `Customizing the Parser`_ below for details.<N><N>2. Gather input (a multi-line string), by reading a file or the standard<N>   input::<N><N>
       input = sys.stdin.read()<N><N>3. Create a new empty `docutils.nodes.document` tree::<N><N>       document = docutils.utils.new_document(source, settings)<N><N>   See `docutils.utils.new_document()` for parameter details.<N><N>4. Run the parser, populating the document tree::<N><N>
       parser.parse(input, document)<N><N><N>Parser Overview<N>===============<N><N>The reStructuredText parser is implemented as a state machine, examining its<N>input one line at a time. To understand how the parser works, please first<N>become familiar with the `docutils.statemachine` module, then see the<N>`states` module.<N><N>
# $Id: tableparser.py 8373 2019-08-27 12:11:30Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This module defines table parser classes,which parse plaintext-graphic tables<N>and produce a well-formed data structure suitable for building a CALS table.<N><N>
:Classes:<N>    - `GridTableParser`: Parse fully-formed tables represented with a grid.<N>    - `SimpleTableParser`: Parse simple tables, delimited by top & bottom<N>      borders.<N><N>:Exception class: `TableMarkupError`<N><N>:Function:<N>    `update_dict_of_lists()`: Merge two dictionaries containing list values.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N><N>import re<N>import sys<N>from docutils import DataError<N>from docutils.utils import strip_combining_chars<N><N><N>class TableMarkupError(DataError):<N><N>    """<N>    Raise if there is any problem with table markup.<N><N>
    The keyword argument `offset` denotes the offset of the problem<N>    from the table's start line.<N>    """<N><N>    def __init__(self, *args, **kwargs):<N>            self.offset = kwargs.pop('offset', 0)<N>            DataError.__init__(self, *args)<N><N>
<N>class TableParser(object):<N><N>    """<N>    Abstract superclass for the common parts of the syntax-specific parsers.<N>    """<N><N>    head_body_separator_pat = None<N>    """Matches the row separator between head rows and body rows."""<N><N>    double_width_pad_char = '\x00'<N>    """Padding character for East Asian double-width text."""<N><N>
    def parse(self, block):<N>        """<N>        Analyze the text `block` and return a table data structure.<N><N>        Given a plaintext-graphic table in `block` (list of lines of text; no<N>        whitespace padding), parse the table, construct and return the data<N>        necessary to construct a CALS table or equivalent.<N><N>
        Raise `TableMarkupError` if there is any problem with the markup.<N>        """<N>        self.setup(block)<N>        self.find_head_body_sep()<N>        self.parse_table()<N>        structure = self.structure_from_cells()<N>        return structure<N><N>
# $Id: roles.py 8571 2020-10-28 08:46:19Z milde $<N># Author: Edward Loper <edloper@gradient.cis.upenn.edu><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This module defines standard interpreted text role functions, a registry for<N>interpreted text roles, and an API for adding to and retrieving from the<N>registry.<N><N>
The interface for interpreted role functions is as follows::<N><N>    def role_fn(name, rawtext, text, lineno, inliner,<N>                options={}, content=[]):<N>        code...<N><N>    # Set function attributes for customization:<N>    role_fn.options = ...<N>    role_fn.content = ...<N><N>
Parameters:<N><N>- ``name`` is the local name of the interpreted text role, the role name<N>  actually used in the document.<N><N>- ``rawtext`` is a string containing the entire interpreted text construct.<N>  Return it as a ``problematic`` node linked to a system message if there is a<N>  problem.<N><N>
- ``text`` is the interpreted text content, with backslash escapes converted<N>  to nulls (``\x00``).<N><N>- ``lineno`` is the line number where the interpreted text beings.<N><N>- ``inliner`` is the Inliner object that called the role function.<N>  It defines the following useful attributes: ``reporter``,<N>  ``problematic``, ``memo``, ``parent``, ``document``.<N><N>
- ``options``: A dictionary of directive options for customization, to be<N>  interpreted by the role function.  Used for additional attributes for the<N>  generated elements and other functionality.<N><N>- ``content``: A list of strings, the directive content for customization<N>  ("role" directive).  To be interpreted by the role function.<N><N>
Function attributes for customization, interpreted by the "role" directive:<N><N>- ``options``: A dictionary, mapping known option names to conversion<N>  functions such as `int` or `float`.  ``None`` or an empty dict implies no<N>  options to parse.  Several directive option conversion functions are defined<N>  in the `directives` module.<N><N>
  All role functions implicitly support the "class" option, unless disabled<N>  with an explicit ``{'class': None}``.<N><N>- ``content``: A boolean; true if content is allowed.  Client code must handle<N>  the case where content is required but not supplied (an empty content list<N>  will be supplied).<N><N>
Note that unlike directives, the "arguments" function attribute is not<N>supported for role customization.  Directive arguments are handled by the<N>"role" directive itself.<N><N>Interpreted role functions return a tuple of two values:<N><N>- A list of nodes which will be inserted into the document tree at the<N>  point where the interpreted role was encountered (can be an empty<N>  list).<N><N>
- A list of system messages, which will be inserted into the document tree<N>  immediately after the end of the current inline block (can also be empty).<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>from docutils import nodes, utils<N>from docutils.parsers.rst import directives<N>from docutils.parsers.rst.languages import en as _fallback_language_module<N>from docutils.utils.code_analyzer import Lexer, LexerError<N><N>
DEFAULT_INTERPRETED_ROLE = 'title-reference'<N>"""<N>The canonical name of the default interpreted role.  This role is used<N>when no role is specified for a piece of interpreted text.<N>"""<N><N>_role_registry = {}<N>"""Mapping of canonical role names to role functions.  Language-dependent role<N>names are defined in the ``language`` subpackage."""<N><N>
# $Id: states.py 8587 2020-12-09 15:33:58Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This is the ``docutils.parsers.rst.states`` module, the core of<N>the reStructuredText parser.  It defines the following:<N><N>
# -*- coding: utf-8 -*-<N># $Id: sv.py 8012 2017-01-03 23:08:19Z milde $<N># Author: Adam Chodorowski <chodorowski@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: zh_tw.py 7119 2011-09-02 13:00:23Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: fa.py 4564 2016-08-10 11:48:42Z<N># Author: Shahin <me@5hah.in><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: __init__.py 8467 2020-01-26 21:23:42Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># Internationalization details are documented in<N># <http://docutils.sf.net/docs/howto/i18n.html>.<N><N>
"""<N>This package contains modules for language-dependent features of<N>reStructuredText.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>import sys<N><N>from docutils.languages import LanguageImporter<N><N>class RstLanguageImporter(LanguageImporter):<N>    """Import language modules.<N><N>
    When called with a BCP 47 language tag, instances return a module<N>    with localisations for "directive" and "role" names for  from<N>    `docutils.parsers.rst.languages` or the PYTHONPATH.<N><N>    If there is no matching module, warn (if a `reporter` is passed)<N>    and return None.<N>    """<N>    packages = ('docutils.parsers.rst.languages.', '')<N>    warn_msg = 'rST localisation for language "%s" not found.'<N>    fallback = None<N><N>
    def check_content(self, module):<N>        """Check if we got an rST language module."""<N>        if not (isinstance(module.directives, dict)<N>                and isinstance(module.roles, dict)):<N>            raise ImportError<N><N>get_language = RstLanguageImporter()<N><N><N>
# $Id: ca.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Ivan Vilata i Balaguer <ivan@selidor.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: pt_br.py 7119 2011-09-02 13:00:23Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: es.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Marcelo Huerta San MartÃ­n <richieadler@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: it.py 7119 2011-09-02 13:00:23Z milde $<N># Authors: Nicola Larosa <docutils@tekNico.net>;<N>#          Lele Gaifax <lele@seldati.it><N># Copyright: This module has been placed in the public domain.<N><N># Beware: the italian translation of the reStructuredText documentation<N># at http://docit.bice.dyndns.org/static/ReST, in particular<N># http://docit.bice.dyndns.org/static/ReST/ref/rst/directives.html, needs<N># to be synced with the content of this file.<N><N>
# -*- coding: utf-8 -*-<N># $Id: zh_cn.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Panjunyong <panjy@zopechina.com><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ja.py 7119 2011-09-02 13:00:23Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# Author: Meir Kriheli<N># Id: $Id: he.py 7119 2011-09-02 13:00:23Z milde $<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: eo.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Marcelo Huerta San Martin <richieadler@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: sk.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Miroslav Vasko <zemiak@zoznam.sk><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: da.py 7678 2013-07-03 09:57:36Z milde $<N># Author: E D<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: fi.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Asko Soukka <asko.soukka@iki.fi><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: nl.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Martijn Pieters <mjpieters@users.sourceforge.net><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># Author: David Goodger<N># Contact: goodger@users.sourceforge.net<N># Revision: $Revision: 4229 $<N># Date: $Date: 2005-12-23 00:46:16 +0100 (Fri, 23 Dec 2005) $<N># Copyright: This module has been placed in the public domain.<N><N>
# New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: lt.py 7668 2013-06-04 12:46:30Z milde $<N># Author: Dalius Dobravolskas <dalius.do...@gmail.com><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: en.py 7179 2011-10-15 22:06:45Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: lv.py 7975 2016-10-20 20:00:19Z milde $<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: af.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Jannie Hofmeyr <jhsh@sun.ac.za><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id$<N># Author: Robert Wojciechowicz <rw@smsnet.pl><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: cs.py 7119 2011-09-02 13:00:23Z milde $<N># Author: Marek Blaha <mb@dat.cz><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ru.py 7123 2011-09-12 08:28:31Z milde $<N># Author: Roman Suzi <rnd@onego.ru><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: ko.py 8541 2020-08-22 22:16:25Z milde $<N># Author: Thomas SJ Kang <thomas.kangsj@ujuc.kr><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: fr.py 7119 2011-09-02 13:00:23Z milde $<N># Authors: David Goodger <goodger@python.org>; William Dode<N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# -*- coding: utf-8 -*-<N># $Id: fa.py 4564 2016-08-10 11:48:42Z<N># Author: Shahin <me@5hah.in><N># Copyright: This module has been placed in the public domain.<N><N># New language mappings are welcome.  Before doing a new translation, please<N># read <http://docutils.sf.net/docs/howto/i18n.html>.  Two files must be<N># translated for each language: one in docutils/languages, the other in<N># docutils/parsers/rst/languages.<N><N>
# $Id: html.py 8603 2021-01-08 15:24:32Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for typically HTML-specific constructs.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import sys<N>from docutils import nodes, utils<N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import states<N>from docutils.transforms import components<N><N><N>class MetaBody(states.SpecializedBody):<N><N>    class meta(nodes.Special, nodes.PreBibliographic, nodes.Element):<N>        """HTML-specific "meta" element."""<N>        pass<N><N>
# $Id: __init__.py 8595 2020-12-15 23:06:58Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>This package contains directive implementation modules.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
import re<N>import codecs<N>import sys<N>from importlib import import_module<N><N>from docutils import nodes, parsers<N>from docutils.utils import split_escaped_whitespace, escape2null, unescape<N>from docutils.parsers.rst.languages import en as _fallback_language_module<N><N>
# $Id: body.py 8596 2020-12-16 10:41:03Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for additional body elements.<N><N>See `docutils.parsers.rst.directives` for API details.<N>"""<N><N>
__docformat__ = 'reStructuredText'<N><N><N>from docutils import nodes<N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import directives<N>from docutils.parsers.rst.roles import set_classes<N>from docutils.utils.code_analyzer import Lexer, LexerError, NumberLines<N><N>
<N>class BasePseudoSection(Directive):<N><N>    required_arguments = 1<N>    optional_arguments = 0<N>    final_argument_whitespace = True<N>    option_spec = {'class': directives.class_option,<N>                   'name': directives.unchanged}<N>    has_content = True<N><N>
# $Id: tables.py 8377 2019-08-27 19:49:45Z milde $<N># Authors: David Goodger <goodger@python.org>; David Priest<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for table elements.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
<N>import sys<N>import os.path<N>import csv<N><N>from docutils import io, nodes, statemachine, utils<N>from docutils.utils.error_reporting import SafeString<N>from docutils.utils import SystemMessagePropagation<N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import directives<N><N>
# $Id: references.py 7062 2011-06-30 22:14:29Z milde $<N># Authors: David Goodger <goodger@python.org>; Dmitry Jemerov<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for references and targets.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
from docutils import nodes<N>from docutils.transforms import references<N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import directives<N><N><N>class TargetNotes(Directive):<N><N>    """Target footnote generation."""<N><N>    option_spec = {'class': directives.class_option,<N>                   'name': directives.unchanged}<N><N>
# $Id: images.py 8583 2020-12-01 10:53:27Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for figures and simple images.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
<N>import sys<N><N>from docutils import nodes, utils<N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import directives, states<N>from docutils.nodes import fully_normalize_name, whitespace_normalize_name<N>from docutils.parsers.rst.roles import set_classes<N><N>
try: # check for the Python Imaging Library<N>    import PIL.Image<N>except ImportError:<N>    try:  # sometimes PIL modules are put in PYTHONPATH's root<N>        import Image<N>        class PIL(object): pass  # dummy wrapper<N>        PIL.Image = Image<N>    except ImportError:<N>        PIL = None<N><N>
if sys.version_info >= (3, 0):<N>    from urllib.request import url2pathname<N>else:<N>    from urllib import url2pathname<N><N><N>class Image(Directive):<N><N>    align_h_values = ('left', 'center', 'right')<N>    align_v_values = ('top', 'middle', 'bottom')<N>    align_values = align_v_values + align_h_values<N><N>
    def align(argument):<N>        # This is not callable as self.align.  We cannot make it a<N>        # staticmethod because we're saving an unbound method in<N>        # option_spec below.<N>        return directives.choice(argument, Image.align_values)<N><N>
# $Id: admonitions.py 7681 2013-07-12 07:52:27Z milde $<N># Author: David Goodger <goodger@python.org><N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Admonition directives.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N><N>from docutils.parsers.rst import Directive<N>from docutils.parsers.rst import states, directives<N>from docutils.parsers.rst.roles import set_classes<N>from docutils import nodes<N><N>
<N>class BaseAdmonition(Directive):<N><N>    final_argument_whitespace = True<N>    option_spec = {'class': directives.class_option,<N>                   'name': directives.unchanged}<N>    has_content = True<N><N>    node_class = None<N>    """Subclasses must set this to the appropriate admonition node class."""<N><N>
# $Id: misc.py 8595 2020-12-15 23:06:58Z milde $<N># Authors: David Goodger <goodger@python.org>; Dethe Elza<N># Copyright: This module has been placed in the public domain.<N><N>"""Miscellaneous directives."""<N><N>__docformat__ = 'reStructuredText'<N><N>
# $Id: parts.py 7308 2012-01-06 12:08:43Z milde $<N># Authors: David Goodger <goodger@python.org>; Dmitry Jemerov<N># Copyright: This module has been placed in the public domain.<N><N>"""<N>Directives for document parts.<N>"""<N><N>__docformat__ = 'reStructuredText'<N><N>
"""Python 2/3 compatibility"""<N>import json<N>import sys<N><N><N># Handle reading and writing JSON in UTF-8, on Python 3 and 2.<N><N>if sys.version_info[0] >= 3:<N>    # Python 3<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'w', encoding='utf-8') as f:<N>            json.dump(obj, f, **kwargs)<N><N>
    def read_json(path):<N>        with open(path, 'r', encoding='utf-8') as f:<N>            return json.load(f)<N><N>else:<N>    # Python 2<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'wb') as f:<N>            json.dump(obj, f, encoding='utf-8', **kwargs)<N><N>
import os<N>import io<N>import contextlib<N>import tempfile<N>import shutil<N>import errno<N>import zipfile<N><N><N>@contextlib.contextmanager<N>def tempdir():<N>    """Create a temporary directory in a context manager."""<N>    td = tempfile.mkdtemp()<N>    try:<N>        yield td<N>    finally:<N>        shutil.rmtree(td)<N><N>
<N>def mkdir_p(*args, **kwargs):<N>    """Like `mkdir`, but does not raise an exception if the<N>    directory already exists.<N>    """<N>    try:<N>        return os.mkdir(*args, **kwargs)<N>    except OSError as exc:<N>        if exc.errno != errno.EEXIST:<N>            raise<N><N>
import threading<N>from contextlib import contextmanager<N>import os<N>from os.path import dirname, abspath, join as pjoin<N>import shutil<N>from subprocess import check_call, check_output, STDOUT<N>import sys<N>from tempfile import mkdtemp<N><N>from . import compat<N><N>
_in_proc_script = pjoin(dirname(abspath(__file__)), '_in_process.py')<N><N><N>@contextmanager<N>def tempdir():<N>    td = mkdtemp()<N>    try:<N>        yield td<N>    finally:<N>        shutil.rmtree(td)<N><N><N>class BackendUnavailable(Exception):<N>    """Will be raised if the backend cannot be imported in the hook process."""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N>
<N>class BackendInvalid(Exception):<N>    """Will be raised if the backend is invalid."""<N>    def __init__(self, backend_name, backend_path, message):<N>        self.backend_name = backend_name<N>        self.backend_path = backend_path<N>        self.message = message<N><N>
<N>class UnsupportedOperation(Exception):<N>    """May be raised by build_sdist if the backend indicates that it can't."""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N><N>def default_subprocess_runner(cmd, cwd=None, extra_environ=None):<N>    """The default method of calling the wrapper subprocess."""<N>    env = os.environ.copy()<N>    if extra_environ:<N>        env.update(extra_environ)<N><N>
    check_call(cmd, cwd=cwd, env=env)<N><N><N>def quiet_subprocess_runner(cmd, cwd=None, extra_environ=None):<N>    """A method of calling the wrapper subprocess while suppressing output."""<N>    env = os.environ.copy()<N>    if extra_environ:<N>        env.update(extra_environ)<N><N>
    check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)<N><N><N>def norm_and_check(source_tree, requested):<N>    """Normalise and check a backend path.<N><N>    Ensure that the requested backend path is specified as a relative path,<N>    and resolves to a location under the given source tree.<N><N>
"""Check a project and backend by attempting to build using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>from os.path import isfile, join as pjoin<N>from pytoml import TomlError, load as toml_load<N>import shutil<N>from subprocess import CalledProcessError<N>import sys<N>import tarfile<N>from tempfile import mkdtemp<N>import zipfile<N><N>
"""This is invoked in a subprocess to call the build backend hooks.<N><N>It expects:<N>- Command line args: hook_name, control_dir<N>- Environment variables:<N>      PEP517_BUILD_BACKEND=entry.point:spec<N>      PEP517_BACKEND_PATH=paths (separated with os.pathsep)<N>- control_dir/input.json:<N>  - {"kwargs": {...}}<N><N>
Results:<N>- control_dir/output.json<N>  - {"return_val": ...}<N>"""<N>from glob import glob<N>from importlib import import_module<N>import os<N>import os.path<N>from os.path import join as pjoin<N>import re<N>import shutil<N>import sys<N>import traceback<N><N>
# This is run as a script, not a module, so it can't do a relative import<N>import compat<N><N><N>class BackendUnavailable(Exception):<N>    """Raised if we cannot import the backend"""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N>
<N>class BackendInvalid(Exception):<N>    """Raised if the backend is invalid"""<N>    def __init__(self, message):<N>        self.message = message<N><N><N>def contained_in(filename, directory):<N>    """Test if a file is located within the given directory."""<N>    filename = os.path.normcase(os.path.abspath(filename))<N>    directory = os.path.normcase(os.path.abspath(directory))<N>    return os.path.commonprefix([filename, directory]) == directory<N><N>
<N>def _build_backend():<N>    """Find and load the build backend"""<N>    # Add in-tree backend directories to the front of sys.path.<N>    backend_path = os.environ.get('PEP517_BACKEND_PATH')<N>    if backend_path:<N>        extra_pathitems = backend_path.split(os.pathsep)<N>        sys.path[:0] = extra_pathitems<N><N>
    ep = os.environ['PEP517_BUILD_BACKEND']<N>    mod_path, _, obj_path = ep.partition(':')<N>    try:<N>        obj = import_module(mod_path)<N>    except ImportError:<N>        raise BackendUnavailable(traceback.format_exc())<N><N>    if backend_path:<N>        if not any(<N>            contained_in(obj.__file__, path)<N>            for path in extra_pathitems<N>        ):<N>            raise BackendInvalid("Backend was not loaded from backend-path")<N><N>
    if obj_path:<N>        for path_part in obj_path.split('.'):<N>            obj = getattr(obj, path_part)<N>    return obj<N><N><N>def get_requires_for_build_wheel(config_settings):<N>    """Invoke the optional get_requires_for_build_wheel hook<N><N>    Returns [] if the hook is not defined.<N>    """<N>    backend = _build_backend()<N>    try:<N>        hook = backend.get_requires_for_build_wheel<N>    except AttributeError:<N>        return []<N>    else:<N>        return hook(config_settings)<N><N>
"""Build a project using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>import pytoml<N>import shutil<N><N>from .envbuild import BuildEnvironment<N>from .wrappers import Pep517HookCaller<N>from .dirtools import tempdir, mkdir_p<N>from .compat import FileNotFoundError<N><N>
log = logging.getLogger(__name__)<N><N><N>def validate_system(system):<N>    """<N>    Ensure build system has the requisite fields.<N>    """<N>    required = {'requires', 'build-backend'}<N>    if not (required <= set(system)):<N>        message = "Missing required fields: {missing}".format(<N>            missing=required-set(system),<N>        )<N>        raise ValueError(message)<N><N>
<N>def load_system(source_dir):<N>    """<N>    Load the build system from a source dir (pyproject.toml).<N>    """<N>    pyproject = os.path.join(source_dir, 'pyproject.toml')<N>    with open(pyproject) as f:<N>        pyproject_data = pytoml.load(f)<N>    return pyproject_data['build-system']<N><N>
"""Build metadata for a project using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>import shutil<N>import functools<N><N>try:<N>    import importlib.metadata as imp_meta<N>except ImportError:<N>    import importlib_metadata as imp_meta<N><N>
try:<N>    from zipfile import Path<N>except ImportError:<N>    from zipp import Path<N><N>from .envbuild import BuildEnvironment<N>from .wrappers import Pep517HookCaller, quiet_subprocess_runner<N>from .dirtools import tempdir, mkdir_p, dir_to_zipfile<N>from .build import validate_system, load_system, compat_system<N><N>
log = logging.getLogger(__name__)<N><N><N>def _prep_meta(hooks, env, dest):<N>    reqs = hooks.get_requires_for_build_wheel({})<N>    log.info('Got build requires: %s', reqs)<N><N>    env.pip_install(reqs)<N>    log.info('Installed dynamic build dependencies')<N><N>
    with tempdir() as td:<N>        log.info('Trying to build metadata in %s', td)<N>        filename = hooks.prepare_metadata_for_build_wheel(td, {})<N>        source = os.path.join(td, filename)<N>        shutil.move(source, os.path.join(dest, os.path.basename(filename)))<N><N>
<N>def build(source_dir='.', dest=None, system=None):<N>    system = system or load_system(source_dir)<N>    dest = os.path.join(source_dir, dest or 'dist')<N>    mkdir_p(dest)<N>    validate_system(system)<N>    hooks = Pep517HookCaller(source_dir, system['build-backend'])<N><N>
    with hooks.subprocess_runner(quiet_subprocess_runner):<N>        with BuildEnvironment() as env:<N>            env.pip_install(system['requires'])<N>            _prep_meta(hooks, env, dest)<N><N><N>def build_as_zip(builder=build):<N>    with tempdir() as out_dir:<N>        builder(dest=out_dir)<N>        return dir_to_zipfile(out_dir)<N><N>
<N>def load(root):<N>    """<N>    Given a source directory (root) of a package,<N>    return an importlib.metadata.Distribution object<N>    with metadata build from that package.<N>    """<N>    root = os.path.expanduser(root)<N>    system = compat_system(root)<N>    builder = functools.partial(build, source_dir=root, system=system)<N>    path = Path(build_as_zip(builder))<N>    return imp_meta.PathDistribution(path)<N><N>
<N>parser = argparse.ArgumentParser()<N>parser.add_argument(<N>    'source_dir',<N>    help="A directory containing pyproject.toml",<N>)<N>parser.add_argument(<N>    '--out-dir', '-o',<N>    help="Destination in which to save the builds relative to source dir",<N>)<N><N>
"""Build wheels/sdists by installing build deps to a temporary environment.<N>"""<N><N>import os<N>import logging<N>import pytoml<N>import shutil<N>from subprocess import check_call<N>import sys<N>from sysconfig import get_paths<N>from tempfile import mkdtemp<N><N>
from .wrappers import Pep517HookCaller, LoggerWrapper<N><N>log = logging.getLogger(__name__)<N><N><N>def _load_pyproject(source_dir):<N>    with open(os.path.join(source_dir, 'pyproject.toml')) as f:<N>        pyproject_data = pytoml.load(f)<N>    buildsys = pyproject_data['build-system']<N>    return buildsys['requires'], buildsys['build-backend']<N><N>
<N>"""The following code is required to make the dependency binaries available to<N>kivy when it imports this package.<N>"""<N><N>import sys<N>import os<N>from os.path import join, isdir, dirname<N><N>__all__ = ('dep_bins', )<N><N>__version__ = '0.3.0'<N><N>
<N><N>dep_bins = []<N>"""A list of paths that contain the binaries of this distribution.<N>Can be used e.g. with pyinstaller to ensure it copies all the binaries.<N>"""<N><N>_root = sys.prefix<N>dep_bins = [join(_root, 'share', 'glew', 'bin')]<N>if isdir(dep_bins[0]):<N>    os.environ["PATH"] = dep_bins[0] + os.pathsep + os.environ["PATH"]<N>    if hasattr(os, 'add_dll_directory'):<N>        os.add_dll_directory(dep_bins[0])<N>else:<N>    dep_bins = []<N><N>
<N>"""The following code is required to make the dependency binaries available to<N>kivy when it imports this package.<N>"""<N><N>import sys<N>import os<N>from os.path import join, isdir, dirname<N><N>__all__ = ('dep_bins', )<N><N>__version__ = '0.3.1'<N><N>
<N><N>dep_bins = []<N>"""A list of paths that contain the binaries of this distribution.<N>Can be used e.g. with pyinstaller to ensure it copies all the binaries.<N>"""<N><N>_root = sys.prefix<N>dep_bins = [join(_root, 'share', 'sdl2', 'bin')]<N>if isdir(dep_bins[0]):<N>    os.environ["PATH"] = dep_bins[0] + os.pathsep + os.environ["PATH"]<N>    if hasattr(os, 'add_dll_directory'):<N>        os.add_dll_directory(dep_bins[0])<N>else:<N>    dep_bins = []<N><N>
<N>"""The following code is required to make the dependency binaries available to<N>kivy when it imports this package.<N>"""<N><N>import sys<N>import os<N>from os.path import join, isdir, dirname<N><N>__all__ = ('dep_bins', )<N><N>__version__ = '0.3.0'<N><N>
<N><N>dep_bins = []<N>"""A list of paths that contain the binaries of this distribution.<N>Can be used e.g. with pyinstaller to ensure it copies all the binaries.<N>"""<N><N>_root = sys.prefix<N>dep_bins = [join(_root, 'share', 'angle', 'bin')]<N>if isdir(dep_bins[0]):<N>    os.environ["PATH"] = dep_bins[0] + os.pathsep + os.environ["PATH"]<N>    if hasattr(os, 'add_dll_directory'):<N>        os.add_dll_directory(dep_bins[0])<N>else:<N>    dep_bins = []<N><N>
import collections<N>import os<N>import sys<N>import warnings<N><N>import PIL<N><N>from . import Image<N><N>modules = {<N>    "pil": ("PIL._imaging", "PILLOW_VERSION"),<N>    "tkinter": ("PIL._tkinter_finder", "tk_version"),<N>    "freetype2": ("PIL._imagingft", "freetype2_version"),<N>    "littlecms2": ("PIL._imagingcms", "littlecms_version"),<N>    "webp": ("PIL._webp", "webpdecoder_version"),<N>}<N><N>
<N>def check_module(feature):<N>    """<N>    Checks if a module is available.<N><N>    :param feature: The module to check for.<N>    :returns: ``True`` if available, ``False`` otherwise.<N>    :raises ValueError: If the module is not defined in this version of Pillow.<N>    """<N>    if not (feature in modules):<N>        raise ValueError(f"Unknown module {feature}")<N><N>
    module, ver = modules[feature]<N><N>    try:<N>        __import__(module)<N>        return True<N>    except ImportError:<N>        return False<N><N><N>def version_module(feature):<N>    """<N>    :param feature: The module to check for.<N>    :returns:<N>        The loaded version number as a string, or ``None`` if unknown or not available.<N>    :raises ValueError: If the module is not defined in this version of Pillow.<N>    """<N>    if not check_module(feature):<N>        return None<N><N>
    module, ver = modules[feature]<N><N>    if ver is None:<N>        return None<N><N>    return getattr(__import__(module, fromlist=[ver]), ver)<N><N><N>def get_supported_modules():<N>    """<N>    :returns: A list of all supported modules.<N>    """<N>    return [f for f in modules if check_module(f)]<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># HDF5 stub adapter<N>#<N># Copyright (c) 2000-2003 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>from . import Image, ImageFile<N><N>_handler = None<N><N>
<N>def register_handler(handler):<N>    """<N>    Install application-specific HDF5 image handler.<N><N>    :param handler: Handler object.<N>    """<N>    global _handler<N>    _handler = handler<N><N><N># --------------------------------------------------------------------<N># Image adapter<N><N>
<N>def _accept(prefix):<N>    return prefix[:8] == b"\x89HDF\r\n\x1a\n"<N><N><N>class HDF5StubImageFile(ImageFile.StubImageFile):<N><N>    format = "HDF5"<N>    format_description = "HDF5"<N><N>    def _open(self):<N><N>        offset = self.fp.tell()<N><N>
        if not _accept(self.fp.read(8)):<N>            raise SyntaxError("Not an HDF file")<N><N>        self.fp.seek(offset)<N><N>        # make something up<N>        self.mode = "F"<N>        self._size = 1, 1<N><N>        loader = self._load()<N>        if loader:<N>            loader.open(self)<N><N>
    def _load(self):<N>        return _handler<N><N><N>def _save(im, fp, filename):<N>    if _handler is None or not hasattr("_handler", "save"):<N>        raise OSError("HDF5 save handler not installed")<N>    _handler.save(im, fp, filename)<N><N><N># --------------------------------------------------------------------<N># Registry<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># standard channel operations<N>#<N># History:<N># 1996-03-24 fl   Created<N># 1996-08-13 fl   Added logical operations (for "1" images)<N># 2000-10-12 fl   Added offset method (from Image.py)<N>#<N># Copyright (c) 1997-2000 by Secret Labs AB<N># Copyright (c) 1996-2000 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
from . import Image<N><N><N>def constant(image, value):<N>    """Fill a channel with a given grey level.<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    return Image.new("L", image.size, value)<N><N><N>def duplicate(image):<N>    """Copy a channel. Alias for :py:meth:`PIL.Image.Image.copy`.<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    return image.copy()<N><N><N>def invert(image):<N>    """<N>    Invert an image (channel).<N><N>    .. code-block:: python<N><N>        out = MAX - image<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>
    image.load()<N>    return image._new(image.im.chop_invert())<N><N><N>def lighter(image1, image2):<N>    """<N>    Compares the two images, pixel by pixel, and returns a new image containing<N>    the lighter values.<N><N>    .. code-block:: python<N><N>
        out = max(image1, image2)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_lighter(image2.im))<N><N><N>def darker(image1, image2):<N>    """<N>    Compares the two images, pixel by pixel, and returns a new image containing<N>    the darker values.<N><N>
    .. code-block:: python<N><N>        out = min(image1, image2)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_darker(image2.im))<N><N><N>def difference(image1, image2):<N>    """<N>    Returns the absolute value of the pixel-by-pixel difference between the two<N>    images.<N><N>
    .. code-block:: python<N><N>        out = abs(image1 - image2)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_difference(image2.im))<N><N><N>def multiply(image1, image2):<N>    """<N>    Superimposes two images on top of each other.<N><N>
    If you multiply an image with a solid black image, the result is black. If<N>    you multiply with a solid white image, the image is unaffected.<N><N>    .. code-block:: python<N><N>        out = image1 * image2 / MAX<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>
    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_multiply(image2.im))<N><N><N>def screen(image1, image2):<N>    """<N>    Superimposes two inverted images on top of each other.<N><N>    .. code-block:: python<N><N>        out = MAX - ((MAX - image1) * (MAX - image2) / MAX)<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_screen(image2.im))<N><N><N>def soft_light(image1, image2):<N>    """<N>    Superimposes two images on top of each other using the Soft Light algorithm<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_soft_light(image2.im))<N><N><N>def hard_light(image1, image2):<N>    """<N>    Superimposes two images on top of each other using the Hard Light algorithm<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_hard_light(image2.im))<N><N><N>def overlay(image1, image2):<N>    """<N>    Superimposes two images on top of each other using the Overlay algorithm<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_overlay(image2.im))<N><N><N>def add(image1, image2, scale=1.0, offset=0):<N>    """<N>    Adds two images, dividing the result by scale and adding the<N>    offset. If omitted, scale defaults to 1.0, and offset to 0.0.<N><N>
    .. code-block:: python<N><N>        out = ((image1 + image2) / scale + offset)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_add(image2.im, scale, offset))<N><N>
<N>def subtract(image1, image2, scale=1.0, offset=0):<N>    """<N>    Subtracts two images, dividing the result by scale and adding the offset.<N>    If omitted, scale defaults to 1.0, and offset to 0.0.<N><N>    .. code-block:: python<N><N>        out = ((image1 - image2) / scale + offset)<N><N>
    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_subtract(image2.im, scale, offset))<N><N><N>def add_modulo(image1, image2):<N>    """Add two images, without clipping the result.<N><N>
    .. code-block:: python<N><N>        out = ((image1 + image2) % MAX)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_add_modulo(image2.im))<N><N><N>def subtract_modulo(image1, image2):<N>    """Subtract two images, without clipping the result.<N><N>
    .. code-block:: python<N><N>        out = ((image1 - image2) % MAX)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_subtract_modulo(image2.im))<N><N><N>def logical_and(image1, image2):<N>    """Logical AND between two images.<N><N>
    Both of the images must have mode "1". If you would like to perform a<N>    logical AND on an image with a mode other than "1", try<N>    :py:meth:`~PIL.ImageChops.multiply` instead, using a black-and-white mask<N>    as the second image.<N><N>    .. code-block:: python<N><N>
        out = ((image1 and image2) % MAX)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_and(image2.im))<N><N><N>def logical_or(image1, image2):<N>    """Logical OR between two images.<N><N>
    Both of the images must have mode "1".<N><N>    .. code-block:: python<N><N>        out = ((image1 or image2) % MAX)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_or(image2.im))<N><N>
<N>def logical_xor(image1, image2):<N>    """Logical XOR between two images.<N><N>    Both of the images must have mode "1".<N><N>    .. code-block:: python<N><N>        out = ((bool(image1) != bool(image2)) % MAX)<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>
    image1.load()<N>    image2.load()<N>    return image1._new(image1.im.chop_xor(image2.im))<N><N><N>def blend(image1, image2, alpha):<N>    """Blend images using constant transparency weight. Alias for<N>    :py:func:`PIL.Image.blend`.<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>
    return Image.blend(image1, image2, alpha)<N><N><N>def composite(image1, image2, mask):<N>    """Create composite using transparency mask. Alias for<N>    :py:func:`PIL.Image.composite`.<N><N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>    return Image.composite(image1, image2, mask)<N><N>
<N>def offset(image, xoffset, yoffset=None):<N>    """Returns a copy of the image where data has been offset by the given<N>    distances. Data wraps around the edges. If ``yoffset`` is omitted, it<N>    is assumed to be equal to ``xoffset``.<N><N>    :param xoffset: The horizontal distance.<N>    :param yoffset: The vertical distance.  If omitted, both<N>        distances are set to the same value.<N>    :rtype: :py:class:`~PIL.Image.Image`<N>    """<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Basic McIdas support for PIL<N>#<N># History:<N># 1997-05-05 fl  Created (8-bit images only)<N># 2009-03-08 fl  Added 16/32-bit support.<N>#<N># Thanks to Richard Jones and Craig Swank for specs and samples.<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1997.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import struct<N><N>from . import Image, ImageFile<N><N><N>def _accept(s):<N>    return s[:8] == b"\x00\x00\x00\x00\x00\x00\x00\x04"<N><N><N>##<N># Image plugin for McIdas area images.<N><N><N>class McIdasImageFile(ImageFile.ImageFile):<N><N>    format = "MCIDAS"<N>    format_description = "McIdas area file"<N><N>
    def _open(self):<N><N>        # parse area file directory<N>        s = self.fp.read(256)<N>        if not _accept(s) or len(s) != 256:<N>            raise SyntaxError("not an McIdas area file")<N><N>        self.area_descriptor_raw = s<N>        self.area_descriptor = w = [0] + list(struct.unpack("!64i", s))<N><N>
        # get mode<N>        if w[11] == 1:<N>            mode = rawmode = "L"<N>        elif w[11] == 2:<N>            # FIXME: add memory map support<N>            mode = "I"<N>            rawmode = "I;16B"<N>        elif w[11] == 4:<N>            # FIXME: add memory map support<N>            mode = "I"<N>            rawmode = "I;32B"<N>        else:<N>            raise SyntaxError("unsupported McIdas format")<N><N>
        self.mode = mode<N>        self._size = w[10], w[9]<N><N>        offset = w[34] + w[15]<N>        stride = w[15] + w[10] * w[11] * w[14]<N><N>        self.tile = [("raw", (0, 0) + self.size, offset, (rawmode, stride, 1))]<N><N><N># --------------------------------------------------------------------<N># registry<N><N>
"""Pillow (Fork of the Python Imaging Library)<N><N>Pillow is the friendly PIL fork by Alex Clark and Contributors.<N>    https://github.com/python-pillow/Pillow/<N><N>Pillow is forked from PIL 1.1.7.<N><N>PIL is the Python Imaging Library by Fredrik Lundh and Contributors.<N>Copyright (c) 1999 by Secret Labs AB.<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># GD file handling<N>#<N># History:<N># 1996-04-12 fl   Created<N>#<N># Copyright (c) 1997 by Secret Labs AB.<N># Copyright (c) 1996 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>"""<N>.. note::<N>    This format cannot be automatically recognized, so the<N>    class is not registered for use with :py:func:`PIL.Image.open()`.  To open a<N>    gd file, use the :py:func:`PIL.GdImageFile.open()` function instead.<N><N>.. warning::<N>    THE GD FORMAT IS NOT DESIGNED FOR DATA INTERCHANGE.  This<N>    implementation is provided for convenience and demonstrational<N>    purposes only.<N>"""<N><N>
<N>from . import ImageFile, ImagePalette, UnidentifiedImageError<N>from ._binary import i16be as i16<N>from ._binary import i32be as i32<N><N><N>class GdImageFile(ImageFile.ImageFile):<N>    """<N>    Image plugin for the GD uncompressed format.  Note that this format<N>    is not supported by the standard :py:func:`PIL.Image.open()` function.  To use<N>    this plugin, you have to import the :py:mod:`PIL.GdImageFile` module and<N>    use the :py:func:`PIL.GdImageFile.open()` function.<N>    """<N><N>
    format = "GD"<N>    format_description = "GD uncompressed images"<N><N>    def _open(self):<N><N>        # Header<N>        s = self.fp.read(1037)<N><N>        if not i16(s) in [65534, 65535]:<N>            raise SyntaxError("Not a valid GD 2.x .gd file")<N><N>
        self.mode = "L"  # FIXME: "P"<N>        self._size = i16(s, 2), i16(s, 4)<N><N>        trueColor = s[6]<N>        trueColorOffset = 2 if trueColor else 0<N><N>        # transparency index<N>        tindex = i32(s, 7 + trueColorOffset)<N>        if tindex < 256:<N>            self.info["transparency"] = tindex<N><N>
        self.palette = ImagePalette.raw(<N>            "XBGR", s[7 + trueColorOffset + 4 : 7 + trueColorOffset + 4 + 256 * 4]<N>        )<N><N>        self.tile = [<N>            ("raw", (0, 0) + self.size, 7 + trueColorOffset + 4 + 256 * 4, ("L", 0, 1))<N>        ]<N><N>
<N>def open(fp, mode="r"):<N>    """<N>    Load texture from a GD image file.<N><N>    :param filename: GD file name, or an opened file handle.<N>    :param mode: Optional mode.  In this version, if the mode argument<N>        is given, it must be "r".<N>    :returns: An image instance.<N>    :raises OSError: If the image could not be read.<N>    """<N>    if mode != "r":<N>        raise ValueError("bad mode")<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># XV Thumbnail file handler by Charles E. "Gene" Cash<N># (gcash@magicnet.net)<N>#<N># see xvcolor.c and xvbrowse.c in the sources to John Bradley's XV,<N># available from ftp://ftp.cis.upenn.edu/pub/xv/<N>#<N># history:<N># 98-08-15 cec  created (b/w only)<N># 98-12-09 cec  added color palette<N># 98-12-28 fl   added to PIL (with only a few very minor modifications)<N>#<N># To do:<N># FIXME: make save work (this requires quantization support)<N>#<N><N>
from . import Image, ImageFile, ImagePalette<N>from ._binary import o8<N><N>_MAGIC = b"P7 332"<N><N># standard color palette for thumbnails (RGB332)<N>PALETTE = b""<N>for r in range(8):<N>    for g in range(8):<N>        for b in range(4):<N>            PALETTE = PALETTE + (<N>                o8((r * 255) // 7) + o8((g * 255) // 7) + o8((b * 255) // 3)<N>            )<N><N>
<N>def _accept(prefix):<N>    return prefix[:6] == _MAGIC<N><N><N>##<N># Image plugin for XV thumbnail images.<N><N><N>class XVThumbImageFile(ImageFile.ImageFile):<N><N>    format = "XVThumb"<N>    format_description = "XV thumbnail image"<N><N>    def _open(self):<N><N>
        # check magic<N>        if not _accept(self.fp.read(6)):<N>            raise SyntaxError("not an XV thumbnail file")<N><N>        # Skip to beginning of next line<N>        self.fp.readline()<N><N>        # skip info comments<N>        while True:<N>            s = self.fp.readline()<N>            if not s:<N>                raise SyntaxError("Unexpected EOF reading XV thumbnail file")<N>            if s[0] != 35:  # ie. when not a comment: '#'<N>                break<N><N>
        # parse header line (already read)<N>        s = s.strip().split()<N><N>        self.mode = "P"<N>        self._size = int(s[0]), int(s[1])<N><N>        self.palette = ImagePalette.raw("RGB", PALETTE)<N><N>        self.tile = [("raw", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))]<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># screen grabber<N>#<N># History:<N># 2001-04-26 fl  created<N># 2001-09-17 fl  use builtin driver, if present<N># 2002-11-19 fl  added grabclipboard support<N>#<N># Copyright (c) 2001-2002 by Secret Labs AB<N># Copyright (c) 2001-2002 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
"""<N>A Pillow loader for .dds files (S3TC-compressed aka DXTC)<N>Jerome Leclanche <jerome@leclan.ch><N><N>Documentation:<N>  https://web.archive.org/web/20170802060935/http://oss.sgi.com/projects/ogl-sample/registry/EXT/texture_compression_s3tc.txt<N><N>The contents of this file are hereby released in the public domain (CC0)<N>Full text of the CC0 license:<N>  https://creativecommons.org/publicdomain/zero/1.0/<N>"""<N><N>
import struct<N>from io import BytesIO<N><N>from . import Image, ImageFile<N><N># Magic ("DDS ")<N>DDS_MAGIC = 0x20534444<N><N># DDS flags<N>DDSD_CAPS = 0x1<N>DDSD_HEIGHT = 0x2<N>DDSD_WIDTH = 0x4<N>DDSD_PITCH = 0x8<N>DDSD_PIXELFORMAT = 0x1000<N>DDSD_MIPMAPCOUNT = 0x20000<N>DDSD_LINEARSIZE = 0x80000<N>DDSD_DEPTH = 0x800000<N><N>
# DDS caps<N>DDSCAPS_COMPLEX = 0x8<N>DDSCAPS_TEXTURE = 0x1000<N>DDSCAPS_MIPMAP = 0x400000<N><N>DDSCAPS2_CUBEMAP = 0x200<N>DDSCAPS2_CUBEMAP_POSITIVEX = 0x400<N>DDSCAPS2_CUBEMAP_NEGATIVEX = 0x800<N>DDSCAPS2_CUBEMAP_POSITIVEY = 0x1000<N>DDSCAPS2_CUBEMAP_NEGATIVEY = 0x2000<N>DDSCAPS2_CUBEMAP_POSITIVEZ = 0x4000<N>DDSCAPS2_CUBEMAP_NEGATIVEZ = 0x8000<N>DDSCAPS2_VOLUME = 0x200000<N><N>
# Pixel Format<N>DDPF_ALPHAPIXELS = 0x1<N>DDPF_ALPHA = 0x2<N>DDPF_FOURCC = 0x4<N>DDPF_PALETTEINDEXED8 = 0x20<N>DDPF_RGB = 0x40<N>DDPF_LUMINANCE = 0x20000<N><N><N># dds.h<N><N>DDS_FOURCC = DDPF_FOURCC<N>DDS_RGB = DDPF_RGB<N>DDS_RGBA = DDPF_RGB | DDPF_ALPHAPIXELS<N>DDS_LUMINANCE = DDPF_LUMINANCE<N>DDS_LUMINANCEA = DDPF_LUMINANCE | DDPF_ALPHAPIXELS<N>DDS_ALPHA = DDPF_ALPHA<N>DDS_PAL8 = DDPF_PALETTEINDEXED8<N><N>
DDS_HEADER_FLAGS_TEXTURE = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH | DDSD_PIXELFORMAT<N>DDS_HEADER_FLAGS_MIPMAP = DDSD_MIPMAPCOUNT<N>DDS_HEADER_FLAGS_VOLUME = DDSD_DEPTH<N>DDS_HEADER_FLAGS_PITCH = DDSD_PITCH<N>DDS_HEADER_FLAGS_LINEARSIZE = DDSD_LINEARSIZE<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Binary input/output support routines.<N>#<N># Copyright (c) 1997-2003 by Secret Labs AB<N># Copyright (c) 1995-2003 by Fredrik Lundh<N># Copyright (c) 2012 by Brian Crowell<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>"""Binary input/output support routines."""<N><N><N>from struct import pack, unpack_from<N><N><N>def i8(c):<N>    return c if c.__class__ is int else c[0]<N><N><N>def o8(i):<N>    return bytes((i & 255,))<N><N><N># Input, le = little endian, be = big endian<N>def i16le(c, o=0):<N>    """<N>    Converts a 2-bytes (16 bits) string to an unsigned integer.<N><N>
    :param c: string containing bytes to convert<N>    :param o: offset of bytes to convert in string<N>    """<N>    return unpack_from("<H", c, o)[0]<N><N><N>def si16le(c, o=0):<N>    """<N>    Converts a 2-bytes (16 bits) string to a signed integer.<N><N>
    :param c: string containing bytes to convert<N>    :param o: offset of bytes to convert in string<N>    """<N>    return unpack_from("<h", c, o)[0]<N><N><N>def i32le(c, o=0):<N>    """<N>    Converts a 4-bytes (32 bits) string to an unsigned integer.<N><N>
    :param c: string containing bytes to convert<N>    :param o: offset of bytes to convert in string<N>    """<N>    return unpack_from("<I", c, o)[0]<N><N><N>def si32le(c, o=0):<N>    """<N>    Converts a 4-bytes (32 bits) string to a signed integer.<N><N>
    :param c: string containing bytes to convert<N>    :param o: offset of bytes to convert in string<N>    """<N>    return unpack_from("<i", c, o)[0]<N><N><N>def i16be(c, o=0):<N>    return unpack_from(">H", c, o)[0]<N><N><N>def i32be(c, o=0):<N>    return unpack_from(">I", c, o)[0]<N><N>
#<N># Python Imaging Library<N># $Id$<N>#<N># stuff to read (and render) GIMP gradient files<N>#<N># History:<N>#       97-08-23 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1997.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
"""<N>Stuff to translate curve segments to palette values (derived from<N>the corresponding code in GIMP, written by Federico Mena Quintero.<N>See the GIMP distribution for more information.)<N>"""<N><N><N>from math import log, pi, sin, sqrt<N><N>from ._binary import o8<N><N>
EPSILON = 1e-10<N>""""""  # Enable auto-doc for data member<N><N><N>def linear(middle, pos):<N>    if pos <= middle:<N>        if middle < EPSILON:<N>            return 0.0<N>        else:<N>            return 0.5 * pos / middle<N>    else:<N>        pos = pos - middle<N>        middle = 1.0 - middle<N>        if middle < EPSILON:<N>            return 1.0<N>        else:<N>            return 0.5 + 0.5 * pos / middle<N><N>
<N>def curved(middle, pos):<N>    return pos ** (log(0.5) / log(max(middle, EPSILON)))<N><N><N>def sine(middle, pos):<N>    return (sin((-pi / 2.0) + pi * linear(middle, pos)) + 1.0) / 2.0<N><N><N>def sphere_increasing(middle, pos):<N>    return sqrt(1.0 - (linear(middle, pos) - 1.0) ** 2)<N><N>
<N>def sphere_decreasing(middle, pos):<N>    return 1.0 - sqrt(1.0 - linear(middle, pos) ** 2)<N><N><N>SEGMENTS = [linear, curved, sine, sphere_increasing, sphere_decreasing]<N>""""""  # Enable auto-doc for data member<N><N><N>class GradientFile:<N><N>    gradient = None<N><N>
    def getpalette(self, entries=256):<N><N>        palette = []<N><N>        ix = 0<N>        x0, x1, xm, rgb0, rgb1, segment = self.gradient[ix]<N><N>        for i in range(entries):<N><N>            x = i / (entries - 1)<N><N>            while x1 < x:<N>                ix += 1<N>                x0, x1, xm, rgb0, rgb1, segment = self.gradient[ix]<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># IPTC/NAA file handling<N>#<N># history:<N># 1995-10-01 fl   Created<N># 1998-03-09 fl   Cleaned up and added to PIL<N># 2002-06-18 fl   Added getiptcinfo helper<N>#<N># Copyright (c) Secret Labs AB 1997-2002.<N># Copyright (c) Fredrik Lundh 1995.<N>#<N># See the README file for information on usage and redistribution.<N>#<N>import os<N>import tempfile<N><N>
from . import Image, ImageFile<N>from ._binary import i8<N>from ._binary import i16be as i16<N>from ._binary import i32be as i32<N>from ._binary import o8<N><N>COMPRESSION = {1: "raw", 5: "jpeg"}<N><N>PAD = o8(0) * 4<N><N><N>#<N># Helpers<N><N><N>def i(c):<N>    return i32((PAD + c)[-4:])<N><N>
<N>def dump(c):<N>    for i in c:<N>        print("%02x" % i8(i), end=" ")<N>    print()<N><N><N>##<N># Image plugin for IPTC/NAA datastreams.  To read IPTC/NAA fields<N># from TIFF and JPEG files, use the <b>getiptcinfo</b> function.<N><N><N>class IptcImageFile(ImageFile.ImageFile):<N><N>
    format = "IPTC"<N>    format_description = "IPTC/NAA"<N><N>    def getint(self, key):<N>        return i(self.info[key])<N><N>    def field(self):<N>        #<N>        # get a IPTC field header<N>        s = self.fp.read(5)<N>        if not len(s):<N>            return None, 0<N><N>
        tag = s[1], s[2]<N><N>        # syntax<N>        if s[0] != 0x1C or tag[0] < 1 or tag[0] > 9:<N>            raise SyntaxError("invalid IPTC/NAA file")<N><N>        # field size<N>        size = s[3]<N>        if size > 132:<N>            raise OSError("illegal field length in IPTC/NAA file")<N>        elif size == 128:<N>            size = 0<N>        elif size > 128:<N>            size = i(self.fp.read(size - 128))<N>        else:<N>            size = i16(s, 3)<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># FLI/FLC file handling.<N>#<N># History:<N>#       95-09-01 fl     Created<N>#       97-01-03 fl     Fixed parser, setup decoder tile<N>#       98-07-15 fl     Renamed offset attribute to avoid name clash<N>#<N># Copyright (c) Secret Labs AB 1997-98.<N># Copyright (c) Fredrik Lundh 1995-97.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>from . import Image, ImageFile, ImagePalette<N>from ._binary import i16le as i16<N>from ._binary import i32le as i32<N>from ._binary import o8<N><N>#<N># decoder<N><N><N>def _accept(prefix):<N>    return len(prefix) >= 6 and i16(prefix, 4) in [0xAF11, 0xAF12]<N><N>
<N>##<N># Image plugin for the FLI/FLC animation format.  Use the <b>seek</b><N># method to load individual frames.<N><N><N>class FliImageFile(ImageFile.ImageFile):<N><N>    format = "FLI"<N>    format_description = "Autodesk FLI/FLC Animation"<N>    _close_exclusive_fp_after_loading = False<N><N>
    def _open(self):<N><N>        # HEAD<N>        s = self.fp.read(128)<N>        if not (<N>            _accept(s)<N>            and i16(s, 14) in [0, 3]  # flags<N>            and s[20:22] == b"\x00\x00"  # reserved<N>        ):<N>            raise SyntaxError("not an FLI/FLC file")<N><N>
        # frames<N>        self.n_frames = i16(s, 6)<N>        self.is_animated = self.n_frames > 1<N><N>        # image characteristics<N>        self.mode = "P"<N>        self._size = i16(s, 8), i16(s, 10)<N><N>        # animation speed<N>        duration = i32(s, 16)<N>        magic = i16(s, 4)<N>        if magic == 0xAF11:<N>            duration = (duration * 1000) // 70<N>        self.info["duration"] = duration<N><N>
        # look for palette<N>        palette = [(a, a, a) for a in range(256)]<N><N>        s = self.fp.read(16)<N><N>        self.__offset = 128<N><N>        if i16(s, 4) == 0xF100:<N>            # prefix chunk; ignore it<N>            self.__offset = self.__offset + i32(s)<N>            s = self.fp.read(16)<N><N>
        if i16(s, 4) == 0xF1FA:<N>            # look for palette chunk<N>            s = self.fp.read(6)<N>            if i16(s, 4) == 11:<N>                self._palette(palette, 2)<N>            elif i16(s, 4) == 4:<N>                self._palette(palette, 0)<N><N>
        palette = [o8(r) + o8(g) + o8(b) for (r, g, b) in palette]<N>        self.palette = ImagePalette.raw("RGB", b"".join(palette))<N><N>        # set things up to decode first frame<N>        self.__frame = -1<N>        self.__fp = self.fp<N>        self.__rewind = self.fp.tell()<N>        self.seek(0)<N><N>
#<N># THIS IS WORK IN PROGRESS<N>#<N># The Python Imaging Library<N># $Id$<N>#<N># portable compiled font file parser<N>#<N># history:<N># 1997-08-19 fl   created<N># 2003-09-13 fl   fixed loading of unicode fonts<N>#<N># Copyright (c) 1997-2003 by Secret Labs AB.<N># Copyright (c) 1997-2003 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import io<N><N>from . import FontFile, Image<N>from ._binary import i8<N>from ._binary import i16be as b16<N>from ._binary import i16le as l16<N>from ._binary import i32be as b32<N>from ._binary import i32le as l32<N><N># --------------------------------------------------------------------<N># declarations<N><N>
PCF_MAGIC = 0x70636601  # "\x01fcp"<N><N>PCF_PROPERTIES = 1 << 0<N>PCF_ACCELERATORS = 1 << 1<N>PCF_METRICS = 1 << 2<N>PCF_BITMAPS = 1 << 3<N>PCF_INK_METRICS = 1 << 4<N>PCF_BDF_ENCODINGS = 1 << 5<N>PCF_SWIDTHS = 1 << 6<N>PCF_GLYPH_NAMES = 1 << 7<N>PCF_BDF_ACCELERATORS = 1 << 8<N><N>
BYTES_PER_ROW = [<N>    lambda bits: ((bits + 7) >> 3),<N>    lambda bits: ((bits + 15) >> 3) & ~1,<N>    lambda bits: ((bits + 31) >> 3) & ~3,<N>    lambda bits: ((bits + 63) >> 3) & ~7,<N>]<N><N><N>def sz(s, o):<N>    return s[o : s.index(b"\0", o)]<N><N>
<N>class PcfFontFile(FontFile.FontFile):<N>    """Font file plugin for the X11 PCF format."""<N><N>    name = "name"<N><N>    def __init__(self, fp, charset_encoding="iso8859-1"):<N><N>        self.charset_encoding = charset_encoding<N><N>        magic = l32(fp.read(4))<N>        if magic != PCF_MAGIC:<N>            raise SyntaxError("not a PCF file")<N><N>
        super().__init__()<N><N>        count = l32(fp.read(4))<N>        self.toc = {}<N>        for i in range(count):<N>            type = l32(fp.read(4))<N>            self.toc[type] = l32(fp.read(4)), l32(fp.read(4)), l32(fp.read(4))<N><N>        self.fp = fp<N><N>
        self.info = self._load_properties()<N><N>        metrics = self._load_metrics()<N>        bitmaps = self._load_bitmaps(metrics)<N>        encoding = self._load_encoding()<N><N>        #<N>        # create glyph structure<N><N>        for ch in range(256):<N>            ix = encoding[ch]<N>            if ix is not None:<N>                x, y, l, r, w, a, d, f = metrics[ix]<N>                glyph = (w, 0), (l, d - y, x + l, d), (0, 0, x, y), bitmaps[ix]<N>                self.glyph[ch] = glyph<N><N>
    def _getformat(self, tag):<N><N>        format, size, offset = self.toc[tag]<N><N>        fp = self.fp<N>        fp.seek(offset)<N><N>        format = l32(fp.read(4))<N><N>        if format & 4:<N>            i16, i32 = b16, b32<N>        else:<N>            i16, i32 = l16, l32<N><N>
        return fp, format, i16, i32<N><N>    def _load_properties(self):<N><N>        #<N>        # font properties<N><N>        properties = {}<N><N>        fp, format, i16, i32 = self._getformat(PCF_PROPERTIES)<N><N>        nprops = i32(fp.read(4))<N><N>
        # read property description<N>        p = []<N>        for i in range(nprops):<N>            p.append((i32(fp.read(4)), i8(fp.read(1)), i32(fp.read(4))))<N>        if nprops & 3:<N>            fp.seek(4 - (nprops & 3), io.SEEK_CUR)  # pad<N><N>        data = fp.read(i32(fp.read(4)))<N><N>
        for k, s, v in p:<N>            k = sz(data, k)<N>            if s:<N>                v = sz(data, v)<N>            properties[k] = v<N><N>        return properties<N><N>    def _load_metrics(self):<N><N>        #<N>        # font metrics<N><N>        metrics = []<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># PDF (Acrobat) file handling<N>#<N># History:<N># 1996-07-16 fl   Created<N># 1997-01-18 fl   Fixed header<N># 2004-02-21 fl   Fixes for 1/L/CMYK images, etc.<N># 2004-02-24 fl   Fixes for 1 and P images.<N>#<N># Copyright (c) 1997-2004 by Secret Labs AB.  All rights reserved.<N># Copyright (c) 1996-1997 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
##<N># Image plugin for PDF images (output only).<N>##<N><N>import io<N>import os<N>import time<N><N>from . import Image, ImageFile, ImageSequence, PdfParser, __version__<N><N>#<N># --------------------------------------------------------------------<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Sun image file handling<N>#<N># History:<N># 1995-09-10 fl   Created<N># 1996-05-28 fl   Fixed 32-bit alignment<N># 1998-12-29 fl   Import ImagePalette module<N># 2001-12-18 fl   Fixed palette loading (from Jean-Claude Rimbault)<N>#<N># Copyright (c) 1997-2001 by Secret Labs AB<N># Copyright (c) 1995-1996 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>from . import Image, ImageFile, ImagePalette<N>from ._binary import i32be as i32<N><N><N>def _accept(prefix):<N>    return len(prefix) >= 4 and i32(prefix) == 0x59A66A95<N><N><N>##<N># Image plugin for Sun raster files.<N><N><N>class SunImageFile(ImageFile.ImageFile):<N><N>
"""<N>JPEG quality settings equivalent to the Photoshop settings.<N>Can be used when saving JPEG files.<N><N>The following presets are available by default:<N>``web_low``, ``web_medium``, ``web_high``, ``web_very_high``, ``web_maximum``,<N>``low``, ``medium``, ``high``, ``maximum``.<N>More presets can be added to the :py:data:`presets` dict if needed.<N><N>
To apply the preset, specify::<N><N>  quality="preset_name"<N><N>To apply only the quantization table::<N><N>  qtables="preset_name"<N><N>To apply only the subsampling setting::<N><N>  subsampling="preset_name"<N><N>Example::<N><N>  im.save("image_name.jpg", quality="web_high")<N><N>
Subsampling<N>-----------<N><N>Subsampling is the practice of encoding images by implementing less resolution<N>for chroma information than for luma information.<N>(ref.: https://en.wikipedia.org/wiki/Chroma_subsampling)<N><N>Possible subsampling values are 0, 1 and 2 that correspond to 4:4:4, 4:2:2 and<N>4:2:0.<N><N>
You can get the subsampling of a JPEG with the<N>:func:`.JpegImagePlugin.get_sampling` function.<N><N>In JPEG compressed data a JPEG marker is used instead of an EXIFÂ tag.<N>(ref.: https://www.exiv2.org/tags.html)<N><N><N>Quantization tables<N>-------------------<N><N>
They are values use by the DCT (Discrete cosine transform) to remove<N>*unnecessary* information from the image (the lossy part of the compression).<N>(ref.: https://en.wikipedia.org/wiki/Quantization_matrix#Quantization_matrices,<N>https://en.wikipedia.org/wiki/JPEG#Quantization)<N><N>
You can get the quantization tables of a JPEG with::<N><N>  im.quantization<N><N>This will return a dict with a number of arrays. You can pass this dict<N>directly as the qtables argument when saving a JPEG.<N><N>The tables format between im.quantization and quantization in presets differ in<N>3 ways:<N><N>
1. The base container of the preset is a list with sublists instead of dict.<N>   dict[0] -> list[0], dict[1] -> list[1], ...<N>2. Each table in a preset is a list instead of an array.<N>3. The zigzag order is remove in the preset (needed by libjpeg >= 6a).<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># read files from within a tar file<N>#<N># History:<N># 95-06-18 fl   Created<N># 96-05-28 fl   Open files in binary mode<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1995-96.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import io<N><N>from . import ContainerIO<N><N><N>class TarIO(ContainerIO.ContainerIO):<N>    """A file object that provides read access to a given member of a TAR file."""<N><N>    def __init__(self, tarfile, file):<N>        """<N>        Create file object.<N><N>
        :param tarfile: Name of TAR file.<N>        :param file: Name of member file.<N>        """<N>        self.fh = open(tarfile, "rb")<N><N>        while True:<N><N>            s = self.fh.read(512)<N>            if len(s) != 512:<N>                raise OSError("unexpected end of tar file")<N><N>
            name = s[:100].decode("utf-8")<N>            i = name.find("\0")<N>            if i == 0:<N>                raise OSError("cannot find subfile")<N>            if i > 0:<N>                name = name[:i]<N><N>            size = int(s[124:135], 8)<N><N>
            if file == name:<N>                break<N><N>            self.fh.seek((size + 511) & (~511), io.SEEK_CUR)<N><N>        # Open region<N>        super().__init__(self.fh, self.fh.tell(), size)<N><N>    # Context manager support<N>    def __enter__(self):<N>        return self<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Microsoft Image Composer support for PIL<N>#<N># Notes:<N>#       uses TiffImagePlugin.py to read the actual image streams<N>#<N># History:<N>#       97-01-20 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1997.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import olefile<N><N>from . import Image, TiffImagePlugin<N><N>#<N># --------------------------------------------------------------------<N><N><N>def _accept(prefix):<N>    return prefix[:8] == olefile.MAGIC<N><N><N>##<N># Image plugin for Microsoft's Image Composer file format.<N><N>
<N>class MicImageFile(TiffImagePlugin.TiffImageFile):<N><N>    format = "MIC"<N>    format_description = "Microsoft Image Composer"<N>    _close_exclusive_fp_after_loading = False<N><N>    def _open(self):<N><N>        # read the OLE directory and see if this is a likely<N>        # to be a Microsoft Image Composer file<N><N>
        try:<N>            self.ole = olefile.OleFileIO(self.fp)<N>        except OSError as e:<N>            raise SyntaxError("not an MIC file; invalid OLE file") from e<N><N>        # find ACI subfiles with Image members (maybe not the<N>        # best way to identify MIC files, but what the... ;-)<N><N>
        self.images = []<N>        for path in self.ole.listdir():<N>            if path[1:] and path[0][-4:] == ".ACI" and path[1] == "Image":<N>                self.images.append(path)<N><N>        # if we didn't find any images, this is probably not<N>        # an MIC file.<N>        if not self.images:<N>            raise SyntaxError("not an MIC file; no image entries")<N><N>
        self.__fp = self.fp<N>        self.frame = None<N>        self._n_frames = len(self.images)<N>        self.is_animated = self._n_frames > 1<N><N>        if len(self.images) > 1:<N>            self._category = Image.CONTAINER<N><N>        self.seek(0)<N><N>
    def seek(self, frame):<N>        if not self._seek_check(frame):<N>            return<N>        try:<N>            filename = self.images[frame]<N>        except IndexError as e:<N>            raise EOFError("no such frame") from e<N><N>        self.fp = self.ole.openstream(filename)<N><N>
        TiffImagePlugin.TiffImageFile._open(self)<N><N>        self.frame = frame<N><N>    def tell(self):<N>        return self.frame<N><N>    def _close__fp(self):<N>        try:<N>            if self.__fp != self.fp:<N>                self.__fp.close()<N>        except AttributeError:<N>            pass<N>        finally:<N>            self.__fp = None<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Windows Cursor support for PIL<N>#<N># notes:<N>#       uses BmpImagePlugin.py to read the bitmap data.<N>#<N># history:<N>#       96-05-27 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1996.<N>#<N># See the README file for information on usage and redistribution.<N>#<N>from . import BmpImagePlugin, Image<N>from ._binary import i16le as i16<N>from ._binary import i32le as i32<N><N>
#<N># --------------------------------------------------------------------<N><N><N>def _accept(prefix):<N>    return prefix[:4] == b"\0\0\2\0"<N><N><N>##<N># Image plugin for Windows Cursor files.<N><N><N>class CurImageFile(BmpImagePlugin.BmpImageFile):<N><N>
    format = "CUR"<N>    format_description = "Windows Cursor"<N><N>    def _open(self):<N><N>        offset = self.fp.tell()<N><N>        # check magic<N>        s = self.fp.read(6)<N>        if not _accept(s):<N>            raise SyntaxError("not a CUR file")<N><N>
        # pick the largest cursor in the file<N>        m = b""<N>        for i in range(i16(s, 4)):<N>            s = self.fp.read(16)<N>            if not m:<N>                m = s<N>            elif s[0] > m[0] and s[1] > m[1]:<N>                m = s<N>        if not m:<N>            raise TypeError("No cursors were found")<N><N>
        # load as bitmap<N>        self._bitmap(i32(m, 12) + offset)<N><N>        # patch up the bitmap height<N>        self._size = self.size[0], self.size[1] // 2<N>        d, e, o, a = self.tile[0]<N>        self.tile[0] = d, (0, 0) + self.size, o, a<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># WAL file handling<N>#<N># History:<N># 2003-04-23 fl   created<N>#<N># Copyright (c) 2003 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>"""<N>This reader is based on the specification available from:<N>https://www.flipcode.com/archives/Quake_2_BSP_File_Format.shtml<N>and has been tested with a few sample files found using google.<N><N>
.. note::<N>    This format cannot be automatically recognized, so the reader<N>    is not registered for use with :py:func:`PIL.Image.open()`.<N>    To open a WAL file, use the :py:func:`PIL.WalImageFile.open()` function instead.<N>"""<N><N>import builtins<N><N>
from . import Image<N>from ._binary import i32le as i32<N><N><N>def open(filename):<N>    """<N>    Load texture from a Quake2 WAL texture file.<N><N>    By default, a Quake2 standard palette is attached to the texture.<N>    To override the palette, use the :py:func:`PIL.Image.Image.putpalette()` method.<N><N>
    :param filename: WAL file name, or an opened file handle.<N>    :returns: An image instance.<N>    """<N>    # FIXME: modify to return a WalImageFile instance instead of<N>    # plain Image object ?<N><N>    def imopen(fp):<N>        # read header fields<N>        header = fp.read(32 + 24 + 32 + 12)<N>        size = i32(header, 32), i32(header, 36)<N>        offset = i32(header, 40)<N><N>
        # load pixel data<N>        fp.seek(offset)<N><N>        Image._decompression_bomb_check(size)<N>        im = Image.frombytes("P", size, fp.read(size[0] * size[1]))<N>        im.putpalette(quake2palette)<N><N>        im.format = "WAL"<N>        im.format_description = "Quake2 Texture"<N><N>
        # strings are null-terminated<N>        im.info["name"] = header[:32].split(b"\0", 1)[0]<N>        next_name = header[56 : 56 + 32].split(b"\0", 1)[0]<N>        if next_name:<N>            im.info["next_name"] = next_name<N><N>        return im<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># macOS icns file decoder, based on icns.py by Bob Ippolito.<N>#<N># history:<N># 2004-10-09 fl   Turned into a PIL plugin; removed 2.3 dependencies.<N>#<N># Copyright (c) 2004 by Bob Ippolito.<N># Copyright (c) 2004 by Secret Labs.<N># Copyright (c) 2004 by Fredrik Lundh.<N># Copyright (c) 2014 by Alastair Houghton.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import io<N>import os<N>import shutil<N>import struct<N>import subprocess<N>import sys<N>import tempfile<N><N>from PIL import Image, ImageFile, PngImagePlugin, features<N><N>enable_jpeg2k = features.check_codec("jpg_2000")<N>if enable_jpeg2k:<N>    from PIL import Jpeg2KImagePlugin<N><N>
HEADERSIZE = 8<N><N><N>def nextheader(fobj):<N>    return struct.unpack(">4sI", fobj.read(HEADERSIZE))<N><N><N>def read_32t(fobj, start_length, size):<N>    # The 128x128 icon seems to have an extra header for some reason.<N>    (start, length) = start_length<N>    fobj.seek(start)<N>    sig = fobj.read(4)<N>    if sig != b"\x00\x00\x00\x00":<N>        raise SyntaxError("Unknown signature, expecting 0x00000000")<N>    return read_32(fobj, (start + 4, length - 4), size)<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># Simple PostScript graphics interface<N>#<N># History:<N># 1996-04-20 fl   Created<N># 1999-01-10 fl   Added gsave/grestore to image method<N># 2005-05-04 fl   Fixed floating point issue in image (from Eric Etheridge)<N>#<N># Copyright (c) 1997-2005 by Secret Labs AB.  All rights reserved.<N># Copyright (c) 1996 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import sys<N><N>from . import EpsImagePlugin<N><N>##<N># Simple PostScript graphics interface.<N><N><N>class PSDraw:<N>    """<N>    Sets up printing to the given file. If ``fp`` is omitted,<N>    :py:data:`sys.stdout` is assumed.<N>    """<N><N>    def __init__(self, fp=None):<N>        if not fp:<N>            fp = sys.stdout<N>        self.fp = fp<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># PPM support for PIL<N>#<N># History:<N>#       96-03-24 fl     Created<N>#       98-03-06 fl     Write RGBA images (as RGB, that is)<N>#<N># Copyright (c) Secret Labs AB 1997-98.<N># Copyright (c) Fredrik Lundh 1996.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>from . import Image, ImageFile<N><N>#<N># --------------------------------------------------------------------<N><N>b_whitespace = b"\x20\x09\x0a\x0b\x0c\x0d"<N><N>MODES = {<N>    # standard<N>    b"P4": "1",<N>    b"P5": "L",<N>    b"P6": "RGB",<N>    # extensions<N>    b"P0CMYK": "CMYK",<N>    # PIL extensions (for test purposes only)<N>    b"PyP": "P",<N>    b"PyRGBA": "RGBA",<N>    b"PyCMYK": "CMYK",<N>}<N><N>
<N>def _accept(prefix):<N>    return prefix[0:1] == b"P" and prefix[1] in b"0456y"<N><N><N>##<N># Image plugin for PBM, PGM, and PPM images.<N><N><N>class PpmImageFile(ImageFile.ImageFile):<N><N>    format = "PPM"<N>    format_description = "Pbmplus image"<N><N>
    def _token(self, s=b""):<N>        while True:  # read until next whitespace<N>            c = self.fp.read(1)<N>            if not c or c in b_whitespace:<N>                break<N>            if c > b"\x79":<N>                raise ValueError("Expected ASCII value, found binary")<N>            s = s + c<N>            if len(s) > 9:<N>                raise ValueError("Expected int, got > 9 digits")<N>        return s<N><N>
    def _open(self):<N><N>        # check magic<N>        s = self.fp.read(1)<N>        if s != b"P":<N>            raise SyntaxError("not a PPM file")<N>        magic_number = self._token(s)<N>        mode = MODES[magic_number]<N><N>        self.custom_mimetype = {<N>            b"P4": "image/x-portable-bitmap",<N>            b"P5": "image/x-portable-graymap",<N>            b"P6": "image/x-portable-pixmap",<N>        }.get(magic_number)<N><N>
""" Find compiled module linking to Tcl / Tk libraries<N>"""<N>import sys<N>import tkinter<N>import warnings<N>from tkinter import _tkinter as tk<N><N>if hasattr(sys, "pypy_find_executable"):<N>    TKINTER_LIB = tk.tklib_cffi.__file__<N>else:<N>    TKINTER_LIB = tk.__file__<N><N>
tk_version = str(tkinter.TkVersion)<N>if tk_version == "8.4":<N>    warnings.warn(<N>        "Support for Tk/Tcl 8.4 is deprecated and will be removed"<N>        " in Pillow 10 (2023-01-02). Please upgrade to Tk/Tcl 8.5 "<N>        "or newer.",<N>        DeprecationWarning,<N>    )<N><N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># BUFR stub adapter<N>#<N># Copyright (c) 1996-2003 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>from . import Image, ImageFile<N><N>_handler = None<N><N>
<N>def register_handler(handler):<N>    """<N>    Install application-specific BUFR image handler.<N><N>    :param handler: Handler object.<N>    """<N>    global _handler<N>    _handler = handler<N><N><N># --------------------------------------------------------------------<N># Image adapter<N><N>
<N>def _accept(prefix):<N>    return prefix[:4] == b"BUFR" or prefix[:4] == b"ZCZC"<N><N><N>class BufrStubImageFile(ImageFile.StubImageFile):<N><N>    format = "BUFR"<N>    format_description = "BUFR"<N><N>    def _open(self):<N><N>        offset = self.fp.tell()<N><N>
        if not _accept(self.fp.read(4)):<N>            raise SyntaxError("Not a BUFR file")<N><N>        self.fp.seek(offset)<N><N>        # make something up<N>        self.mode = "F"<N>        self._size = 1, 1<N><N>        loader = self._load()<N>        if loader:<N>            loader.open(self)<N><N>
    def _load(self):<N>        return _handler<N><N><N>def _save(im, fp, filename):<N>    if _handler is None or not hasattr("_handler", "save"):<N>        raise OSError("BUFR save handler not installed")<N>    _handler.save(im, fp, filename)<N><N><N># --------------------------------------------------------------------<N># Registry<N><N>
#<N># Python Imaging Library<N># $Id$<N>#<N># stuff to read GIMP palette files<N>#<N># History:<N># 1997-08-23 fl     Created<N># 2004-09-07 fl     Support GIMP 2.0 palette files.<N>#<N># Copyright (c) Secret Labs AB 1997-2004.  All rights reserved.<N># Copyright (c) Fredrik Lundh 1997-2004.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import re<N><N>from ._binary import o8<N><N><N>class GimpPaletteFile:<N>    """File handler for GIMP's palette format."""<N><N>    rawmode = "RGB"<N><N>    def __init__(self, fp):<N><N>        self.palette = [o8(i) * 3 for i in range(256)]<N><N>        if fp.readline()[:12] != b"GIMP Palette":<N>            raise SyntaxError("not a GIMP palette file")<N><N>
        for i in range(256):<N><N>            s = fp.readline()<N>            if not s:<N>                break<N><N>            # skip fields and comment lines<N>            if re.match(br"\w+:|#", s):<N>                continue<N>            if len(s) > 100:<N>                raise SyntaxError("bad palette file")<N><N>
            v = tuple(map(int, s.split()[:3]))<N>            if len(v) != 3:<N>                raise ValueError("bad palette entry")<N><N>            self.palette[i] = o8(v[0]) + o8(v[1]) + o8(v[2])<N><N>        self.palette = b"".join(self.palette)<N><N>    def getpalette(self):<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># Windows Icon support for PIL<N>#<N># History:<N>#       96-05-27 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1996.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
# This plugin is a refactored version of Win32IconImagePlugin by Bryan Davis<N># <casadebender@gmail.com>.<N># https://code.google.com/archive/p/casadebender/wikis/Win32IconImagePlugin.wiki<N>#<N># Icon format references:<N>#   * https://en.wikipedia.org/wiki/ICO_(file_format)<N>#   * https://msdn.microsoft.com/en-us/library/ms997538.aspx<N><N>
<N>import struct<N>import warnings<N>from io import BytesIO<N>from math import ceil, log<N><N>from . import BmpImagePlugin, Image, ImageFile, PngImagePlugin<N>from ._binary import i16le as i16<N>from ._binary import i32le as i32<N><N>#<N># --------------------------------------------------------------------<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># EXIF tags<N>#<N># Copyright (c) 2003 by Secret Labs AB<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>"""<N>This module provides constants and clear-text names for various<N>well-known EXIF tags.<N>"""<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># TGA file handling<N>#<N># History:<N># 95-09-01 fl   created (reads 24-bit files only)<N># 97-01-04 fl   support more TGA versions, including compressed images<N># 98-07-04 fl   fixed orientation and alpha layer bugs<N># 98-09-11 fl   fixed orientation for runlength decoder<N>#<N># Copyright (c) Secret Labs AB 1997-98.<N># Copyright (c) Fredrik Lundh 1995-97.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import warnings<N><N>from . import Image, ImageFile, ImagePalette<N>from ._binary import i16le as i16<N>from ._binary import o8<N>from ._binary import o16le as o16<N><N>#<N># --------------------------------------------------------------------<N># Read RGA file<N><N>
<N>MODES = {<N>    # map imagetype/depth to rawmode<N>    (1, 8): "P",<N>    (3, 1): "1",<N>    (3, 8): "L",<N>    (3, 16): "LA",<N>    (2, 16): "BGR;5",<N>    (2, 24): "BGR",<N>    (2, 32): "BGRA",<N>}<N><N><N>##<N># Image plugin for Targa files.<N><N><N>class TgaImageFile(ImageFile.ImageFile):<N><N>
    format = "TGA"<N>    format_description = "Targa"<N><N>    def _open(self):<N><N>        # process header<N>        s = self.fp.read(18)<N><N>        id_len = s[0]<N><N>        colormaptype = s[1]<N>        imagetype = s[2]<N><N>        depth = s[16]<N><N>
        flags = s[17]<N><N>        self._size = i16(s, 12), i16(s, 14)<N><N>        # validate header fields<N>        if (<N>            colormaptype not in (0, 1)<N>            or self.size[0] <= 0<N>            or self.size[1] <= 0<N>            or depth not in (1, 8, 16, 24, 32)<N>        ):<N>            raise SyntaxError("not a TGA file")<N><N>
        # image mode<N>        if imagetype in (3, 11):<N>            self.mode = "L"<N>            if depth == 1:<N>                self.mode = "1"  # ???<N>            elif depth == 16:<N>                self.mode = "LA"<N>        elif imagetype in (1, 9):<N>            self.mode = "P"<N>        elif imagetype in (2, 10):<N>            self.mode = "RGB"<N>            if depth == 32:<N>                self.mode = "RGBA"<N>        else:<N>            raise SyntaxError("unknown TGA mode")<N><N>
        # orientation<N>        orientation = flags & 0x30<N>        if orientation == 0x20:<N>            orientation = 1<N>        elif not orientation:<N>            orientation = -1<N>        else:<N>            raise SyntaxError("unknown TGA orientation")<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># TIFF tags<N>#<N># This module provides clear-text names for various well-known<N># TIFF tags.  the TIFF codec works just fine without it.<N>#<N># Copyright (c) Secret Labs AB 1999.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
##<N># This module provides constants and clear-text names for various<N># well-known TIFF tags.<N>##<N><N>from collections import namedtuple<N><N><N>class TagInfo(namedtuple("_TagInfo", "value name type length enum")):<N>    __slots__ = []<N><N>    def __new__(cls, value=None, name="unknown", type=None, length=None, enum=None):<N>        return super().__new__(cls, value, name, type, length, enum or {})<N><N>
    def cvt_enum(self, value):<N>        # Using get will call hash(value), which can be expensive<N>        # for some types (e.g. Fraction). Since self.enum is rarely<N>        # used, it's usually better to test it first.<N>        return self.enum.get(value, value) if self.enum else value<N><N>
<N>def lookup(tag):<N>    """<N>    :param tag: Integer tag number<N>    :returns: Taginfo namedtuple, From the TAGS_V2 info if possible,<N>        otherwise just populating the value and name from TAGS.<N>        If the tag is not recognized, "unknown" is returned for the name<N><N>
    """<N><N>    return TAGS_V2.get(tag, TagInfo(tag, TAGS.get(tag, "unknown")))<N><N><N>##<N># Map tag numbers to tag info.<N>#<N>#  id: (Name, Type, Length, enum_values)<N>#<N># The length here differs from the length in the tiff spec.  For<N># numbers, the tiff spec is for the number of fields returned. We<N># agree here.  For string-like types, the tiff spec uses the length of<N># field in bytes.  In Pillow, we are using the number of expected<N># fields, in general 1 for string-like types.<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># XPM File handling<N>#<N># History:<N># 1996-12-29 fl   Created<N># 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.7)<N>#<N># Copyright (c) Secret Labs AB 1997-2001.<N># Copyright (c) Fredrik Lundh 1996-2001.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import re<N><N>from . import Image, ImageFile, ImagePalette<N>from ._binary import o8<N><N># XPM header<N>xpm_head = re.compile(b'"([0-9]*) ([0-9]*) ([0-9]*) ([0-9]*)')<N><N><N>def _accept(prefix):<N>    return prefix[:9] == b"/* XPM */"<N><N><N>##<N># Image plugin for X11 pixel maps.<N><N>
<N>class XpmImageFile(ImageFile.ImageFile):<N><N>    format = "XPM"<N>    format_description = "X11 Pixel Map"<N><N>    def _open(self):<N><N>        if not _accept(self.fp.read(9)):<N>            raise SyntaxError("not an XPM file")<N><N>        # skip forward to next string<N>        while True:<N>            s = self.fp.readline()<N>            if not s:<N>                raise SyntaxError("broken XPM file")<N>            m = xpm_head.match(s)<N>            if m:<N>                break<N><N>
        self._size = int(m.group(1)), int(m.group(2))<N><N>        pal = int(m.group(3))<N>        bpp = int(m.group(4))<N><N>        if pal > 256 or bpp != 1:<N>            raise ValueError("cannot read this XPM file")<N><N>        #<N>        # load palette description<N><N>
        palette = [b"\0\0\0"] * 256<N><N>        for i in range(pal):<N><N>            s = self.fp.readline()<N>            if s[-2:] == b"\r\n":<N>                s = s[:-2]<N>            elif s[-1:] in b"\r\n":<N>                s = s[:-1]<N><N>            c = s[1]<N>            s = s[2:-2].split()<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># sequence support classes<N>#<N># history:<N># 1997-02-20 fl     Created<N>#<N># Copyright (c) 1997 by Secret Labs AB.<N># Copyright (c) 1997 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
##<N><N><N>class Iterator:<N>    """<N>    This class implements an iterator object that can be used to loop<N>    over an image sequence.<N><N>    You can use the ``[]`` operator to access elements by index. This operator<N>    will raise an :py:exc:`IndexError` if you try to access a nonexistent<N>    frame.<N><N>
    :param im: An image object.<N>    """<N><N>    def __init__(self, im):<N>        if not hasattr(im, "seek"):<N>            raise AttributeError("im must have seek method")<N>        self.im = im<N>        self.position = getattr(self.im, "_min_frame", 0)<N><N>
    def __getitem__(self, ix):<N>        try:<N>            self.im.seek(ix)<N>            return self.im<N>        except EOFError as e:<N>            raise IndexError from e  # end of sequence<N><N>    def __iter__(self):<N>        return self<N><N>    def __next__(self):<N>        try:<N>            self.im.seek(self.position)<N>            self.position += 1<N>            return self.im<N>        except EOFError as e:<N>            raise StopIteration from e<N><N>
<N>def all_frames(im, func=None):<N>    """<N>    Applies a given function to all frames in an image or a list of images.<N>    The frames are returned as a list of separate images.<N><N>    :param im: An image, or a list of images.<N>    :param func: The function to apply to all of the image frames.<N>    :returns: A list of images.<N>    """<N>    if not isinstance(im, list):<N>        im = [im]<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># image palette object<N>#<N># History:<N># 1996-03-11 fl   Rewritten.<N># 1997-01-03 fl   Up and running.<N># 1997-08-23 fl   Added load hack<N># 2001-04-16 fl   Fixed randint shadow bug in random()<N>#<N># Copyright (c) 1997-2001 by Secret Labs AB<N># Copyright (c) 1996-1997 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
#<N># THIS IS WORK IN PROGRESS<N>#<N># The Python Imaging Library.<N># $Id$<N>#<N># FlashPix support for PIL<N>#<N># History:<N># 97-01-25 fl   Created (reads uncompressed RGB images only)<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1997.<N>#<N># See the README file for information on usage and redistribution.<N>#<N>import olefile<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># a simple math add-on for the Python Imaging Library<N>#<N># History:<N># 1999-02-15 fl   Original PIL Plus release<N># 2005-05-05 fl   Simplified and cleaned up for PIL 1.1.6<N># 2005-09-12 fl   Fixed int() and float() for Python 2.4.1<N>#<N># Copyright (c) 1999-2005 by Secret Labs AB<N># Copyright (c) 2005 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import builtins<N><N>from . import Image, _imagingmath<N><N>VERBOSE = 0<N><N><N>def _isconstant(v):<N>    return isinstance(v, (int, float))<N><N><N>class _Operand:<N>    """Wraps an image operand, providing standard operators"""<N><N>    def __init__(self, im):<N>        self.im = im<N><N>
#<N># Python Imaging Library<N># $Id$<N>#<N># stuff to read simple, teragon-style palette files<N>#<N># History:<N>#       97-08-23 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1997.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
from ._binary import o8<N><N><N>class PaletteFile:<N>    """File handler for Teragon-style palette files."""<N><N>    rawmode = "RGB"<N><N>    def __init__(self, fp):<N><N>        self.palette = [(i, i, i) for i in range(256)]<N><N>        while True:<N><N>
            s = fp.readline()<N><N>            if not s:<N>                break<N>            if s[0:1] == b"#":<N>                continue<N>            if len(s) > 100:<N>                raise SyntaxError("bad palette file")<N><N>            v = [int(x) for x in s.split()]<N>            try:<N>                [i, r, g, b] = v<N>            except ValueError:<N>                [i, r] = v<N>                g = b = r<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># PCD file handling<N>#<N># History:<N>#       96-05-10 fl     Created<N>#       96-05-27 fl     Added draft mode (128x192, 256x384)<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1996.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>from . import Image, ImageFile<N><N>##<N># Image plugin for PhotoCD images.  This plugin only reads the 768x512<N># image from the file; higher resolutions are encoded in a proprietary<N># encoding.<N><N><N>class PcdImageFile(ImageFile.ImageFile):<N><N>
    format = "PCD"<N>    format_description = "Kodak PhotoCD"<N><N>    def _open(self):<N><N>        # rough<N>        self.fp.seek(2048)<N>        s = self.fp.read(2048)<N><N>        if s[:4] != b"PCD_":<N>            raise SyntaxError("not a PCD file")<N><N>
        orientation = s[1538] & 3<N>        self.tile_post_rotate = None<N>        if orientation == 1:<N>            self.tile_post_rotate = 90<N>        elif orientation == 3:<N>            self.tile_post_rotate = -90<N><N>        self.mode = "RGB"<N>        self._size = 768, 512  # FIXME: not correct for rotated images!<N>        self.tile = [("pcd", (0, 0) + self.size, 96 * 2048, None)]<N><N>
    def load_end(self):<N>        if self.tile_post_rotate:<N>            # Handle rotated PCDs<N>            self.im = self.im.rotate(self.tile_post_rotate)<N>            self._size = self.im.size<N><N><N>#<N># registry<N><N>Image.register_open(PcdImageFile.format, PcdImageFile)<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># IM Tools support for PIL<N>#<N># history:<N># 1996-05-27 fl   Created (read 8-bit images only)<N># 2001-02-17 fl   Use 're' instead of 'regex' (Python 2.1) (0.2)<N>#<N># Copyright (c) Secret Labs AB 1997-2001.<N># Copyright (c) Fredrik Lundh 1996-2001.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import re<N><N>from . import Image, ImageFile<N><N>#<N># --------------------------------------------------------------------<N><N>field = re.compile(br"([a-z]*) ([^ \r\n]*)")<N><N><N>##<N># Image plugin for IM Tools images.<N><N><N>class ImtImageFile(ImageFile.ImageFile):<N><N>
    format = "IMT"<N>    format_description = "IM Tools"<N><N>    def _open(self):<N><N>        # Quick rejection: if there's not a LF among the first<N>        # 100 bytes, this is (probably) not a text header.<N><N>        if b"\n" not in self.fp.read(100):<N>            raise SyntaxError("not an IM file")<N>        self.fp.seek(0)<N><N>
        xsize = ysize = 0<N><N>        while True:<N><N>            s = self.fp.read(1)<N>            if not s:<N>                break<N><N>            if s == b"\x0C":<N><N>                # image data begins<N>                self.tile = [<N>                    ("raw", (0, 0) + self.size, self.fp.tell(), (self.mode, 0, 1))<N>                ]<N><N>
                break<N><N>            else:<N><N>                # read key/value pair<N>                # FIXME: dangerous, may read whole file<N>                s = s + self.fp.readline()<N>                if len(s) == 1 or len(s) > 100:<N>                    break<N>                if s[0] == ord(b"*"):<N>                    continue  # comment<N><N>
                m = field.match(s)<N>                if not m:<N>                    break<N>                k, v = m.group(1, 2)<N>                if k == "width":<N>                    xsize = int(v)<N>                    self._size = xsize, ysize<N>                elif k == "height":<N>                    ysize = int(v)<N>                    self._size = xsize, ysize<N>                elif k == "pixel" and v == "n8":<N>                    self.mode = "L"<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># standard filters<N>#<N># History:<N># 1995-11-27 fl   Created<N># 2002-06-08 fl   Added rank and mode filters<N># 2003-09-15 fl   Fixed rank calculation in rank filter; added expand call<N>#<N># Copyright (c) 1997-2003 by Secret Labs AB.<N># Copyright (c) 1995-2002 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N>import functools<N><N>
<N>class Filter:<N>    pass<N><N><N>class MultibandFilter(Filter):<N>    pass<N><N><N>class BuiltinFilter(MultibandFilter):<N>    def filter(self, image):<N>        if image.mode == "P":<N>            raise ValueError("cannot filter palette images")<N>        return image.filter(*self.filterargs)<N><N>
<N>class Kernel(BuiltinFilter):<N>    """<N>    Create a convolution kernel.  The current version only<N>    supports 3x3 and 5x5 integer and floating point kernels.<N><N>    In the current version, kernels can only be applied to<N>    "L" and "RGB" images.<N><N>
# The Python Imaging Library.<N># $Id$<N><N># Optional color management support, based on Kevin Cazabon's PyCMS<N># library.<N><N># History:<N><N># 2009-03-08 fl   Added to PIL.<N><N># Copyright (C) 2002-2003 Kevin Cazabon<N># Copyright (c) 2009 by Fredrik Lundh<N># Copyright (c) 2013 by Eric Soroos<N><N>
# See the README file for information on usage and redistribution.  See<N># below for the original description.<N><N>import sys<N><N>from PIL import Image<N><N>try:<N>    from PIL import _imagingcms<N>except ImportError as ex:<N>    # Allow error import for doc purposes, but error out when accessing<N>    # anything in core.<N>    from ._util import deferred_error<N><N>
    _imagingcms = deferred_error(ex)<N><N>DESCRIPTION = """<N>pyCMS<N><N>    a Python / PIL interface to the littleCMS ICC Color Management System<N>    Copyright (C) 2002-2003 Kevin Cazabon<N>    kevin@cazabon.com<N>    http://www.cazabon.com<N><N>    pyCMS home page:  http://www.cazabon.com/pyCMS<N>    littleCMS home page:  http://www.littlecms.com<N>    (littleCMS is Copyright (C) 1998-2001 Marti Maria)<N><N>
    Originally released under LGPL.  Graciously donated to PIL in<N>    March 2009, for distribution under the standard PIL license<N><N>    The pyCMS.py module provides a "clean" interface between Python/PIL and<N>    pyCMSdll, taking care of some of the more complex handling of the direct<N>    pyCMSdll functions, as well as error-checking and making sure that all<N>    relevant data is kept together.<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># WCK-style drawing interface operations<N>#<N># History:<N># 2003-12-07 fl   created<N># 2005-05-15 fl   updated; added to PIL as ImageDraw2<N># 2005-05-15 fl   added text support<N># 2005-05-20 fl   added arc/chord/pieslice support<N>#<N># Copyright (c) 2003-2005 by Secret Labs AB<N># Copyright (c) 2003-2005 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>"""<N>(Experimental) WCK-style drawing interface operations<N><N>.. seealso:: :py:mod:`PIL.ImageDraw`<N>"""<N><N><N>from . import Image, ImageColor, ImageDraw, ImageFont, ImagePath<N><N><N>class Pen:<N>    """Stores an outline color and width."""<N><N>    def __init__(self, color, width=1, opacity=255):<N>        self.color = ImageColor.getrgb(color)<N>        self.width = width<N><N>
<N>class Brush:<N>    """Stores a fill color"""<N><N>    def __init__(self, color, opacity=255):<N>        self.color = ImageColor.getrgb(color)<N><N><N>class Font:<N>    """Stores a TrueType font and color"""<N><N>    def __init__(self, color, file, size=12):<N>        # FIXME: add support for bitmap fonts<N>        self.color = ImageColor.getrgb(color)<N>        self.font = ImageFont.truetype(file, size)<N><N>
<N>class Draw:<N>    """<N>    (Experimental) WCK-style drawing interface<N>    """<N><N>    def __init__(self, image, size=None, color=None):<N>        if not hasattr(image, "im"):<N>            image = Image.new(image, size, color)<N>        self.draw = ImageDraw.Draw(image)<N>        self.image = image<N>        self.transform = None<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># MPEG file handling<N>#<N># History:<N>#       95-09-09 fl     Created<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1995.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>from . import Image, ImageFile<N>from ._binary import i8<N><N>#<N># Bitstream parser<N><N><N>class BitStream:<N>    def __init__(self, fp):<N>        self.fp = fp<N>        self.bits = 0<N>        self.bitbuffer = 0<N><N>    def next(self):<N>        return i8(self.fp.read(1))<N><N>
    def peek(self, bits):<N>        while self.bits < bits:<N>            c = self.next()<N>            if c < 0:<N>                self.bits = 0<N>                continue<N>            self.bitbuffer = (self.bitbuffer << 8) + c<N>            self.bits += 8<N>        return self.bitbuffer >> (self.bits - bits) & (1 << bits) - 1<N><N>
    def skip(self, bits):<N>        while self.bits < bits:<N>            self.bitbuffer = (self.bitbuffer << 8) + i8(self.fp.read(1))<N>            self.bits += 8<N>        self.bits = self.bits - bits<N><N>    def read(self, bits):<N>        v = self.peek(bits)<N>        self.bits = self.bits - bits<N>        return v<N><N>
<N>##<N># Image plugin for MPEG streams.  This plugin can identify a stream,<N># but it cannot read it.<N><N><N>class MpegImageFile(ImageFile.ImageFile):<N><N>    format = "MPEG"<N>    format_description = "MPEG"<N><N>    def _open(self):<N><N>        s = BitStream(self.fp)<N><N>
        if s.read(32) != 0x1B3:<N>            raise SyntaxError("not an MPEG file")<N><N>        self.mode = "RGB"<N>        self._size = s.read(12), s.read(12)<N><N><N># --------------------------------------------------------------------<N># Registry stuff<N><N>
"""<N>A Pillow loader for .ftc and .ftu files (FTEX)<N>Jerome Leclanche <jerome@leclan.ch><N><N>The contents of this file are hereby released in the public domain (CC0)<N>Full text of the CC0 license:<N>  https://creativecommons.org/publicdomain/zero/1.0/<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># path interface<N>#<N># History:<N># 1996-11-04 fl   Created<N># 2002-04-14 fl   Added documentation stub class<N>#<N># Copyright (c) Secret Labs AB 1997.<N># Copyright (c) Fredrik Lundh 1996.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>from . import Image<N><N>Path = Image.core.path<N>
# A binary morphology add-on for the Python Imaging Library<N>#<N># History:<N>#   2014-06-04 Initial version.<N>#<N># Copyright (c) 2014 Dov Grobgeld <dov.grobgeld@gmail.com><N><N>import re<N><N>from . import Image, _imagingmorph<N><N>LUT_SIZE = 1 << 9<N><N>
# fmt: off<N>ROTATION_MATRIX = [<N>    6, 3, 0,<N>    7, 4, 1,<N>    8, 5, 2,<N>]<N>MIRROR_MATRIX = [<N>    2, 1, 0,<N>    5, 4, 3,<N>    8, 7, 6,<N>]<N># fmt: on<N><N><N>class LutBuilder:<N>    """A class for building a MorphLut from a descriptive language<N><N>
    The input patterns is a list of a strings sequences like these::<N><N>        4:(...<N>           .1.<N>           111)->1<N><N>    (whitespaces including linebreaks are ignored). The option 4<N>    describes a series of symmetry operations (in this case a<N>    4-rotation), the pattern is described by:<N><N>
    - . or X - Ignore<N>    - 1 - Pixel is on<N>    - 0 - Pixel is off<N><N>    The result of the operation is described after "->" string.<N><N>    The default is to return the current pixel value, which is<N>    returned if no other match is found.<N><N>
    Operations:<N><N>    - 4 - 4 way rotation<N>    - N - Negate<N>    - 1 - Dummy op for no other operation (an op must always be given)<N>    - M - Mirroring<N><N>    Example::<N><N>        lb = LutBuilder(patterns = ["4:(... .1. 111)->1"])<N>        lut = lb.build_lut()<N><N>
import os<N>from pathlib import Path<N><N><N>def isPath(f):<N>    return isinstance(f, (bytes, str, Path))<N><N><N># Checks if an object is a string, and that it points to a directory.<N>def isDirectory(f):<N>    return isPath(f) and os.path.isdir(f)<N><N><N>class deferred_error:<N>    def __init__(self, ex):<N>        self.ex = ex<N><N>    def __getattr__(self, elt):<N>        raise self.ex<N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># im.show() drivers<N>#<N># History:<N># 2008-04-06 fl   Created<N>#<N># Copyright (c) Secret Labs AB 2008.<N>#<N># See the README file for information on usage and redistribution.<N>#<N>import os<N>import shutil<N>import subprocess<N>import sys<N>import tempfile<N>from shlex import quote<N><N>
#<N># The Python Imaging Library<N># Pillow fork<N>#<N># Python implementation of the PixelAccess Object<N>#<N># Copyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.<N># Copyright (c) 1995-2009 by Fredrik Lundh.<N># Copyright (c) 2013 Eric Soroos<N>#<N># See the README file for information on usage and redistribution<N>#<N><N>
# Notes:<N>#<N>#  * Implements the pixel access object following Access.<N>#  * Does not implement the line functions, as they don't appear to be used<N>#  * Taking only the tuple form, which is used from python.<N>#    * Fill.c uses the integer form, but it's still going to use the old<N>#      Access.c implementation.<N>#<N><N>
import logging<N>import sys<N><N>try:<N>    from cffi import FFI<N><N>    defs = """<N>    struct Pixel_RGBA {<N>        unsigned char r,g,b,a;<N>    };<N>    struct Pixel_I16 {<N>        unsigned char l,r;<N>    };<N>    """<N>    ffi = FFI()<N>    ffi.cdef(defs)<N>except ImportError as ex:<N>    # Allow error import for doc purposes, but error out when accessing<N>    # anything in core.<N>    from ._util import deferred_error<N><N>
    FFI = ffi = deferred_error(ex)<N><N>logger = logging.getLogger(__name__)<N><N><N>class PyAccess:<N>    def __init__(self, img, readonly=False):<N>        vals = dict(img.im.unsafe_ptrs)<N>        self.readonly = readonly<N>        self.image8 = ffi.cast("unsigned char **", vals["image8"])<N>        self.image32 = ffi.cast("int **", vals["image32"])<N>        self.image = ffi.cast("unsigned char **", vals["image"])<N>        self.xsize, self.ysize = img.im.size<N><N>
        # Keep pointer to im object to prevent dereferencing.<N>        self._im = img.im<N>        if self._im.mode == "P":<N>            self._palette = img.palette<N><N>        # Debugging is polluting test traces, only useful here<N>        # when hacking on PyAccess<N>        # logger.debug("%s", vals)<N>        self._post_init()<N><N>
    def _post_init(self):<N>        pass<N><N>    def __setitem__(self, xy, color):<N>        """<N>        Modifies the pixel at x,y. The color is given as a single<N>        numerical value for single band images, and a tuple for<N>        multi-band images<N><N>
        :param xy: The pixel coordinate, given as (x, y). See<N>           :ref:`coordinate-system`.<N>        :param color: The pixel value.<N>        """<N>        if self.readonly:<N>            raise ValueError("Attempt to putpixel a read only image")<N>        (x, y) = xy<N>        if x < 0:<N>            x = self.xsize + x<N>        if y < 0:<N>            y = self.ysize + y<N>        (x, y) = self.check_xy((x, y))<N><N>
        if (<N>            self._im.mode == "P"<N>            and isinstance(color, (list, tuple))<N>            and len(color) in [3, 4]<N>        ):<N>            # RGB or RGBA value for a P image<N>            color = self._palette.getcolor(color)<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># a class to read from a container file<N>#<N># History:<N># 1995-06-18 fl     Created<N># 1995-09-07 fl     Added readline(), readlines()<N>#<N># Copyright (c) 1997-2001 by Secret Labs AB<N># Copyright (c) 1995 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import io<N><N><N>class ContainerIO:<N>    """<N>    A file object that provides read access to a part of an existing<N>    file (for example a TAR file).<N>    """<N><N>    def __init__(self, file, offset, length):<N>        """<N>        Create file object.<N><N>
        :param file: Existing file.<N>        :param offset: Start of region, in bytes.<N>        :param length: Size of region, in bytes.<N>        """<N>        self.fh = file<N>        self.pos = 0<N>        self.offset = offset<N>        self.length = length<N>        self.fh.seek(offset)<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># GRIB stub adapter<N>#<N># Copyright (c) 1996-2003 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>from . import Image, ImageFile<N><N>_handler = None<N><N>
<N>def register_handler(handler):<N>    """<N>    Install application-specific GRIB image handler.<N><N>    :param handler: Handler object.<N>    """<N>    global _handler<N>    _handler = handler<N><N><N># --------------------------------------------------------------------<N># Image adapter<N><N>
<N>def _accept(prefix):<N>    return prefix[0:4] == b"GRIB" and prefix[7] == 1<N><N><N>class GribStubImageFile(ImageFile.StubImageFile):<N><N>    format = "GRIB"<N>    format_description = "GRIB"<N><N>    def _open(self):<N><N>        offset = self.fp.tell()<N><N>
        if not _accept(self.fp.read(8)):<N>            raise SyntaxError("Not a GRIB file")<N><N>        self.fp.seek(offset)<N><N>        # make something up<N>        self.mode = "F"<N>        self._size = 1, 1<N><N>        loader = self._load()<N>        if loader:<N>            loader.open(self)<N><N>
    def _load(self):<N>        return _handler<N><N><N>def _save(im, fp, filename):<N>    if _handler is None or not hasattr("_handler", "save"):<N>        raise OSError("GRIB save handler not installed")<N>    _handler.save(im, fp, filename)<N><N><N># --------------------------------------------------------------------<N># Registry<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># a simple Qt image interface.<N>#<N># history:<N># 2006-06-03 fl: created<N># 2006-06-04 fl: inherit from QImage instead of wrapping it<N># 2006-06-05 fl: removed toimage helper; move string support to ImageQt<N># 2013-11-13 fl: add support for Qt5 (aurelien.ballier@cyclonit.com)<N>#<N># Copyright (c) 2006 by Secret Labs AB<N># Copyright (c) 2006 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># FITS stub adapter<N>#<N># Copyright (c) 1998-2003 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>from . import Image, ImageFile<N><N>_handler = None<N><N>
<N>def register_handler(handler):<N>    """<N>    Install application-specific FITS image handler.<N><N>    :param handler: Handler object.<N>    """<N>    global _handler<N>    _handler = handler<N><N><N># --------------------------------------------------------------------<N># Image adapter<N><N>
<N>def _accept(prefix):<N>    return prefix[:6] == b"SIMPLE"<N><N><N>class FITSStubImageFile(ImageFile.StubImageFile):<N><N>    format = "FITS"<N>    format_description = "FITS"<N><N>    def _open(self):<N><N>        offset = self.fp.tell()<N><N>        if not _accept(self.fp.read(6)):<N>            raise SyntaxError("Not a FITS file")<N><N>
        # FIXME: add more sanity checks here; mandatory header items<N>        # include SIMPLE, BITPIX, NAXIS, etc.<N><N>        self.fp.seek(offset)<N><N>        # make something up<N>        self.mode = "F"<N>        self._size = 1, 1<N><N>        loader = self._load()<N>        if loader:<N>            loader.open(self)<N><N>
    def _load(self):<N>        return _handler<N><N><N>def _save(im, fp, filename):<N>    if _handler is None or not hasattr("_handler", "save"):<N>        raise OSError("FITS save handler not installed")<N>    _handler.save(im, fp, filename)<N><N><N># --------------------------------------------------------------------<N># Registry<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># Adobe PSD 2.5/3.0 file handling<N>#<N># History:<N># 1995-09-01 fl   Created<N># 1997-01-03 fl   Read most PSD images<N># 1997-01-18 fl   Fixed P and CMYK support<N># 2001-10-21 fl   Added seek/tell support (for layers)<N>#<N># Copyright (c) 1997-2001 by Secret Labs AB.<N># Copyright (c) 1995-2001 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
import io<N><N>from . import Image, ImageFile, ImagePalette<N>from ._binary import i8<N>from ._binary import i16be as i16<N>from ._binary import i32be as i32<N><N>MODES = {<N>    # (photoshop mode, bits) -> (pil mode, required channels)<N>    (0, 1): ("1", 1),<N>    (0, 8): ("L", 1),<N>    (1, 8): ("L", 1),<N>    (2, 8): ("P", 1),<N>    (3, 8): ("RGB", 3),<N>    (4, 8): ("CMYK", 4),<N>    (7, 8): ("L", 1),  # FIXME: multilayer<N>    (8, 8): ("L", 1),  # duotone<N>    (9, 8): ("LAB", 3),<N>}<N><N>
<N># --------------------------------------------------------------------.<N># read PSD images<N><N><N>def _accept(prefix):<N>    return prefix[:4] == b"8BPS"<N><N><N>##<N># Image plugin for Photoshop images.<N><N><N>class PsdImageFile(ImageFile.ImageFile):<N><N>
    format = "PSD"<N>    format_description = "Adobe Photoshop"<N>    _close_exclusive_fp_after_loading = False<N><N>    def _open(self):<N><N>        read = self.fp.read<N><N>        #<N>        # header<N><N>        s = read(26)<N>        if not _accept(s) or i16(s, 4) != 1:<N>            raise SyntaxError("not a PSD file")<N><N>
        psd_bits = i16(s, 22)<N>        psd_channels = i16(s, 12)<N>        psd_mode = i16(s, 24)<N><N>        mode, channels = MODES[(psd_mode, psd_bits)]<N><N>        if channels > psd_channels:<N>            raise OSError("not enough channels")<N><N>        self.mode = mode<N>        self._size = i32(s, 18), i32(s, 14)<N><N>
        #<N>        # color mode data<N><N>        size = i32(read(4))<N>        if size:<N>            data = read(size)<N>            if mode == "P" and size == 768:<N>                self.palette = ImagePalette.raw("RGB;L", data)<N><N>        #<N>        # image resources<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># JPEG2000 file handling<N>#<N># History:<N># 2014-03-12 ajh  Created<N>#<N># Copyright (c) 2014 Coriolis Systems Limited<N># Copyright (c) 2014 Alastair Houghton<N>#<N># See the README file for information on usage and redistribution.<N>#<N>import io<N>import os<N>import struct<N><N>
#<N># The Python Imaging Library<N># $Id$<N>#<N># base class for raster font file parsers<N>#<N># history:<N># 1997-06-05 fl   created<N># 1997-08-19 fl   restrict image width<N>#<N># Copyright (c) 1997-1998 by Secret Labs AB<N># Copyright (c) 1997-1998 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
<N>import os<N><N>from . import Image, _binary<N><N>WIDTH = 800<N><N><N>def puti16(fp, values):<N>    """Write network order (big-endian) 16-bit sequence"""<N>    for v in values:<N>        if v < 0:<N>            v += 65536<N>        fp.write(_binary.o16be(v))<N><N>
<N>class FontFile:<N>    """Base class for raster font file handlers."""<N><N>    bitmap = None<N><N>    def __init__(self):<N><N>        self.info = {}<N>        self.glyph = [None] * 256<N><N>    def __getitem__(self, ix):<N>        return self.glyph[ix]<N><N>
#<N># The Python Imaging Library.<N>#<N># SPIDER image file handling<N>#<N># History:<N># 2004-08-02    Created BB<N># 2006-03-02    added save method<N># 2006-03-13    added support for stack images<N>#<N># Copyright (c) 2004 by Health Research Inc. (HRI) RENSSELAER, NY 12144.<N># Copyright (c) 2004 by William Baxter.<N># Copyright (c) 2004 by Secret Labs AB.<N># Copyright (c) 2004 by Fredrik Lundh.<N>#<N><N>
"""<N>Blizzard Mipmap Format (.blp)<N>Jerome Leclanche <jerome@leclan.ch><N><N>The contents of this file are hereby released in the public domain (CC0)<N>Full text of the CC0 license:<N>  https://creativecommons.org/publicdomain/zero/1.0/<N><N>BLP1 files, used mostly in Warcraft III, are not fully supported.<N>All types of BLP2 files used in World of Warcraft are supported.<N><N>
The BLP file structure consists of a header, up to 16 mipmaps of the<N>texture<N><N>Texture sizes must be powers of two, though the two dimensions do<N>not have to be equal; 512x256 is valid, but 512x200 is not.<N>The first mipmap (mipmap #0) is the full size image; each subsequent<N>mipmap halves both dimensions. The final mipmap should be 1x1.<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># transform wrappers<N>#<N># History:<N># 2002-04-08 fl   Created<N>#<N># Copyright (c) 2002 by Secret Labs AB<N># Copyright (c) 2002 by Fredrik Lundh<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
from . import Image<N><N><N>class Transform(Image.ImageTransformHandler):<N>    def __init__(self, data):<N>        self.data = data<N><N>    def getdata(self):<N>        return self.method, self.data<N><N>    def transform(self, size, image, **options):<N>        # can be overridden<N>        method, data = self.getdata()<N>        return image.transform(size, method, data, **options)<N><N>
<N>class AffineTransform(Transform):<N>    """<N>    Define an affine image transform.<N><N>    This function takes a 6-tuple (a, b, c, d, e, f) which contain the first<N>    two rows from an affine transform matrix. For each pixel (x, y) in the<N>    output image, the new value is taken from a position (a x + b y + c,<N>    d x + e y + f) in the input image, rounded to nearest pixel.<N><N>
    This function can be used to scale, translate, rotate, and shear the<N>    original image.<N><N>    See :py:meth:`~PIL.Image.Image.transform`<N><N>    :param matrix: A 6-tuple (a, b, c, d, e, f) containing the first two rows<N>        from an affine transform matrix.<N>    """<N><N>
    method = Image.AFFINE<N><N><N>class ExtentTransform(Transform):<N>    """<N>    Define a transform to extract a subregion from an image.<N><N>    Maps a rectangle (defined by two corners) from the image to a rectangle of<N>    the given size. The resulting image will contain data sampled from between<N>    the corners, such that (x0, y0) in the input image will end up at (0,0) in<N>    the output image, and (x1, y1) at size.<N><N>
    This method can be used to crop, stretch, shrink, or mirror an arbitrary<N>    rectangle in the current image. It is slightly slower than crop, but about<N>    as fast as a corresponding resize operation.<N><N>    See :py:meth:`~PIL.Image.Image.transform`<N><N>
    :param bbox: A 4-tuple (x0, y0, x1, y1) which specifies two points in the<N>        input image's coordinate system. See :ref:`coordinate-system`.<N>    """<N><N>    method = Image.EXTENT<N><N><N>class QuadTransform(Transform):<N>    """<N>    Define a quad image transform.<N><N>
    Maps a quadrilateral (a region defined by four corners) from the image to a<N>    rectangle of the given size.<N><N>    See :py:meth:`~PIL.Image.Image.transform`<N><N>    :param xy: An 8-tuple (x0, y0, x1, y1, x2, y2, x3, y3) which contain the<N>        upper left, lower left, lower right, and upper right corner of the<N>        source quadrilateral.<N>    """<N><N>
    method = Image.QUAD<N><N><N>class MeshTransform(Transform):<N>    """<N>    Define a mesh image transform.  A mesh transform consists of one or more<N>    individual quad transforms.<N><N>    See :py:meth:`~PIL.Image.Image.transform`<N><N>    :param data: A list of (bbox, quad) tuples.<N>    """<N><N>
import calendar<N>import codecs<N>import collections<N>import mmap<N>import os<N>import re<N>import time<N>import zlib<N><N><N># see 7.9.2.2 Text String Type on page 86 and D.3 PDFDocEncoding Character Set<N># on page 656<N>def encode_text(s):<N>    return codecs.BOM_UTF16_BE + s.encode("utf_16_be")<N><N>
from io import BytesIO<N><N>from . import Image, ImageFile<N><N>try:<N>    from . import _webp<N><N>    SUPPORTED = True<N>except ImportError:<N>    SUPPORTED = False<N><N><N>_VALID_WEBP_MODES = {"RGBX": True, "RGBA": True, "RGB": True}<N><N>_VALID_WEBP_LEGACY_MODES = {"RGB": True, "RGBA": True}<N><N>
_VP8_MODES_BY_IDENTIFIER = {<N>    b"VP8 ": "RGB",<N>    b"VP8X": "RGBA",<N>    b"VP8L": "RGBA",  # lossless<N>}<N><N><N>def _accept(prefix):<N>    is_riff_file_format = prefix[:4] == b"RIFF"<N>    is_webp_file = prefix[8:12] == b"WEBP"<N>    is_valid_vp8_mode = prefix[12:16] in _VP8_MODES_BY_IDENTIFIER<N><N>
    if is_riff_file_format and is_webp_file and is_valid_vp8_mode:<N>        if not SUPPORTED:<N>            return (<N>                "image file could not be identified because WEBP support not installed"<N>            )<N>        return True<N><N><N>class WebPImageFile(ImageFile.ImageFile):<N><N>
#<N># The Python Imaging Library.<N># $Id$<N>#<N># standard mode descriptors<N>#<N># History:<N># 2006-03-20 fl   Added<N>#<N># Copyright (c) 2006 by Secret Labs AB.<N># Copyright (c) 2006 by Fredrik Lundh.<N>#<N># See the README file for information on usage and redistribution.<N>#<N><N>
# mode descriptor cache<N>_modes = None<N><N><N>class ModeDescriptor:<N>    """Wrapper for mode strings."""<N><N>    def __init__(self, mode, bands, basemode, basetype):<N>        self.mode = mode<N>        self.bands = bands<N>        self.basemode = basemode<N>        self.basetype = basetype<N><N>
# -*- coding: utf-8 -*-<N><N>r"""<N>The ``codes`` object defines a mapping from common names for HTTP statuses<N>to their numerical codes, accessible either as attributes or as dictionary<N>items.<N><N>Example::<N><N>    >>> import requests<N>    >>> requests.codes['temporary_redirect']<N>    307<N>    >>> requests.codes.teapot<N>    418<N>    >>> requests.codes['\o/']<N>    200<N><N>
Some codes have multiple names, and both upper- and lower-case versions of<N>the names are allowed. For example, ``codes.ok``, ``codes.OK``, and<N>``codes.okay`` all correspond to the HTTP status code 200.<N>"""<N><N>from .structures import LookupDict<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.compat<N>~~~~~~~~~~~~~~~<N><N>This module handles import compatibility issues between Python 2 and<N>Python 3.<N>"""<N><N>import chardet<N><N>import sys<N><N># -------<N># Pythons<N># -------<N><N># Syntax sugar.<N>_ver = sys.version_info<N><N>
# -*- coding: utf-8 -*-<N><N>#   __<N>#  /__)  _  _     _   _ _/   _<N># / (   (- (/ (/ (- _)  /  _)<N>#          /<N><N>"""<N>Requests HTTP Library<N>~~~~~~~~~~~~~~~~~~~~~<N><N>Requests is an HTTP library, written in Python, for human beings.<N>Basic GET usage:<N><N>
   >>> import requests<N>   >>> r = requests.get('https://www.python.org')<N>   >>> r.status_code<N>   200<N>   >>> b'Python is a programming language' in r.content<N>   True<N><N>... or POST:<N><N>   >>> payload = dict(key1='value1', key2='value2')<N>   >>> r = requests.post('https://httpbin.org/post', data=payload)<N>   >>> print(r.text)<N>   {<N>     ...<N>     "form": {<N>       "key1": "value1",<N>       "key2": "value2"<N>     },<N>     ...<N>   }<N><N>
The other HTTP methods are supported - see `requests.api`. Full documentation<N>is at <https://requests.readthedocs.io>.<N><N>:copyright: (c) 2017 by Kenneth Reitz.<N>:license: Apache 2.0, see LICENSE for more details.<N>"""<N><N>import urllib3<N>import chardet<N>import warnings<N>from .exceptions import RequestsDependencyWarning<N><N>
<N>def check_compatibility(urllib3_version, chardet_version):<N>    urllib3_version = urllib3_version.split('.')<N>    assert urllib3_version != ['dev']  # Verify urllib3 isn't installed from git.<N><N>    # Sometimes, urllib3 only reports its version as 16.1.<N>    if len(urllib3_version) == 2:<N>        urllib3_version.append('0')<N><N>
    # Check urllib3 for compatibility.<N>    major, minor, patch = urllib3_version  # noqa: F811<N>    major, minor, patch = int(major), int(minor), int(patch)<N>    # urllib3 >= 1.21.1, <= 1.26<N>    assert major == 1<N>    assert minor >= 21<N>    assert minor <= 26<N><N>
    # Check chardet for compatibility.<N>    major, minor, patch = chardet_version.split('.')[:3]<N>    major, minor, patch = int(major), int(minor), int(patch)<N>    # chardet >= 3.0.2, < 5.0.0<N>    assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)<N><N>
<N>def _check_cryptography(cryptography_version):<N>    # cryptography < 1.3.4<N>    try:<N>        cryptography_version = list(map(int, cryptography_version.split('.')))<N>    except ValueError:<N>        return<N><N>    if cryptography_version < [1, 3, 4]:<N>        warning = 'Old version of cryptography ({}) may cause slowdown.'.format(cryptography_version)<N>        warnings.warn(warning, RequestsDependencyWarning)<N><N>
# Check imported dependencies for compatibility.<N>try:<N>    check_compatibility(urllib3.__version__, chardet.__version__)<N>except (AssertionError, ValueError):<N>    warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "<N>                  "version!".format(urllib3.__version__, chardet.__version__),<N>                  RequestsDependencyWarning)<N><N>
# Attempt to enable urllib3's fallback for SNI support<N># if the standard library doesn't support SNI or the<N># 'ssl' library isn't available.<N>try:<N>    try:<N>        import ssl<N>    except ImportError:<N>        ssl = None<N><N>    if not getattr(ssl, "HAS_SNI", False):<N>        from urllib3.contrib import pyopenssl<N>        pyopenssl.inject_into_urllib3()<N><N>
        # Check cryptography version<N>        from cryptography import __version__ as cryptography_version<N>        _check_cryptography(cryptography_version)<N>except ImportError:<N>    pass<N><N># urllib3's DependencyWarnings should be silenced.<N>from urllib3.exceptions import DependencyWarning<N>warnings.simplefilter('ignore', DependencyWarning)<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.structures<N>~~~~~~~~~~~~~~~~~~~<N><N>Data structures that power Requests.<N>"""<N><N>from collections import OrderedDict<N><N>from .compat import Mapping, MutableMapping<N><N><N>class CaseInsensitiveDict(MutableMapping):<N>    """A case-insensitive ``dict``-like object.<N><N>
    Implements all methods and operations of<N>    ``MutableMapping`` as well as dict's ``copy``. Also<N>    provides ``lower_items``.<N><N>    All keys are expected to be strings. The structure remembers the<N>    case of the last key to be set, and ``iter(instance)``,<N>    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``<N>    will contain case-sensitive keys. However, querying and contains<N>    testing is case insensitive::<N><N>
        cid = CaseInsensitiveDict()<N>        cid['Accept'] = 'application/json'<N>        cid['aCCEPT'] == 'application/json'  # True<N>        list(cid) == ['Accept']  # True<N><N>    For example, ``headers['content-encoding']`` will return the<N>    value of a ``'Content-Encoding'`` response header, regardless<N>    of how the header name was originally stored.<N><N>
    If the constructor, ``.update``, or equality comparison<N>    operations are given keys that have equal ``.lower()``s, the<N>    behavior is undefined.<N>    """<N><N>    def __init__(self, data=None, **kwargs):<N>        self._store = OrderedDict()<N>        if data is None:<N>            data = {}<N>        self.update(data, **kwargs)<N><N>
    def __setitem__(self, key, value):<N>        # Use the lowercased key for lookups, but store the actual<N>        # key alongside the value.<N>        self._store[key.lower()] = (key, value)<N><N>    def __getitem__(self, key):<N>        return self._store[key.lower()][1]<N><N>
    def __delitem__(self, key):<N>        del self._store[key.lower()]<N><N>    def __iter__(self):<N>        return (casedkey for casedkey, mappedvalue in self._store.values())<N><N>    def __len__(self):<N>        return len(self._store)<N><N>    def lower_items(self):<N>        """Like iteritems(), but with all lowercase keys."""<N>        return (<N>            (lowerkey, keyval[1])<N>            for (lowerkey, keyval)<N>            in self._store.items()<N>        )<N><N>
    def __eq__(self, other):<N>        if isinstance(other, Mapping):<N>            other = CaseInsensitiveDict(other)<N>        else:<N>            return NotImplemented<N>        # Compare insensitively<N>        return dict(self.lower_items()) == dict(other.lower_items())<N><N>
    # Copy is required<N>    def copy(self):<N>        return CaseInsensitiveDict(self._store.values())<N><N>    def __repr__(self):<N>        return str(dict(self.items()))<N><N><N>class LookupDict(dict):<N>    """Dictionary lookup object."""<N><N>    def __init__(self, name=None):<N>        self.name = name<N>        super(LookupDict, self).__init__()<N><N>
    def __repr__(self):<N>        return '<lookup \'%s\'>' % (self.name)<N><N>    def __getitem__(self, key):<N>        # We allow fall-through here, so values default to None<N><N>        return self.__dict__.get(key, None)<N><N>    def get(self, key, default=None):<N>        return self.__dict__.get(key, default)<N><N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.models<N>~~~~~~~~~~~~~~~<N><N>This module contains the primary objects that power Requests.<N>"""<N><N>import datetime<N>import sys<N><N># Import encoding now, to avoid implicit import later.<N># Implicit import within threads may cause LookupError when standard library is in a ZIP,<N># such as in Embedded Python. See https://github.com/psf/requests/issues/3578.<N>import encodings.idna<N><N>
from urllib3.fields import RequestField<N>from urllib3.filepost import encode_multipart_formdata<N>from urllib3.util import parse_url<N>from urllib3.exceptions import (<N>    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)<N><N>from io import UnsupportedOperation<N>from .hooks import default_hooks<N>from .structures import CaseInsensitiveDict<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.cookies<N>~~~~~~~~~~~~~~~~<N><N>Compatibility code to be able to use `cookielib.CookieJar` with requests.<N><N>requests.utils imports from here, so be careful with imports.<N>"""<N><N>import copy<N>import time<N>import calendar<N><N>
from ._internal_utils import to_native_string<N>from .compat import cookielib, urlparse, urlunparse, Morsel, MutableMapping<N><N>try:<N>    import threading<N>except ImportError:<N>    import dummy_threading as threading<N><N><N>class MockRequest(object):<N>    """Wraps a `requests.Request` to mimic a `urllib2.Request`.<N><N>
    The code in `cookielib.CookieJar` expects this interface in order to correctly<N>    manage cookie policies, i.e., determine whether a cookie can be set, given the<N>    domains of the request and the cookie.<N><N>    The original request object is read-only. The client is responsible for collecting<N>    the new headers via `get_new_headers()` and interpreting them appropriately. You<N>    probably want `get_cookie_header`, defined below.<N>    """<N><N>
    def __init__(self, request):<N>        self._r = request<N>        self._new_headers = {}<N>        self.type = urlparse(self._r.url).scheme<N><N>    def get_type(self):<N>        return self.type<N><N>    def get_host(self):<N>        return urlparse(self._r.url).netloc<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.hooks<N>~~~~~~~~~~~~~~<N><N>This module provides the capabilities for the Requests hooks system.<N><N>Available hooks:<N><N>``response``:<N>    The response generated from a Request.<N>"""<N>HOOKS = ['response']<N><N>
# .-. .-. .-. . . .-. .-. .-. .-.<N># |(  |-  |.| | | |-  `-.  |  `-.<N># ' ' `-' `-`.`-' `-' `-'  '  `-'<N><N>__title__ = 'requests'<N>__description__ = 'Python HTTP for Humans.'<N>__url__ = 'https://requests.readthedocs.io'<N>__version__ = '2.25.1'<N>__build__ = 0x022501<N>__author__ = 'Kenneth Reitz'<N>__author_email__ = 'me@kennethreitz.org'<N>__license__ = 'Apache 2.0'<N>__copyright__ = 'Copyright 2020 Kenneth Reitz'<N>__cake__ = u'\u2728 \U0001f370 \u2728'<N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.api<N>~~~~~~~~~~~~<N><N>This module implements the Requests API.<N><N>:copyright: (c) 2012 by Kenneth Reitz.<N>:license: Apache2, see LICENSE for more details.<N>"""<N><N>from . import sessions<N><N><N>def request(method, url, **kwargs):<N>    """Constructs and sends a :class:`Request <Request>`.<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests._internal_utils<N>~~~~~~~~~~~~~~<N><N>Provides utility functions that are consumed internally by Requests<N>which depend on extremely few external helpers (such as compat)<N>"""<N><N>from .compat import is_py2, builtin_str, str<N><N>
<N>def to_native_string(string, encoding='ascii'):<N>    """Given a string object, regardless of type, returns a representation of<N>    that string in the native string type, encoding and decoding where<N>    necessary. This assumes ASCII unless told otherwise.<N>    """<N>    if isinstance(string, builtin_str):<N>        out = string<N>    else:<N>        if is_py2:<N>            out = string.encode(encoding)<N>        else:<N>            out = string.decode(encoding)<N><N>
    return out<N><N><N>def unicode_is_ascii(u_string):<N>    """Determine if unicode string only contains ASCII characters.<N><N>    :param str u_string: unicode string to check. Must be unicode<N>        and not Python 2 `str`.<N>    :rtype: bool<N>    """<N>    assert isinstance(u_string, str)<N>    try:<N>        u_string.encode('ascii')<N>        return True<N>    except UnicodeEncodeError:<N>        return False<N><N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.sessions<N>~~~~~~~~~~~~~~~~~<N><N>This module provides a Session object to manage and persist settings across<N>requests (cookies, auth, proxies).<N>"""<N>import os<N>import sys<N>import time<N>from datetime import timedelta<N>from collections import OrderedDict<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.auth<N>~~~~~~~~~~~~~<N><N>This module contains the authentication handlers for Requests.<N>"""<N><N>import os<N>import re<N>import time<N>import hashlib<N>import threading<N>import warnings<N><N>from base64 import b64encode<N><N>
from .compat import urlparse, str, basestring<N>from .cookies import extract_cookies_to_jar<N>from ._internal_utils import to_native_string<N>from .utils import parse_dict_header<N><N>CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'<N>CONTENT_TYPE_MULTI_PART = 'multipart/form-data'<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.exceptions<N>~~~~~~~~~~~~~~~~~~~<N><N>This module contains the set of Requests' exceptions.<N>"""<N>from urllib3.exceptions import HTTPError as BaseHTTPError<N><N><N>class RequestException(IOError):<N>    """There was an ambiguous exception that occurred while handling your<N>    request.<N>    """<N><N>
    def __init__(self, *args, **kwargs):<N>        """Initialize RequestException with `request` and `response` objects."""<N>        response = kwargs.pop('response', None)<N>        self.response = response<N>        self.request = kwargs.pop('request', None)<N>        if (response is not None and not self.request and<N>                hasattr(response, 'request')):<N>            self.request = self.response.request<N>        super(RequestException, self).__init__(*args, **kwargs)<N><N>
<N>class HTTPError(RequestException):<N>    """An HTTP error occurred."""<N><N><N>class ConnectionError(RequestException):<N>    """A Connection error occurred."""<N><N><N>class ProxyError(ConnectionError):<N>    """A proxy error occurred."""<N><N><N>class SSLError(ConnectionError):<N>    """An SSL error occurred."""<N><N>
<N>class Timeout(RequestException):<N>    """The request timed out.<N><N>    Catching this error will catch both<N>    :exc:`~requests.exceptions.ConnectTimeout` and<N>    :exc:`~requests.exceptions.ReadTimeout` errors.<N>    """<N><N><N>class ConnectTimeout(ConnectionError, Timeout):<N>    """The request timed out while trying to connect to the remote server.<N><N>
    Requests that produced this error are safe to retry.<N>    """<N><N><N>class ReadTimeout(Timeout):<N>    """The server did not send any data in the allotted amount of time."""<N><N><N>class URLRequired(RequestException):<N>    """A valid URL is required to make a request."""<N><N>
<N>class TooManyRedirects(RequestException):<N>    """Too many redirects."""<N><N><N>class MissingSchema(RequestException, ValueError):<N>    """The URL schema (e.g. http or https) is missing."""<N><N><N>class InvalidSchema(RequestException, ValueError):<N>    """See defaults.py for valid schemas."""<N><N>
<N>class InvalidURL(RequestException, ValueError):<N>    """The URL provided was somehow invalid."""<N><N><N>class InvalidHeader(RequestException, ValueError):<N>    """The header value provided was somehow invalid."""<N><N><N>class InvalidProxyURL(InvalidURL):<N>    """The proxy URL provided is invalid."""<N><N>
<N>class ChunkedEncodingError(RequestException):<N>    """The server declared chunked encoding but sent an invalid chunk."""<N><N><N>class ContentDecodingError(RequestException, BaseHTTPError):<N>    """Failed to decode response content."""<N><N><N>class StreamConsumedError(RequestException, TypeError):<N>    """The content for this response was already consumed."""<N><N>
<N>class RetryError(RequestException):<N>    """Custom retries logic failed"""<N><N><N>class UnrewindableBodyError(RequestException):<N>    """Requests encountered an error when trying to rewind a body."""<N><N># Warnings<N><N><N>class RequestsWarning(Warning):<N>    """Base warning for Requests."""<N><N>
<N>class FileModeWarning(RequestsWarning, DeprecationWarning):<N>    """A file was opened in text mode, but Requests determined its binary length."""<N><N><N>class RequestsDependencyWarning(RequestsWarning):<N>    """An imported dependency doesn't match the expected version range."""<N><N><N>
"""Module containing bug report helper(s)."""<N>from __future__ import print_function<N><N>import json<N>import platform<N>import sys<N>import ssl<N><N>import idna<N>import urllib3<N>import chardet<N><N>from . import __version__ as requests_version<N><N>try:<N>    from urllib3.contrib import pyopenssl<N>except ImportError:<N>    pyopenssl = None<N>    OpenSSL = None<N>    cryptography = None<N>else:<N>    import OpenSSL<N>    import cryptography<N><N>
<N>def _implementation():<N>    """Return a dict with the Python implementation and version.<N><N>    Provide both the name and the version of the Python implementation<N>    currently running. For example, on CPython 2.7.5 it will return<N>    {'name': 'CPython', 'version': '2.7.5'}.<N><N>
    This function works best on CPython and PyPy: in particular, it probably<N>    doesn't work for Jython or IronPython. Future investigation should be done<N>    to work out the correct shape of the code for those platforms.<N>    """<N>    implementation = platform.python_implementation()<N><N>
#!/usr/bin/env python<N># -*- coding: utf-8 -*-<N><N>"""<N>requests.certs<N>~~~~~~~~~~~~~~<N><N>This module returns the preferred default CA certificate bundle. There is<N>only one â€” the one from the certifi package.<N><N>If you are packaging Requests, e.g., for a Linux distribution or a managed<N>environment, you can change the definition of where() to return a separately<N>packaged CA bundle.<N>"""<N>from certifi import where<N><N>if __name__ == '__main__':<N>    print(where())<N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.utils<N>~~~~~~~~~~~~~~<N><N>This module provides utility functions that are used within Requests<N>that are also useful for external consumption.<N>"""<N><N>import codecs<N>import contextlib<N>import io<N>import os<N>import re<N>import socket<N>import struct<N>import sys<N>import tempfile<N>import warnings<N>import zipfile<N>from collections import OrderedDict<N><N>
from sys import exit<N>import os<N>from os.path import join<N><N><N>def no_config(f):<N>    f.__no_config = True<N>    return f<N><N><N>class Target:<N>    def __init__(self, buildozer):<N>        self.buildozer = buildozer<N>        self.build_mode = 'debug'<N>        self.platform_update = False<N><N>
    def check_requirements(self):<N>        pass<N><N>    def check_configuration_tokens(self, errors=None):<N>        if errors:<N>            self.buildozer.info('Check target configuration tokens')<N>            self.buildozer.error(<N>                '{0} error(s) found in the buildozer.spec'.format(<N>                len(errors)))<N>            for error in errors:<N>                print(error)<N>            exit(1)<N><N>
    def compile_platform(self):<N>        pass<N><N>    def install_platform(self):<N>        pass<N><N>    def get_custom_commands(self):<N>        result = []<N>        for x in dir(self):<N>            if not x.startswith('cmd_'):<N>                continue<N>            if x[4:] in self.buildozer.standard_cmds:<N>                continue<N>            result.append((x[4:], getattr(self, x).__doc__))<N>        return result<N><N>
'''<N>Buildozer remote<N>================<N><N>.. warning::<N><N>    This is an experimental tool and not widely used. It might not fit for you.<N><N>Pack and send the source code to a remote SSH server, bundle buildozer with it,<N>and start the build on the remote.<N>You need paramiko to make it work.<N>'''<N><N>
'''<N>OSX target, based on kivy-sdk-packager<N>'''<N><N>import sys<N>if sys.platform != 'darwin':<N>    raise NotImplementedError('This will only work on osx')<N><N>from buildozer.target import Target<N>from os.path import exists, join, abspath, dirname<N>from subprocess import check_call, check_output<N><N>
<N>class TargetOSX(Target):<N>    targetname = "osx"<N><N>    def ensure_sdk(self):<N>        self.buildozer.info('Check if kivy-sdk-packager exists')<N>        if exists(<N>                join(self.buildozer.platform_dir, 'kivy-sdk-packager-master')):<N>            self.buildozer.info(<N>                    'kivy-sdk-packager found at '<N>                '{}'.format(self.buildozer.platform_dir))<N>            return<N><N>
        self.buildozer.info('kivy-sdk-packager does not exist, clone it')<N>        platdir = self.buildozer.platform_dir<N>        check_call(<N>            ('curl', '-O', '-L',<N>            'https://github.com/kivy/kivy-sdk-packager/archive/master.zip'),<N>            cwd=platdir)<N>        check_call(('unzip', 'master.zip'), cwd=platdir)<N>        check_call(('rm', 'master.zip'), cwd=platdir)<N><N>
    def download_kivy(self, cwd, py_branch=2):<N>        current_kivy_vers = self.buildozer.config.get('app', 'osx.kivy_version')<N><N>        if exists('/Applications/Kivy{}.app'.format(py_branch)):<N>            self.buildozer.info('Kivy found in Applications dir...')<N>            check_call(<N>                ('cp', '-a', '/Applications/Kivy{}.app'.format(py_branch),<N>                'Kivy.app'), cwd=cwd)<N><N>
        else:<N>            if not exists(join(cwd, 'Kivy{}.dmg'.format(py_branch))):<N>                self.buildozer.info('Downloading kivy...')<N>                status_code = check_output(<N>                    ('curl', '-L', '--write-out', '%{http_code}', '-o', 'Kivy{}.dmg'.format(py_branch),<N>                    'https://kivy.org/downloads/{}/Kivy-{}-osx-python{}.dmg'<N>                    .format(current_kivy_vers, current_kivy_vers, py_branch)),<N>                    cwd=cwd)<N><N>
                if status_code == "404":<N>                    self.buildozer.error(<N>                        "Unable to download the Kivy App. Check osx.kivy_version in your buildozer.spec, and verify "<N>                        "Kivy servers are accessible. https://kivy.org/downloads/")<N>                    check_call(("rm", "Kivy{}.dmg".format(py_branch)), cwd=cwd)<N>                    sys.exit(1)<N><N>
            self.buildozer.info('Extracting and installing Kivy...')<N>            check_call(('hdiutil', 'attach', cwd + '/Kivy{}.dmg'.format(py_branch)))<N>            check_call(('cp', '-a', '/Volumes/Kivy/Kivy.app', './Kivy.app'), cwd=cwd)<N><N>    def ensure_kivyapp(self):<N>        self.buildozer.info('check if Kivy.app exists in local dir')<N>        kivy_app_dir = join(self.buildozer.platform_dir, 'kivy-sdk-packager-master', 'osx')<N><N>
        py_branch = self.buildozer.config.get('app', 'osx.python_version')<N><N>        if not int(py_branch) in (2, 3):<N>            self.buildozer.error('incompatible python version... aborting')<N>            sys.exit(1)<N><N>        if exists(join(kivy_app_dir, 'Kivy.app')):<N>            self.buildozer.info('Kivy.app found at ' + kivy_app_dir)<N>        else:<N>            self.download_kivy(kivy_app_dir, py_branch)<N><N>
    def check_requirements(self):<N>        self.ensure_sdk()<N>        self.ensure_kivyapp()<N><N>    def check_configuration_tokens(self, errors=None):<N>        if errors:<N>            self.buildozer.info('Check target configuration tokens')<N>            self.buildozer.error(<N>                '{0} error(s) found in the buildozer.spec'.format(<N>                len(errors)))<N>            for error in errors:<N>                print(error)<N>            sys.exit(1)<N>        # check<N><N>
    def build_package(self):<N>        self.buildozer.info('Building package')<N><N>        bc = self.buildozer.config<N>        bcg = bc.get<N>        package_name = bcg('app', 'package.name')<N>        domain = bcg('app', 'package.domain')<N>        title = bcg('app', 'title')<N>        app_deps = open('requirements.txt').read()<N>        icon = bc.getdefault('app', 'icon.filename', '')<N>        version = self.buildozer.get_version()<N>        author = bc.getdefault('app', 'author', '')<N><N>
        self.buildozer.info('Create {}.app'.format(package_name))<N>        cwd = join(self.buildozer.platform_dir, 'kivy-sdk-packager-master', 'osx')<N>        # remove kivy from app_deps<N>        app_deps = [a for a in app_deps.split('\n') if not a.startswith('#') and a not in ['kivy', '']]<N><N>
'''<N>Android target, based on python-for-android project<N>'''<N><N>import sys<N>if sys.platform == 'win32':<N>    raise NotImplementedError('Windows platform not yet working for Android')<N><N>from platform import uname<N>WSL = 'microsoft' in uname()[2].lower()<N><N>
ANDROID_API = '27'<N>ANDROID_MINAPI = '21'<N>APACHE_ANT_VERSION = '1.9.4'<N><N># This constant should *not* be updated, it is used only in the case<N># that python-for-android cannot provide a recommendation, which in<N># turn only happens if the python-for-android is old and probably<N># doesn't support any newer NDK.<N>DEFAULT_ANDROID_NDK_VERSION = '17c'<N><N>
import traceback<N>import os<N>import io<N>import re<N>import ast<N>from pipes import quote<N>from sys import platform, executable<N>from buildozer import BuildozerException, USE_COLOR<N>from buildozer.target import Target<N>from os import environ<N>from os.path import exists, join, realpath, expanduser, basename, relpath<N>from platform import architecture<N>from shutil import copyfile, rmtree<N>from glob import glob<N>from time import sleep<N><N>
from buildozer.libs.version import parse<N>from distutils.version import LooseVersion<N><N># buildozer.spec tokens that used to exist but are now ignored<N>DEPRECATED_TOKENS = (('app', 'android.sdk'), )<N><N># Default SDK tag to download. This is not a configurable option<N># because it doesn't seem to matter much, it is normally correct to<N># download once then update all the components as buildozer already<N># does.<N>DEFAULT_SDK_TAG = '6514223'<N><N>
DEFAULT_ARCH = 'armeabi-v7a'<N><N>MSG_P4A_RECOMMENDED_NDK_ERROR = (<N>    "WARNING: Unable to find recommended Android NDK for current "<N>    "installation of python-for-android, defaulting to the default "<N>    "version r{android_ndk}".format(android_ndk=DEFAULT_ANDROID_NDK_VERSION)<N>)<N><N>
<N>class TargetAndroid(Target):<N>    targetname = 'android'<N>    p4a_directory_name = "python-for-android"<N>    p4a_fork = 'kivy'<N>    p4a_branch = 'master'<N>    p4a_apk_cmd = "apk --debug --bootstrap="<N>    p4a_recommended_ndk_version = None<N>    extra_p4a_args = ''<N><N>
'''<N>iOS target, based on kivy-ios project<N>'''<N><N>import sys<N>import plistlib<N>from buildozer import BuildozerCommandException<N>from buildozer.target import Target, no_config<N>from os.path import join, basename, expanduser, realpath<N>from getpass import getpass<N><N>
#!/usr/bin/env python<N># -*- coding: utf-8 -*-<N>"""<N>Continuous Integration helper script.<N>Automatically detects recipes modified in a changeset (compares with master)<N>and recompiles them.<N><N>To run locally, set the environment variables before running:<N>```<N>ANDROID_SDK_HOME=~/.buildozer/android/platform/android-sdk-20<N>ANDROID_NDK_HOME=~/.buildozer/android/platform/android-ndk-r9c<N>./ci/rebuild_update_recipes.py<N>```<N><N>
import os<N>import sys<N>import warnings<N><N># Remove '' and current working directory from the first entry<N># of sys.path, if present to avoid using current directory<N># in pip commands check, freeze, install, list and show,<N># when invoked as python -m pip <command><N>if sys.path[0] in ("", os.getcwd()):<N>    sys.path.pop(0)<N><N>
# If we are running from a wheel, add the wheel to sys.path<N># This allows the usage python pip-*.whl/pip install pip-*.whl<N>if __package__ == "":<N>    # __file__ is pip-*.whl/pip/__main__.py<N>    # first dirname call strips of '/__main__.py', second strips off '/pip'<N>    # Resulting path is the name of the wheel itself<N>    # Add that to sys.path so we can import pip<N>    path = os.path.dirname(os.path.dirname(__file__))<N>    sys.path.insert(0, path)<N><N>
if __name__ == "__main__":<N>    # Work around the error reported in #9540, pending a proper fix.<N>    # Note: It is essential the warning filter is set *before* importing<N>    #       pip, as the deprecation happens at import time, not runtime.<N>    warnings.filterwarnings(<N>        "ignore", category=DeprecationWarning, module=".*packaging\\.version"<N>    )<N>    from pip._internal.cli.main import main as _main<N><N>
from typing import List, Optional<N><N>__version__ = "21.1.1"<N><N><N>def main(args=None):<N>    # type: (Optional[List[str]]) -> int<N>    """This is an internal API only meant for use by pip's own console scripts.<N><N>    For additional details, see https://github.com/pypa/pip/issues/7498.<N>    """<N>    from pip._internal.utils.entrypoints import _wrapper<N><N>    return _wrapper(args)<N>
from typing import List, Optional<N><N>import pip._internal.utils.inject_securetransport  # noqa<N><N><N>def main(args=None):<N>    # type: (Optional[List[str]]) -> int<N>    """This is preserved for old console scripts that may still be referencing<N>    it.<N><N>    For additional details, see https://github.com/pypa/pip/issues/7498.<N>    """<N>    from pip._internal.utils.entrypoints import _wrapper<N><N>    return _wrapper(args)<N>
"""Configuration management setup<N><N>Some terminology:<N>- name<N>  As written in config files.<N>- value<N>  Value associated with a name<N>- key<N>  Name combined with it's section (section.name)<N>- variant<N>  A single word describing where the configuration key-value pair came from<N>"""<N><N>
import configparser<N>import locale<N>import logging<N>import os<N>import sys<N>from typing import Any, Dict, Iterable, List, NewType, Optional, Tuple<N><N>from pip._internal.exceptions import (<N>    ConfigurationError,<N>    ConfigurationFileCouldNotBeLoaded,<N>)<N>from pip._internal.utils import appdirs<N>from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.misc import ensure_dir, enum<N><N>
"""Orchestrator for building wheels from InstallRequirements.<N>"""<N><N>import logging<N>import os.path<N>import re<N>import shutil<N>from typing import Any, Callable, Iterable, List, Optional, Tuple<N><N>from pip._vendor.packaging.utils import canonicalize_name, canonicalize_version<N>from pip._vendor.packaging.version import InvalidVersion, Version<N><N>
"""Cache Management<N>"""<N><N>import hashlib<N>import json<N>import logging<N>import os<N>from typing import Any, Dict, List, Optional, Set<N><N>from pip._vendor.packaging.tags import Tag, interpreter_name, interpreter_version<N>from pip._vendor.packaging.utils import canonicalize_name<N><N>
from pip._internal.exceptions import InvalidWheelFilename<N>from pip._internal.models.format_control import FormatControl<N>from pip._internal.models.link import Link<N>from pip._internal.models.wheel import Wheel<N>from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds<N>from pip._internal.utils.urls import path_to_url<N><N>
logger = logging.getLogger(__name__)<N><N><N>def _hash_dict(d):<N>    # type: (Dict[str, str]) -> str<N>    """Return a stable sha224 of a dictionary."""<N>    s = json.dumps(d, sort_keys=True, separators=(",", ":"), ensure_ascii=True)<N>    return hashlib.sha224(s.encode("ascii")).hexdigest()<N><N>
<N>class Cache:<N>    """An abstract class - provides cache directories for data from links<N><N><N>        :param cache_dir: The root of the cache.<N>        :param format_control: An object of FormatControl class to limit<N>            binaries being read from the cache.<N>        :param allowed_formats: which formats of files the cache should store.<N>            ('binary' and 'source' are the only allowed values)<N>    """<N><N>
    def __init__(self, cache_dir, format_control, allowed_formats):<N>        # type: (str, FormatControl, Set[str]) -> None<N>        super().__init__()<N>        assert not cache_dir or os.path.isabs(cache_dir)<N>        self.cache_dir = cache_dir or None<N>        self.format_control = format_control<N>        self.allowed_formats = allowed_formats<N><N>
        _valid_formats = {"source", "binary"}<N>        assert self.allowed_formats.union(_valid_formats) == _valid_formats<N><N>    def _get_cache_path_parts(self, link):<N>        # type: (Link) -> List[str]<N>        """Get parts of part that must be os.path.joined with cache_dir<N>        """<N><N>
        # We want to generate an url to use as our cache key, we don't want to<N>        # just re-use the URL because it might have other items in the fragment<N>        # and we don't care about those.<N>        key_parts = {"url": link.url_without_fragment}<N>        if link.hash_name is not None and link.hash is not None:<N>            key_parts[link.hash_name] = link.hash<N>        if link.subdirectory_fragment:<N>            key_parts["subdirectory"] = link.subdirectory_fragment<N><N>
        # Include interpreter name, major and minor version in cache key<N>        # to cope with ill-behaved sdists that build a different wheel<N>        # depending on the python version their setup.py is being run on,<N>        # and don't encode the difference in compatibility tags.<N>        # https://github.com/pypa/pip/issues/7296<N>        key_parts["interpreter_name"] = interpreter_name()<N>        key_parts["interpreter_version"] = interpreter_version()<N><N>
        # Encode our key url with sha224, we'll use this because it has similar<N>        # security properties to sha256, but with a shorter total output (and<N>        # thus less secure). However the differences don't make a lot of<N>        # difference for our use case here.<N>        hashed = _hash_dict(key_parts)<N><N>
        # We want to nest the directories some to prevent having a ton of top<N>        # level directories where we might run out of sub directories on some<N>        # FS.<N>        parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]<N><N>        return parts<N><N>
    def _get_candidates(self, link, canonical_package_name):<N>        # type: (Link, str) -> List[Any]<N>        can_not_cache = (<N>            not self.cache_dir or<N>            not canonical_package_name or<N>            not link<N>        )<N>        if can_not_cache:<N>            return []<N><N>
        formats = self.format_control.get_allowed_formats(<N>            canonical_package_name<N>        )<N>        if not self.allowed_formats.intersection(formats):<N>            return []<N><N>        candidates = []<N>        path = self.get_path_for_link(link)<N>        if os.path.isdir(path):<N>            for candidate in os.listdir(path):<N>                candidates.append((candidate, path))<N>        return candidates<N><N>
import os<N>from collections import namedtuple<N>from typing import Any, List, Optional<N><N>from pip._vendor import toml<N>from pip._vendor.packaging.requirements import InvalidRequirement, Requirement<N><N>from pip._internal.exceptions import InstallationError<N><N>
<N>def _is_list_of_str(obj):<N>    # type: (Any) -> bool<N>    return (<N>        isinstance(obj, list) and<N>        all(isinstance(item, str) for item in obj)<N>    )<N><N><N>def make_pyproject_path(unpacked_source_directory):<N>    # type: (str) -> str<N>    return os.path.join(unpacked_source_directory, 'pyproject.toml')<N><N>
<N>BuildSystemDetails = namedtuple('BuildSystemDetails', [<N>    'requires', 'backend', 'check', 'backend_path'<N>])<N><N><N>def load_pyproject_toml(<N>    use_pep517,  # type: Optional[bool]<N>    pyproject_toml,  # type: str<N>    setup_py,  # type: str<N>    req_name  # type: str<N>):<N>    # type: (...) -> Optional[BuildSystemDetails]<N>    """Load the pyproject.toml file.<N><N>
    Parameters:<N>        use_pep517 - Has the user requested PEP 517 processing? None<N>                     means the user hasn't explicitly specified.<N>        pyproject_toml - Location of the project's pyproject.toml file<N>        setup_py - Location of the project's setup.py file<N>        req_name - The name of the requirement we're processing (for<N>                   error reporting)<N><N>
"""Exceptions used throughout package"""<N><N>import configparser<N>from itertools import chain, groupby, repeat<N>from typing import TYPE_CHECKING, Dict, List, Optional<N><N>from pip._vendor.pkg_resources import Distribution<N>from pip._vendor.requests.models import Request, Response<N><N>
if TYPE_CHECKING:<N>    from hashlib import _Hash<N><N>    from pip._internal.req.req_install import InstallRequirement<N><N><N>class PipError(Exception):<N>    """Base pip exception"""<N><N><N>class ConfigurationError(PipError):<N>    """General exception in configuration"""<N><N>
"""Build Environment used for isolation during sdist building<N>"""<N><N>import contextlib<N>import logging<N>import os<N>import pathlib<N>import sys<N>import textwrap<N>import zipfile<N>from collections import OrderedDict<N>from sysconfig import get_paths<N>from types import TracebackType<N>from typing import TYPE_CHECKING, Iterable, Iterator, List, Optional, Set, Tuple, Type<N><N>
from pip._vendor.certifi import where<N>from pip._vendor.pkg_resources import Requirement, VersionConflict, WorkingSet<N><N>from pip import __file__ as pip_location<N>from pip._internal.cli.spinners import open_spinner<N>from pip._internal.locations import get_platlib, get_prefixed_libs, get_purelib<N>from pip._internal.utils.subprocess import call_subprocess<N>from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds<N><N>
if TYPE_CHECKING:<N>    from pip._internal.index.package_finder import PackageFinder<N><N>logger = logging.getLogger(__name__)<N><N><N>class _Prefix:<N><N>    def __init__(self, path):<N>        # type: (str) -> None<N>        self.path = path<N>        self.setup = False<N>        self.bin_dir = get_paths(<N>            'nt' if os.name == 'nt' else 'posix_prefix',<N>            vars={'base': path, 'platbase': path}<N>        )['scripts']<N>        self.lib_dirs = get_prefixed_libs(path)<N><N>
<N>@contextlib.contextmanager<N>def _create_standalone_pip() -> Iterator[str]:<N>    """Create a "standalone pip" zip file.<N><N>    The zip file's content is identical to the currently-running pip.<N>    It will be used to install requirements into the build environment.<N>    """<N>    source = pathlib.Path(pip_location).resolve().parent<N><N>
    # Return the current instance if it is already a zip file. This can happen<N>    # if a PEP 517 requirement is an sdist itself.<N>    if not source.is_dir() and source.parent.name == "__env_pip__.zip":<N>        yield str(source)<N>        return<N><N>
    with TempDirectory(kind="standalone-pip") as tmp_dir:<N>        pip_zip = os.path.join(tmp_dir.path, "__env_pip__.zip")<N>        with zipfile.ZipFile(pip_zip, "w") as zf:<N>            for child in source.rglob("*"):<N>                zf.write(child, child.relative_to(source.parent).as_posix())<N>        yield os.path.join(pip_zip, "pip")<N><N>
<N>class BuildEnvironment:<N>    """Creates and manages an isolated environment to install build deps<N>    """<N><N>    def __init__(self):<N>        # type: () -> None<N>        temp_dir = TempDirectory(<N>            kind=tempdir_kinds.BUILD_ENV, globally_managed=True<N>        )<N><N>
        self._prefixes = OrderedDict(<N>            (name, _Prefix(os.path.join(temp_dir.path, name)))<N>            for name in ('normal', 'overlay')<N>        )<N><N>        self._bin_dirs = []  # type: List[str]<N>        self._lib_dirs = []  # type: List[str]<N>        for prefix in reversed(list(self._prefixes.values())):<N>            self._bin_dirs.append(prefix.bin_dir)<N>            self._lib_dirs.extend(prefix.lib_dirs)<N><N>
from typing import List, Optional<N><N><N>def main(args=None):<N>    # type: (Optional[List[str]]) -> int<N>    """This is preserved for old console scripts that may still be referencing<N>    it.<N><N>    For additional details, see https://github.com/pypa/pip/issues/7498.<N>    """<N>    from pip._internal.utils.entrypoints import _wrapper<N><N>    return _wrapper(args)<N>
import zipfile<N>from typing import Iterator, List, Optional<N><N>from pip._vendor import pkg_resources<N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.packaging.version import parse as parse_version<N><N>from pip._internal.utils import misc  # TODO: Move definition here.<N>from pip._internal.utils.packaging import get_installer<N>from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel<N><N>
from .base import BaseDistribution, BaseEnvironment, DistributionVersion<N><N><N>class Distribution(BaseDistribution):<N>    def __init__(self, dist):<N>        # type: (pkg_resources.Distribution) -> None<N>        self._dist = dist<N><N>    @classmethod<N>    def from_wheel(cls, path, name):<N>        # type: (str, str) -> Distribution<N>        with zipfile.ZipFile(path, allowZip64=True) as zf:<N>            dist = pkg_resources_distribution_for_wheel(zf, name, path)<N>        return cls(dist)<N><N>
    @property<N>    def location(self):<N>        # type: () -> Optional[str]<N>        return self._dist.location<N><N>    @property<N>    def metadata_version(self):<N>        # type: () -> Optional[str]<N>        for line in self._dist.get_metadata_lines(self._dist.PKG_INFO):<N>            if line.lower().startswith("metadata-version:"):<N>                return line.split(":", 1)[-1].strip()<N>        return None<N><N>
    @property<N>    def canonical_name(self):<N>        # type: () -> str<N>        return canonicalize_name(self._dist.project_name)<N><N>    @property<N>    def version(self):<N>        # type: () -> DistributionVersion<N>        return parse_version(self._dist.version)<N><N>
    @property<N>    def installer(self):<N>        # type: () -> str<N>        return get_installer(self._dist)<N><N>    @property<N>    def editable(self):<N>        # type: () -> bool<N>        return misc.dist_is_editable(self._dist)<N><N>    @property<N>    def local(self):<N>        # type: () -> bool<N>        return misc.dist_is_local(self._dist)<N><N>
    @property<N>    def in_usersite(self):<N>        # type: () -> bool<N>        return misc.dist_in_usersite(self._dist)<N><N><N>class Environment(BaseEnvironment):<N>    def __init__(self, ws):<N>        # type: (pkg_resources.WorkingSet) -> None<N>        self._ws = ws<N><N>
    @classmethod<N>    def default(cls):<N>        # type: () -> BaseEnvironment<N>        return cls(pkg_resources.working_set)<N><N>    @classmethod<N>    def from_paths(cls, paths):<N>        # type: (Optional[List[str]]) -> BaseEnvironment<N>        return cls(pkg_resources.WorkingSet(paths))<N><N>
from typing import List, Optional<N><N>from .base import BaseDistribution, BaseEnvironment<N><N><N>def get_default_environment():<N>    # type: () -> BaseEnvironment<N>    """Get the default representation for the current environment.<N><N>    This returns an Environment instance from the chosen backend. The default<N>    Environment instance should be built from ``sys.path`` and may use caching<N>    to share instance state accorss calls.<N>    """<N>    from .pkg_resources import Environment<N><N>
    return Environment.default()<N><N><N>def get_environment(paths):<N>    # type: (Optional[List[str]]) -> BaseEnvironment<N>    """Get a representation of the environment specified by ``paths``.<N><N>    This returns an Environment instance from the chosen backend based on the<N>    given import paths. The backend must build a fresh instance representing<N>    the state of installed distributions when this function is called.<N>    """<N>    from .pkg_resources import Environment<N><N>
    return Environment.from_paths(paths)<N><N><N>def get_wheel_distribution(wheel_path, canonical_name):<N>    # type: (str, str) -> BaseDistribution<N>    """Get the representation of the specified wheel's distribution metadata.<N><N>    This returns a Distribution instance from the chosen backend based on<N>    the given wheel's ``.dist-info`` directory.<N><N>
import logging<N>import re<N>from typing import Container, Iterator, List, Optional, Union<N><N>from pip._vendor.packaging.version import LegacyVersion, Version<N><N>from pip._internal.utils.misc import stdlib_pkgs  # TODO: Move definition here.<N><N>DistributionVersion = Union[LegacyVersion, Version]<N><N>
logger = logging.getLogger(__name__)<N><N><N>class BaseDistribution:<N>    @property<N>    def location(self):<N>        # type: () -> Optional[str]<N>        """Where the distribution is loaded from.<N><N>        A string value is not necessarily a filesystem path, since distributions<N>        can be loaded from other sources, e.g. arbitrary zip archives. ``None``<N>        means the distribution is created in-memory.<N>        """<N>        raise NotImplementedError()<N><N>
    @property<N>    def metadata_version(self):<N>        # type: () -> Optional[str]<N>        """Value of "Metadata-Version:" in the distribution, if available."""<N>        raise NotImplementedError()<N><N>    @property<N>    def canonical_name(self):<N>        # type: () -> str<N>        raise NotImplementedError()<N><N>
    @property<N>    def version(self):<N>        # type: () -> DistributionVersion<N>        raise NotImplementedError()<N><N>    @property<N>    def installer(self):<N>        # type: () -> str<N>        raise NotImplementedError()<N><N>    @property<N>    def editable(self):<N>        # type: () -> bool<N>        raise NotImplementedError()<N><N>
    @property<N>    def local(self):<N>        # type: () -> bool<N>        raise NotImplementedError()<N><N>    @property<N>    def in_usersite(self):<N>        # type: () -> bool<N>        raise NotImplementedError()<N><N><N>class BaseEnvironment:<N>    """An environment containing distributions to introspect."""<N><N>
    @classmethod<N>    def default(cls):<N>        # type: () -> BaseEnvironment<N>        raise NotImplementedError()<N><N>    @classmethod<N>    def from_paths(cls, paths):<N>        # type: (Optional[List[str]]) -> BaseEnvironment<N>        raise NotImplementedError()<N><N>
    def get_distribution(self, name):<N>        # type: (str) -> Optional[BaseDistribution]<N>        """Given a requirement name, return the installed distributions."""<N>        raise NotImplementedError()<N><N>    def _iter_distributions(self):<N>        # type: () -> Iterator[BaseDistribution]<N>        """Iterate through installed distributions.<N><N>
        This function should be implemented by subclass, but never called<N>        directly. Use the public ``iter_distribution()`` instead, which<N>        implements additional logic to make sure the distributions are valid.<N>        """<N>        raise NotImplementedError()<N><N>
import distutils.util  # FIXME: For change_root.<N>import logging<N>import os<N>import sys<N>import sysconfig<N>import typing<N><N>from pip._internal.exceptions import InvalidSchemeCombination, UserInstallationInvalid<N>from pip._internal.models.scheme import SCHEME_KEYS, Scheme<N>from pip._internal.utils.virtualenv import running_under_virtualenv<N><N>
import logging<N>import pathlib<N>import sys<N>import sysconfig<N>from typing import List, Optional<N><N>from pip._internal.models.scheme import SCHEME_KEYS, Scheme<N><N>from . import _distutils, _sysconfig<N>from .base import (<N>    USER_CACHE_DIR,<N>    get_major_minor_version,<N>    get_src_prefix,<N>    site_packages,<N>    user_site,<N>)<N><N>
__all__ = [<N>    "USER_CACHE_DIR",<N>    "get_bin_prefix",<N>    "get_bin_user",<N>    "get_major_minor_version",<N>    "get_platlib",<N>    "get_prefixed_libs",<N>    "get_purelib",<N>    "get_scheme",<N>    "get_src_prefix",<N>    "site_packages",<N>    "user_site",<N>]<N><N>
<N>logger = logging.getLogger(__name__)<N><N><N>def _default_base(*, user: bool) -> str:<N>    if user:<N>        base = sysconfig.get_config_var("userbase")<N>    else:<N>        base = sysconfig.get_config_var("base")<N>    assert base is not None<N>    return base<N><N>
<N>def _warn_if_mismatch(old: pathlib.Path, new: pathlib.Path, *, key: str) -> bool:<N>    if old == new:<N>        return False<N>    issue_url = "https://github.com/pypa/pip/issues/9617"<N>    message = (<N>        "Value for %s does not match. Please report this to <%s>"<N>        "\ndistutils: %s"<N>        "\nsysconfig: %s"<N>    )<N>    logger.debug(message, key, issue_url, old, new)<N>    return True<N><N>
<N>def _log_context(<N>    *,<N>    user: bool = False,<N>    home: Optional[str] = None,<N>    root: Optional[str] = None,<N>    prefix: Optional[str] = None,<N>) -> None:<N>    message = (<N>        "Additional context:" "\nuser = %r" "\nhome = %r" "\nroot = %r" "\nprefix = %r"<N>    )<N>    logger.debug(message, user, home, root, prefix)<N><N>
"""Locations where we look for configs, install stuff, etc"""<N><N># The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import os<N>import sys<N>from distutils.cmd import Command as DistutilsCommand<N>from distutils.command.install import SCHEME_KEYS<N>from distutils.command.install import install as distutils_install_command<N>from distutils.sysconfig import get_python_lib<N>from typing import Dict, List, Optional, Tuple, Union, cast<N><N>
from pip._internal.models.scheme import Scheme<N>from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.virtualenv import running_under_virtualenv<N><N>from .base import get_major_minor_version<N><N><N>def _distutils_scheme(<N>    dist_name, user=False, home=None, root=None, isolated=False, prefix=None<N>):<N>    # type:(str, bool, str, str, bool, str) -> Dict[str, str]<N>    """<N>    Return a distutils install scheme<N>    """<N>    from distutils.dist import Distribution<N><N>
import os<N>import site<N>import sys<N>import sysconfig<N>import typing<N><N>from pip._internal.utils import appdirs<N>from pip._internal.utils.virtualenv import running_under_virtualenv<N><N># Application Directories<N>USER_CACHE_DIR = appdirs.user_cache_dir("pip")<N><N>
# FIXME doesn't account for venv linked to global site-packages<N>site_packages = sysconfig.get_path("purelib")  # type: typing.Optional[str]<N><N><N>def get_major_minor_version():<N>    # type: () -> str<N>    """<N>    Return the major-minor version of the current Python as a string, e.g.<N>    "3.7" or "3.10".<N>    """<N>    return "{}.{}".format(*sys.version_info)<N><N>
<N>def get_src_prefix():<N>    # type: () -> str<N>    if running_under_virtualenv():<N>        src_prefix = os.path.join(sys.prefix, "src")<N>    else:<N>        # FIXME: keep src in cwd for now (it is not a temporary folder)<N>        try:<N>            src_prefix = os.path.join(os.getcwd(), "src")<N>        except OSError:<N>            # In case the current working directory has been renamed or deleted<N>            sys.exit("The folder you are executing pip from can no longer be found.")<N><N>
    # under macOS + virtualenv sys.prefix is not properly resolved<N>    # it is something like /path/to/python/bin/..<N>    return os.path.abspath(src_prefix)<N><N><N>try:<N>    # Use getusersitepackages if this is present, as it ensures that the<N>    # value is initialised properly.<N>    user_site = site.getusersitepackages()  # type: typing.Optional[str]<N>except AttributeError:<N>    user_site = site.USER_SITE<N><N><N>
import contextlib<N>import itertools<N>import logging<N>import sys<N>import time<N>from typing import IO, Iterator<N><N>from pip._vendor.progress import HIDE_CURSOR, SHOW_CURSOR<N><N>from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.logging import get_indentation<N><N>
logger = logging.getLogger(__name__)<N><N><N>class SpinnerInterface:<N>    def spin(self):<N>        # type: () -> None<N>        raise NotImplementedError()<N><N>    def finish(self, final_status):<N>        # type: (str) -> None<N>        raise NotImplementedError()<N><N>
SUCCESS = 0<N>ERROR = 1<N>UNKNOWN_ERROR = 2<N>VIRTUALENV_NOT_FOUND = 3<N>PREVIOUS_BUILD_DIR_ERROR = 4<N>NO_MATCHES_FOUND = 23<N>
"""Logic that powers autocompletion installed by ``pip completion``.<N>"""<N><N>import optparse<N>import os<N>import sys<N>from itertools import chain<N>from typing import Any, Iterable, List, Optional<N><N>from pip._internal.cli.main_parser import create_main_parser<N>from pip._internal.commands import commands_dict, create_command<N>from pip._internal.utils.misc import get_installed_distributions<N><N>
<N>def autocomplete():<N>    # type: () -> None<N>    """Entry Point for completion of main and subcommand options."""<N>    # Don't complete if user hasn't sourced bash_completion file.<N>    if "PIP_AUTO_COMPLETE" not in os.environ:<N>        return<N>    cwords = os.environ["COMP_WORDS"].split()[1:]<N>    cword = int(os.environ["COMP_CWORD"])<N>    try:<N>        current = cwords[cword - 1]<N>    except IndexError:<N>        current = ""<N><N>
"""Subpackage containing all of pip's command line interface related code<N>"""<N><N># This file intentionally does not import submodules<N>
import itertools<N>import sys<N>from signal import SIGINT, default_int_handler, signal<N>from typing import Any, Dict, List<N><N>from pip._vendor.progress.bar import Bar, FillingCirclesBar, IncrementalBar<N>from pip._vendor.progress.spinner import Spinner<N><N>
from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.logging import get_indentation<N>from pip._internal.utils.misc import format_size<N><N>try:<N>    from pip._vendor import colorama<N># Lots of different errors can come from this, including SystemError and<N># ImportError.<N>except Exception:<N>    colorama = None<N><N>
<N>def _select_progress_class(preferred, fallback):<N>    # type: (Bar, Bar) -> Bar<N>    encoding = getattr(preferred.file, "encoding", None)<N><N>    # If we don't know what encoding this file is in, then we'll just assume<N>    # that it doesn't support unicode and use the ASCII bar.<N>    if not encoding:<N>        return fallback<N><N>
    # Collect all of the possible characters we want to use with the preferred<N>    # bar.<N>    characters = [<N>        getattr(preferred, "empty_fill", ""),<N>        getattr(preferred, "fill", ""),<N>    ]<N>    characters += list(getattr(preferred, "phases", []))<N><N>
    # Try to decode the characters we're using for the bar using the encoding<N>    # of the given file, if this works then we'll assume that we can use the<N>    # fancier bar and if not we'll fall back to the plaintext bar.<N>    try:<N>        "".join(characters).encode(encoding)<N>    except UnicodeEncodeError:<N>        return fallback<N>    else:<N>        return preferred<N><N>
<N>_BaseBar = _select_progress_class(IncrementalBar, Bar)  # type: Any<N><N><N>class InterruptibleMixin:<N>    """<N>    Helper to ensure that self.finish() gets called on keyboard interrupt.<N><N>    This allows downloads to be interrupted without leaving temporary state<N>    (like hidden cursors) behind.<N><N>
"""<N>shared options and groups<N><N>The principle here is to define options once, but *not* instantiate them<N>globally. One reason being that options with action='append' can carry state<N>between parses. pip parses general options twice internally, and shouldn't<N>pass on state. To be consistent, all options will follow this design.<N>"""<N><N>
# The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import os<N>import textwrap<N>import warnings<N>from functools import partial<N>from optparse import SUPPRESS_HELP, Option, OptionGroup, OptionParser, Values<N>from textwrap import dedent<N>from typing import Any, Callable, Dict, Optional, Tuple<N><N>
"""A single place for constructing and exposing the main parser<N>"""<N><N>import os<N>import sys<N>from typing import List, Tuple<N><N>from pip._internal.cli import cmdoptions<N>from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter<N>from pip._internal.commands import commands_dict, get_similar_commands<N>from pip._internal.exceptions import CommandError<N>from pip._internal.utils.misc import get_pip_version, get_prog<N><N>
__all__ = ["create_main_parser", "parse_command"]<N><N><N>def create_main_parser():<N>    # type: () -> ConfigOptionParser<N>    """Creates and returns the main parser for pip's CLI"""<N><N>    parser = ConfigOptionParser(<N>        usage="\n%prog <command> [options]",<N>        add_help_option=False,<N>        formatter=UpdatingDefaultsHelpFormatter(),<N>        name="global",<N>        prog=get_prog(),<N>    )<N>    parser.disable_interspersed_args()<N><N>
    parser.version = get_pip_version()<N><N>    # add the general options<N>    gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)<N>    parser.add_option_group(gen_opts)<N><N>    # so the help formatter knows<N>    parser.main = True  # type: ignore<N><N>
    # create command listing for description<N>    description = [""] + [<N>        f"{name:27} {command_info.summary}"<N>        for name, command_info in commands_dict.items()<N>    ]<N>    parser.description = "\n".join(description)<N><N>    return parser<N><N>
"""Base option parser setup"""<N><N>import logging<N>import optparse<N>import shutil<N>import sys<N>import textwrap<N>from contextlib import suppress<N>from typing import Any, Dict, Iterator, List, Tuple<N><N>from pip._internal.cli.status_codes import UNKNOWN_ERROR<N>from pip._internal.configuration import Configuration, ConfigurationError<N>from pip._internal.utils.misc import redact_auth_from_url, strtobool<N><N>
from contextlib import ExitStack, contextmanager<N>from typing import ContextManager, Iterator, TypeVar<N><N>_T = TypeVar("_T", covariant=True)<N><N><N>class CommandContextMixIn:<N>    def __init__(self):<N>        # type: () -> None<N>        super().__init__()<N>        self._in_main_context = False<N>        self._main_context = ExitStack()<N><N>
    @contextmanager<N>    def main_context(self):<N>        # type: () -> Iterator[None]<N>        assert not self._in_main_context<N><N>        self._in_main_context = True<N>        try:<N>            with self._main_context:<N>                yield<N>        finally:<N>            self._in_main_context = False<N><N>
"""Contains the Command base classes that depend on PipSession.<N><N>The classes in this module are in a separate module so the commands not<N>needing download / PackageFinder capability don't unnecessarily import the<N>PackageFinder machinery and all its vendored dependencies, etc.<N>"""<N><N>
"""Primary application entrypoint.<N>"""<N>import locale<N>import logging<N>import os<N>import sys<N>from typing import List, Optional<N><N>from pip._internal.cli.autocompletion import autocomplete<N>from pip._internal.cli.main_parser import parse_command<N>from pip._internal.commands import create_command<N>from pip._internal.exceptions import PipError<N>from pip._internal.utils import deprecation<N><N>
logger = logging.getLogger(__name__)<N><N><N># Do not import and use main() directly! Using it directly is actively<N># discouraged by pip's maintainers. The name, location and behavior of<N># this function is subject to change, so calling it directly is not<N># portable across different pip versions.<N><N>
# In addition, running pip in-process is unsupported and unsafe. This is<N># elaborated in detail at<N># https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program.<N># That document also provides suggestions that should work for nearly<N># all users that are considering importing and using main() directly.<N><N>
# However, we know that certain users will still want to invoke pip<N># in-process. If you understand and accept the implications of using pip<N># in an unsupported manner, the best approach is to use runpy to avoid<N># depending on the exact location of this entry point.<N><N>
# The following example shows how to use runpy to invoke pip in that<N># case:<N>#<N>#     sys.argv = ["pip", your, args, here]<N>#     runpy.run_module("pip", run_name="__main__")<N>#<N># Note that this will exit the process after running, unlike a direct<N># call to main. As it is not safe to do any processing after calling<N># main, this should not be an issue in practice.<N><N>
<N>def main(args=None):<N>    # type: (Optional[List[str]]) -> int<N>    if args is None:<N>        args = sys.argv[1:]<N><N>    # Configure our deprecation warnings to be sent through loggers<N>    deprecation.install_warning_logger()<N><N>    autocomplete()<N><N>
import logging<N>from typing import List, Optional, Tuple<N><N>from pip._internal.utils.misc import HiddenText, display_path<N>from pip._internal.utils.subprocess import make_command<N>from pip._internal.utils.urls import path_to_url<N>from pip._internal.vcs.versioncontrol import (<N>    AuthInfo,<N>    RemoteNotFoundError,<N>    RevOptions,<N>    VersionControl,<N>    vcs,<N>)<N><N>
logger = logging.getLogger(__name__)<N><N><N>class Bazaar(VersionControl):<N>    name = 'bzr'<N>    dirname = '.bzr'<N>    repo_name = 'branch'<N>    schemes = (<N>        'bzr+http', 'bzr+https', 'bzr+ssh', 'bzr+sftp', 'bzr+ftp',<N>        'bzr+lp', 'bzr+file'<N>    )<N><N>
import logging<N>import os.path<N>import re<N>import urllib.parse<N>import urllib.request<N>from typing import List, Optional, Tuple<N><N>from pip._vendor.packaging.version import _BaseVersion<N>from pip._vendor.packaging.version import parse as parse_version<N><N>
from pip._internal.exceptions import BadCommand, InstallationError<N>from pip._internal.utils.misc import HiddenText, display_path, hide_url<N>from pip._internal.utils.subprocess import make_command<N>from pip._internal.vcs.versioncontrol import (<N>    AuthInfo,<N>    RemoteNotFoundError,<N>    RevOptions,<N>    VersionControl,<N>    find_path_to_setup_from_repo_root,<N>    vcs,<N>)<N><N>
urlsplit = urllib.parse.urlsplit<N>urlunsplit = urllib.parse.urlunsplit<N><N><N>logger = logging.getLogger(__name__)<N><N><N>HASH_REGEX = re.compile('^[a-fA-F0-9]{40}$')<N><N><N>def looks_like_hash(sha):<N>    # type: (str) -> bool<N>    return bool(HASH_REGEX.match(sha))<N><N>
<N>class Git(VersionControl):<N>    name = 'git'<N>    dirname = '.git'<N>    repo_name = 'clone'<N>    schemes = (<N>        'git+http', 'git+https', 'git+ssh', 'git+git', 'git+file',<N>    )<N>    # Prevent the user's environment variables from interfering with pip:<N>    # https://github.com/pypa/pip/issues/1130<N>    unset_environ = ('GIT_DIR', 'GIT_WORK_TREE')<N>    default_arg_rev = 'HEAD'<N><N>
"""Handles all VCS (version control) support"""<N><N>import logging<N>import os<N>import shutil<N>import sys<N>import urllib.parse<N>from typing import (<N>    Any,<N>    Dict,<N>    Iterable,<N>    Iterator,<N>    List,<N>    Mapping,<N>    Optional,<N>    Tuple,<N>    Type,<N>    Union,<N>)<N><N>
from pip._internal.cli.spinners import SpinnerInterface<N>from pip._internal.exceptions import BadCommand, InstallationError<N>from pip._internal.utils.misc import (<N>    HiddenText,<N>    ask_path_exists,<N>    backup_dir,<N>    display_path,<N>    hide_url,<N>    hide_value,<N>    rmtree,<N>)<N>from pip._internal.utils.subprocess import CommandArgs, call_subprocess, make_command<N>from pip._internal.utils.urls import get_url_scheme<N><N>
__all__ = ['vcs']<N><N><N>logger = logging.getLogger(__name__)<N><N>AuthInfo = Tuple[Optional[str], Optional[str]]<N><N><N>def is_url(name):<N>    # type: (str) -> bool<N>    """<N>    Return true if the name looks like a URL.<N>    """<N>    scheme = get_url_scheme(name)<N>    if scheme is None:<N>        return False<N>    return scheme in ['http', 'https', 'file', 'ftp'] + vcs.all_schemes<N><N>
import logging<N>import os<N>import re<N>from typing import List, Optional, Tuple<N><N>from pip._internal.utils.misc import (<N>    HiddenText,<N>    display_path,<N>    is_console_interactive,<N>    split_auth_from_netloc,<N>)<N>from pip._internal.utils.subprocess import CommandArgs, make_command<N>from pip._internal.vcs.versioncontrol import (<N>    AuthInfo,<N>    RemoteNotFoundError,<N>    RevOptions,<N>    VersionControl,<N>    vcs,<N>)<N><N>
logger = logging.getLogger(__name__)<N><N>_svn_xml_url_re = re.compile('url="([^"]+)"')<N>_svn_rev_re = re.compile(r'committed-rev="(\d+)"')<N>_svn_info_xml_rev_re = re.compile(r'\s*revision="(\d+)"')<N>_svn_info_xml_url_re = re.compile(r'<url>(.*)</url>')<N><N>
<N>class Subversion(VersionControl):<N>    name = 'svn'<N>    dirname = '.svn'<N>    repo_name = 'checkout'<N>    schemes = (<N>        'svn+ssh', 'svn+http', 'svn+https', 'svn+svn', 'svn+file'<N>    )<N><N>    @classmethod<N>    def should_add_vcs_url_prefix(cls, remote_url):<N>        # type: (str) -> bool<N>        return True<N><N>
    @staticmethod<N>    def get_base_rev_args(rev):<N>        # type: (str) -> List[str]<N>        return ['-r', rev]<N><N>    @classmethod<N>    def get_revision(cls, location):<N>        # type: (str) -> str<N>        """<N>        Return the maximum revision for all files under a given location<N>        """<N>        # Note: taken from setuptools.command.egg_info<N>        revision = 0<N><N>
        for base, dirs, _ in os.walk(location):<N>            if cls.dirname not in dirs:<N>                dirs[:] = []<N>                continue    # no sense walking uncontrolled subdirs<N>            dirs.remove(cls.dirname)<N>            entries_fn = os.path.join(base, cls.dirname, 'entries')<N>            if not os.path.exists(entries_fn):<N>                # FIXME: should we warn?<N>                continue<N><N>
            dirurl, localrev = cls._get_svn_url_rev(base)<N><N>            if base == location:<N>                assert dirurl is not None<N>                base = dirurl + '/'   # save the root url<N>            elif not dirurl or not dirurl.startswith(base):<N>                dirs[:] = []<N>                continue    # not part of the same svn tree, skip it<N>            revision = max(revision, localrev)<N>        return str(revision)<N><N>
import configparser<N>import logging<N>import os<N>from typing import List, Optional<N><N>from pip._internal.exceptions import BadCommand, InstallationError<N>from pip._internal.utils.misc import HiddenText, display_path<N>from pip._internal.utils.subprocess import make_command<N>from pip._internal.utils.urls import path_to_url<N>from pip._internal.vcs.versioncontrol import (<N>    RevOptions,<N>    VersionControl,<N>    find_path_to_setup_from_repo_root,<N>    vcs,<N>)<N><N>
logger = logging.getLogger(__name__)<N><N><N>class Mercurial(VersionControl):<N>    name = 'hg'<N>    dirname = '.hg'<N>    repo_name = 'clone'<N>    schemes = (<N>        'hg+file', 'hg+http', 'hg+https', 'hg+ssh', 'hg+static-http',<N>    )<N><N>    @staticmethod<N>    def get_base_rev_args(rev):<N>        # type: (str) -> List[str]<N>        return [rev]<N><N>
from typing import Dict, Iterable, List<N><N>from pip._vendor.pkg_resources import yield_lines<N><N><N>class DictMetadata:<N>    """IMetadataProvider that reads metadata files from a dictionary."""<N><N>    def __init__(self, metadata):<N>        # type: (Dict[str, bytes]) -> None<N>        self._metadata = metadata<N><N>
    def has_metadata(self, name):<N>        # type: (str) -> bool<N>        return name in self._metadata<N><N>    def get_metadata(self, name):<N>        # type: (str) -> str<N>        try:<N>            return self._metadata[name].decode()<N>        except UnicodeDecodeError as e:<N>            # Mirrors handling done in pkg_resources.NullProvider.<N>            e.reason += f" in {name} file"<N>            raise<N><N>
    def get_metadata_lines(self, name):<N>        # type: (str) -> Iterable[str]<N>        return yield_lines(self.get_metadata(name))<N><N>    def metadata_isdir(self, name):<N>        # type: (str) -> bool<N>        return False<N><N>    def metadata_listdir(self, name):<N>        # type: (str) -> List[str]<N>        return []<N><N>
import os<N>import sys<N>import urllib.parse<N>import urllib.request<N>from typing import Optional<N><N><N>def get_url_scheme(url):<N>    # type: (str) -> Optional[str]<N>    if ":" not in url:<N>        return None<N>    return url.split(":", 1)[0].lower()<N><N>
<N>def path_to_url(path):<N>    # type: (str) -> str<N>    """<N>    Convert a path to a file: URL.  The path will be made absolute and have<N>    quoted path parts.<N>    """<N>    path = os.path.normpath(os.path.abspath(path))<N>    url = urllib.parse.urljoin("file:", urllib.request.pathname2url(path))<N>    return url<N><N>
<N>def url_to_path(url):<N>    # type: (str) -> str<N>    """<N>    Convert a file: URL to a path.<N>    """<N>    assert url.startswith(<N>        "file:"<N>    ), f"You can only turn file: urls into filenames (not {url!r})"<N><N>    _, netloc, path, _, _ = urllib.parse.urlsplit(url)<N><N>
    if not netloc or netloc == "localhost":<N>        # According to RFC 8089, same as empty authority.<N>        netloc = ""<N>    elif sys.platform == "win32":<N>        # If we have a UNC path, prepend UNC share notation.<N>        netloc = "\\\\" + netloc<N>    else:<N>        raise ValueError(<N>            f"non-local file URIs are not supported on this platform: {url!r}"<N>        )<N><N>
"""Stuff that differs in different Python versions and platform<N>distributions."""<N><N>import logging<N>import os<N>import sys<N><N>__all__ = ["get_path_uid", "stdlib_pkgs", "WINDOWS"]<N><N><N>logger = logging.getLogger(__name__)<N><N><N>def has_tls():<N>    # type: () -> bool<N>    try:<N>        import _ssl  # noqa: F401  # ignore unused<N><N>
        return True<N>    except ImportError:<N>        pass<N><N>    from pip._vendor.urllib3.util import IS_PYOPENSSL<N><N>    return IS_PYOPENSSL<N><N><N>def get_path_uid(path):<N>    # type: (str) -> int<N>    """<N>    Return path's uid.<N><N>    Does not follow symlinks:<N>        https://github.com/pypa/pip/pull/935#discussion_r5307003<N><N>
"""For when pip wants to check the date or time.<N>"""<N><N>import datetime<N><N><N>def today_is_later_than(year, month, day):<N>    # type: (int, int, int) -> bool<N>    today = datetime.date.today()<N>    given = datetime.date(year, month, day)<N><N>    return today > given<N>
"""Utilities for defining models<N>"""<N><N>import operator<N>from typing import Any, Callable, Type<N><N><N>class KeyBasedCompareMixin:<N>    """Provides comparison capabilities that is based on a key"""<N><N>    __slots__ = ["_compare_key", "_defining_class"]<N><N>
    def __init__(self, key, defining_class):<N>        # type: (Any, Type[KeyBasedCompareMixin]) -> None<N>        self._compare_key = key<N>        self._defining_class = defining_class<N><N>    def __hash__(self):<N>        # type: () -> int<N>        return hash(self._compare_key)<N><N>
    def __lt__(self, other):<N>        # type: (Any) -> bool<N>        return self._compare(other, operator.__lt__)<N><N>    def __le__(self, other):<N>        # type: (Any) -> bool<N>        return self._compare(other, operator.__le__)<N><N>    def __gt__(self, other):<N>        # type: (Any) -> bool<N>        return self._compare(other, operator.__gt__)<N><N>
    def __ge__(self, other):<N>        # type: (Any) -> bool<N>        return self._compare(other, operator.__ge__)<N><N>    def __eq__(self, other):<N>        # type: (Any) -> bool<N>        return self._compare(other, operator.__eq__)<N><N>    def _compare(self, other, method):<N>        # type: (Any, Callable[[Any, Any], bool]) -> bool<N>        if not isinstance(other, self._defining_class):<N>            return NotImplemented<N><N>
import codecs<N>import locale<N>import re<N>import sys<N>from typing import List, Tuple<N><N>BOMS = [<N>    (codecs.BOM_UTF8, "utf-8"),<N>    (codecs.BOM_UTF16, "utf-16"),<N>    (codecs.BOM_UTF16_BE, "utf-16-be"),<N>    (codecs.BOM_UTF16_LE, "utf-16-le"),<N>    (codecs.BOM_UTF32, "utf-32"),<N>    (codecs.BOM_UTF32_BE, "utf-32-be"),<N>    (codecs.BOM_UTF32_LE, "utf-32-le"),<N>]  # type: List[Tuple[bytes, str]]<N><N>
import hashlib<N>from typing import TYPE_CHECKING, BinaryIO, Dict, Iterator, List<N><N>from pip._internal.exceptions import HashMismatch, HashMissing, InstallationError<N>from pip._internal.utils.misc import read_chunks<N><N>if TYPE_CHECKING:<N>    from hashlib import _Hash<N><N>
    # NoReturn introduced in 3.6.2; imported only for type checking to maintain<N>    # pip compatibility with older patch versions of Python 3.6<N>    from typing import NoReturn<N><N><N># The recommended hash algo of the moment. Change this whenever the state of<N># the art changes; it won't hurt backward compatibility.<N>FAVORITE_HASH = "sha256"<N><N>
<N># Names of hashlib algorithms allowed by the --hash option and ``pip hash``<N># Currently, those are the ones at least as collision-resistant as sha256.<N>STRONG_HASHES = ["sha256", "sha384", "sha512"]<N><N><N>class Hashes:<N>    """A wrapper that builds multiple hashes at once and checks them against<N>    known-good values<N><N>
    """<N><N>    def __init__(self, hashes=None):<N>        # type: (Dict[str, List[str]]) -> None<N>        """<N>        :param hashes: A dict of algorithm names pointing to lists of allowed<N>            hex digests<N>        """<N>        allowed = {}<N>        if hashes is not None:<N>            for alg, keys in hashes.items():<N>                # Make sure values are always sorted (to ease equality checks)<N>                allowed[alg] = sorted(keys)<N>        self._allowed = allowed<N><N>
    def __and__(self, other):<N>        # type: (Hashes) -> Hashes<N>        if not isinstance(other, Hashes):<N>            return NotImplemented<N><N>        # If either of the Hashes object is entirely empty (i.e. no hash<N>        # specified at all), all hashes from the other object are allowed.<N>        if not other:<N>            return self<N>        if not self:<N>            return other<N><N>
        # Otherwise only hashes that present in both objects are allowed.<N>        new = {}<N>        for alg, values in other._allowed.items():<N>            if alg not in self._allowed:<N>                continue<N>            new[alg] = [v for v in values if v in self._allowed[alg]]<N>        return Hashes(new)<N><N>
    @property<N>    def digest_count(self):<N>        # type: () -> int<N>        return sum(len(digests) for digests in self._allowed.values())<N><N>    def is_hash_allowed(<N>        self,<N>        hash_name,  # type: str<N>        hex_digest,  # type: str<N>    ):<N>        # type: (...) -> bool<N>        """Return whether the given hex digest is allowed."""<N>        return hex_digest in self._allowed.get(hash_name, [])<N><N>
"""<N>This code wraps the vendored appdirs module to so the return values are<N>compatible for the current pip code base.<N><N>The intention is to rewrite current usages gradually, keeping the tests pass,<N>and eventually drop this after all usages are changed.<N>"""<N><N>
"""Utilities related archives.<N>"""<N><N>import logging<N>import os<N>import shutil<N>import stat<N>import tarfile<N>import zipfile<N>from typing import Iterable, List, Optional<N>from zipfile import ZipInfo<N><N>from pip._internal.exceptions import InstallationError<N>from pip._internal.utils.filetypes import (<N>    BZ2_EXTENSIONS,<N>    TAR_EXTENSIONS,<N>    XZ_EXTENSIONS,<N>    ZIP_EXTENSIONS,<N>)<N>from pip._internal.utils.misc import ensure_dir<N><N>
logger = logging.getLogger(__name__)<N><N><N>SUPPORTED_EXTENSIONS = ZIP_EXTENSIONS + TAR_EXTENSIONS<N><N>try:<N>    import bz2  # noqa<N><N>    SUPPORTED_EXTENSIONS += BZ2_EXTENSIONS<N>except ImportError:<N>    logger.debug("bz2 module is not available")<N><N>
try:<N>    # Only for Python 3.3+<N>    import lzma  # noqa<N><N>    SUPPORTED_EXTENSIONS += XZ_EXTENSIONS<N>except ImportError:<N>    logger.debug("lzma module is not available")<N><N><N>def current_umask():<N>    # type: () -> int<N>    """Get the current umask which involves having to set it temporarily."""<N>    mask = os.umask(0)<N>    os.umask(mask)<N>    return mask<N><N>
<N>def split_leading_dir(path):<N>    # type: (str) -> List[str]<N>    path = path.lstrip("/").lstrip("\\")<N>    if "/" in path and (<N>        ("\\" in path and path.find("/") < path.find("\\")) or "\\" not in path<N>    ):<N>        return path.split("/", 1)<N>    elif "\\" in path:<N>        return path.split("\\", 1)<N>    else:<N>        return [path, ""]<N><N>
import json<N>import logging<N>from typing import Optional<N><N>from pip._vendor.pkg_resources import Distribution<N><N>from pip._internal.models.direct_url import (<N>    DIRECT_URL_METADATA_NAME,<N>    ArchiveInfo,<N>    DirectUrl,<N>    DirectUrlValidationError,<N>    DirInfo,<N>    VcsInfo,<N>)<N>from pip._internal.models.link import Link<N>from pip._internal.vcs import vcs<N><N>
import logging<N>from email.message import Message<N>from email.parser import FeedParser<N>from typing import Optional, Tuple<N><N>from pip._vendor import pkg_resources<N>from pip._vendor.packaging import specifiers, version<N>from pip._vendor.pkg_resources import Distribution<N><N>
from pip._internal.exceptions import NoneMetadataError<N>from pip._internal.utils.misc import display_path<N><N>logger = logging.getLogger(__name__)<N><N><N>def check_requires_python(requires_python, version_info):<N>    # type: (Optional[str], Tuple[int, ...]) -> bool<N>    """<N>    Check if the given Python version matches a "Requires-Python" specifier.<N><N>
    :param version_info: A 3-tuple of ints representing a Python<N>        major-minor-micro version to check (e.g. `sys.version_info[:3]`).<N><N>    :return: `True` if the given Python version satisfies the requirement.<N>        Otherwise, return `False`.<N><N>
    :raises InvalidSpecifier: If `requires_python` has an invalid format.<N>    """<N>    if requires_python is None:<N>        # The package provides no information<N>        return True<N>    requires_python_specifier = specifiers.SpecifierSet(requires_python)<N><N>
"""Convenient parallelization of higher order functions.<N><N>This module provides two helper functions, with appropriate fallbacks on<N>Python 2 and on systems lacking support for synchronization mechanisms:<N><N>- map_multiprocess<N>- map_multithread<N><N>
These helpers work like Python 3's map, with two differences:<N><N>- They don't guarantee the order of processing of<N>  the elements of the iterable.<N>- The underlying process/thread pools chop the iterable into<N>  a number of chunks, so that for very long iterables using<N>  a large value for chunksize can make the job complete much faster<N>  than using the default value of 1.<N>"""<N><N>
__all__ = ["map_multiprocess", "map_multithread"]<N><N>from contextlib import contextmanager<N>from multiprocessing import Pool as ProcessPool<N>from multiprocessing import pool<N>from multiprocessing.dummy import Pool as ThreadPool<N>from typing import Callable, Iterable, Iterator, TypeVar, Union<N><N>
from pip._vendor.requests.adapters import DEFAULT_POOLSIZE<N><N>Pool = Union[pool.Pool, pool.ThreadPool]<N>S = TypeVar("S")<N>T = TypeVar("T")<N><N># On platforms without sem_open, multiprocessing[.dummy] Pool<N># cannot be created.<N>try:<N>    import multiprocessing.synchronize  # noqa<N>except ImportError:<N>    LACK_SEM_OPEN = True<N>else:<N>    LACK_SEM_OPEN = False<N><N>
# Incredibly large timeout to work around bpo-8296 on Python 2.<N>TIMEOUT = 2000000<N><N><N>@contextmanager<N>def closing(pool):<N>    # type: (Pool) -> Iterator[Pool]<N>    """Return a context manager making sure the pool closes properly."""<N>    try:<N>        yield pool<N>    finally:<N>        # For Pool.imap*, close and join are needed<N>        # for the returned iterator to begin yielding.<N>        pool.close()<N>        pool.join()<N>        pool.terminate()<N><N>
<N>def _map_fallback(func, iterable, chunksize=1):<N>    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]<N>    """Make an iterator applying func to each element in iterable.<N><N>    This function is the sequential fallback either on Python 2<N>    where Pool.imap* doesn't react to KeyboardInterrupt<N>    or when sem_open is unavailable.<N>    """<N>    return map(func, iterable)<N><N>
<N>def _map_multiprocess(func, iterable, chunksize=1):<N>    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]<N>    """Chop iterable into chunks and submit them to a process pool.<N><N>    For very long iterables using a large value for chunksize can make<N>    the job complete much faster than using the default value of 1.<N><N>
    Return an unordered iterator of the results.<N>    """<N>    with closing(ProcessPool()) as pool:<N>        return pool.imap_unordered(func, iterable, chunksize)<N><N><N>def _map_multithread(func, iterable, chunksize=1):<N>    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]<N>    """Chop iterable into chunks and submit them to a thread pool.<N><N>
    For very long iterables using a large value for chunksize can make<N>    the job complete much faster than using the default value of 1.<N><N>    Return an unordered iterator of the results.<N>    """<N>    with closing(ThreadPool(DEFAULT_POOLSIZE)) as pool:<N>        return pool.imap_unordered(func, iterable, chunksize)<N><N>
"""A helper module that injects SecureTransport, on import.<N><N>The import should be done as early as possible, to ensure all requests and<N>sessions (or whatever) are created after injecting SecureTransport.<N><N>Note that we only do the injection on macOS, when the linked OpenSSL is too<N>old to handle TLSv1.2.<N>"""<N><N>
import sys<N><N><N>def inject_securetransport():<N>    # type: () -> None<N>    # Only relevant on macOS<N>    if sys.platform != "darwin":<N>        return<N><N>    try:<N>        import ssl<N>    except ImportError:<N>        return<N><N>    # Checks for OpenSSL 1.0.1<N>    if ssl.OPENSSL_VERSION_NUMBER >= 0x1000100F:<N>        return<N><N>
import logging<N>import os<N>import shlex<N>import subprocess<N>from typing import Any, Callable, Iterable, List, Mapping, Optional, Union<N><N>from pip._internal.cli.spinners import SpinnerInterface, open_spinner<N>from pip._internal.exceptions import InstallationSubprocessError<N>from pip._internal.utils.logging import subprocess_logger<N>from pip._internal.utils.misc import HiddenText<N><N>
import contextlib<N>import errno<N>import logging<N>import logging.handlers<N>import os<N>import sys<N>from logging import Filter, getLogger<N>from typing import IO, Any, Callable, Iterator, Optional, TextIO, Type, cast<N><N>from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.deprecation import DEPRECATION_MSG_PREFIX<N>from pip._internal.utils.misc import ensure_dir<N><N>
try:<N>    import threading<N>except ImportError:<N>    import dummy_threading as threading  # type: ignore<N><N><N>try:<N>    from pip._vendor import colorama<N># Lots of different errors can come from this, including SystemError and<N># ImportError.<N>except Exception:<N>    colorama = None<N><N>
import fnmatch<N>import os<N>import os.path<N>import random<N>import shutil<N>import stat<N>import sys<N>from contextlib import contextmanager<N>from tempfile import NamedTemporaryFile<N>from typing import Any, BinaryIO, Iterator, List, Union, cast<N><N>from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed<N><N>
from pip._internal.utils.compat import get_path_uid<N>from pip._internal.utils.misc import format_size<N><N><N>def check_path_owner(path):<N>    # type: (str) -> bool<N>    # If we don't have a way to check the effective uid of this process, then<N>    # we'll just assume that we own the directory.<N>    if sys.platform == "win32" or not hasattr(os, "geteuid"):<N>        return True<N><N>
"""<N>A module that implements tooling to enable easy warnings about deprecations.<N>"""<N><N>import logging<N>import warnings<N>from typing import Any, Optional, TextIO, Type, Union<N><N>from pip._vendor.packaging.version import parse<N><N>from pip import __version__ as current_version<N><N>
"""Generate and work with PEP 425 Compatibility Tags.<N>"""<N><N>import re<N>from typing import TYPE_CHECKING, List, Optional, Tuple<N><N>from pip._vendor.packaging.tags import (<N>    Tag,<N>    compatible_tags,<N>    cpython_tags,<N>    generic_tags,<N>    interpreter_name,<N>    interpreter_version,<N>    mac_platforms,<N>)<N><N>
if TYPE_CHECKING:<N>    from pip._vendor.packaging.tags import PythonVersion<N><N><N>_osx_arch_pat = re.compile(r"(.+)_(\d+)_(\d+)_(.+)")<N><N><N>def version_info_to_nodot(version_info):<N>    # type: (Tuple[int, ...]) -> str<N>    # Only use up to the first two numbers.<N>    return "".join(map(str, version_info[:2]))<N><N>
"""Support functions for working with wheel files.<N>"""<N><N>import logging<N>from email.message import Message<N>from email.parser import Parser<N>from typing import Dict, Tuple<N>from zipfile import BadZipFile, ZipFile<N><N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.pkg_resources import DistInfoDistribution, Distribution<N><N>
from pip._internal.exceptions import UnsupportedWheel<N>from pip._internal.utils.pkg_resources import DictMetadata<N><N>VERSION_COMPATIBLE = (1, 0)<N><N><N>logger = logging.getLogger(__name__)<N><N><N>class WheelMetadata(DictMetadata):<N>    """Metadata provider that maps metadata decoding exceptions to our<N>    internal exception type.<N>    """<N><N>
import errno<N>import itertools<N>import logging<N>import os.path<N>import tempfile<N>from contextlib import ExitStack, contextmanager<N>from typing import Any, Dict, Iterator, Optional, TypeVar, Union<N><N>from pip._internal.utils.misc import enum, rmtree<N><N>
logger = logging.getLogger(__name__)<N><N>_T = TypeVar("_T", bound="TempDirectory")<N><N><N># Kinds of temporary directories. Only needed for ones that are<N># globally-managed.<N>tempdir_kinds = enum(<N>    BUILD_ENV="build-env",<N>    EPHEM_WHEEL_CACHE="ephem-wheel-cache",<N>    REQ_BUILD="req-build",<N>)<N><N>
<N>_tempdir_manager = None  # type: Optional[ExitStack]<N><N><N>@contextmanager<N>def global_tempdir_manager():<N>    # type: () -> Iterator[None]<N>    global _tempdir_manager<N>    with ExitStack() as stack:<N>        old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack<N>        try:<N>            yield<N>        finally:<N>            _tempdir_manager = old_tempdir_manager<N><N>
<N>class TempDirectoryTypeRegistry:<N>    """Manages temp directory behavior"""<N><N>    def __init__(self):<N>        # type: () -> None<N>        self._should_delete = {}  # type: Dict[str, bool]<N><N>    def set_delete(self, kind, value):<N>        # type: (str, bool) -> None<N>        """Indicate whether a TempDirectory of the given kind should be<N>        auto-deleted.<N>        """<N>        self._should_delete[kind] = value<N><N>
    def get_delete(self, kind):<N>        # type: (str) -> bool<N>        """Get configured auto-delete flag for a given TempDirectory type,<N>        default True.<N>        """<N>        return self._should_delete.get(kind, True)<N><N><N>_tempdir_registry = None  # type: Optional[TempDirectoryTypeRegistry]<N><N>
<N>@contextmanager<N>def tempdir_registry():<N>    # type: () -> Iterator[TempDirectoryTypeRegistry]<N>    """Provides a scoped global tempdir registry that can be used to dictate<N>    whether directories should be deleted.<N>    """<N>    global _tempdir_registry<N>    old_tempdir_registry = _tempdir_registry<N>    _tempdir_registry = TempDirectoryTypeRegistry()<N>    try:<N>        yield _tempdir_registry<N>    finally:<N>        _tempdir_registry = old_tempdir_registry<N><N>
<N>class _Default:<N>    pass<N><N><N>_default = _Default()<N><N><N>class TempDirectory:<N>    """Helper class that owns and cleans up a temporary directory.<N><N>    This class can be used as a context manager or as an OO representation of a<N>    temporary directory.<N><N>
    Attributes:<N>        path<N>            Location to the created temporary directory<N>        delete<N>            Whether the directory should be deleted when exiting<N>            (when used as a contextmanager)<N><N>    Methods:<N>        cleanup()<N>            Deletes the temporary directory<N><N>
    When used as a context manager, if the delete attribute is True, on<N>    exiting the context the temporary directory is deleted.<N>    """<N><N>    def __init__(<N>        self,<N>        path=None,  # type: Optional[str]<N>        delete=_default,  # type: Union[bool, None, _Default]<N>        kind="temp",  # type: str<N>        globally_managed=False,  # type: bool<N>    ):<N>        super().__init__()<N><N>
        if delete is _default:<N>            if path is not None:<N>                # If we were given an explicit directory, resolve delete option<N>                # now.<N>                delete = False<N>            else:<N>                # Otherwise, we wait until cleanup and see what<N>                # tempdir_registry says.<N>                delete = None<N><N>
        # The only time we specify path is in for editables where it<N>        # is the value of the --src option.<N>        if path is None:<N>            path = self._create(kind)<N><N>        self._path = path<N>        self._deleted = False<N>        self.delete = delete<N>        self.kind = kind<N><N>
        if globally_managed:<N>            assert _tempdir_manager is not None<N>            _tempdir_manager.enter_context(self)<N><N>    @property<N>    def path(self):<N>        # type: () -> str<N>        assert not self._deleted, f"Attempted to access deleted path: {self._path}"<N>        return self._path<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        return f"<{self.__class__.__name__} {self.path!r}>"<N><N>    def __enter__(self):<N>        # type: (_T) -> _T<N>        return self<N><N>    def __exit__(self, exc, value, tb):<N>        # type: (Any, Any, Any) -> None<N>        if self.delete is not None:<N>            delete = self.delete<N>        elif _tempdir_registry:<N>            delete = _tempdir_registry.get_delete(self.kind)<N>        else:<N>            delete = True<N><N>
# The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import os<N>import sys<N>from typing import Optional, Tuple<N><N><N>def glibc_version_string():<N>    # type: () -> Optional[str]<N>    "Returns glibc version string, or None if not using glibc."<N>    return glibc_version_string_confstr() or glibc_version_string_ctypes()<N><N>
import logging<N>import os<N>import re<N>import site<N>import sys<N>from typing import List, Optional<N><N>logger = logging.getLogger(__name__)<N>_INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(<N>    r"include-system-site-packages\s*=\s*(?P<value>true|false)"<N>)<N><N>
<N>def _running_under_venv():<N>    # type: () -> bool<N>    """Checks if sys.base_prefix and sys.prefix match.<N><N>    This handles PEP 405 compliant virtual environments.<N>    """<N>    return sys.prefix != getattr(sys, "base_prefix", sys.prefix)<N><N>
<N>def _running_under_regular_virtualenv():<N>    # type: () -> bool<N>    """Checks if sys.real_prefix is set.<N><N>    This handles virtual environments created with pypa's virtualenv.<N>    """<N>    # pypa/virtualenv case<N>    return hasattr(sys, "real_prefix")<N><N>
<N>def running_under_virtualenv():<N>    # type: () -> bool<N>    """Return True if we're running inside a virtualenv, False otherwise."""<N>    return _running_under_venv() or _running_under_regular_virtualenv()<N><N><N>def _get_pyvenv_cfg_lines():<N>    # type: () -> Optional[List[str]]<N>    """Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines<N><N>
    Returns None, if it could not read/access the file.<N>    """<N>    pyvenv_cfg_file = os.path.join(sys.prefix, "pyvenv.cfg")<N>    try:<N>        # Although PEP 405 does not specify, the built-in venv module always<N>        # writes with UTF-8. (pypa/pip#8717)<N>        with open(pyvenv_cfg_file, encoding="utf-8") as f:<N>            return f.read().splitlines()  # avoids trailing newlines<N>    except OSError:<N>        return None<N><N>
<N>def _no_global_under_venv():<N>    # type: () -> bool<N>    """Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion<N><N>    PEP 405 specifies that when system site-packages are not supposed to be<N>    visible from a virtual environment, `pyvenv.cfg` must contain the following<N>    line:<N><N>
import sys<N>from typing import List, Optional<N><N>from pip._internal.cli.main import main<N><N><N>def _wrapper(args=None):<N>    # type: (Optional[List[str]]) -> int<N>    """Central wrapper for all old entrypoints.<N><N>    Historically pip has had several entrypoints defined. Because of issues<N>    arising from PATH, sys.path, multiple Pythons, their interactions, and most<N>    of them having a pip installed, users suffer every time an entrypoint gets<N>    moved.<N><N>
"""Lazy ZIP over HTTP"""<N><N>__all__ = ['HTTPRangeRequestUnsupported', 'dist_from_wheel_url']<N><N>from bisect import bisect_left, bisect_right<N>from contextlib import contextmanager<N>from tempfile import NamedTemporaryFile<N>from typing import Any, Dict, Iterator, List, Optional, Tuple<N>from zipfile import BadZipfile, ZipFile<N><N>
from pip._vendor.pkg_resources import Distribution<N>from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response<N><N>from pip._internal.network.session import PipSession<N>from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks<N>from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel<N><N>
"""HTTP cache implementation.<N>"""<N><N>import os<N>from contextlib import contextmanager<N>from typing import Iterator, Optional<N><N>from pip._vendor.cachecontrol.cache import BaseCache<N>from pip._vendor.cachecontrol.caches import FileCache<N>from pip._vendor.requests.models import Response<N><N>
"""Network Authentication Helpers<N><N>Contains interface (MultiDomainBasicAuth) and associated glue code for<N>providing credentials in the context of network requests.<N>"""<N><N>import logging<N>import urllib.parse<N>from typing import Any, Dict, List, Optional, Tuple<N><N>
from pip._vendor.requests.auth import AuthBase, HTTPBasicAuth<N>from pip._vendor.requests.models import Request, Response<N>from pip._vendor.requests.utils import get_netrc_auth<N><N>from pip._internal.utils.misc import (<N>    ask,<N>    ask_input,<N>    ask_password,<N>    remove_auth_from_url,<N>    split_auth_netloc_from_url,<N>)<N>from pip._internal.vcs.versioncontrol import AuthInfo<N><N>
logger = logging.getLogger(__name__)<N><N>Credentials = Tuple[str, str, str]<N><N>try:<N>    import keyring<N>except ImportError:<N>    keyring = None<N>except Exception as exc:<N>    logger.warning(<N>        "Keyring is skipped due to an exception: %s", str(exc),<N>    )<N>    keyring = None<N><N>
"""PipSession and supporting code, containing all pip-specific<N>network request configuration and behavior.<N>"""<N><N># When mypy runs on Windows the call to distro.linux_distribution() is skipped<N># resulting in the failure:<N>#<N>#     error: unused 'type: ignore' comment<N>#<N># If the upstream module adds typing, this comment should be removed. See<N># https://github.com/nir0s/distro/pull/269<N>#<N># mypy: warn-unused-ignores=False<N><N>
import email.utils<N>import ipaddress<N>import json<N>import logging<N>import mimetypes<N>import os<N>import platform<N>import sys<N>import urllib.parse<N>import warnings<N>from typing import Any, Dict, Iterator, List, Mapping, Optional, Sequence, Tuple, Union<N><N>
from pip._vendor import requests, urllib3<N>from pip._vendor.cachecontrol import CacheControlAdapter<N>from pip._vendor.requests.adapters import BaseAdapter, HTTPAdapter<N>from pip._vendor.requests.models import PreparedRequest, Response<N>from pip._vendor.requests.structures import CaseInsensitiveDict<N>from pip._vendor.urllib3.connectionpool import ConnectionPool<N>from pip._vendor.urllib3.exceptions import InsecureRequestWarning<N><N>
from pip import __version__<N>from pip._internal.metadata import get_default_environment<N>from pip._internal.models.link import Link<N>from pip._internal.network.auth import MultiDomainBasicAuth<N>from pip._internal.network.cache import SafeFileCache<N><N>
# Import ssl from compat so the initial import occurs in only one place.<N>from pip._internal.utils.compat import has_tls<N>from pip._internal.utils.glibc import libc_ver<N>from pip._internal.utils.misc import build_url_from_netloc, parse_netloc<N>from pip._internal.utils.urls import url_to_path<N><N>
"""xmlrpclib.Transport implementation<N>"""<N><N>import logging<N>import urllib.parse<N>import xmlrpc.client<N>from typing import TYPE_CHECKING, Tuple<N><N>from pip._internal.exceptions import NetworkConnectionError<N>from pip._internal.network.session import PipSession<N>from pip._internal.network.utils import raise_for_status<N><N>
if TYPE_CHECKING:<N>    from xmlrpc.client import _HostType, _Marshallable<N><N>logger = logging.getLogger(__name__)<N><N><N>class PipXmlrpcTransport(xmlrpc.client.Transport):<N>    """Provide a `xmlrpclib.Transport` implementation via a `PipSession`<N>    object.<N>    """<N><N>
    def __init__(self, index_url, session, use_datetime=False):<N>        # type: (str, PipSession, bool) -> None<N>        super().__init__(use_datetime)<N>        index_parts = urllib.parse.urlparse(index_url)<N>        self._scheme = index_parts.scheme<N>        self._session = session<N><N>
"""<N>Package containing all pip commands<N>"""<N><N>import importlib<N>from collections import OrderedDict, namedtuple<N>from typing import Any, Optional<N><N>from pip._internal.cli.base_command import Command<N><N>CommandInfo = namedtuple('CommandInfo', 'module_path, class_name, summary')<N><N>
import hashlib<N>import logging<N>import sys<N>from optparse import Values<N>from typing import List<N><N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import ERROR, SUCCESS<N>from pip._internal.utils.hashes import FAVORITE_HASH, STRONG_HASHES<N>from pip._internal.utils.misc import read_chunks, write_output<N><N>
logger = logging.getLogger(__name__)<N><N><N>class HashCommand(Command):<N>    """<N>    Compute a hash of a local package archive.<N><N>    These can be used with --hash in a requirements file to do repeatable<N>    installs.<N>    """<N><N>    usage = '%prog [options] <file> ...'<N>    ignore_require_venv = True<N><N>
    def add_options(self):<N>        # type: () -> None<N>        self.cmd_opts.add_option(<N>            '-a', '--algorithm',<N>            dest='algorithm',<N>            choices=STRONG_HASHES,<N>            action='store',<N>            default=FAVORITE_HASH,<N>            help='The hash algorithm to use: one of {}'.format(<N>                 ', '.join(STRONG_HASHES)))<N>        self.parser.insert_option_group(0, self.cmd_opts)<N><N>
    def run(self, options, args):<N>        # type: (Values, List[str]) -> int<N>        if not args:<N>            self.parser.print_usage(sys.stderr)<N>            return ERROR<N><N>        algorithm = options.algorithm<N>        for path in args:<N>            write_output('%s:\n--hash=%s:%s',<N>                         path, algorithm, _hash_of_file(path, algorithm))<N>        return SUCCESS<N><N>
<N>def _hash_of_file(path, algorithm):<N>    # type: (str, str) -> str<N>    """Return the hash digest of a file."""<N>    with open(path, 'rb') as archive:<N>        hash = hashlib.new(algorithm)<N>        for chunk in read_chunks(archive):<N>            hash.update(chunk)<N>    return hash.hexdigest()<N><N><N>
import sys<N>from optparse import Values<N>from typing import List<N><N>from pip._internal.cli import cmdoptions<N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import SUCCESS<N>from pip._internal.operations.freeze import freeze<N>from pip._internal.utils.compat import stdlib_pkgs<N>from pip._internal.utils.deprecation import deprecated<N><N>
DEV_PKGS = {'pip', 'setuptools', 'distribute', 'wheel'}<N><N><N>class FreezeCommand(Command):<N>    """<N>    Output installed packages in requirements format.<N><N>    packages are listed in a case-insensitive sorted order.<N>    """<N><N>    usage = """<N>      %prog [options]"""<N>    log_streams = ("ext://sys.stderr", "ext://sys.stderr")<N><N>
import logging<N>from optparse import Values<N>from typing import Any, List<N><N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import ERROR, SUCCESS<N>from pip._internal.operations.check import (<N>    check_package_set,<N>    create_package_set_from_installed,<N>)<N>from pip._internal.utils.misc import write_output<N><N>
logger = logging.getLogger(__name__)<N><N><N>class CheckCommand(Command):<N>    """Verify installed packages have compatible dependencies."""<N><N>    usage = """<N>      %prog [options]"""<N><N>    def run(self, options, args):<N>        # type: (Values, List[Any]) -> int<N><N>
        package_set, parsing_probs = create_package_set_from_installed()<N>        missing, conflicting = check_package_set(package_set)<N><N>        for project_name in missing:<N>            version = package_set[project_name].version<N>            for dependency in missing[project_name]:<N>                write_output(<N>                    "%s %s requires %s, which is not installed.",<N>                    project_name, version, dependency[0],<N>                )<N><N>
        for project_name in conflicting:<N>            version = package_set[project_name].version<N>            for dep_name, dep_version, req in conflicting[project_name]:<N>                write_output(<N>                    "%s %s has requirement %s, but you have %s %s.",<N>                    project_name, version, req, dep_name, dep_version,<N>                )<N><N>
import locale<N>import logging<N>import os<N>import sys<N>from optparse import Values<N>from types import ModuleType<N>from typing import Any, Dict, List, Optional<N><N>import pip._vendor<N>from pip._vendor.certifi import where<N>from pip._vendor.packaging.version import parse as parse_version<N><N>
from pip import __file__ as pip_location<N>from pip._internal.cli import cmdoptions<N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.cmdoptions import make_target_python<N>from pip._internal.cli.status_codes import SUCCESS<N>from pip._internal.configuration import Configuration<N>from pip._internal.metadata import get_environment<N>from pip._internal.utils.logging import indent_log<N>from pip._internal.utils.misc import get_pip_version<N><N>
logger = logging.getLogger(__name__)<N><N><N>def show_value(name, value):<N>    # type: (str, Any) -> None<N>    logger.info('%s: %s', name, value)<N><N><N>def show_sys_implementation():<N>    # type: () -> None<N>    logger.info('sys.implementation:')<N>    implementation_name = sys.implementation.name<N>    with indent_log():<N>        show_value('name', implementation_name)<N><N>
<N>def create_vendor_txt_map():<N>    # type: () -> Dict[str, str]<N>    vendor_txt_path = os.path.join(<N>        os.path.dirname(pip_location),<N>        '_vendor',<N>        'vendor.txt'<N>    )<N><N>    with open(vendor_txt_path) as f:<N>        # Purge non version specifying lines.<N>        # Also, remove any space prefix or suffixes (including comments).<N>        lines = [line.strip().split(' ', 1)[0]<N>                 for line in f.readlines() if '==' in line]<N><N>
    # Transform into "module" -> version dict.<N>    return dict(line.split('==', 1) for line in lines)  # type: ignore<N><N><N>def get_module_from_module_name(module_name):<N>    # type: (str) -> ModuleType<N>    # Module name can be uppercase in vendor.txt for some reason...<N>    module_name = module_name.lower()<N>    # PATCH: setuptools is actually only pkg_resources.<N>    if module_name == 'setuptools':<N>        module_name = 'pkg_resources'<N><N>
    __import__(<N>        f'pip._vendor.{module_name}',<N>        globals(),<N>        locals(),<N>        level=0<N>    )<N>    return getattr(pip._vendor, module_name)<N><N><N>def get_vendor_version_from_module(module_name):<N>    # type: (str) -> Optional[str]<N>    module = get_module_from_module_name(module_name)<N>    version = getattr(module, '__version__', None)<N><N>
    if not version:<N>        # Try to find version in debundled module info.<N>        env = get_environment([os.path.dirname(module.__file__)])<N>        dist = env.get_distribution(module_name)<N>        if dist:<N>            version = str(dist.version)<N><N>
import logging<N>import os<N>import textwrap<N>from optparse import Values<N>from typing import Any, List<N><N>import pip._internal.utils.filesystem as filesystem<N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import ERROR, SUCCESS<N>from pip._internal.exceptions import CommandError, PipError<N><N>
logger = logging.getLogger(__name__)<N><N><N>class CacheCommand(Command):<N>    """<N>    Inspect and manage pip's wheel cache.<N><N>    Subcommands:<N><N>    - dir: Show the cache directory.<N>    - info: Show information about the cache.<N>    - list: List filenames of packages stored in the cache.<N>    - remove: Remove one or more package from the cache.<N>    - purge: Remove all items from the cache.<N><N>
    ``<pattern>`` can be a glob expression or a package name.<N>    """<N><N>    ignore_require_venv = True<N>    usage = """<N>        %prog dir<N>        %prog info<N>        %prog list [<pattern>] [--format=[human, abspath]]<N>        %prog remove <pattern><N>        %prog purge<N>    """<N><N>
    def add_options(self):<N>        # type: () -> None<N><N>        self.cmd_opts.add_option(<N>            '--format',<N>            action='store',<N>            dest='list_format',<N>            default="human",<N>            choices=('human', 'abspath'),<N>            help="Select the output format among: human (default) or abspath"<N>        )<N><N>
        self.parser.insert_option_group(0, self.cmd_opts)<N><N>    def run(self, options, args):<N>        # type: (Values, List[Any]) -> int<N>        handlers = {<N>            "dir": self.get_cache_dir,<N>            "info": self.get_cache_info,<N>            "list": self.list_cache_items,<N>            "remove": self.remove_cache_items,<N>            "purge": self.purge_cache,<N>        }<N><N>
        if not options.cache_dir:<N>            logger.error("pip cache commands can not "<N>                         "function since cache is disabled.")<N>            return ERROR<N><N>        # Determine action<N>        if not args or args[0] not in handlers:<N>            logger.error(<N>                "Need an action (%s) to perform.",<N>                ", ".join(sorted(handlers)),<N>            )<N>            return ERROR<N><N>
        action = args[0]<N><N>        # Error handling happens here, not in the action-handlers.<N>        try:<N>            handlers[action](options, args[1:])<N>        except PipError as e:<N>            logger.error(e.args[0])<N>            return ERROR<N><N>
        return SUCCESS<N><N>    def get_cache_dir(self, options, args):<N>        # type: (Values, List[Any]) -> None<N>        if args:<N>            raise CommandError('Too many arguments')<N><N>        logger.info(options.cache_dir)<N><N>    def get_cache_info(self, options, args):<N>        # type: (Values, List[Any]) -> None<N>        if args:<N>            raise CommandError('Too many arguments')<N><N>
        num_http_files = len(self._find_http_files(options))<N>        num_packages = len(self._find_wheels(options, '*'))<N><N>        http_cache_location = self._cache_dir(options, 'http')<N>        wheels_cache_location = self._cache_dir(options, 'wheels')<N>        http_cache_size = filesystem.format_directory_size(http_cache_location)<N>        wheels_cache_size = filesystem.format_directory_size(<N>            wheels_cache_location<N>        )<N><N>
import sys<N>import textwrap<N>from optparse import Values<N>from typing import List<N><N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import SUCCESS<N>from pip._internal.utils.misc import get_prog<N><N>BASE_COMPLETION = """<N># pip {shell} completion start{script}# pip {shell} completion end<N>"""<N><N>
from optparse import Values<N>from typing import List<N><N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import SUCCESS<N>from pip._internal.exceptions import CommandError<N><N><N>class HelpCommand(Command):<N>    """Show help for commands"""<N><N>
    usage = """<N>      %prog <command>"""<N>    ignore_require_venv = True<N><N>    def run(self, options, args):<N>        # type: (Values, List[str]) -> int<N>        from pip._internal.commands import (<N>            commands_dict,<N>            create_command,<N>            get_similar_commands,<N>        )<N><N>
        try:<N>            # 'pip help' with no args is handled by pip.__init__.parseopt()<N>            cmd_name = args[0]  # the command we need help for<N>        except IndexError:<N>            return SUCCESS<N><N>        if cmd_name not in commands_dict:<N>            guess = get_similar_commands(cmd_name)<N><N>
            msg = [f'unknown command "{cmd_name}"']<N>            if guess:<N>                msg.append(f'maybe you meant "{guess}"')<N><N>            raise CommandError(' - '.join(msg))<N><N>        command = create_command(cmd_name)<N>        command.parser.print_help()<N><N>
import logging<N>import shutil<N>import sys<N>import textwrap<N>import xmlrpc.client<N>from collections import OrderedDict<N>from optparse import Values<N>from typing import TYPE_CHECKING, Dict, List, Optional<N><N>from pip._vendor.packaging.version import parse as parse_version<N><N>
import logging<N>import os<N>from email.parser import FeedParser<N>from optparse import Values<N>from typing import Dict, Iterator, List<N><N>from pip._vendor import pkg_resources<N>from pip._vendor.packaging.utils import canonicalize_name<N><N>from pip._internal.cli.base_command import Command<N>from pip._internal.cli.status_codes import ERROR, SUCCESS<N>from pip._internal.utils.misc import write_output<N><N>
logger = logging.getLogger(__name__)<N><N><N>class ShowCommand(Command):<N>    """<N>    Show information about one or more installed packages.<N><N>    The output is in RFC-compliant mail header format.<N>    """<N><N>    usage = """<N>      %prog [options] <package> ..."""<N>    ignore_require_venv = True<N><N>
    def add_options(self):<N>        # type: () -> None<N>        self.cmd_opts.add_option(<N>            '-f', '--files',<N>            dest='files',<N>            action='store_true',<N>            default=False,<N>            help='Show the full list of installed files for each package.')<N><N>
        self.parser.insert_option_group(0, self.cmd_opts)<N><N>    def run(self, options, args):<N>        # type: (Values, List[str]) -> int<N>        if not args:<N>            logger.warning('ERROR: Please provide a package name or names.')<N>            return ERROR<N>        query = args<N><N>
"""<N>For types associated with installation schemes.<N><N>For a general overview of available schemes and their context, see<N>https://docs.python.org/3/install/index.html#alternate-installation.<N>"""<N><N><N>SCHEME_KEYS = ['platlib', 'purelib', 'headers', 'scripts', 'data']<N><N>
from typing import FrozenSet, Optional, Set<N><N>from pip._vendor.packaging.utils import canonicalize_name<N><N>from pip._internal.exceptions import CommandError<N><N><N>class FormatControl:<N>    """Helper for managing formats from which a package can be installed.<N>    """<N><N>
    __slots__ = ["no_binary", "only_binary"]<N><N>    def __init__(self, no_binary=None, only_binary=None):<N>        # type: (Optional[Set[str]], Optional[Set[str]]) -> None<N>        if no_binary is None:<N>            no_binary = set()<N>        if only_binary is None:<N>            only_binary = set()<N><N>
        self.no_binary = no_binary<N>        self.only_binary = only_binary<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        if not isinstance(other, self.__class__):<N>            return NotImplemented<N><N>        if self.__slots__ != other.__slots__:<N>            return False<N><N>
        return all(<N>            getattr(self, k) == getattr(other, k)<N>            for k in self.__slots__<N>        )<N><N>    def __repr__(self):<N>        # type: () -> str<N>        return "{}({}, {})".format(<N>            self.__class__.__name__,<N>            self.no_binary,<N>            self.only_binary<N>        )<N><N>
import itertools<N>import logging<N>import os<N>import posixpath<N>import urllib.parse<N>from typing import List<N><N>from pip._vendor.packaging.utils import canonicalize_name<N><N>from pip._internal.models.index import PyPI<N>from pip._internal.utils.compat import has_tls<N>from pip._internal.utils.misc import normalize_path, redact_auth_from_url<N><N>
""" PEP 610 """<N>import json<N>import re<N>import urllib.parse<N>from typing import Any, Dict, Iterable, Optional, Type, TypeVar, Union<N><N>__all__ = [<N>    "DirectUrl",<N>    "DirectUrlValidationError",<N>    "DirInfo",<N>    "ArchiveInfo",<N>    "VcsInfo",<N>]<N><N>
import sys<N>from typing import List, Optional, Tuple<N><N>from pip._vendor.packaging.tags import Tag<N><N>from pip._internal.utils.compatibility_tags import get_supported, version_info_to_nodot<N>from pip._internal.utils.misc import normalize_version_info<N><N>
<N>class TargetPython:<N><N>    """<N>    Encapsulates the properties of a Python interpreter one is targeting<N>    for a package install, download, etc.<N>    """<N><N>    __slots__ = [<N>        "_given_py_version_info",<N>        "abis",<N>        "implementation",<N>        "platforms",<N>        "py_version",<N>        "py_version_info",<N>        "_valid_tags",<N>    ]<N><N>
"""Represents a wheel file and provides access to the various parts of the<N>name that have meaning.<N>"""<N>import re<N>from typing import Dict, Iterable, List<N><N>from pip._vendor.packaging.tags import Tag<N><N>from pip._internal.exceptions import InvalidWheelFilename<N><N>
<N>class Wheel:<N>    """A wheel file"""<N><N>    wheel_file_re = re.compile(<N>        r"""^(?P<namever>(?P<name>.+?)-(?P<ver>.*?))<N>        ((-(?P<build>\d[^-]*?))?-(?P<pyver>.+?)-(?P<abi>.+?)-(?P<plat>.+?)<N>        \.whl|\.dist-info)$""",<N>        re.VERBOSE<N>    )<N><N>
from typing import Optional<N><N>from pip._internal.models.format_control import FormatControl<N><N><N>class SelectionPreferences:<N>    """<N>    Encapsulates the candidate selection preferences for downloading<N>    and installing files.<N>    """<N><N>    __slots__ = ['allow_yanked', 'allow_all_prereleases', 'format_control',<N>                 'prefer_binary', 'ignore_requires_python']<N><N>
import os<N>import posixpath<N>import re<N>import urllib.parse<N>from typing import TYPE_CHECKING, Optional, Tuple, Union<N><N>from pip._internal.utils.filetypes import WHEEL_EXTENSION<N>from pip._internal.utils.hashes import Hashes<N>from pip._internal.utils.misc import (<N>    redact_auth_from_url,<N>    split_auth_from_netloc,<N>    splitext,<N>)<N>from pip._internal.utils.models import KeyBasedCompareMixin<N>from pip._internal.utils.urls import path_to_url, url_to_path<N><N>
if TYPE_CHECKING:<N>    from pip._internal.index.collector import HTMLPage<N><N><N>class Link(KeyBasedCompareMixin):<N>    """Represents a parsed link from a Package Index's simple URL<N>    """<N><N>    __slots__ = [<N>        "_parsed_url",<N>        "_url",<N>        "comes_from",<N>        "requires_python",<N>        "yanked_reason",<N>        "cache_link_parsing",<N>    ]<N><N>
from pip._vendor.packaging.version import parse as parse_version<N><N>from pip._internal.models.link import Link<N>from pip._internal.utils.models import KeyBasedCompareMixin<N><N><N>class InstallationCandidate(KeyBasedCompareMixin):<N>    """Represents a potential "candidate" for installation.<N>    """<N><N>
    __slots__ = ["name", "version", "link"]<N><N>    def __init__(self, name, version, link):<N>        # type: (str, str, Link) -> None<N>        self.name = name<N>        self.version = parse_version(version)<N>        self.link = link<N><N>        super().__init__(<N>            key=(self.name, self.version, self.link),<N>            defining_class=InstallationCandidate<N>        )<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        return "<InstallationCandidate({!r}, {!r}, {!r})>".format(<N>            self.name, self.version, self.link,<N>        )<N><N>    def __str__(self):<N>        # type: () -> str<N>        return '{!r} candidate (version {} at {})'.format(<N>            self.name, self.version, self.link,<N>        )<N><N><N>
import collections<N>import logging<N>import os<N>from typing import (<N>    Container,<N>    Dict,<N>    Iterable,<N>    Iterator,<N>    List,<N>    Optional,<N>    Set,<N>    Tuple,<N>    Union,<N>)<N><N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.pkg_resources import Distribution, Requirement, RequirementParseError<N><N>
from pip._internal.exceptions import BadCommand, InstallationError<N>from pip._internal.req.constructors import (<N>    install_req_from_editable,<N>    install_req_from_line,<N>)<N>from pip._internal.req.req_file import COMMENT_RE<N>from pip._internal.utils.direct_url_helpers import (<N>    direct_url_as_pep440_direct_reference,<N>    dist_get_direct_url,<N>)<N>from pip._internal.utils.misc import dist_is_editable, get_installed_distributions<N><N>
"""Validation of dependencies of packages<N>"""<N><N>import logging<N>from collections import namedtuple<N>from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Set, Tuple<N><N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.pkg_resources import RequirementParseError<N><N>
from pip._internal.distributions import make_distribution_for_install_requirement<N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.utils.misc import get_installed_distributions<N><N>if TYPE_CHECKING:<N>    from pip._vendor.packaging.utils import NormalizedName<N><N>
logger = logging.getLogger(__name__)<N><N># Shorthands<N>PackageSet = Dict['NormalizedName', 'PackageDetails']<N>Missing = Tuple[str, Any]<N>Conflicting = Tuple[str, str, Any]<N><N>MissingDict = Dict['NormalizedName', List[Missing]]<N>ConflictingDict = Dict['NormalizedName', List[Conflicting]]<N>CheckResult = Tuple[MissingDict, ConflictingDict]<N>ConflictDetails = Tuple[PackageSet, CheckResult]<N><N>
PackageDetails = namedtuple('PackageDetails', ['version', 'requires'])<N><N><N>def create_package_set_from_installed(**kwargs: Any) -> Tuple["PackageSet", bool]:<N>    """Converts a list of distributions into a PackageSet.<N>    """<N>    # Default to using all packages installed on the system<N>    if kwargs == {}:<N>        kwargs = {"local_only": False, "skip": ()}<N><N>
"""Prepares a distribution for installation<N>"""<N><N># The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import logging<N>import mimetypes<N>import os<N>import shutil<N>from typing import Dict, Iterable, List, Optional, Tuple<N><N>
"""Legacy editable installation process, i.e. `setup.py develop`.<N>"""<N>import logging<N>from typing import List, Optional, Sequence<N><N>from pip._internal.build_env import BuildEnvironment<N>from pip._internal.utils.logging import indent_log<N>from pip._internal.utils.setuptools_build import make_setuptools_develop_args<N>from pip._internal.utils.subprocess import call_subprocess<N><N>
import logging<N>import os.path<N>from typing import List, Optional<N><N>from pip._internal.cli.spinners import open_spinner<N>from pip._internal.utils.setuptools_build import make_setuptools_bdist_wheel_args<N>from pip._internal.utils.subprocess import (<N>    LOG_DIVIDER,<N>    call_subprocess,<N>    format_command_args,<N>)<N><N>
logger = logging.getLogger(__name__)<N><N><N>def format_command_result(<N>    command_args,  # type: List[str]<N>    command_output,  # type: str<N>):<N>    # type: (...) -> str<N>    """Format command information for logging."""<N>    command_desc = format_command_args(command_args)<N>    text = f'Command arguments: {command_desc}\n'<N><N>
    if not command_output:<N>        text += 'Command output: None'<N>    elif logger.getEffectiveLevel() > logging.DEBUG:<N>        text += 'Command output: [use --verbose to show]'<N>    else:<N>        if not command_output.endswith('\n'):<N>            command_output += '\n'<N>        text += f'Command output:\n{command_output}{LOG_DIVIDER}'<N><N>
"""Metadata generation logic for legacy source distributions.<N>"""<N><N>import logging<N>import os<N><N>from pip._internal.build_env import BuildEnvironment<N>from pip._internal.exceptions import InstallationError<N>from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args<N>from pip._internal.utils.subprocess import call_subprocess<N>from pip._internal.utils.temp_dir import TempDirectory<N><N>
logger = logging.getLogger(__name__)<N><N><N>def _find_egg_info(directory):<N>    # type: (str) -> str<N>    """Find an .egg-info subdirectory in `directory`.<N>    """<N>    filenames = [<N>        f for f in os.listdir(directory) if f.endswith(".egg-info")<N>    ]<N><N>
    if not filenames:<N>        raise InstallationError(<N>            f"No .egg-info directory found in {directory}"<N>        )<N><N>    if len(filenames) > 1:<N>        raise InstallationError(<N>            "More than one .egg-info directory found in {}".format(<N>                directory<N>            )<N>        )<N><N>
    return os.path.join(directory, filenames[0])<N><N><N>def generate_metadata(<N>    build_env,  # type: BuildEnvironment<N>    setup_py_path,  # type: str<N>    source_dir,  # type: str<N>    isolated,  # type: bool<N>    details,  # type: str<N>):<N>    # type: (...) -> str<N>    """Generate metadata using setup.py-based defacto mechanisms.<N><N>
    Returns the generated metadata directory.<N>    """<N>    logger.debug(<N>        'Running setup.py (path:%s) egg_info for package %s',<N>        setup_py_path, details,<N>    )<N><N>    egg_info_dir = TempDirectory(<N>        kind="pip-egg-info", globally_managed=True<N>    ).path<N><N>
    args = make_setuptools_egg_info_args(<N>        setup_py_path,<N>        egg_info_dir=egg_info_dir,<N>        no_user_config=isolated,<N>    )<N><N>    with build_env:<N>        call_subprocess(<N>            args,<N>            cwd=source_dir,<N>            command_desc='python setup.py egg_info',<N>        )<N><N>
"""Metadata generation logic for source distributions.<N>"""<N><N>import os<N><N>from pip._vendor.pep517.wrappers import Pep517HookCaller<N><N>from pip._internal.build_env import BuildEnvironment<N>from pip._internal.utils.subprocess import runner_with_spinner_message<N>from pip._internal.utils.temp_dir import TempDirectory<N><N>
<N>def generate_metadata(build_env, backend):<N>    # type: (BuildEnvironment, Pep517HookCaller) -> str<N>    """Generate metadata using mechanisms described in PEP 517.<N><N>    Returns the generated metadata directory.<N>    """<N>    metadata_tmpdir = TempDirectory(<N>        kind="modern-metadata", globally_managed=True<N>    )<N><N>
    metadata_dir = metadata_tmpdir.path<N><N>    with build_env:<N>        # Note that Pep517HookCaller implements a fallback for<N>        # prepare_metadata_for_build_wheel, so we don't have to<N>        # consider the possibility that this hook doesn't exist.<N>        runner = runner_with_spinner_message("Preparing wheel metadata")<N>        with backend.subprocess_runner(runner):<N>            distinfo_dir = backend.prepare_metadata_for_build_wheel(<N>                metadata_dir<N>            )<N><N>
from typing import Optional<N><N>from pip._vendor.pkg_resources import Distribution<N><N>from pip._internal.distributions.base import AbstractDistribution<N>from pip._internal.index.package_finder import PackageFinder<N><N><N>class InstalledDistribution(AbstractDistribution):<N>    """Represents an installed package.<N><N>
    This does not need any preparation as the required information has already<N>    been computed.<N>    """<N><N>    def get_pkg_resources_distribution(self):<N>        # type: () -> Optional[Distribution]<N>        return self.req.satisfied_by<N><N>    def prepare_distribution_metadata(self, finder, build_isolation):<N>        # type: (PackageFinder, bool) -> None<N>        pass<N><N><N>
from pip._internal.distributions.base import AbstractDistribution<N>from pip._internal.distributions.sdist import SourceDistribution<N>from pip._internal.distributions.wheel import WheelDistribution<N>from pip._internal.req.req_install import InstallRequirement<N><N>
<N>def make_distribution_for_install_requirement(install_req):<N>    # type: (InstallRequirement) -> AbstractDistribution<N>    """Returns a Distribution for the given InstallRequirement"""<N>    # Editable requirements will always be source distributions. They use the<N>    # legacy logic until we create a modern standard for them.<N>    if install_req.editable:<N>        return SourceDistribution(install_req)<N><N>
import logging<N>from typing import Set, Tuple<N><N>from pip._vendor.pkg_resources import Distribution<N><N>from pip._internal.build_env import BuildEnvironment<N>from pip._internal.distributions.base import AbstractDistribution<N>from pip._internal.exceptions import InstallationError<N>from pip._internal.index.package_finder import PackageFinder<N>from pip._internal.utils.subprocess import runner_with_spinner_message<N><N>
logger = logging.getLogger(__name__)<N><N><N>class SourceDistribution(AbstractDistribution):<N>    """Represents a source distribution.<N><N>    The preparation step for these needs metadata for the packages to be<N>    generated, either using PEP 517 or using the legacy `setup.py egg_info`.<N>    """<N><N>
    def get_pkg_resources_distribution(self):<N>        # type: () -> Distribution<N>        return self.req.get_dist()<N><N>    def prepare_distribution_metadata(self, finder, build_isolation):<N>        # type: (PackageFinder, bool) -> None<N>        # Load pyproject.toml, to determine whether PEP 517 is to be used<N>        self.req.load_pyproject_toml()<N><N>
        # Set up the build isolation, if this requirement should be isolated<N>        should_isolate = self.req.use_pep517 and build_isolation<N>        if should_isolate:<N>            self._setup_isolation(finder)<N><N>        self.req.prepare_metadata()<N><N>
import abc<N>from typing import Optional<N><N>from pip._vendor.pkg_resources import Distribution<N><N>from pip._internal.index.package_finder import PackageFinder<N>from pip._internal.req import InstallRequirement<N><N><N>class AbstractDistribution(metaclass=abc.ABCMeta):<N>    """A base class for handling installable artifacts.<N><N>
    The requirements for anything installable are as follows:<N><N>     - we must be able to determine the requirement name<N>       (or we can't correctly handle the non-upgrade case).<N><N>     - for packages with setup requirements, we must also be able<N>       to determine their requirements without installing additional<N>       packages (for the same reason as run-time dependencies)<N><N>
     - we must be able to create a Distribution object exposing the<N>       above metadata.<N>    """<N><N>    def __init__(self, req):<N>        # type: (InstallRequirement) -> None<N>        super().__init__()<N>        self.req = req<N><N>    @abc.abstractmethod<N>    def get_pkg_resources_distribution(self):<N>        # type: () -> Optional[Distribution]<N>        raise NotImplementedError()<N><N>
from zipfile import ZipFile<N><N>from pip._vendor.pkg_resources import Distribution<N><N>from pip._internal.distributions.base import AbstractDistribution<N>from pip._internal.index.package_finder import PackageFinder<N>from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel<N><N>
"""Routines related to PyPI, indexes"""<N><N># The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import functools<N>import itertools<N>import logging<N>import re<N>from typing import FrozenSet, Iterable, List, Optional, Set, Tuple, Union<N><N>
from pip._vendor.packaging import specifiers<N>from pip._vendor.packaging.tags import Tag<N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.packaging.version import _BaseVersion<N>from pip._vendor.packaging.version import parse as parse_version<N><N>
"""<N>The main purpose of this module is to expose LinkCollector.collect_sources().<N>"""<N><N>import cgi<N>import collections<N>import functools<N>import html<N>import itertools<N>import logging<N>import os<N>import re<N>import urllib.parse<N>import urllib.request<N>import xml.etree.ElementTree<N>from optparse import Values<N>from typing import (<N>    Callable,<N>    Iterable,<N>    List,<N>    MutableMapping,<N>    NamedTuple,<N>    Optional,<N>    Sequence,<N>    Union,<N>)<N><N>
import logging<N>import mimetypes<N>import os<N>import pathlib<N>from typing import Callable, Iterable, Optional, Tuple<N><N>from pip._internal.models.candidate import InstallationCandidate<N>from pip._internal.models.link import Link<N>from pip._internal.utils.urls import path_to_url, url_to_path<N>from pip._internal.vcs import is_url<N><N>
logger = logging.getLogger(__name__)<N><N>FoundCandidates = Iterable[InstallationCandidate]<N>FoundLinks = Iterable[Link]<N>CandidatesFromPage = Callable[[Link], Iterable[InstallationCandidate]]<N>PageValidator = Callable[[Link], bool]<N><N><N>class LinkSource:<N>    @property<N>    def link(self) -> Optional[Link]:<N>        """Returns the underlying link, if there's one."""<N>        raise NotImplementedError()<N><N>
    def page_candidates(self) -> FoundCandidates:<N>        """Candidates found by parsing an archive listing HTML file."""<N>        raise NotImplementedError()<N><N>    def file_links(self) -> FoundLinks:<N>        """Links found by specifying archives directly."""<N>        raise NotImplementedError()<N><N>
<N>def _is_html_file(file_url: str) -> bool:<N>    return mimetypes.guess_type(file_url, strict=False)[0] == "text/html"<N><N><N>class _FlatDirectorySource(LinkSource):<N>    """Link source specified by ``--find-links=<path-to-dir>``.<N><N>    This looks the content of the directory, and returns:<N><N>
    * ``page_candidates``: Links listed on each HTML file in the directory.<N>    * ``file_candidates``: Archives in the directory.<N>    """<N><N>    def __init__(<N>        self,<N>        candidates_from_page: CandidatesFromPage,<N>        path: str,<N>    ) -> None:<N>        self._candidates_from_page = candidates_from_page<N>        self._path = pathlib.Path(os.path.realpath(path))<N><N>
    @property<N>    def link(self) -> Optional[Link]:<N>        return None<N><N>    def page_candidates(self) -> FoundCandidates:<N>        for path in self._path.iterdir():<N>            url = path_to_url(str(path))<N>            if not _is_html_file(url):<N>                continue<N>            yield from self._candidates_from_page(Link(url))<N><N>
    def file_links(self) -> FoundLinks:<N>        for path in self._path.iterdir():<N>            url = path_to_url(str(path))<N>            if _is_html_file(url):<N>                continue<N>            yield Link(url)<N><N><N>class _LocalFileSource(LinkSource):<N>    """``--find-links=<path-or-url>`` or ``--[extra-]index-url=<path-or-url>``.<N><N>
    If a URL is supplied, it must be a ``file:`` URL. If a path is supplied to<N>    the option, it is converted to a URL first. This returns:<N><N>    * ``page_candidates``: Links listed on an HTML file.<N>    * ``file_candidates``: The non-HTML file.<N>    """<N><N>
    def __init__(<N>        self,<N>        candidates_from_page: CandidatesFromPage,<N>        link: Link,<N>    ) -> None:<N>        self._candidates_from_page = candidates_from_page<N>        self._link = link<N><N>    @property<N>    def link(self) -> Optional[Link]:<N>        return self._link<N><N>
    def page_candidates(self) -> FoundCandidates:<N>        if not _is_html_file(self._link.url):<N>            return<N>        yield from self._candidates_from_page(self._link)<N><N>    def file_links(self) -> FoundLinks:<N>        if _is_html_file(self._link.url):<N>            return<N>        yield self._link<N><N>
from typing import Callable, List<N><N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.req.req_set import RequirementSet<N><N>InstallRequirementProvider = Callable[[str, InstallRequirement], InstallRequirement]<N><N><N>class BaseResolver:<N>    def resolve(self, root_reqs, check_supported_wheels):<N>        # type: (List[InstallRequirement], bool) -> RequirementSet<N>        raise NotImplementedError()<N><N>
"""Dependency Resolution<N><N>The dependency resolution in pip is performed as follows:<N><N>for top-level requirements:<N>    a. only one spec allowed per project, regardless of conflicts or not.<N>       otherwise a "double requirement" exception is raised<N>    b. they override sub-dependency requirements.<N>for sub-dependencies<N>    a. "first found, wins" (where the order is breadth first)<N>"""<N><N>
# The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import logging<N>import sys<N>from collections import defaultdict<N>from itertools import chain<N>from typing import DefaultDict, Iterable, List, Optional, Set, Tuple<N><N>
from pip._vendor.packaging.specifiers import SpecifierSet<N>from pip._vendor.packaging.utils import NormalizedName, canonicalize_name<N><N>from pip._internal.req.req_install import InstallRequirement<N><N>from .base import Candidate, CandidateLookup, Requirement, format_name<N><N>
<N>class ExplicitRequirement(Requirement):<N>    def __init__(self, candidate):<N>        # type: (Candidate) -> None<N>        self.candidate = candidate<N><N>    def __str__(self):<N>        # type: () -> str<N>        return str(self.candidate)<N><N>    def __repr__(self):<N>        # type: () -> str<N>        return "{class_name}({candidate!r})".format(<N>            class_name=self.__class__.__name__,<N>            candidate=self.candidate,<N>        )<N><N>
    @property<N>    def project_name(self):<N>        # type: () -> NormalizedName<N>        # No need to canonicalise - the candidate did this<N>        return self.candidate.project_name<N><N>    @property<N>    def name(self):<N>        # type: () -> str<N>        # No need to canonicalise - the candidate did this<N>        return self.candidate.name<N><N>
    def format_for_error(self):<N>        # type: () -> str<N>        return self.candidate.format_for_error()<N><N>    def get_candidate_lookup(self):<N>        # type: () -> CandidateLookup<N>        return self.candidate, None<N><N>    def is_satisfied_by(self, candidate):<N>        # type: (Candidate) -> bool<N>        return candidate == self.candidate<N><N>
<N>class SpecifierRequirement(Requirement):<N>    def __init__(self, ireq):<N>        # type: (InstallRequirement) -> None<N>        assert ireq.link is None, "This is a link, not a specifier"<N>        self._ireq = ireq<N>        self._extras = frozenset(ireq.extras)<N><N>
    def __str__(self):<N>        # type: () -> str<N>        return str(self._ireq.req)<N><N>    def __repr__(self):<N>        # type: () -> str<N>        return "{class_name}({requirement!r})".format(<N>            class_name=self.__class__.__name__,<N>            requirement=str(self._ireq.req),<N>        )<N><N>
    @property<N>    def project_name(self):<N>        # type: () -> NormalizedName<N>        assert self._ireq.req, "Specifier-backed ireq is always PEP 508"<N>        return canonicalize_name(self._ireq.req.name)<N><N>    @property<N>    def name(self):<N>        # type: () -> str<N>        return format_name(self.project_name, self._extras)<N><N>
    def format_for_error(self):<N>        # type: () -> str<N><N>        # Convert comma-separated specifiers into "A, B, ..., F and G"<N>        # This makes the specifier a bit more "human readable", without<N>        # risking a change in meaning. (Hopefully! Not all edge cases have<N>        # been checked)<N>        parts = [s.strip() for s in str(self).split(",")]<N>        if len(parts) == 0:<N>            return ""<N>        elif len(parts) == 1:<N>            return parts[0]<N><N>
"""Utilities to lazily create and visit candidates found.<N><N>Creating and visiting a candidate is a *very* costly operation. It involves<N>fetching, extracting, potentially building modules from source, and verifying<N>distribution metadata. It is therefore crucial for performance to keep<N>everything here lazy all the way down, so we only touch candidates that we<N>absolutely need, and not "download the world" when we only need one version of<N>something.<N>"""<N><N>
import functools<N>from typing import Callable, Iterator, Optional, Set, Tuple<N><N>from pip._vendor.packaging.version import _BaseVersion<N>from pip._vendor.six.moves import collections_abc  # type: ignore<N><N>from .base import Candidate<N><N>IndexCandidateInfo = Tuple[_BaseVersion, Callable[[], Optional[Candidate]]]<N><N>
import functools<N>import logging<N>import os<N>from typing import TYPE_CHECKING, Dict, List, Optional, Set, Tuple, cast<N><N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.packaging.version import parse as parse_version<N>from pip._vendor.resolvelib import BaseReporter, ResolutionImpossible<N>from pip._vendor.resolvelib import Resolver as RLResolver<N>from pip._vendor.resolvelib.structs import DirectedGraph<N><N>
from typing import TYPE_CHECKING, Dict, Iterable, Iterator, Mapping, Sequence, Union<N><N>from pip._vendor.resolvelib.providers import AbstractProvider<N><N>from .base import Candidate, Constraint, Requirement<N>from .factory import Factory<N><N>if TYPE_CHECKING:<N>    from pip._vendor.resolvelib.providers import Preference<N>    from pip._vendor.resolvelib.resolvers import RequirementInformation<N><N>
import logging<N>import sys<N>from typing import TYPE_CHECKING, Any, FrozenSet, Iterable, Optional, Tuple, Union, cast<N><N>from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet<N>from pip._vendor.packaging.utils import NormalizedName, canonicalize_name<N>from pip._vendor.packaging.version import Version<N>from pip._vendor.packaging.version import parse as parse_version<N>from pip._vendor.pkg_resources import Distribution<N><N>
from pip._internal.exceptions import HashError, MetadataInconsistent<N>from pip._internal.models.link import Link, links_equivalent<N>from pip._internal.models.wheel import Wheel<N>from pip._internal.req.constructors import (<N>    install_req_from_editable,<N>    install_req_from_line,<N>)<N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.utils.misc import dist_is_editable, normalize_version_info<N>from pip._internal.utils.packaging import get_requires_python<N><N>
from .base import Candidate, CandidateVersion, Requirement, format_name<N><N>if TYPE_CHECKING:<N>    from .factory import Factory<N><N>logger = logging.getLogger(__name__)<N><N>BaseCandidate = Union[<N>    "AlreadyInstalledCandidate",<N>    "EditableCandidate",<N>    "LinkCandidate",<N>]<N><N>
<N>def as_base_candidate(candidate: Candidate) -> Optional[BaseCandidate]:<N>    """The runtime version of BaseCandidate."""<N>    base_candidate_classes = (<N>        AlreadyInstalledCandidate,<N>        EditableCandidate,<N>        LinkCandidate,<N>    )<N>    if isinstance(candidate, base_candidate_classes):<N>        return candidate<N>    return None<N><N>
import contextlib<N>import functools<N>import logging<N>from typing import (<N>    TYPE_CHECKING,<N>    Dict,<N>    FrozenSet,<N>    Iterable,<N>    Iterator,<N>    List,<N>    Mapping,<N>    Optional,<N>    Sequence,<N>    Set,<N>    Tuple,<N>    TypeVar,<N>    cast,<N>)<N><N>
from pip._vendor.packaging.requirements import InvalidRequirement<N>from pip._vendor.packaging.requirements import Requirement as PackagingRequirement<N>from pip._vendor.packaging.specifiers import SpecifierSet<N>from pip._vendor.packaging.utils import NormalizedName, canonicalize_name<N>from pip._vendor.pkg_resources import Distribution<N>from pip._vendor.resolvelib import ResolutionImpossible<N><N>
from typing import FrozenSet, Iterable, Optional, Tuple, Union<N><N>from pip._vendor.packaging.specifiers import SpecifierSet<N>from pip._vendor.packaging.utils import NormalizedName, canonicalize_name<N>from pip._vendor.packaging.version import LegacyVersion, Version<N><N>
from pip._internal.models.link import Link, links_equivalent<N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.utils.hashes import Hashes<N><N>CandidateLookup = Tuple[Optional["Candidate"], Optional[InstallRequirement]]<N>CandidateVersion = Union[LegacyVersion, Version]<N><N>
<N>def format_name(project, extras):<N>    # type: (str, FrozenSet[str]) -> str<N>    if not extras:<N>        return project<N>    canonical_extras = sorted(canonicalize_name(e) for e in extras)<N>    return "{}[{}]".format(project, ",".join(canonical_extras))<N><N>
<N>class Constraint:<N>    def __init__(self, specifier, hashes, links):<N>        # type: (SpecifierSet, Hashes, FrozenSet[Link]) -> None<N>        self.specifier = specifier<N>        self.hashes = hashes<N>        self.links = links<N><N>    @classmethod<N>    def empty(cls):<N>        # type: () -> Constraint<N>        return Constraint(SpecifierSet(), Hashes(), frozenset())<N><N>
    @classmethod<N>    def from_ireq(cls, ireq):<N>        # type: (InstallRequirement) -> Constraint<N>        links = frozenset([ireq.link]) if ireq.link else frozenset()<N>        return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)<N><N>
from collections import defaultdict<N>from logging import getLogger<N>from typing import Any, DefaultDict<N><N>from pip._vendor.resolvelib.reporters import BaseReporter<N><N>from .base import Candidate, Requirement<N><N>logger = getLogger(__name__)<N><N><N>class PipReporter(BaseReporter):<N>    def __init__(self):<N>        # type: () -> None<N>        self.backtracks_by_package = defaultdict(int)  # type: DefaultDict[str, int]<N><N>
import collections<N>import logging<N>from typing import Iterator, List, Optional, Sequence, Tuple<N><N>from pip._internal.utils.logging import indent_log<N><N>from .req_file import parse_requirements<N>from .req_install import InstallRequirement<N>from .req_set import RequirementSet<N><N>
__all__ = [<N>    "RequirementSet", "InstallRequirement",<N>    "parse_requirements", "install_given_reqs",<N>]<N><N>logger = logging.getLogger(__name__)<N><N><N>class InstallationResult:<N>    def __init__(self, name):<N>        # type: (str) -> None<N>        self.name = name<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        return f"InstallationResult(name={self.name!r})"<N><N><N>def _validate_requirements(<N>    requirements,  # type: List[InstallRequirement]<N>):<N>    # type: (...) -> Iterator[Tuple[str, InstallRequirement]]<N>    for req in requirements:<N>        assert req.name, f"invalid to-be-installed requirement: {req}"<N>        yield req.name, req<N><N>
<N>def install_given_reqs(<N>    requirements,  # type: List[InstallRequirement]<N>    install_options,  # type: List[str]<N>    global_options,  # type: Sequence[str]<N>    root,  # type: Optional[str]<N>    home,  # type: Optional[str]<N>    prefix,  # type: Optional[str]<N>    warn_script_location,  # type: bool<N>    use_user_site,  # type: bool<N>    pycompile,  # type: bool<N>):<N>    # type: (...) -> List[InstallationResult]<N>    """<N>    Install everything in the given list.<N><N>
    (to be called after having downloaded and unpacked the packages)<N>    """<N>    to_install = collections.OrderedDict(_validate_requirements(requirements))<N><N>    if to_install:<N>        logger.info(<N>            'Installing collected packages: %s',<N>            ', '.join(to_install.keys()),<N>        )<N><N>
    installed = []<N><N>    with indent_log():<N>        for req_name, requirement in to_install.items():<N>            if requirement.should_reinstall:<N>                logger.info('Attempting uninstall: %s', req_name)<N>                with indent_log():<N>                    uninstalled_pathset = requirement.uninstall(<N>                        auto_confirm=True<N>                    )<N>            else:<N>                uninstalled_pathset = None<N><N>
"""Backing implementation for InstallRequirement's various constructors<N><N>The idea here is that these formed a major chunk of InstallRequirement's size<N>so, moving them and support code dedicated to them outside of that class<N>helps creates for better understandability for the rest of the code.<N><N>
These are meant to be used elsewhere within pip to create instances of<N>InstallRequirement.<N>"""<N><N>import logging<N>import os<N>import re<N>from typing import Any, Dict, Optional, Set, Tuple, Union<N><N>from pip._vendor.packaging.markers import Marker<N>from pip._vendor.packaging.requirements import InvalidRequirement, Requirement<N>from pip._vendor.packaging.specifiers import Specifier<N>from pip._vendor.pkg_resources import RequirementParseError, parse_requirements<N><N>
import logging<N>from collections import OrderedDict<N>from typing import Dict, Iterable, List, Optional, Tuple<N><N>from pip._vendor.packaging.utils import canonicalize_name<N><N>from pip._internal.exceptions import InstallationError<N>from pip._internal.models.wheel import Wheel<N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.utils import compatibility_tags<N><N>
logger = logging.getLogger(__name__)<N><N><N>class RequirementSet:<N><N>    def __init__(self, check_supported_wheels=True):<N>        # type: (bool) -> None<N>        """Create a RequirementSet.<N>        """<N><N>        self.requirements = OrderedDict()  # type: Dict[str, InstallRequirement]<N>        self.check_supported_wheels = check_supported_wheels<N><N>
        self.unnamed_requirements = []  # type: List[InstallRequirement]<N><N>    def __str__(self):<N>        # type: () -> str<N>        requirements = sorted(<N>            (req for req in self.requirements.values() if not req.comes_from),<N>            key=lambda req: canonicalize_name(req.name or ""),<N>        )<N>        return ' '.join(str(req.req) for req in requirements)<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        requirements = sorted(<N>            self.requirements.values(),<N>            key=lambda req: canonicalize_name(req.name or ""),<N>        )<N><N>        format_string = '<{classname} object; {count} requirement(s): {reqs}>'<N>        return format_string.format(<N>            classname=self.__class__.__name__,<N>            count=len(requirements),<N>            reqs=', '.join(str(req.req) for req in requirements),<N>        )<N><N>
    def add_unnamed_requirement(self, install_req):<N>        # type: (InstallRequirement) -> None<N>        assert not install_req.name<N>        self.unnamed_requirements.append(install_req)<N><N>    def add_named_requirement(self, install_req):<N>        # type: (InstallRequirement) -> None<N>        assert install_req.name<N><N>
        project_name = canonicalize_name(install_req.name)<N>        self.requirements[project_name] = install_req<N><N>    def add_requirement(<N>        self,<N>        install_req,  # type: InstallRequirement<N>        parent_req_name=None,  # type: Optional[str]<N>        extras_requested=None  # type: Optional[Iterable[str]]<N>    ):<N>        # type: (...) -> Tuple[List[InstallRequirement], Optional[InstallRequirement]]<N>        """Add install_req as a requirement to install.<N><N>
import csv<N>import functools<N>import logging<N>import os<N>import sys<N>import sysconfig<N>from importlib.util import cache_from_source<N>from typing import Any, Callable, Dict, Iterable, Iterator, List, Optional, Set, Tuple<N><N>from pip._vendor import pkg_resources<N>from pip._vendor.pkg_resources import Distribution<N><N>
from pip._internal.exceptions import UninstallationError<N>from pip._internal.locations import get_bin_prefix, get_bin_user<N>from pip._internal.utils.compat import WINDOWS<N>from pip._internal.utils.logging import indent_log<N>from pip._internal.utils.misc import (<N>    ask,<N>    dist_in_usersite,<N>    dist_is_local,<N>    egg_link_path,<N>    is_local,<N>    normalize_path,<N>    renames,<N>    rmtree,<N>)<N>from pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory<N><N>
import contextlib<N>import hashlib<N>import logging<N>import os<N>from types import TracebackType<N>from typing import Dict, Iterator, Optional, Set, Type, Union<N><N>from pip._internal.models.link import Link<N>from pip._internal.req.req_install import InstallRequirement<N>from pip._internal.utils.temp_dir import TempDirectory<N><N>
# The following comment should be removed at some point in the future.<N># mypy: strict-optional=False<N><N>import logging<N>import os<N>import shutil<N>import sys<N>import uuid<N>import zipfile<N>from typing import Any, Dict, Iterable, List, Optional, Sequence, Union<N><N>
from pip._vendor import pkg_resources, six<N>from pip._vendor.packaging.markers import Marker<N>from pip._vendor.packaging.requirements import Requirement<N>from pip._vendor.packaging.specifiers import SpecifierSet<N>from pip._vendor.packaging.utils import canonicalize_name<N>from pip._vendor.packaging.version import Version<N>from pip._vendor.packaging.version import parse as parse_version<N>from pip._vendor.pep517.wrappers import Pep517HookCaller<N>from pip._vendor.pkg_resources import Distribution<N><N>
"""<N>pip._vendor is for vendoring dependencies of pip to prevent needing pip to<N>depend on something external.<N><N>Files inside of pip._vendor should be considered immutable and should only be<N>updated to versions from upstream.<N>"""<N>from __future__ import absolute_import<N><N>
import glob<N>import os.path<N>import sys<N><N># Downstream redistributors which have debundled our dependencies should also<N># patch this value to be true. This will trigger the additional patching<N># to cause things like "six" to be available as pip.<N>DEBUNDLED = False<N><N>
# By default, look in this directory for a bunch of .whl files which we will<N># add to the beginning of sys.path before attempting to import anything. This<N># is done to support downstream re-distributors like Debian and Fedora who<N># wish to create their own Wheels for our dependencies to aid in debundling.<N>WHEEL_DIR = os.path.abspath(os.path.dirname(__file__))<N><N>
<N># Define a small helper function to alias our vendored modules to the real ones<N># if the vendored ones do not exist. This idea of this was taken from<N># https://github.com/kennethreitz/requests/pull/2567.<N>def vendored(modulename):<N>    vendored_name = "{0}.{1}".format(__name__, modulename)<N><N>
"""<N>All of the Enums that are used throughout the chardet package.<N><N>:author: Dan Blanchard (dan.blanchard@gmail.com)<N>"""<N><N><N>class InputState(object):<N>    """<N>    This enum represents the different states a universal detector can be in.<N>    """<N>    PURE_ASCII = 0<N>    ESC_ASCII = 1<N>    HIGH_BYTE = 2<N><N>
<N>class LanguageFilter(object):<N>    """<N>    This enum represents the different language filters we can apply to a<N>    ``UniversalDetector``.<N>    """<N>    CHINESE_SIMPLIFIED = 0x01<N>    CHINESE_TRADITIONAL = 0x02<N>    JAPANESE = 0x04<N>    KOREAN = 0x08<N>    NON_CJK = 0x10<N>    ALL = 0x1F<N>    CHINESE = CHINESE_SIMPLIFIED | CHINESE_TRADITIONAL<N>    CJK = CHINESE | JAPANESE | KOREAN<N><N>
<N>class ProbingState(object):<N>    """<N>    This enum represents the different states a prober can be in.<N>    """<N>    DETECTING = 0<N>    FOUND_IT = 1<N>    NOT_ME = 2<N><N><N>class MachineState(object):<N>    """<N>    This enum represents the different states a state machine can be in.<N>    """<N>    START = 0<N>    ERROR = 1<N>    ITS_ME = 2<N><N>
<N>class SequenceLikelihood(object):<N>    """<N>    This enum represents the likelihood of a character following the previous one.<N>    """<N>    NEGATIVE = 0<N>    UNLIKELY = 1<N>    LIKELY = 2<N>    POSITIVE = 3<N><N>    @classmethod<N>    def get_num_categories(cls):<N>        """:returns: The number of likelihood categories in the enum."""<N>        return 4<N><N>
<N>class CharacterCategory(object):<N>    """<N>    This enum represents the different categories language models for<N>    ``SingleByteCharsetProber`` put characters into.<N><N>    Anything less than CONTROL is considered a letter.<N>    """<N>    UNDEFINED = 255<N>    LINE_BREAK = 254<N>    SYMBOL = 253<N>    DIGIT = 252<N>    CONTROL = 251<N><N><N>
"""<N>This module exists only to simplify retrieving the version number of chardet<N>from within setup.py and from chardet subpackages.<N><N>:author: Dan Blanchard (dan.blanchard@gmail.com)<N>"""<N><N>__version__ = "4.0.0"<N>VERSION = __version__.split('.')<N>
#!/usr/bin/env python<N># -*- coding: utf-8 -*-<N>"""<N>Metadata about languages used by our model training code for our<N>SingleByteCharSetProbers.  Could be used for other things in the future.<N><N>This code is based on the language metadata from the uchardet project.<N>"""<N>from __future__ import absolute_import, print_function<N><N>
"""<N>Script which takes one or more file paths and reports on their detected<N>encodings<N><N>Example::<N><N>    % chardetect somefile someotherfile<N>    somefile: windows-1252 with confidence 0.5<N>    someotherfile: ascii with confidence 1.0<N><N>If no paths are provided, it takes its input from stdin.<N><N>
"""<N><N>from __future__ import absolute_import, print_function, unicode_literals<N><N>import argparse<N>import sys<N><N>from pip._vendor.chardet import __version__<N>from pip._vendor.chardet.compat import PY2<N>from pip._vendor.chardet.universaldetector import UniversalDetector<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import sys<N><N>from ._typing import TYPE_CHECKING<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Any, Dict, Tuple, Type<N><N><N>PY2 = sys.version_info[0] == 2<N>PY3 = sys.version_info[0] == 3<N><N># flake8: noqa<N><N>if PY3:<N>    string_types = (str,)<N>else:<N>    string_types = (basestring,)<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import re<N>import string<N>import sys<N><N>from pip._vendor.pyparsing import (  # noqa: N817<N>    Combine,<N>    Literal as L,<N>    Optional,<N>    ParseException,<N>    Regex,<N>    Word,<N>    ZeroOrMore,<N>    originalTextFor,<N>    stringEnd,<N>    stringStart,<N>)<N><N>
from ._typing import TYPE_CHECKING<N>from .markers import MARKER_EXPR, Marker<N>from .specifiers import LegacySpecifier, Specifier, SpecifierSet<N><N>if sys.version_info[0] >= 3:<N>    from urllib import parse as urlparse  # pragma: no cover<N>else:  # pragma: no cover<N>    import urlparse<N><N>
<N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import List, Optional as TOptional, Set<N><N><N>class InvalidRequirement(ValueError):<N>    """<N>    An invalid requirement was found, users should refer to PEP 508.<N>    """<N><N><N>ALPHANUM = Word(string.ascii_letters + string.digits)<N><N>
LBRACKET = L("[").suppress()<N>RBRACKET = L("]").suppress()<N>LPAREN = L("(").suppress()<N>RPAREN = L(")").suppress()<N>COMMA = L(",").suppress()<N>SEMICOLON = L(";").suppress()<N>AT = L("@").suppress()<N><N>PUNCTUATION = Word("-_.")<N>IDENTIFIER_END = ALPHANUM | (ZeroOrMore(PUNCTUATION) + ALPHANUM)<N>IDENTIFIER = Combine(ALPHANUM + ZeroOrMore(IDENTIFIER_END))<N><N>
NAME = IDENTIFIER("name")<N>EXTRA = IDENTIFIER<N><N>URI = Regex(r"[^ ]+")("url")<N>URL = AT + URI<N><N>EXTRAS_LIST = EXTRA + ZeroOrMore(COMMA + EXTRA)<N>EXTRAS = (LBRACKET + Optional(EXTRAS_LIST) + RBRACKET)("extras")<N><N>VERSION_PEP440 = Regex(Specifier._regex_str, re.VERBOSE | re.IGNORECASE)<N>VERSION_LEGACY = Regex(LegacySpecifier._regex_str, re.VERBOSE | re.IGNORECASE)<N><N>
VERSION_ONE = VERSION_PEP440 ^ VERSION_LEGACY<N>VERSION_MANY = Combine(<N>    VERSION_ONE + ZeroOrMore(COMMA + VERSION_ONE), joinString=",", adjacent=False<N>)("_raw_spec")<N>_VERSION_SPEC = Optional(((LPAREN + VERSION_MANY + RPAREN) | VERSION_MANY))<N>_VERSION_SPEC.setParseAction(lambda s, l, t: t._raw_spec or "")<N><N>
VERSION_SPEC = originalTextFor(_VERSION_SPEC)("specifier")<N>VERSION_SPEC.setParseAction(lambda s, l, t: t[1])<N><N>MARKER_EXPR = originalTextFor(MARKER_EXPR())("marker")<N>MARKER_EXPR.setParseAction(<N>    lambda s, l, t: Marker(s[t._original_start : t._original_end])<N>)<N>MARKER_SEPARATOR = SEMICOLON<N>MARKER = MARKER_SEPARATOR + MARKER_EXPR<N><N>
VERSION_AND_MARKER = VERSION_SPEC + Optional(MARKER)<N>URL_AND_MARKER = URL + Optional(MARKER)<N><N>NAMED_REQUIREMENT = NAME + Optional(EXTRAS) + (URL_AND_MARKER | VERSION_AND_MARKER)<N><N>REQUIREMENT = stringStart + NAMED_REQUIREMENT + stringEnd<N># pyparsing isn't thread safe during initialization, so we do it eagerly, see<N># issue #104<N>REQUIREMENT.parseString("x[]")<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
from .__about__ import (<N>    __author__,<N>    __copyright__,<N>    __email__,<N>    __license__,<N>    __summary__,<N>    __title__,<N>    __uri__,<N>    __version__,<N>)<N><N>__all__ = [<N>    "__title__",<N>    "__summary__",<N>    "__uri__",<N>    "__version__",<N>    "__author__",<N>    "__email__",<N>    "__license__",<N>    "__copyright__",<N>]<N><N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import abc<N>import functools<N>import itertools<N>import re<N>import warnings<N><N>from ._compat import string_types, with_metaclass<N>from ._typing import TYPE_CHECKING<N>from .utils import canonicalize_version<N>from .version import LegacyVersion, Version, parse<N><N>
if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Callable, Dict, Iterable, Iterator, List, Optional, Tuple, Union<N><N>    ParsedVersion = Union[Version, LegacyVersion]<N>    UnparsedVersion = Union[Version, LegacyVersion, str]<N>    CallableOperator = Callable[[ParsedVersion, str], bool]<N><N>
<N>class InvalidSpecifier(ValueError):<N>    """<N>    An invalid specifier was found, users should refer to PEP 440.<N>    """<N><N><N>class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):  # type: ignore<N>    @abc.abstractmethod<N>    def __str__(self):<N>        # type: () -> str<N>        """<N>        Returns the str representation of this Specifier like object. This<N>        should be representative of the Specifier itself.<N>        """<N><N>
    @abc.abstractmethod<N>    def __hash__(self):<N>        # type: () -> int<N>        """<N>        Returns a hash value for this Specifier like object.<N>        """<N><N>    @abc.abstractmethod<N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        """<N>        Returns a boolean representing whether or not the two Specifier like<N>        objects are equal.<N>        """<N><N>
    @abc.abstractmethod<N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        """<N>        Returns a boolean representing whether or not the two Specifier like<N>        objects are not equal.<N>        """<N><N>    @abc.abstractproperty<N>    def prereleases(self):<N>        # type: () -> Optional[bool]<N>        """<N>        Returns whether or not pre-releases as a whole are allowed by this<N>        specifier.<N>        """<N><N>
    @prereleases.setter<N>    def prereleases(self, value):<N>        # type: (bool) -> None<N>        """<N>        Sets whether or not pre-releases as a whole are allowed by this<N>        specifier.<N>        """<N><N>    @abc.abstractmethod<N>    def contains(self, item, prereleases=None):<N>        # type: (str, Optional[bool]) -> bool<N>        """<N>        Determines if the given item is contained within this specifier.<N>        """<N><N>
    @abc.abstractmethod<N>    def filter(self, iterable, prereleases=None):<N>        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]<N>        """<N>        Takes an iterable of items and filters them so that only items which<N>        are contained within this specifier are allowed in it.<N>        """<N><N>
<N>class _IndividualSpecifier(BaseSpecifier):<N><N>    _operators = {}  # type: Dict[str, str]<N><N>    def __init__(self, spec="", prereleases=None):<N>        # type: (str, Optional[bool]) -> None<N>        match = self._regex.search(spec)<N>        if not match:<N>            raise InvalidSpecifier("Invalid specifier: '{0}'".format(spec))<N><N>
        self._spec = (<N>            match.group("operator").strip(),<N>            match.group("version").strip(),<N>        )  # type: Tuple[str, str]<N><N>        # Store whether or not this Specifier should accept prereleases<N>        self._prereleases = prereleases<N><N>
    def __repr__(self):<N>        # type: () -> str<N>        pre = (<N>            ", prereleases={0!r}".format(self.prereleases)<N>            if self._prereleases is not None<N>            else ""<N>        )<N><N>        return "<{0}({1!r}{2})>".format(self.__class__.__name__, str(self), pre)<N><N>
    def __str__(self):<N>        # type: () -> str<N>        return "{0}{1}".format(*self._spec)<N><N>    @property<N>    def _canonical_spec(self):<N>        # type: () -> Tuple[str, Union[Version, str]]<N>        return self._spec[0], canonicalize_version(self._spec[1])<N><N>
    def __hash__(self):<N>        # type: () -> int<N>        return hash(self._canonical_spec)<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        if isinstance(other, string_types):<N>            try:<N>                other = self.__class__(str(other))<N>            except InvalidSpecifier:<N>                return NotImplemented<N>        elif not isinstance(other, self.__class__):<N>            return NotImplemented<N><N>
        return self._canonical_spec == other._canonical_spec<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        if isinstance(other, string_types):<N>            try:<N>                other = self.__class__(str(other))<N>            except InvalidSpecifier:<N>                return NotImplemented<N>        elif not isinstance(other, self.__class__):<N>            return NotImplemented<N><N>
        return self._spec != other._spec<N><N>    def _get_operator(self, op):<N>        # type: (str) -> CallableOperator<N>        operator_callable = getattr(<N>            self, "_compare_{0}".format(self._operators[op])<N>        )  # type: CallableOperator<N>        return operator_callable<N><N>
    def _coerce_version(self, version):<N>        # type: (UnparsedVersion) -> ParsedVersion<N>        if not isinstance(version, (LegacyVersion, Version)):<N>            version = parse(version)<N>        return version<N><N>    @property<N>    def operator(self):<N>        # type: () -> str<N>        return self._spec[0]<N><N>
    @property<N>    def version(self):<N>        # type: () -> str<N>        return self._spec[1]<N><N>    @property<N>    def prereleases(self):<N>        # type: () -> Optional[bool]<N>        return self._prereleases<N><N>    @prereleases.setter<N>    def prereleases(self, value):<N>        # type: (bool) -> None<N>        self._prereleases = value<N><N>
    def __contains__(self, item):<N>        # type: (str) -> bool<N>        return self.contains(item)<N><N>    def contains(self, item, prereleases=None):<N>        # type: (UnparsedVersion, Optional[bool]) -> bool<N><N>        # Determine if prereleases are to be allowed or not.<N>        if prereleases is None:<N>            prereleases = self.prereleases<N><N>
        # Normalize item to a Version or LegacyVersion, this allows us to have<N>        # a shortcut for ``"2.0" in Specifier(">=2")<N>        normalized_item = self._coerce_version(item)<N><N>        # Determine if we should be supporting prereleases in this specifier<N>        # or not, if we do not support prereleases than we can short circuit<N>        # logic if this version is a prereleases.<N>        if normalized_item.is_prerelease and not prereleases:<N>            return False<N><N>
        # Actually do the comparison to determine if this item is contained<N>        # within this Specifier or not.<N>        operator_callable = self._get_operator(self.operator)  # type: CallableOperator<N>        return operator_callable(normalized_item, self.version)<N><N>
    def filter(self, iterable, prereleases=None):<N>        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]<N><N>        yielded = False<N>        found_prereleases = []<N><N>        kw = {"prereleases": prereleases if prereleases is not None else True}<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N><N>from __future__ import absolute_import<N><N>import distutils.util<N><N>
try:<N>    from importlib.machinery import EXTENSION_SUFFIXES<N>except ImportError:  # pragma: no cover<N>    import imp<N><N>    EXTENSION_SUFFIXES = [x[0] for x in imp.get_suffixes()]<N>    del imp<N>import collections<N>import logging<N>import os<N>import platform<N>import re<N>import struct<N>import sys<N>import sysconfig<N>import warnings<N><N>
from ._typing import TYPE_CHECKING, cast<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import (<N>        IO,<N>        Dict,<N>        FrozenSet,<N>        Iterable,<N>        Iterator,<N>        List,<N>        Optional,<N>        Sequence,<N>        Tuple,<N>        Union,<N>    )<N><N>
    PythonVersion = Sequence[int]<N>    MacVersion = Tuple[int, int]<N>    GlibcVersion = Tuple[int, int]<N><N><N>logger = logging.getLogger(__name__)<N><N>INTERPRETER_SHORT_NAMES = {<N>    "python": "py",  # Generic.<N>    "cpython": "cp",<N>    "pypy": "pp",<N>    "ironpython": "ip",<N>    "jython": "jy",<N>}  # type: Dict[str, str]<N><N>
<N>_32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32<N><N><N>_LEGACY_MANYLINUX_MAP = {<N>    # CentOS 7 w/ glibc 2.17 (PEP 599)<N>    (2, 17): "manylinux2014",<N>    # CentOS 6 w/ glibc 2.12 (PEP 571)<N>    (2, 12): "manylinux2010",<N>    # CentOS 5 w/ glibc 2.5 (PEP 513)<N>    (2, 5): "manylinux1",<N>}<N><N>
# If glibc ever changes its major version, we need to know what the last<N># minor version was, so we can build the complete list of all versions.<N># For now, guess what the highest minor version might be, assume it will<N># be 50 for testing. Once this actually happens, update the dictionary<N># with the actual value.<N>_LAST_GLIBC_MINOR = collections.defaultdict(lambda: 50)  # type: Dict[int, int]<N>glibcVersion = collections.namedtuple("Version", ["major", "minor"])<N><N>
<N>class Tag(object):<N>    """<N>    A representation of the tag triple for a wheel.<N><N>    Instances are considered immutable and thus are hashable. Equality checking<N>    is also supported.<N>    """<N><N>    __slots__ = ["_interpreter", "_abi", "_platform", "_hash"]<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import collections<N>import itertools<N>import re<N>import warnings<N><N>from ._structures import Infinity, NegativeInfinity<N>from ._typing import TYPE_CHECKING<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
<N>class InfinityType(object):<N>    def __repr__(self):<N>        # type: () -> str<N>        return "Infinity"<N><N>    def __hash__(self):<N>        # type: () -> int<N>        return hash(repr(self))<N><N>    def __lt__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>
    def __le__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        return isinstance(other, self.__class__)<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        return not isinstance(other, self.__class__)<N><N>
    def __gt__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __ge__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __neg__(self):<N>        # type: (object) -> NegativeInfinityType<N>        return NegativeInfinity<N><N>
<N>Infinity = InfinityType()<N><N><N>class NegativeInfinityType(object):<N>    def __repr__(self):<N>        # type: () -> str<N>        return "-Infinity"<N><N>    def __hash__(self):<N>        # type: () -> int<N>        return hash(repr(self))<N><N>    def __lt__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>
    def __le__(self, other):<N>        # type: (object) -> bool<N>        return True<N><N>    def __eq__(self, other):<N>        # type: (object) -> bool<N>        return isinstance(other, self.__class__)<N><N>    def __ne__(self, other):<N>        # type: (object) -> bool<N>        return not isinstance(other, self.__class__)<N><N>
    def __gt__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __ge__(self, other):<N>        # type: (object) -> bool<N>        return False<N><N>    def __neg__(self):<N>        # type: (object) -> InfinityType<N>        return Infinity<N><N>
"""For neatly implementing static typing in packaging.<N><N>`mypy` - the static type analysis tool we use - uses the `typing` module, which<N>provides core functionality fundamental to mypy's functioning.<N><N>Generally, `typing` would be imported at runtime and used in that fashion -<N>it acts as a no-op at runtime and does not have any run-time overhead by<N>design.<N><N>
As it turns out, `typing` is not vendorable - it uses separate sources for<N>Python 2/Python 3. Thus, this codebase can not expect it to be present.<N>To work around this, mypy allows the typing import to be behind a False-y<N>optional to prevent it from running at runtime and type-comments can be used<N>to remove the need for the types to be accessible directly during runtime.<N><N>
This module provides the False-y guard in a nicely named fashion so that a<N>curious maintainer can reach here to read this.<N><N>In packaging, all static-typing related imports should be guarded as follows:<N><N>    from pip._vendor.packaging._typing import TYPE_CHECKING<N><N>
    if TYPE_CHECKING:<N>        from typing import ...<N><N>Ref: https://github.com/python/mypy/issues/3216<N>"""<N><N>__all__ = ["TYPE_CHECKING", "cast"]<N><N># The TYPE_CHECKING constant defined by the typing module is False at runtime<N># but True while type checking.<N>if False:  # pragma: no cover<N>    from typing import TYPE_CHECKING<N>else:<N>    TYPE_CHECKING = False<N><N>
# typing's cast syntax requires calling typing.cast at runtime, but we don't<N># want to import typing at runtime. Here, we inform the type checkers that<N># we're importing `typing.cast` as `cast` and re-implement typing.cast's<N># runtime behavior in a block that is ignored by type checkers.<N>if TYPE_CHECKING:  # pragma: no cover<N>    # not executed at runtime<N>    from typing import cast<N>else:<N>    # executed at runtime<N>    def cast(type_, value):  # noqa<N>        return value<N><N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
__all__ = [<N>    "__title__",<N>    "__summary__",<N>    "__uri__",<N>    "__version__",<N>    "__author__",<N>    "__email__",<N>    "__license__",<N>    "__copyright__",<N>]<N><N>__title__ = "packaging"<N>__summary__ = "Core utilities for Python packages"<N>__uri__ = "https://github.com/pypa/packaging"<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import operator<N>import os<N>import platform<N>import sys<N><N>from pip._vendor.pyparsing import (  # noqa: N817<N>    Forward,<N>    Group,<N>    Literal as L,<N>    ParseException,<N>    ParseResults,<N>    QuotedString,<N>    ZeroOrMore,<N>    stringEnd,<N>    stringStart,<N>)<N><N>
from ._compat import string_types<N>from ._typing import TYPE_CHECKING<N>from .specifiers import InvalidSpecifier, Specifier<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import Any, Callable, Dict, List, Optional, Tuple, Union<N><N>    Operator = Callable[[str, str], bool]<N><N>
<N>__all__ = [<N>    "InvalidMarker",<N>    "UndefinedComparison",<N>    "UndefinedEnvironmentName",<N>    "Marker",<N>    "default_environment",<N>]<N><N><N>class InvalidMarker(ValueError):<N>    """<N>    An invalid marker was found, users should refer to PEP 508.<N>    """<N><N>
<N>class UndefinedComparison(ValueError):<N>    """<N>    An invalid operation was attempted on a value that doesn't support it.<N>    """<N><N><N>class UndefinedEnvironmentName(ValueError):<N>    """<N>    A name was attempted to be used that does not exist inside of the<N>    environment.<N>    """<N><N>
<N>class Node(object):<N>    def __init__(self, value):<N>        # type: (Any) -> None<N>        self.value = value<N><N>    def __str__(self):<N>        # type: () -> str<N>        return str(self.value)<N><N>    def __repr__(self):<N>        # type: () -> str<N>        return "<{0}({1!r})>".format(self.__class__.__name__, str(self))<N><N>
    def serialize(self):<N>        # type: () -> str<N>        raise NotImplementedError<N><N><N>class Variable(Node):<N>    def serialize(self):<N>        # type: () -> str<N>        return str(self)<N><N><N>class Value(Node):<N>    def serialize(self):<N>        # type: () -> str<N>        return '"{0}"'.format(self)<N><N>
# This file is dual licensed under the terms of the Apache License, Version<N># 2.0, and the BSD License. See the LICENSE file in the root of this repository<N># for complete details.<N>from __future__ import absolute_import, division, print_function<N><N>
import re<N><N>from ._typing import TYPE_CHECKING, cast<N>from .tags import Tag, parse_tag<N>from .version import InvalidVersion, Version<N><N>if TYPE_CHECKING:  # pragma: no cover<N>    from typing import FrozenSet, NewType, Tuple, Union<N><N>    BuildTag = Union[Tuple[()], Tuple[int, str]]<N>    NormalizedName = NewType("NormalizedName", str)<N>else:<N>    BuildTag = tuple<N>    NormalizedName = str<N><N>
<N>class InvalidWheelFilename(ValueError):<N>    """<N>    An invalid wheel filename was found, users should refer to PEP 427.<N>    """<N><N><N>class InvalidSdistFilename(ValueError):<N>    """<N>    An invalid sdist filename was found, users should refer to the packaging user guide.<N>    """<N><N>
<N>_canonicalize_regex = re.compile(r"[-_.]+")<N># PEP 427: The build number must start with a digit.<N>_build_tag_regex = re.compile(r"(\d+)(.*)")<N><N><N>def canonicalize_name(name):<N>    # type: (str) -> NormalizedName<N>    # This is taken from PEP 503.<N>    value = _canonicalize_regex.sub("-", name).lower()<N>    return cast(NormalizedName, value)<N><N>
<N>def canonicalize_version(version):<N>    # type: (Union[Version, str]) -> Union[Version, str]<N>    """<N>    This is very similar to Version.__str__, but has one subtle difference<N>    with the way it handles the release segment.<N>    """<N>    if not isinstance(version, Version):<N>        try:<N>            version = Version(version)<N>        except InvalidVersion:<N>            # Legacy versions cannot be normalized<N>            return version<N><N>
    parts = []<N><N>    # Epoch<N>    if version.epoch != 0:<N>        parts.append("{0}!".format(version.epoch))<N><N>    # Release segment<N>    # NB: This strips trailing '.0's to normalize<N>    parts.append(re.sub(r"(\.0)+$", "", ".".join(str(x) for x in version.release)))<N><N>
    # Pre-release<N>    if version.pre is not None:<N>        parts.append("".join(str(x) for x in version.pre))<N><N>    # Post-release<N>    if version.post is not None:<N>        parts.append(".post{0}".format(version.post))<N><N>    # Development release<N>    if version.dev is not None:<N>        parts.append(".dev{0}".format(version.dev))<N><N>
    # Local version segment<N>    if version.local is not None:<N>        parts.append("+{0}".format(version.local))<N><N>    return "".join(parts)<N><N><N>def parse_wheel_filename(filename):<N>    # type: (str) -> Tuple[NormalizedName, Version, BuildTag, FrozenSet[Tag]]<N>    if not filename.endswith(".whl"):<N>        raise InvalidWheelFilename(<N>            "Invalid wheel filename (extension must be '.whl'): {0}".format(filename)<N>        )<N><N>
import argparse<N><N>from pip._vendor.certifi import contents, where<N><N>parser = argparse.ArgumentParser()<N>parser.add_argument("-c", "--contents", action="store_true")<N>args = parser.parse_args()<N><N>if args.contents:<N>    print(contents())<N>else:<N>    print(where())<N>
"""Python 2/3 compatibility"""<N>import json<N>import sys<N><N><N># Handle reading and writing JSON in UTF-8, on Python 3 and 2.<N><N>if sys.version_info[0] >= 3:<N>    # Python 3<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'w', encoding='utf-8') as f:<N>            json.dump(obj, f, **kwargs)<N><N>
    def read_json(path):<N>        with open(path, 'r', encoding='utf-8') as f:<N>            return json.load(f)<N><N>else:<N>    # Python 2<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'wb') as f:<N>            json.dump(obj, f, encoding='utf-8', **kwargs)<N><N>
"""Wrappers to build Python packages using PEP 517 hooks<N>"""<N><N>__version__ = '0.10.0'<N><N>from .wrappers import *  # noqa: F401, F403<N>
import os<N>import io<N>import contextlib<N>import tempfile<N>import shutil<N>import errno<N>import zipfile<N><N><N>@contextlib.contextmanager<N>def tempdir():<N>    """Create a temporary directory in a context manager."""<N>    td = tempfile.mkdtemp()<N>    try:<N>        yield td<N>    finally:<N>        shutil.rmtree(td)<N><N>
<N>def mkdir_p(*args, **kwargs):<N>    """Like `mkdir`, but does not raise an exception if the<N>    directory already exists.<N>    """<N>    try:<N>        return os.mkdir(*args, **kwargs)<N>    except OSError as exc:<N>        if exc.errno != errno.EEXIST:<N>            raise<N><N>
import threading<N>from contextlib import contextmanager<N>import os<N>from os.path import abspath, join as pjoin<N>import shutil<N>from subprocess import check_call, check_output, STDOUT<N>import sys<N>from tempfile import mkdtemp<N><N>from . import compat<N>from .in_process import _in_proc_script_path<N><N>
__all__ = [<N>    'BackendUnavailable',<N>    'BackendInvalid',<N>    'HookMissing',<N>    'UnsupportedOperation',<N>    'default_subprocess_runner',<N>    'quiet_subprocess_runner',<N>    'Pep517HookCaller',<N>]<N><N><N>@contextmanager<N>def tempdir():<N>    td = mkdtemp()<N>    try:<N>        yield td<N>    finally:<N>        shutil.rmtree(td)<N><N>
<N>class BackendUnavailable(Exception):<N>    """Will be raised if the backend cannot be imported in the hook process."""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N><N>class BackendInvalid(Exception):<N>    """Will be raised if the backend is invalid."""<N>    def __init__(self, backend_name, backend_path, message):<N>        self.backend_name = backend_name<N>        self.backend_path = backend_path<N>        self.message = message<N><N>
<N>class HookMissing(Exception):<N>    """Will be raised on missing hooks."""<N>    def __init__(self, hook_name):<N>        super(HookMissing, self).__init__(hook_name)<N>        self.hook_name = hook_name<N><N><N>class UnsupportedOperation(Exception):<N>    """May be raised by build_sdist if the backend indicates that it can't."""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N>
<N>def default_subprocess_runner(cmd, cwd=None, extra_environ=None):<N>    """The default method of calling the wrapper subprocess."""<N>    env = os.environ.copy()<N>    if extra_environ:<N>        env.update(extra_environ)<N><N>    check_call(cmd, cwd=cwd, env=env)<N><N>
<N>def quiet_subprocess_runner(cmd, cwd=None, extra_environ=None):<N>    """A method of calling the wrapper subprocess while suppressing output."""<N>    env = os.environ.copy()<N>    if extra_environ:<N>        env.update(extra_environ)<N><N>    check_output(cmd, cwd=cwd, env=env, stderr=STDOUT)<N><N>
<N>def norm_and_check(source_tree, requested):<N>    """Normalise and check a backend path.<N><N>    Ensure that the requested backend path is specified as a relative path,<N>    and resolves to a location under the given source tree.<N><N>    Return an absolute version of the requested path.<N>    """<N>    if os.path.isabs(requested):<N>        raise ValueError("paths must be relative")<N><N>
"""Check a project and backend by attempting to build using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>from os.path import isfile, join as pjoin<N>from pip._vendor.toml import TomlDecodeError, load as toml_load<N>import shutil<N>from subprocess import CalledProcessError<N>import sys<N>import tarfile<N>from tempfile import mkdtemp<N>import zipfile<N><N>
"""Build a project using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>from pip._vendor import toml<N>import shutil<N><N>from .envbuild import BuildEnvironment<N>from .wrappers import Pep517HookCaller<N>from .dirtools import tempdir, mkdir_p<N>from .compat import FileNotFoundError<N><N>
log = logging.getLogger(__name__)<N><N><N>def validate_system(system):<N>    """<N>    Ensure build system has the requisite fields.<N>    """<N>    required = {'requires', 'build-backend'}<N>    if not (required <= set(system)):<N>        message = "Missing required fields: {missing}".format(<N>            missing=required-set(system),<N>        )<N>        raise ValueError(message)<N><N>
<N>def load_system(source_dir):<N>    """<N>    Load the build system from a source dir (pyproject.toml).<N>    """<N>    pyproject = os.path.join(source_dir, 'pyproject.toml')<N>    with open(pyproject) as f:<N>        pyproject_data = toml.load(f)<N>    return pyproject_data['build-system']<N><N>
"""Build metadata for a project using PEP 517 hooks.<N>"""<N>import argparse<N>import logging<N>import os<N>import shutil<N>import functools<N><N>try:<N>    import importlib.metadata as imp_meta<N>except ImportError:<N>    import importlib_metadata as imp_meta<N><N>
try:<N>    from zipfile import Path<N>except ImportError:<N>    from zipp import Path<N><N>from .envbuild import BuildEnvironment<N>from .wrappers import Pep517HookCaller, quiet_subprocess_runner<N>from .dirtools import tempdir, mkdir_p, dir_to_zipfile<N>from .build import validate_system, load_system, compat_system<N><N>
log = logging.getLogger(__name__)<N><N><N>def _prep_meta(hooks, env, dest):<N>    reqs = hooks.get_requires_for_build_wheel({})<N>    log.info('Got build requires: %s', reqs)<N><N>    env.pip_install(reqs)<N>    log.info('Installed dynamic build dependencies')<N><N>
    with tempdir() as td:<N>        log.info('Trying to build metadata in %s', td)<N>        filename = hooks.prepare_metadata_for_build_wheel(td, {})<N>        source = os.path.join(td, filename)<N>        shutil.move(source, os.path.join(dest, os.path.basename(filename)))<N><N>
<N>def build(source_dir='.', dest=None, system=None):<N>    system = system or load_system(source_dir)<N>    dest = os.path.join(source_dir, dest or 'dist')<N>    mkdir_p(dest)<N>    validate_system(system)<N>    hooks = Pep517HookCaller(<N>        source_dir, system['build-backend'], system.get('backend-path')<N>    )<N><N>
    with hooks.subprocess_runner(quiet_subprocess_runner):<N>        with BuildEnvironment() as env:<N>            env.pip_install(system['requires'])<N>            _prep_meta(hooks, env, dest)<N><N><N>def build_as_zip(builder=build):<N>    with tempdir() as out_dir:<N>        builder(dest=out_dir)<N>        return dir_to_zipfile(out_dir)<N><N>
<N>def load(root):<N>    """<N>    Given a source directory (root) of a package,<N>    return an importlib.metadata.Distribution object<N>    with metadata build from that package.<N>    """<N>    root = os.path.expanduser(root)<N>    system = compat_system(root)<N>    builder = functools.partial(build, source_dir=root, system=system)<N>    path = Path(build_as_zip(builder))<N>    return imp_meta.PathDistribution(path)<N><N>
<N>parser = argparse.ArgumentParser()<N>parser.add_argument(<N>    'source_dir',<N>    help="A directory containing pyproject.toml",<N>)<N>parser.add_argument(<N>    '--out-dir', '-o',<N>    help="Destination in which to save the builds relative to source dir",<N>)<N><N>
"""Build wheels/sdists by installing build deps to a temporary environment.<N>"""<N><N>import os<N>import logging<N>from pip._vendor import toml<N>import shutil<N>from subprocess import check_call<N>import sys<N>from sysconfig import get_paths<N>from tempfile import mkdtemp<N><N>
from .wrappers import Pep517HookCaller, LoggerWrapper<N><N>log = logging.getLogger(__name__)<N><N><N>def _load_pyproject(source_dir):<N>    with open(os.path.join(source_dir, 'pyproject.toml')) as f:<N>        pyproject_data = toml.load(f)<N>    buildsys = pyproject_data['build-system']<N>    return (<N>        buildsys['requires'],<N>        buildsys['build-backend'],<N>        buildsys.get('backend-path'),<N>    )<N><N>
"""This is a subpackage because the directory is on sys.path for _in_process.py<N><N>The subpackage should stay as empty as possible to avoid shadowing modules that<N>the backend might import.<N>"""<N>from os.path import dirname, abspath, join as pjoin<N>from contextlib import contextmanager<N><N>
try:<N>    import importlib.resources as resources<N><N>    def _in_proc_script_path():<N>        return resources.path(__package__, '_in_process.py')<N>except ImportError:<N>    @contextmanager<N>    def _in_proc_script_path():<N>        yield pjoin(dirname(abspath(__file__)), '_in_process.py')<N><N><N>
"""This is invoked in a subprocess to call the build backend hooks.<N><N>It expects:<N>- Command line args: hook_name, control_dir<N>- Environment variables:<N>      PEP517_BUILD_BACKEND=entry.point:spec<N>      PEP517_BACKEND_PATH=paths (separated with os.pathsep)<N>- control_dir/input.json:<N>  - {"kwargs": {...}}<N><N>
Results:<N>- control_dir/output.json<N>  - {"return_val": ...}<N>"""<N>from glob import glob<N>from importlib import import_module<N>import json<N>import os<N>import os.path<N>from os.path import join as pjoin<N>import re<N>import shutil<N>import sys<N>import traceback<N><N>
# This file is run as a script, and `import compat` is not zip-safe, so we<N># include write_json() and read_json() from compat.py.<N>#<N># Handle reading and writing JSON in UTF-8, on Python 3 and 2.<N><N>if sys.version_info[0] >= 3:<N>    # Python 3<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'w', encoding='utf-8') as f:<N>            json.dump(obj, f, **kwargs)<N><N>
    def read_json(path):<N>        with open(path, 'r', encoding='utf-8') as f:<N>            return json.load(f)<N><N>else:<N>    # Python 2<N>    def write_json(obj, path, **kwargs):<N>        with open(path, 'wb') as f:<N>            json.dump(obj, f, encoding='utf-8', **kwargs)<N><N>
    def read_json(path):<N>        with open(path, 'rb') as f:<N>            return json.load(f)<N><N><N>class BackendUnavailable(Exception):<N>    """Raised if we cannot import the backend"""<N>    def __init__(self, traceback):<N>        self.traceback = traceback<N><N>
<N>class BackendInvalid(Exception):<N>    """Raised if the backend is invalid"""<N>    def __init__(self, message):<N>        self.message = message<N><N><N>class HookMissing(Exception):<N>    """Raised if a hook is missing and we are not executing the fallback"""<N><N>
<N>def contained_in(filename, directory):<N>    """Test if a file is located within the given directory."""<N>    filename = os.path.normcase(os.path.abspath(filename))<N>    directory = os.path.normcase(os.path.abspath(directory))<N>    return os.path.commonprefix([filename, directory]) == directory<N><N>
<N>def _build_backend():<N>    """Find and load the build backend"""<N>    # Add in-tree backend directories to the front of sys.path.<N>    backend_path = os.environ.get('PEP517_BACKEND_PATH')<N>    if backend_path:<N>        extra_pathitems = backend_path.split(os.pathsep)<N>        sys.path[:0] = extra_pathitems<N><N>
    ep = os.environ['PEP517_BUILD_BACKEND']<N>    mod_path, _, obj_path = ep.partition(':')<N>    try:<N>        obj = import_module(mod_path)<N>    except ImportError:<N>        raise BackendUnavailable(traceback.format_exc())<N><N>    if backend_path:<N>        if not any(<N>            contained_in(obj.__file__, path)<N>            for path in extra_pathitems<N>        ):<N>            raise BackendInvalid("Backend was not loaded from backend-path")<N><N>
    if obj_path:<N>        for path_part in obj_path.split('.'):<N>            obj = getattr(obj, path_part)<N>    return obj<N><N><N>def get_requires_for_build_wheel(config_settings):<N>    """Invoke the optional get_requires_for_build_wheel hook<N><N>    Returns [] if the hook is not defined.<N>    """<N>    backend = _build_backend()<N>    try:<N>        hook = backend.get_requires_for_build_wheel<N>    except AttributeError:<N>        return []<N>    else:<N>        return hook(config_settings)<N><N>
# -*- coding: utf-8 -*-<N><N>r"""<N>The ``codes`` object defines a mapping from common names for HTTP statuses<N>to their numerical codes, accessible either as attributes or as dictionary<N>items.<N><N>Example::<N><N>    >>> import requests<N>    >>> requests.codes['temporary_redirect']<N>    307<N>    >>> requests.codes.teapot<N>    418<N>    >>> requests.codes['\o/']<N>    200<N><N>
Some codes have multiple names, and both upper- and lower-case versions of<N>the names are allowed. For example, ``codes.ok``, ``codes.OK``, and<N>``codes.okay`` all correspond to the HTTP status code 200.<N>"""<N><N>from .structures import LookupDict<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.compat<N>~~~~~~~~~~~~~~~<N><N>This module handles import compatibility issues between Python 2 and<N>Python 3.<N>"""<N><N>from pip._vendor import chardet<N><N>import sys<N><N># -------<N># Pythons<N># -------<N><N>
# Syntax sugar.<N>_ver = sys.version_info<N><N>#: Python 2.x?<N>is_py2 = (_ver[0] == 2)<N><N>#: Python 3.x?<N>is_py3 = (_ver[0] == 3)<N><N># Note: We've patched out simplejson support in pip because it prevents<N>#       upgrading simplejson on Windows.<N># try:<N>#     import simplejson as json<N># except (ImportError, SyntaxError):<N>#     # simplejson does not support Python 3.2, it throws a SyntaxError<N>#     # because of u'...' Unicode literals.<N>import json<N><N>
# -*- coding: utf-8 -*-<N><N>#   __<N>#  /__)  _  _     _   _ _/   _<N># / (   (- (/ (/ (- _)  /  _)<N>#          /<N><N>"""<N>Requests HTTP Library<N>~~~~~~~~~~~~~~~~~~~~~<N><N>Requests is an HTTP library, written in Python, for human beings.<N>Basic GET usage:<N><N>
   >>> import requests<N>   >>> r = requests.get('https://www.python.org')<N>   >>> r.status_code<N>   200<N>   >>> b'Python is a programming language' in r.content<N>   True<N><N>... or POST:<N><N>   >>> payload = dict(key1='value1', key2='value2')<N>   >>> r = requests.post('https://httpbin.org/post', data=payload)<N>   >>> print(r.text)<N>   {<N>     ...<N>     "form": {<N>       "key1": "value1",<N>       "key2": "value2"<N>     },<N>     ...<N>   }<N><N>
The other HTTP methods are supported - see `requests.api`. Full documentation<N>is at <https://requests.readthedocs.io>.<N><N>:copyright: (c) 2017 by Kenneth Reitz.<N>:license: Apache 2.0, see LICENSE for more details.<N>"""<N><N>from pip._vendor import urllib3<N>from pip._vendor import chardet<N>import warnings<N>from .exceptions import RequestsDependencyWarning<N><N>
<N>def check_compatibility(urllib3_version, chardet_version):<N>    urllib3_version = urllib3_version.split('.')<N>    assert urllib3_version != ['dev']  # Verify urllib3 isn't installed from git.<N><N>    # Sometimes, urllib3 only reports its version as 16.1.<N>    if len(urllib3_version) == 2:<N>        urllib3_version.append('0')<N><N>
    # Check urllib3 for compatibility.<N>    major, minor, patch = urllib3_version  # noqa: F811<N>    major, minor, patch = int(major), int(minor), int(patch)<N>    # urllib3 >= 1.21.1, <= 1.26<N>    assert major == 1<N>    assert minor >= 21<N>    assert minor <= 26<N><N>
    # Check chardet for compatibility.<N>    major, minor, patch = chardet_version.split('.')[:3]<N>    major, minor, patch = int(major), int(minor), int(patch)<N>    # chardet >= 3.0.2, < 5.0.0<N>    assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)<N><N>
<N>def _check_cryptography(cryptography_version):<N>    # cryptography < 1.3.4<N>    try:<N>        cryptography_version = list(map(int, cryptography_version.split('.')))<N>    except ValueError:<N>        return<N><N>    if cryptography_version < [1, 3, 4]:<N>        warning = 'Old version of cryptography ({}) may cause slowdown.'.format(cryptography_version)<N>        warnings.warn(warning, RequestsDependencyWarning)<N><N>
# Check imported dependencies for compatibility.<N>try:<N>    check_compatibility(urllib3.__version__, chardet.__version__)<N>except (AssertionError, ValueError):<N>    warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "<N>                  "version!".format(urllib3.__version__, chardet.__version__),<N>                  RequestsDependencyWarning)<N><N>
# Attempt to enable urllib3's fallback for SNI support<N># if the standard library doesn't support SNI or the<N># 'ssl' library isn't available.<N>try:<N>    # Note: This logic prevents upgrading cryptography on Windows, if imported<N>    #       as part of pip.<N>    from pip._internal.utils.compat import WINDOWS<N>    if not WINDOWS:<N>        raise ImportError("pip internals: don't import cryptography on Windows")<N>    try:<N>        import ssl<N>    except ImportError:<N>        ssl = None<N><N>
    if not getattr(ssl, "HAS_SNI", False):<N>        from pip._vendor.urllib3.contrib import pyopenssl<N>        pyopenssl.inject_into_urllib3()<N><N>        # Check cryptography version<N>        from cryptography import __version__ as cryptography_version<N>        _check_cryptography(cryptography_version)<N>except ImportError:<N>    pass<N><N>
# urllib3's DependencyWarnings should be silenced.<N>from pip._vendor.urllib3.exceptions import DependencyWarning<N>warnings.simplefilter('ignore', DependencyWarning)<N><N>from .__version__ import __title__, __description__, __url__, __version__<N>from .__version__ import __build__, __author__, __author_email__, __license__<N>from .__version__ import __copyright__, __cake__<N><N>
from . import utils<N>from . import packages<N>from .models import Request, Response, PreparedRequest<N>from .api import request, get, head, post, patch, put, delete, options<N>from .sessions import session, Session<N>from .status_codes import codes<N>from .exceptions import (<N>    RequestException, Timeout, URLRequired,<N>    TooManyRedirects, HTTPError, ConnectionError,<N>    FileModeWarning, ConnectTimeout, ReadTimeout<N>)<N><N>
# Set default logging handler to avoid "No handler found" warnings.<N>import logging<N>from logging import NullHandler<N><N>logging.getLogger(__name__).addHandler(NullHandler())<N><N># FileModeWarnings go off per the default.<N>warnings.simplefilter('default', FileModeWarning, append=True)<N><N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.structures<N>~~~~~~~~~~~~~~~~~~~<N><N>Data structures that power Requests.<N>"""<N><N>from collections import OrderedDict<N><N>from .compat import Mapping, MutableMapping<N><N><N>class CaseInsensitiveDict(MutableMapping):<N>    """A case-insensitive ``dict``-like object.<N><N>
    Implements all methods and operations of<N>    ``MutableMapping`` as well as dict's ``copy``. Also<N>    provides ``lower_items``.<N><N>    All keys are expected to be strings. The structure remembers the<N>    case of the last key to be set, and ``iter(instance)``,<N>    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``<N>    will contain case-sensitive keys. However, querying and contains<N>    testing is case insensitive::<N><N>
        cid = CaseInsensitiveDict()<N>        cid['Accept'] = 'application/json'<N>        cid['aCCEPT'] == 'application/json'  # True<N>        list(cid) == ['Accept']  # True<N><N>    For example, ``headers['content-encoding']`` will return the<N>    value of a ``'Content-Encoding'`` response header, regardless<N>    of how the header name was originally stored.<N><N>
    If the constructor, ``.update``, or equality comparison<N>    operations are given keys that have equal ``.lower()``s, the<N>    behavior is undefined.<N>    """<N><N>    def __init__(self, data=None, **kwargs):<N>        self._store = OrderedDict()<N>        if data is None:<N>            data = {}<N>        self.update(data, **kwargs)<N><N>
    def __setitem__(self, key, value):<N>        # Use the lowercased key for lookups, but store the actual<N>        # key alongside the value.<N>        self._store[key.lower()] = (key, value)<N><N>    def __getitem__(self, key):<N>        return self._store[key.lower()][1]<N><N>
    def __delitem__(self, key):<N>        del self._store[key.lower()]<N><N>    def __iter__(self):<N>        return (casedkey for casedkey, mappedvalue in self._store.values())<N><N>    def __len__(self):<N>        return len(self._store)<N><N>    def lower_items(self):<N>        """Like iteritems(), but with all lowercase keys."""<N>        return (<N>            (lowerkey, keyval[1])<N>            for (lowerkey, keyval)<N>            in self._store.items()<N>        )<N><N>
    def __eq__(self, other):<N>        if isinstance(other, Mapping):<N>            other = CaseInsensitiveDict(other)<N>        else:<N>            return NotImplemented<N>        # Compare insensitively<N>        return dict(self.lower_items()) == dict(other.lower_items())<N><N>
    # Copy is required<N>    def copy(self):<N>        return CaseInsensitiveDict(self._store.values())<N><N>    def __repr__(self):<N>        return str(dict(self.items()))<N><N><N>class LookupDict(dict):<N>    """Dictionary lookup object."""<N><N>    def __init__(self, name=None):<N>        self.name = name<N>        super(LookupDict, self).__init__()<N><N>
    def __repr__(self):<N>        return '<lookup \'%s\'>' % (self.name)<N><N>    def __getitem__(self, key):<N>        # We allow fall-through here, so values default to None<N><N>        return self.__dict__.get(key, None)<N><N>    def get(self, key, default=None):<N>        return self.__dict__.get(key, default)<N><N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.models<N>~~~~~~~~~~~~~~~<N><N>This module contains the primary objects that power Requests.<N>"""<N><N>import datetime<N>import sys<N><N># Import encoding now, to avoid implicit import later.<N># Implicit import within threads may cause LookupError when standard library is in a ZIP,<N># such as in Embedded Python. See https://github.com/psf/requests/issues/3578.<N>import encodings.idna<N><N>
from pip._vendor.urllib3.fields import RequestField<N>from pip._vendor.urllib3.filepost import encode_multipart_formdata<N>from pip._vendor.urllib3.util import parse_url<N>from pip._vendor.urllib3.exceptions import (<N>    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.cookies<N>~~~~~~~~~~~~~~~~<N><N>Compatibility code to be able to use `cookielib.CookieJar` with requests.<N><N>requests.utils imports from here, so be careful with imports.<N>"""<N><N>import copy<N>import time<N>import calendar<N><N>
from ._internal_utils import to_native_string<N>from .compat import cookielib, urlparse, urlunparse, Morsel, MutableMapping<N><N>try:<N>    import threading<N>except ImportError:<N>    import dummy_threading as threading<N><N><N>class MockRequest(object):<N>    """Wraps a `requests.Request` to mimic a `urllib2.Request`.<N><N>
    The code in `cookielib.CookieJar` expects this interface in order to correctly<N>    manage cookie policies, i.e., determine whether a cookie can be set, given the<N>    domains of the request and the cookie.<N><N>    The original request object is read-only. The client is responsible for collecting<N>    the new headers via `get_new_headers()` and interpreting them appropriately. You<N>    probably want `get_cookie_header`, defined below.<N>    """<N><N>
    def __init__(self, request):<N>        self._r = request<N>        self._new_headers = {}<N>        self.type = urlparse(self._r.url).scheme<N><N>    def get_type(self):<N>        return self.type<N><N>    def get_host(self):<N>        return urlparse(self._r.url).netloc<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.hooks<N>~~~~~~~~~~~~~~<N><N>This module provides the capabilities for the Requests hooks system.<N><N>Available hooks:<N><N>``response``:<N>    The response generated from a Request.<N>"""<N>HOOKS = ['response']<N><N>
# .-. .-. .-. . . .-. .-. .-. .-.<N># |(  |-  |.| | | |-  `-.  |  `-.<N># ' ' `-' `-`.`-' `-' `-'  '  `-'<N><N>__title__ = 'requests'<N>__description__ = 'Python HTTP for Humans.'<N>__url__ = 'https://requests.readthedocs.io'<N>__version__ = '2.25.1'<N>__build__ = 0x022501<N>__author__ = 'Kenneth Reitz'<N>__author_email__ = 'me@kennethreitz.org'<N>__license__ = 'Apache 2.0'<N>__copyright__ = 'Copyright 2020 Kenneth Reitz'<N>__cake__ = u'\u2728 \U0001f370 \u2728'<N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.api<N>~~~~~~~~~~~~<N><N>This module implements the Requests API.<N><N>:copyright: (c) 2012 by Kenneth Reitz.<N>:license: Apache2, see LICENSE for more details.<N>"""<N><N>from . import sessions<N><N><N>def request(method, url, **kwargs):<N>    """Constructs and sends a :class:`Request <Request>`.<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests._internal_utils<N>~~~~~~~~~~~~~~<N><N>Provides utility functions that are consumed internally by Requests<N>which depend on extremely few external helpers (such as compat)<N>"""<N><N>from .compat import is_py2, builtin_str, str<N><N>
<N>def to_native_string(string, encoding='ascii'):<N>    """Given a string object, regardless of type, returns a representation of<N>    that string in the native string type, encoding and decoding where<N>    necessary. This assumes ASCII unless told otherwise.<N>    """<N>    if isinstance(string, builtin_str):<N>        out = string<N>    else:<N>        if is_py2:<N>            out = string.encode(encoding)<N>        else:<N>            out = string.decode(encoding)<N><N>
    return out<N><N><N>def unicode_is_ascii(u_string):<N>    """Determine if unicode string only contains ASCII characters.<N><N>    :param str u_string: unicode string to check. Must be unicode<N>        and not Python 2 `str`.<N>    :rtype: bool<N>    """<N>    assert isinstance(u_string, str)<N>    try:<N>        u_string.encode('ascii')<N>        return True<N>    except UnicodeEncodeError:<N>        return False<N><N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.sessions<N>~~~~~~~~~~~~~~~~~<N><N>This module provides a Session object to manage and persist settings across<N>requests (cookies, auth, proxies).<N>"""<N>import os<N>import sys<N>import time<N>from datetime import timedelta<N>from collections import OrderedDict<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.auth<N>~~~~~~~~~~~~~<N><N>This module contains the authentication handlers for Requests.<N>"""<N><N>import os<N>import re<N>import time<N>import hashlib<N>import threading<N>import warnings<N><N>from base64 import b64encode<N><N>
from .compat import urlparse, str, basestring<N>from .cookies import extract_cookies_to_jar<N>from ._internal_utils import to_native_string<N>from .utils import parse_dict_header<N><N>CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'<N>CONTENT_TYPE_MULTI_PART = 'multipart/form-data'<N><N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.exceptions<N>~~~~~~~~~~~~~~~~~~~<N><N>This module contains the set of Requests' exceptions.<N>"""<N>from pip._vendor.urllib3.exceptions import HTTPError as BaseHTTPError<N><N><N>class RequestException(IOError):<N>    """There was an ambiguous exception that occurred while handling your<N>    request.<N>    """<N><N>
    def __init__(self, *args, **kwargs):<N>        """Initialize RequestException with `request` and `response` objects."""<N>        response = kwargs.pop('response', None)<N>        self.response = response<N>        self.request = kwargs.pop('request', None)<N>        if (response is not None and not self.request and<N>                hasattr(response, 'request')):<N>            self.request = self.response.request<N>        super(RequestException, self).__init__(*args, **kwargs)<N><N>
<N>class HTTPError(RequestException):<N>    """An HTTP error occurred."""<N><N><N>class ConnectionError(RequestException):<N>    """A Connection error occurred."""<N><N><N>class ProxyError(ConnectionError):<N>    """A proxy error occurred."""<N><N><N>class SSLError(ConnectionError):<N>    """An SSL error occurred."""<N><N>
<N>class Timeout(RequestException):<N>    """The request timed out.<N><N>    Catching this error will catch both<N>    :exc:`~requests.exceptions.ConnectTimeout` and<N>    :exc:`~requests.exceptions.ReadTimeout` errors.<N>    """<N><N><N>class ConnectTimeout(ConnectionError, Timeout):<N>    """The request timed out while trying to connect to the remote server.<N><N>
    Requests that produced this error are safe to retry.<N>    """<N><N><N>class ReadTimeout(Timeout):<N>    """The server did not send any data in the allotted amount of time."""<N><N><N>class URLRequired(RequestException):<N>    """A valid URL is required to make a request."""<N><N>
<N>class TooManyRedirects(RequestException):<N>    """Too many redirects."""<N><N><N>class MissingSchema(RequestException, ValueError):<N>    """The URL schema (e.g. http or https) is missing."""<N><N><N>class InvalidSchema(RequestException, ValueError):<N>    """See defaults.py for valid schemas."""<N><N>
<N>class InvalidURL(RequestException, ValueError):<N>    """The URL provided was somehow invalid."""<N><N><N>class InvalidHeader(RequestException, ValueError):<N>    """The header value provided was somehow invalid."""<N><N><N>class InvalidProxyURL(InvalidURL):<N>    """The proxy URL provided is invalid."""<N><N>
<N>class ChunkedEncodingError(RequestException):<N>    """The server declared chunked encoding but sent an invalid chunk."""<N><N><N>class ContentDecodingError(RequestException, BaseHTTPError):<N>    """Failed to decode response content."""<N><N><N>class StreamConsumedError(RequestException, TypeError):<N>    """The content for this response was already consumed."""<N><N>
<N>class RetryError(RequestException):<N>    """Custom retries logic failed"""<N><N><N>class UnrewindableBodyError(RequestException):<N>    """Requests encountered an error when trying to rewind a body."""<N><N># Warnings<N><N><N>class RequestsWarning(Warning):<N>    """Base warning for Requests."""<N><N>
<N>class FileModeWarning(RequestsWarning, DeprecationWarning):<N>    """A file was opened in text mode, but Requests determined its binary length."""<N><N><N>class RequestsDependencyWarning(RequestsWarning):<N>    """An imported dependency doesn't match the expected version range."""<N><N><N>
"""Module containing bug report helper(s)."""<N>from __future__ import print_function<N><N>import json<N>import platform<N>import sys<N>import ssl<N><N>from pip._vendor import idna<N>from pip._vendor import urllib3<N>from pip._vendor import chardet<N><N>from . import __version__ as requests_version<N><N>
try:<N>    from pip._vendor.urllib3.contrib import pyopenssl<N>except ImportError:<N>    pyopenssl = None<N>    OpenSSL = None<N>    cryptography = None<N>else:<N>    import OpenSSL<N>    import cryptography<N><N><N>def _implementation():<N>    """Return a dict with the Python implementation and version.<N><N>
    Provide both the name and the version of the Python implementation<N>    currently running. For example, on CPython 2.7.5 it will return<N>    {'name': 'CPython', 'version': '2.7.5'}.<N><N>    This function works best on CPython and PyPy: in particular, it probably<N>    doesn't work for Jython or IronPython. Future investigation should be done<N>    to work out the correct shape of the code for those platforms.<N>    """<N>    implementation = platform.python_implementation()<N><N>
#!/usr/bin/env python<N># -*- coding: utf-8 -*-<N><N>"""<N>requests.certs<N>~~~~~~~~~~~~~~<N><N>This module returns the preferred default CA certificate bundle. There is<N>only one â€” the one from the certifi package.<N><N>If you are packaging Requests, e.g., for a Linux distribution or a managed<N>environment, you can change the definition of where() to return a separately<N>packaged CA bundle.<N>"""<N>from pip._vendor.certifi import where<N><N>if __name__ == '__main__':<N>    print(where())<N>
# -*- coding: utf-8 -*-<N><N>"""<N>requests.utils<N>~~~~~~~~~~~~~~<N><N>This module provides utility functions that are used within Requests<N>that are also useful for external consumption.<N>"""<N><N>import codecs<N>import contextlib<N>import io<N>import os<N>import re<N>import socket<N>import struct<N>import sys<N>import tempfile<N>import warnings<N>import zipfile<N>from collections import OrderedDict<N><N>
# coding: utf-8<N>"""<N><N>    webencodings<N>    ~~~~~~~~~~~~<N><N>    This is a Python implementation of the `WHATWG Encoding standard<N>    <http://encoding.spec.whatwg.org/>`. See README for details.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>
"""<N><N>from __future__ import unicode_literals<N><N>import codecs<N><N>from .labels import LABELS<N><N><N>VERSION = '0.5.1'<N><N><N># Some names in Encoding are not valid Python aliases. Remap these.<N>PYTHON_NAMES = {<N>    'iso-8859-8-i': 'iso-8859-8',<N>    'x-mac-cyrillic': 'mac-cyrillic',<N>    'macintosh': 'mac-roman',<N>    'windows-874': 'cp874'}<N><N>
CACHE = {}<N><N><N>def ascii_lower(string):<N>    r"""Transform (only) ASCII letters to lower case: A-Z is mapped to a-z.<N><N>    :param string: An Unicode string.<N>    :returns: A new Unicode string.<N><N>    This is used for `ASCII case-insensitive<N>    <http://encoding.spec.whatwg.org/#ascii-case-insensitive>`_<N>    matching of encoding labels.<N>    The same matching is also used, among other things,<N>    for `CSS keywords <http://dev.w3.org/csswg/css-values/#keywords>`_.<N><N>
    This is different from the :meth:`~py:str.lower` method of Unicode strings<N>    which also affect non-ASCII characters,<N>    sometimes mapping them into the ASCII range:<N><N>        >>> keyword = u'Bac\N{KELVIN SIGN}ground'<N>        >>> assert keyword.lower() == u'background'<N>        >>> assert ascii_lower(keyword) != keyword.lower()<N>        >>> assert ascii_lower(keyword) == u'bac\N{KELVIN SIGN}ground'<N><N>
    """<N>    # This turns out to be faster than unicode.translate()<N>    return string.encode('utf8').lower().decode('utf8')<N><N><N>def lookup(label):<N>    """<N>    Look for an encoding by its label.<N>    This is the specâ€™s `get an encoding<N>    <http://encoding.spec.whatwg.org/#concept-encoding-get>`_ algorithm.<N>    Supported labels are listed there.<N><N>
"""<N><N>    webencodings.labels<N>    ~~~~~~~~~~~~~~~~~~~<N><N>    Map encoding labels to their name.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>"""<N><N># XXX Do not edit!<N># This file is automatically generated by mklabels.py<N><N>
# coding: utf-8<N>"""<N><N>    webencodings.x_user_defined<N>    ~~~~~~~~~~~~~~~~~~~~~~~~~~~<N><N>    An implementation of the x-user-defined encoding.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>"""<N><N>
from __future__ import unicode_literals<N><N>import codecs<N><N><N>### Codec APIs<N><N>class Codec(codecs.Codec):<N><N>    def encode(self, input, errors='strict'):<N>        return codecs.charmap_encode(input, errors, encoding_table)<N><N>    def decode(self, input, errors='strict'):<N>        return codecs.charmap_decode(input, errors, decoding_table)<N><N>
<N>class IncrementalEncoder(codecs.IncrementalEncoder):<N>    def encode(self, input, final=False):<N>        return codecs.charmap_encode(input, self.errors, encoding_table)[0]<N><N><N>class IncrementalDecoder(codecs.IncrementalDecoder):<N>    def decode(self, input, final=False):<N>        return codecs.charmap_decode(input, self.errors, decoding_table)[0]<N><N>
<N>class StreamWriter(Codec, codecs.StreamWriter):<N>    pass<N><N><N>class StreamReader(Codec, codecs.StreamReader):<N>    pass<N><N><N>### encodings module API<N><N>codec_info = codecs.CodecInfo(<N>    name='x-user-defined',<N>    encode=Codec().encode,<N>    decode=Codec().decode,<N>    incrementalencoder=IncrementalEncoder,<N>    incrementaldecoder=IncrementalDecoder,<N>    streamreader=StreamReader,<N>    streamwriter=StreamWriter,<N>)<N><N>
# coding: utf-8<N>"""<N><N>    webencodings.tests<N>    ~~~~~~~~~~~~~~~~~~<N><N>    A basic test suite for Encoding.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>"""<N><N>from __future__ import unicode_literals<N><N>
from . import (lookup, LABELS, decode, encode, iter_decode, iter_encode,<N>               IncrementalDecoder, IncrementalEncoder, UTF8)<N><N><N>def assert_raises(exception, function, *args, **kwargs):<N>    try:<N>        function(*args, **kwargs)<N>    except exception:<N>        return<N>    else:  # pragma: no cover<N>        raise AssertionError('Did not raise %s.' % exception)<N><N>
<N>def test_labels():<N>    assert lookup('utf-8').name == 'utf-8'<N>    assert lookup('Utf-8').name == 'utf-8'<N>    assert lookup('UTF-8').name == 'utf-8'<N>    assert lookup('utf8').name == 'utf-8'<N>    assert lookup('utf8').name == 'utf-8'<N>    assert lookup('utf8 ').name == 'utf-8'<N>    assert lookup(' \r\nutf8\t').name == 'utf-8'<N>    assert lookup('u8') is None  # Python label.<N>    assert lookup('utf-8Â ') is None  # Non-ASCII white space.<N><N>
    assert lookup('US-ASCII').name == 'windows-1252'<N>    assert lookup('iso-8859-1').name == 'windows-1252'<N>    assert lookup('latin1').name == 'windows-1252'<N>    assert lookup('LATIN1').name == 'windows-1252'<N>    assert lookup('latin-1') is None<N>    assert lookup('LATÄ°N1') is None  # ASCII-only case insensitivity.<N><N>
"""<N><N>    webencodings.mklabels<N>    ~~~~~~~~~~~~~~~~~~~~~<N><N>    Regenarate the webencodings.labels module.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>"""<N><N>import json<N>try:<N>    from urllib import urlopen<N>except ImportError:<N>    from urllib.request import urlopen<N><N>
<N>def assert_lower(string):<N>    assert string == string.lower()<N>    return string<N><N><N>def generate(url):<N>    parts = ['''\<N>"""<N><N>    webencodings.labels<N>    ~~~~~~~~~~~~~~~~~~~<N><N>    Map encoding labels to their name.<N><N>    :copyright: Copyright 2012 by Simon Sapin<N>    :license: BSD, see LICENSE for details.<N><N>
# coding: utf-8<N>from ._version import version<N>from .exceptions import *<N>from .ext import ExtType, Timestamp<N><N>import os<N>import sys<N><N><N>if os.environ.get("MSGPACK_PUREPYTHON") or sys.version_info[0] == 2:<N>    from .fallback import Packer, unpackb, Unpacker<N>else:<N>    try:<N>        from ._cmsgpack import Packer, unpackb, Unpacker<N>    except ImportError:<N>        from .fallback import Packer, unpackb, Unpacker<N><N>
<N>def pack(o, stream, **kwargs):<N>    """<N>    Pack object `o` and write it to `stream`<N><N>    See :class:`Packer` for options.<N>    """<N>    packer = Packer(**kwargs)<N>    stream.write(packer.pack(o))<N><N><N>def packb(o, **kwargs):<N>    """<N>    Pack object `o` and return packed bytes<N><N>
    See :class:`Packer` for options.<N>    """<N>    return Packer(**kwargs).pack(o)<N><N><N>def unpack(stream, **kwargs):<N>    """<N>    Unpack an object from `stream`.<N><N>    Raises `ExtraData` when `stream` contains extra bytes.<N>    See :class:`Unpacker` for options.<N>    """<N>    data = stream.read()<N>    return unpackb(data, **kwargs)<N><N>
"""Fallback pure Python implementation of msgpack"""<N><N>from datetime import datetime as _DateTime<N>import sys<N>import struct<N><N><N>PY2 = sys.version_info[0] == 2<N>if PY2:<N>    int_types = (int, long)<N><N>    def dict_iteritems(d):<N>        return d.iteritems()<N><N>
<N>else:<N>    int_types = int<N>    unicode = str<N>    xrange = range<N><N>    def dict_iteritems(d):<N>        return d.items()<N><N><N>if sys.version_info < (3, 5):<N>    # Ugly hack...<N>    RecursionError = RuntimeError<N><N>    def _is_recursionerror(e):<N>        return (<N>            len(e.args) == 1<N>            and isinstance(e.args[0], str)<N>            and e.args[0].startswith("maximum recursion depth exceeded")<N>        )<N><N>
<N>else:<N><N>    def _is_recursionerror(e):<N>        return True<N><N><N>if hasattr(sys, "pypy_version_info"):<N>    # StringIO is slow on PyPy, StringIO is faster.  However: PyPy's own<N>    # StringBuilder is fastest.<N>    from __pypy__ import newlist_hint<N><N>
    try:<N>        from __pypy__.builders import BytesBuilder as StringBuilder<N>    except ImportError:<N>        from __pypy__.builders import StringBuilder<N>    USING_STRINGBUILDER = True<N><N>    class StringIO(object):<N>        def __init__(self, s=b""):<N>            if s:<N>                self.builder = StringBuilder(len(s))<N>                self.builder.append(s)<N>            else:<N>                self.builder = StringBuilder()<N><N>
        def write(self, s):<N>            if isinstance(s, memoryview):<N>                s = s.tobytes()<N>            elif isinstance(s, bytearray):<N>                s = bytes(s)<N>            self.builder.append(s)<N><N>        def getvalue(self):<N>            return self.builder.build()<N><N>
<N>else:<N>    USING_STRINGBUILDER = False<N>    from io import BytesIO as StringIO<N><N>    newlist_hint = lambda size: []<N><N><N>from .exceptions import BufferFull, OutOfData, ExtraData, FormatError, StackError<N><N>from .ext import ExtType, Timestamp<N><N>
<N>EX_SKIP = 0<N>EX_CONSTRUCT = 1<N>EX_READ_ARRAY_HEADER = 2<N>EX_READ_MAP_HEADER = 3<N><N>TYPE_IMMEDIATE = 0<N>TYPE_ARRAY = 1<N>TYPE_MAP = 2<N>TYPE_RAW = 3<N>TYPE_BIN = 4<N>TYPE_EXT = 5<N><N>DEFAULT_RECURSE_LIMIT = 511<N><N><N>def _check_type_strict(obj, t, type=type, tuple=tuple):<N>    if type(t) is tuple:<N>        return type(obj) in t<N>    else:<N>        return type(obj) is t<N><N>
<N>def _get_data_from_buffer(obj):<N>    view = memoryview(obj)<N>    if view.itemsize != 1:<N>        raise ValueError("cannot unpack from multi-byte object")<N>    return view<N><N><N>def unpackb(packed, **kwargs):<N>    """<N>    Unpack an object from `packed`.<N><N>
    Raises ``ExtraData`` when *packed* contains extra bytes.<N>    Raises ``ValueError`` when *packed* is incomplete.<N>    Raises ``FormatError`` when *packed* is not valid msgpack.<N>    Raises ``StackError`` when *packed* contains too nested.<N>    Other exceptions can be raised during unpacking.<N><N>
# coding: utf-8<N>from collections import namedtuple<N>import datetime<N>import sys<N>import struct<N><N><N>PY2 = sys.version_info[0] == 2<N><N>if PY2:<N>    int_types = (int, long)<N>    _utc = None<N>else:<N>    int_types = int<N>    try:<N>        _utc = datetime.timezone.utc<N>    except AttributeError:<N>        _utc = datetime.timezone(datetime.timedelta(0))<N><N>
<N>class ExtType(namedtuple("ExtType", "code data")):<N>    """ExtType represents ext type in msgpack."""<N><N>    def __new__(cls, code, data):<N>        if not isinstance(code, int):<N>            raise TypeError("code must be int")<N>        if not isinstance(data, bytes):<N>            raise TypeError("data must be bytes")<N>        if not 0 <= code <= 127:<N>            raise ValueError("code must be 0~127")<N>        return super(ExtType, cls).__new__(cls, code, data)<N><N>
<N>class Timestamp(object):<N>    """Timestamp represents the Timestamp extension type in msgpack.<N><N>    When built with Cython, msgpack uses C methods to pack and unpack `Timestamp`. When using pure-Python<N>    msgpack, :func:`to_bytes` and :func:`from_bytes` are used to pack and unpack `Timestamp`.<N><N>
    This class is immutable: Do not override seconds and nanoseconds.<N>    """<N><N>    __slots__ = ["seconds", "nanoseconds"]<N><N>    def __init__(self, seconds, nanoseconds=0):<N>        """Initialize a Timestamp object.<N><N>        :param int seconds:<N>            Number of seconds since the UNIX epoch (00:00:00 UTC Jan 1 1970, minus leap seconds).<N>            May be negative.<N><N>
class UnpackException(Exception):<N>    """Base class for some exceptions raised while unpacking.<N><N>    NOTE: unpack may raise exception other than subclass of<N>    UnpackException.  If you want to catch all error, catch<N>    Exception instead.<N>    """<N><N>
<N>class BufferFull(UnpackException):<N>    pass<N><N><N>class OutOfData(UnpackException):<N>    pass<N><N><N>class FormatError(ValueError, UnpackException):<N>    """Invalid msgpack format"""<N><N><N>class StackError(ValueError, UnpackException):<N>    """Too nested"""<N><N>
<N># Deprecated.  Use ValueError instead<N>UnpackValueError = ValueError<N><N><N>class ExtraData(UnpackValueError):<N>    """ExtraData is raised when there is trailing data.<N><N>    This exception is raised while only one-shot (not streaming)<N>    unpack.<N>    """<N><N>
    def __init__(self, unpacked, extra):<N>        self.unpacked = unpacked<N>        self.extra = extra<N><N>    def __str__(self):<N>        return "unpack(b) received extra data."<N><N><N># Deprecated.  Use Exception instead to catch all exception during packing.<N>PackException = Exception<N>PackValueError = ValueError<N>PackOverflowError = OverflowError<N><N><N>
"""Utilities for providing backward compatibility."""<N>from pip._vendor import six<N><N><N>def get_exc_info_from_future(future):<N>    """<N>    Get an exc_info value from a Future.<N><N>    Given a a Future instance, retrieve an exc_info value suitable for passing<N>    in as the exc_info parameter to logging.Logger.log() and related methods.<N><N>
    On Python 2, this will be a (type, value, traceback) triple.<N>    On Python 3, this will be an exception instance (with embedded traceback).<N><N>    If there was no exception, None is returned on both versions of Python.<N>    """<N>    if six.PY3:<N>        return future.exception()<N>    else:<N>        ex, tb = future.exception_info()<N>        if ex is None:<N>            return None<N>        return type(ex), ex, tb<N><N><N>
try:<N>    from urllib.parse import urljoin<N>except ImportError:<N>    from urlparse import urljoin<N><N><N>try:<N>    import cPickle as pickle<N>except ImportError:<N>    import pickle<N><N><N># Handle the case where the requests module has been patched to not have<N># urllib3 bundled as part of its source.<N>try:<N>    from pip._vendor.requests.packages.urllib3.response import HTTPResponse<N>except ImportError:<N>    from pip._vendor.urllib3.response import HTTPResponse<N><N>
try:<N>    from pip._vendor.requests.packages.urllib3.util import is_fp_closed<N>except ImportError:<N>    from pip._vendor.urllib3.util import is_fp_closed<N><N># Replicate some six behaviour<N>try:<N>    text_type = unicode<N>except NameError:<N>    text_type = str<N><N><N>
"""CacheControl import Interface.<N><N>Make it easy to import from cachecontrol without long namespaces.<N>"""<N>__author__ = "Eric Larson"<N>__email__ = "eric@ionrock.org"<N>__version__ = "0.12.6"<N><N>from .wrapper import CacheControl<N>from .adapter import CacheControlAdapter<N>from .controller import CacheController<N>
from .adapter import CacheControlAdapter<N>from .cache import DictCache<N><N><N>def CacheControl(<N>    sess,<N>    cache=None,<N>    cache_etags=True,<N>    serializer=None,<N>    heuristic=None,<N>    controller_class=None,<N>    adapter_class=None,<N>    cacheable_methods=None,<N>):<N><N>
    cache = DictCache() if cache is None else cache<N>    adapter_class = adapter_class or CacheControlAdapter<N>    adapter = adapter_class(<N>        cache,<N>        cache_etags=cache_etags,<N>        serializer=serializer,<N>        heuristic=heuristic,<N>        controller_class=controller_class,<N>        cacheable_methods=cacheable_methods,<N>    )<N>    sess.mount("http://", adapter)<N>    sess.mount("https://", adapter)<N><N>
import types<N>import functools<N>import zlib<N><N>from pip._vendor.requests.adapters import HTTPAdapter<N><N>from .controller import CacheController<N>from .cache import DictCache<N>from .filewrapper import CallbackFileWrapper<N><N><N>class CacheControlAdapter(HTTPAdapter):<N>    invalidating_methods = {"PUT", "DELETE"}<N><N>
    def __init__(<N>        self,<N>        cache=None,<N>        cache_etags=True,<N>        controller_class=None,<N>        serializer=None,<N>        heuristic=None,<N>        cacheable_methods=None,<N>        *args,<N>        **kw<N>    ):<N>        super(CacheControlAdapter, self).__init__(*args, **kw)<N>        self.cache = DictCache() if cache is None else cache<N>        self.heuristic = heuristic<N>        self.cacheable_methods = cacheable_methods or ("GET",)<N><N>
import calendar<N>import time<N><N>from email.utils import formatdate, parsedate, parsedate_tz<N><N>from datetime import datetime, timedelta<N><N>TIME_FMT = "%a, %d %b %Y %H:%M:%S GMT"<N><N><N>def expire_after(delta, date=None):<N>    date = date or datetime.utcnow()<N>    return date + delta<N><N>
<N>def datetime_to_header(dt):<N>    return formatdate(calendar.timegm(dt.timetuple()))<N><N><N>class BaseHeuristic(object):<N><N>    def warning(self, response):<N>        """<N>        Return a valid 1xx warning header value describing the cache<N>        adjustments.<N><N>
        The response is provided too allow warnings like 113<N>        http://tools.ietf.org/html/rfc7234#section-5.5.4 where we need<N>        to explicitly say response is over 24 hours old.<N>        """<N>        return '110 - "Response is Stale"'<N><N>
    def update_headers(self, response):<N>        """Update the response headers with any new headers.<N><N>        NOTE: This SHOULD always include some Warning header to<N>              signify that the response was cached by the client, not<N>              by way of the provided headers.<N>        """<N>        return {}<N><N>
    def apply(self, response):<N>        updated_headers = self.update_headers(response)<N><N>        if updated_headers:<N>            response.headers.update(updated_headers)<N>            warning_header_value = self.warning(response)<N>            if warning_header_value is not None:<N>                response.headers.update({"Warning": warning_header_value})<N><N>
"""<N>The cache object API for implementing caches. The default is a thread<N>safe in-memory dictionary.<N>"""<N>from threading import Lock<N><N><N>class BaseCache(object):<N><N>    def get(self, key):<N>        raise NotImplementedError()<N><N>    def set(self, key, value):<N>        raise NotImplementedError()<N><N>
    def delete(self, key):<N>        raise NotImplementedError()<N><N>    def close(self):<N>        pass<N><N><N>class DictCache(BaseCache):<N><N>    def __init__(self, init_dict=None):<N>        self.lock = Lock()<N>        self.data = init_dict or {}<N><N>
    def get(self, key):<N>        return self.data.get(key, None)<N><N>    def set(self, key, value):<N>        with self.lock:<N>            self.data.update({key: value})<N><N>    def delete(self, key):<N>        with self.lock:<N>            if key in self.data:<N>                self.data.pop(key)<N><N><N>
import base64<N>import io<N>import json<N>import zlib<N><N>from pip._vendor import msgpack<N>from pip._vendor.requests.structures import CaseInsensitiveDict<N><N>from .compat import HTTPResponse, pickle, text_type<N><N><N>def _b64_decode_bytes(b):<N>    return base64.b64decode(b.encode("ascii"))<N><N>
<N>def _b64_decode_str(s):<N>    return _b64_decode_bytes(s).decode("utf8")<N><N><N>class Serializer(object):<N><N>    def dumps(self, request, response, body=None):<N>        response_headers = CaseInsensitiveDict(response.headers)<N><N>        if body is None:<N>            body = response.read(decode_content=False)<N><N>
from io import BytesIO<N><N><N>class CallbackFileWrapper(object):<N>    """<N>    Small wrapper around a fp object which will tee everything read into a<N>    buffer, and when that file is closed it will execute a callback with the<N>    contents of that buffer.<N><N>
    All attributes are proxied to the underlying file object.<N><N>    This class uses members with a double underscore (__) leading prefix so as<N>    not to accidentally shadow an attribute.<N>    """<N><N>    def __init__(self, fp, callback):<N>        self.__buf = BytesIO()<N>        self.__fp = fp<N>        self.__callback = callback<N><N>
import logging<N><N>from pip._vendor import requests<N><N>from pip._vendor.cachecontrol.adapter import CacheControlAdapter<N>from pip._vendor.cachecontrol.cache import DictCache<N>from pip._vendor.cachecontrol.controller import logger<N><N>from argparse import ArgumentParser<N><N>
<N>def setup_logging():<N>    logger.setLevel(logging.DEBUG)<N>    handler = logging.StreamHandler()<N>    logger.addHandler(handler)<N><N><N>def get_session():<N>    adapter = CacheControlAdapter(<N>        DictCache(), cache_etags=True, serializer=None, heuristic=None<N>    )<N>    sess = requests.Session()<N>    sess.mount("http://", adapter)<N>    sess.mount("https://", adapter)<N><N>
    sess.cache_controller = adapter.controller<N>    return sess<N><N><N>def get_args():<N>    parser = ArgumentParser()<N>    parser.add_argument("url", help="The URL to try and cache")<N>    return parser.parse_args()<N><N><N>def main(args=None):<N>    args = get_args()<N>    sess = get_session()<N><N>
    # Make a request to get a response<N>    resp = sess.get(args.url)<N><N>    # Turn on logging<N>    setup_logging()<N><N>    # try setting the cache<N>    sess.cache_controller.cache_response(resp.request, resp.raw)<N><N>    # Now try to get it<N>    if sess.cache_controller.cached_request(resp.request):<N>        print("Cached!")<N>    else:<N>        print("Not cached :(")<N><N>
"""<N>The httplib2 algorithms ported for use with requests.<N>"""<N>import logging<N>import re<N>import calendar<N>import time<N>from email.utils import parsedate_tz<N><N>from pip._vendor.requests.structures import CaseInsensitiveDict<N><N>from .cache import DictCache<N>from .serialize import Serializer<N><N>
<N>logger = logging.getLogger(__name__)<N><N>URI = re.compile(r"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?")<N><N><N>def parse_uri(uri):<N>    """Parses a URI using the regex given in Appendix B of RFC 3986.<N><N>        (scheme, authority, path, query, fragment) = parse_uri(uri)<N>    """<N>    groups = URI.match(uri).groups()<N>    return (groups[1], groups[3], groups[4], groups[6], groups[8])<N><N>
<N>class CacheController(object):<N>    """An interface to see if request should cached or not.<N>    """<N><N>    def __init__(<N>        self, cache=None, cache_etags=True, serializer=None, status_codes=None<N>    ):<N>        self.cache = DictCache() if cache is None else cache<N>        self.cache_etags = cache_etags<N>        self.serializer = serializer or Serializer()<N>        self.cacheable_status_codes = status_codes or (200, 203, 300, 301)<N><N>
    @classmethod<N>    def _urlnorm(cls, uri):<N>        """Normalize the URL to create a safe key for the cache"""<N>        (scheme, authority, path, query, fragment) = parse_uri(uri)<N>        if not scheme or not authority:<N>            raise Exception("Only absolute URIs are allowed. uri = %s" % uri)<N><N>
        scheme = scheme.lower()<N>        authority = authority.lower()<N><N>        if not path:<N>            path = "/"<N><N>        # Could do syntax based normalization of the URI before<N>        # computing the digest. See Section 6.2.2 of Std 66.<N>        request_uri = query and "?".join([path, query]) or path<N>        defrag_uri = scheme + "://" + authority + request_uri<N><N>
import hashlib<N>import os<N>from textwrap import dedent<N><N>from ..cache import BaseCache<N>from ..controller import CacheController<N><N>try:<N>    FileNotFoundError<N>except NameError:<N>    # py2.X<N>    FileNotFoundError = (IOError, OSError)<N><N><N>def _secure_open_write(filename, fmode):<N>    # We only want to write to this file, so open it in write only mode<N>    flags = os.O_WRONLY<N><N>
    # os.O_CREAT | os.O_EXCL will fail if the file already exists, so we only<N>    #  will open *new* files.<N>    # We specify this because we want to ensure that the mode we pass is the<N>    # mode of the file.<N>    flags |= os.O_CREAT | os.O_EXCL<N><N>
    # Do not follow symlinks to prevent someone from making a symlink that<N>    # we follow and insecurely open a cache file.<N>    if hasattr(os, "O_NOFOLLOW"):<N>        flags |= os.O_NOFOLLOW<N><N>    # On Windows we'll mark this file as binary<N>    if hasattr(os, "O_BINARY"):<N>        flags |= os.O_BINARY<N><N>
    # Before we open our file, we want to delete any existing file that is<N>    # there<N>    try:<N>        os.remove(filename)<N>    except (IOError, OSError):<N>        # The file must not exist already, so we can just skip ahead to opening<N>        pass<N><N>
    # Open our file, the use of os.O_CREAT | os.O_EXCL will ensure that if a<N>    # race condition happens between the os.remove and this line, that an<N>    # error will be raised. Because we utilize a lockfile this should only<N>    # happen if someone is attempting to attack us.<N>    fd = os.open(filename, flags, fmode)<N>    try:<N>        return os.fdopen(fd, "wb")<N><N>
    except:<N>        # An error occurred wrapping our FD in a file object<N>        os.close(fd)<N>        raise<N><N><N>class FileCache(BaseCache):<N><N>    def __init__(<N>        self,<N>        directory,<N>        forever=False,<N>        filemode=0o0600,<N>        dirmode=0o0700,<N>        use_dir_lock=None,<N>        lock_class=None,<N>    ):<N><N>
from __future__ import division<N><N>from datetime import datetime<N>from pip._vendor.cachecontrol.cache import BaseCache<N><N><N>class RedisCache(BaseCache):<N><N>    def __init__(self, conn):<N>        self.conn = conn<N><N>    def get(self, key):<N>        return self.conn.get(key)<N><N>
    def set(self, key, value, expires=None):<N>        if not expires:<N>            self.conn.set(key, value)<N>        else:<N>            expires = expires - datetime.utcnow()<N>            self.conn.setex(key, int(expires.total_seconds()), value)<N><N>
    def delete(self, key):<N>        self.conn.delete(key)<N><N>    def clear(self):<N>        """Helper for clearing all the keys in a database. Use with<N>        caution!"""<N>        for key in self.conn.keys():<N>            self.conn.delete(key)<N><N>
import datetime<N>import io<N>from os import linesep<N>import re<N>import sys<N><N>from pip._vendor.toml.tz import TomlTz<N><N>if sys.version_info < (3,):<N>    _range = xrange  # noqa: F821<N>else:<N>    unicode = str<N>    _range = range<N>    basestring = str<N>    unichr = chr<N><N>
<N>def _detect_pathlib_path(p):<N>    if (3, 4) <= sys.version_info:<N>        import pathlib<N>        if isinstance(p, pathlib.PurePath):<N>            return True<N>    return False<N><N><N>def _ispath(p):<N>    if isinstance(p, (bytes, basestring)):<N>        return True<N>    return _detect_pathlib_path(p)<N><N>
<N>def _getpath(p):<N>    if (3, 6) <= sys.version_info:<N>        import os<N>        return os.fspath(p)<N>    if _detect_pathlib_path(p):<N>        return str(p)<N>    return p<N><N><N>try:<N>    FNFError = FileNotFoundError<N>except NameError:<N>    FNFError = IOError<N><N>
"""Python module which parses and emits TOML.<N><N>Released under the MIT license.<N>"""<N><N>from pip._vendor.toml import encoder<N>from pip._vendor.toml import decoder<N><N>__version__ = "0.10.2"<N>_spec_ = "0.5.0"<N><N>load = decoder.load<N>loads = decoder.loads<N>TomlDecoder = decoder.TomlDecoder<N>TomlDecodeError = decoder.TomlDecodeError<N>TomlPreserveCommentDecoder = decoder.TomlPreserveCommentDecoder<N><N>
dump = encoder.dump<N>dumps = encoder.dumps<N>TomlEncoder = encoder.TomlEncoder<N>TomlArraySeparatorEncoder = encoder.TomlArraySeparatorEncoder<N>TomlPreserveInlineDictEncoder = encoder.TomlPreserveInlineDictEncoder<N>TomlNumpyEncoder = encoder.TomlNumpyEncoder<N>TomlPreserveCommentEncoder = encoder.TomlPreserveCommentEncoder<N>TomlPathlibEncoder = encoder.TomlPathlibEncoder<N><N><N>
from datetime import tzinfo, timedelta<N><N><N>class TomlTz(tzinfo):<N>    def __init__(self, toml_offset):<N>        if toml_offset == "Z":<N>            self._raw_offset = "+00:00"<N>        else:<N>            self._raw_offset = toml_offset<N>        self._sign = -1 if self._raw_offset[0] == '-' else 1<N>        self._hours = int(self._raw_offset[1:3])<N>        self._minutes = int(self._raw_offset[4:6])<N><N>
    def __deepcopy__(self, memo):<N>        return self.__class__(self._raw_offset)<N><N>    def tzname(self, dt):<N>        return "UTC" + self._raw_offset<N><N>    def utcoffset(self, dt):<N>        return self._sign * timedelta(hours=self._hours, minutes=self._minutes)<N><N>
import datetime<N>import re<N>import sys<N>from decimal import Decimal<N><N>from pip._vendor.toml.decoder import InlineTableDict<N><N>if sys.version_info >= (3,):<N>    unicode = str<N><N><N>def dump(o, f, encoder=None):<N>    """Writes out dict as toml to a file<N><N>
    Args:<N>        o: Object to dump into toml<N>        f: File descriptor where the toml should be stored<N>        encoder: The ``TomlEncoder`` to use for constructing the output string<N><N>    Returns:<N>        String containing the toml corresponding to dictionary<N><N>
    Raises:<N>        TypeError: When anything other than file descriptor is passed<N>    """<N><N>    if not f.write:<N>        raise TypeError("You can only dump an object to a file descriptor")<N>    d = dumps(o, encoder=encoder)<N>    f.write(d)<N>    return d<N><N>
<N>def dumps(o, encoder=None):<N>    """Stringifies input dict as toml<N><N>    Args:<N>        o: Object to dump into toml<N>        encoder: The ``TomlEncoder`` to use for constructing the output string<N><N>    Returns:<N>        String containing the toml corresponding to dict<N><N>
    Examples:<N>        ```python<N>        >>> import toml<N>        >>> output = {<N>        ... 'a': "I'm a string",<N>        ... 'b': ["I'm", "a", "list"],<N>        ... 'c': 2400<N>        ... }<N>        >>> toml.dumps(output)<N>        'a = "I\'m a string"\nb = [ "I\'m", "a", "list",]\nc = 2400\n'<N>        ```<N>    """<N><N>
from collections import OrderedDict<N>from pip._vendor.toml import TomlEncoder<N>from pip._vendor.toml import TomlDecoder<N><N><N>class TomlOrderedDecoder(TomlDecoder):<N><N>    def __init__(self):<N>        super(self.__class__, self).__init__(_dict=OrderedDict)<N><N><N>class TomlOrderedEncoder(TomlEncoder):<N><N>    def __init__(self):<N>        super(self.__class__, self).__init__(_dict=OrderedDict)<N>
from .core import *<N>from .codec import *<N><N>def ToASCII(label):<N>    return encode(label)<N><N>def ToUnicode(label):<N>    return decode(label)<N><N>def nameprep(s):<N>    raise NotImplementedError('IDNA 2008 does not utilise nameprep protocol')<N><N>
from .core import encode, decode, alabel, ulabel, IDNAError<N>import codecs<N>import re<N><N>_unicode_dots_re = re.compile('[\u002e\u3002\uff0e\uff61]')<N><N>class Codec(codecs.Codec):<N><N>    def encode(self, data, errors='strict'):<N><N>        if errors != 'strict':<N>            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))<N><N>
        if not data:<N>            return "", 0<N><N>        return encode(data), len(data)<N><N>    def decode(self, data, errors='strict'):<N><N>        if errors != 'strict':<N>            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))<N><N>
        if not data:<N>            return '', 0<N><N>        return decode(data), len(data)<N><N>class IncrementalEncoder(codecs.BufferedIncrementalEncoder):<N>    def _buffer_encode(self, data, errors, final):<N>        if errors != 'strict':<N>            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))<N><N>
        if not data:<N>            return ('', 0)<N><N>        labels = _unicode_dots_re.split(data)<N>        trailing_dot = ''<N>        if labels:<N>            if not labels[-1]:<N>                trailing_dot = '.'<N>                del labels[-1]<N>            elif not final:<N>                # Keep potentially unfinished label until the next call<N>                del labels[-1]<N>                if labels:<N>                    trailing_dot = '.'<N><N>
        result = []<N>        size = 0<N>        for label in labels:<N>            result.append(alabel(label))<N>            if size:<N>                size += 1<N>            size += len(label)<N><N>        # Join with U+002E<N>        result = '.'.join(result) + trailing_dot<N>        size += len(trailing_dot)<N>        return (result, size)<N><N>
class IncrementalDecoder(codecs.BufferedIncrementalDecoder):<N>    def _buffer_decode(self, data, errors, final):<N>        if errors != 'strict':<N>            raise IDNAError('Unsupported error handling \"{}\"'.format(errors))<N><N>        if not data:<N>            return ('', 0)<N><N>
        labels = _unicode_dots_re.split(data)<N>        trailing_dot = ''<N>        if labels:<N>            if not labels[-1]:<N>                trailing_dot = '.'<N>                del labels[-1]<N>            elif not final:<N>                # Keep potentially unfinished label until the next call<N>                del labels[-1]<N>                if labels:<N>                    trailing_dot = '.'<N><N>
        result = []<N>        size = 0<N>        for label in labels:<N>            result.append(ulabel(label))<N>            if size:<N>                size += 1<N>            size += len(label)<N><N>        result = '.'.join(result) + trailing_dot<N>        size += len(trailing_dot)<N>        return (result, size)<N><N>
<N>class StreamWriter(Codec, codecs.StreamWriter):<N>    pass<N><N>class StreamReader(Codec, codecs.StreamReader):<N>    pass<N><N>def getregentry():<N>    return codecs.CodecInfo(<N>        name='idna',<N>        encode=Codec().encode,<N>        decode=Codec().decode,<N>        incrementalencoder=IncrementalEncoder,<N>        incrementaldecoder=IncrementalDecoder,<N>        streamwriter=StreamWriter,<N>        streamreader=StreamReader,<N>    )<N><N><N>
from . import idnadata<N>import bisect<N>import unicodedata<N>import re<N>import sys<N>from .intranges import intranges_contain<N><N>_virama_combining_class = 9<N>_alabel_prefix = b'xn--'<N>_unicode_dots_re = re.compile('[\u002e\u3002\uff0e\uff61]')<N><N>class IDNAError(UnicodeError):<N>    """ Base exception for all IDNA-encoding related problems """<N>    pass<N><N>
<N>class IDNABidiError(IDNAError):<N>    """ Exception when bidirectional requirements are not satisfied """<N>    pass<N><N><N>class InvalidCodepoint(IDNAError):<N>    """ Exception when a disallowed or unallocated codepoint is used """<N>    pass<N><N><N>class InvalidCodepointContext(IDNAError):<N>    """ Exception when the codepoint is not valid in the context it is used """<N>    pass<N><N>
<N>def _combining_class(cp):<N>    v = unicodedata.combining(chr(cp))<N>    if v == 0:<N>        if not unicodedata.name(chr(cp)):<N>            raise ValueError('Unknown character in unicodedata')<N>    return v<N><N>def _is_script(cp, script):<N>    return intranges_contain(ord(cp), idnadata.scripts[script])<N><N>
def _punycode(s):<N>    return s.encode('punycode')<N><N>def _unot(s):<N>    return 'U+{:04X}'.format(s)<N><N><N>def valid_label_length(label):<N><N>    if len(label) > 63:<N>        return False<N>    return True<N><N><N>def valid_string_length(label, trailing_dot):<N><N>
"""<N>Given a list of integers, made up of (hopefully) a small number of long runs<N>of consecutive integers, compute a representation of the form<N>((start1, end1), (start2, end2) ...). Then answer the question "was x present<N>in the original list?" in time O(log(# runs)).<N>"""<N><N>
import bisect<N><N>def intranges_from_list(list_):<N>    """Represent a list of integers as a sequence of ranges:<N>    ((start_0, end_0), (start_1, end_1), ...), such that the original<N>    integers are exactly those x such that start_i <= x < end_i for some i.<N><N>
    Ranges are encoded as single integers (start << 32 | end), not as tuples.<N>    """<N><N>    sorted_list = sorted(list_)<N>    ranges = []<N>    last_write = -1<N>    for i in range(len(sorted_list)):<N>        if i+1 < len(sorted_list):<N>            if sorted_list[i] == sorted_list[i+1]-1:<N>                continue<N>        current_range = sorted_list[last_write+1:i+1]<N>        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))<N>        last_write = i<N><N>
from __future__ import absolute_import<N><N>try:<N>    from collections.abc import Mapping, MutableMapping<N>except ImportError:<N>    from collections import Mapping, MutableMapping<N>try:<N>    from threading import RLock<N>except ImportError:  # Platform-specific: No threads available<N><N>
    class RLock:<N>        def __enter__(self):<N>            pass<N><N>        def __exit__(self, exc_type, exc_value, traceback):<N>            pass<N><N><N>from collections import OrderedDict<N><N>from .exceptions import InvalidHeader<N>from .packages import six<N>from .packages.six import iterkeys, itervalues<N><N>
__all__ = ["RecentlyUsedContainer", "HTTPHeaderDict"]<N><N><N>_Null = object()<N><N><N>class RecentlyUsedContainer(MutableMapping):<N>    """<N>    Provides a thread-safe dict-like container which maintains up to<N>    ``maxsize`` keys while throwing away the least-recently-used keys beyond<N>    ``maxsize``.<N><N>
    :param maxsize:<N>        Maximum number of recent elements to retain.<N><N>    :param dispose_func:<N>        Every time an item is evicted from the container,<N>        ``dispose_func(value)`` is called.  Callback which will get called<N>    """<N><N>
    ContainerCls = OrderedDict<N><N>    def __init__(self, maxsize=10, dispose_func=None):<N>        self._maxsize = maxsize<N>        self.dispose_func = dispose_func<N><N>        self._container = self.ContainerCls()<N>        self.lock = RLock()<N><N>    def __getitem__(self, key):<N>        # Re-insert the item, moving it to the end of the eviction line.<N>        with self.lock:<N>            item = self._container.pop(key)<N>            self._container[key] = item<N>            return item<N><N>
    def __setitem__(self, key, value):<N>        evicted_value = _Null<N>        with self.lock:<N>            # Possibly evict the existing value of 'key'<N>            evicted_value = self._container.get(key, _Null)<N>            self._container[key] = value<N><N>
            # If we didn't evict an existing value, we might have to evict the<N>            # least recently used item from the beginning of the container.<N>            if len(self._container) > self._maxsize:<N>                _key, evicted_value = self._container.popitem(last=False)<N><N>
        if self.dispose_func and evicted_value is not _Null:<N>            self.dispose_func(evicted_value)<N><N>    def __delitem__(self, key):<N>        with self.lock:<N>            value = self._container.pop(key)<N><N>        if self.dispose_func:<N>            self.dispose_func(value)<N><N>
    def __len__(self):<N>        with self.lock:<N>            return len(self._container)<N><N>    def __iter__(self):<N>        raise NotImplementedError(<N>            "Iteration over this class is unlikely to be threadsafe."<N>        )<N><N>    def clear(self):<N>        with self.lock:<N>            # Copy pointers to all values, then wipe the mapping<N>            values = list(itervalues(self._container))<N>            self._container.clear()<N><N>
        if self.dispose_func:<N>            for value in values:<N>                self.dispose_func(value)<N><N>    def keys(self):<N>        with self.lock:<N>            return list(iterkeys(self._container))<N><N><N>class HTTPHeaderDict(MutableMapping):<N>    """<N>    :param headers:<N>        An iterable of field-value pairs. Must not contain multiple field names<N>        when compared case-insensitively.<N><N>
    :param kwargs:<N>        Additional field-value pairs to pass in to ``dict.update``.<N><N>    A ``dict`` like container for storing HTTP Headers.<N><N>    Field names are stored and compared case-insensitively in compliance with<N>    RFC 7230. Iteration provides the first case-sensitive key seen for each<N>    case-insensitive pair.<N><N>
    Using ``__setitem__`` syntax overwrites fields that compare equal<N>    case-insensitively in order to maintain ``dict``'s api. For fields that<N>    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``<N>    in a loop.<N><N>    If multiple fields that are equal case-insensitively are passed to the<N>    constructor or ``.update``, the behavior is undefined and some will be<N>    lost.<N><N>
    >>> headers = HTTPHeaderDict()<N>    >>> headers.add('Set-Cookie', 'foo=bar')<N>    >>> headers.add('set-cookie', 'baz=quxx')<N>    >>> headers['content-length'] = '7'<N>    >>> headers['SET-cookie']<N>    'foo=bar, baz=quxx'<N>    >>> headers['Content-Length']<N>    '7'<N>    """<N><N>
    def __init__(self, headers=None, **kwargs):<N>        super(HTTPHeaderDict, self).__init__()<N>        self._container = OrderedDict()<N>        if headers is not None:<N>            if isinstance(headers, HTTPHeaderDict):<N>                self._copy_from(headers)<N>            else:<N>                self.extend(headers)<N>        if kwargs:<N>            self.extend(kwargs)<N><N>
    def __setitem__(self, key, val):<N>        self._container[key.lower()] = [key, val]<N>        return self._container[key.lower()]<N><N>    def __getitem__(self, key):<N>        val = self._container[key.lower()]<N>        return ", ".join(val[1:])<N><N>
"""<N>Python HTTP library with thread-safe connection pooling, file post support, user friendly, and more<N>"""<N>from __future__ import absolute_import<N><N># Set default logging handler to avoid "No handler found" warnings.<N>import logging<N>import warnings<N>from logging import NullHandler<N><N>
from . import exceptions<N>from ._version import __version__<N>from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, connection_from_url<N>from .filepost import encode_multipart_formdata<N>from .poolmanager import PoolManager, ProxyManager, proxy_from_url<N>from .response import HTTPResponse<N>from .util.request import make_headers<N>from .util.retry import Retry<N>from .util.timeout import Timeout<N>from .util.url import get_host<N><N>
__author__ = "Andrey Petrov (andrey.petrov@shazow.net)"<N>__license__ = "MIT"<N>__version__ = __version__<N><N>__all__ = (<N>    "HTTPConnectionPool",<N>    "HTTPSConnectionPool",<N>    "PoolManager",<N>    "ProxyManager",<N>    "HTTPResponse",<N>    "Retry",<N>    "Timeout",<N>    "add_stderr_logger",<N>    "connection_from_url",<N>    "disable_warnings",<N>    "encode_multipart_formdata",<N>    "get_host",<N>    "make_headers",<N>    "proxy_from_url",<N>)<N><N>
from __future__ import absolute_import<N><N>from .filepost import encode_multipart_formdata<N>from .packages.six.moves.urllib.parse import urlencode<N><N>__all__ = ["RequestMethods"]<N><N><N>class RequestMethods(object):<N>    """<N>    Convenience mixin for classes who implement a :meth:`urlopen` method, such<N>    as :class:`urllib3.HTTPConnectionPool` and<N>    :class:`urllib3.PoolManager`.<N><N>
    Provides behavior for making common types of HTTP request methods and<N>    decides which type of request field encoding to use.<N><N>    Specifically,<N><N>    :meth:`.request_encode_url` is for sending requests whose fields are<N>    encoded in the URL (such as GET, HEAD, DELETE).<N><N>
    :meth:`.request_encode_body` is for sending requests whose fields are<N>    encoded in the *body* of the request using multipart or www-form-urlencoded<N>    (such as for POST, PUT, PATCH).<N><N>    :meth:`.request` is for making any kind of request, it will look up the<N>    appropriate encoding format and use one of the above two methods to make<N>    the request.<N><N>
    Initializer parameters:<N><N>    :param headers:<N>        Headers to include with all requests, unless other headers are given<N>        explicitly.<N>    """<N><N>    _encode_url_methods = {"DELETE", "GET", "HEAD", "OPTIONS"}<N><N>    def __init__(self, headers=None):<N>        self.headers = headers or {}<N><N>
    def urlopen(<N>        self,<N>        method,<N>        url,<N>        body=None,<N>        headers=None,<N>        encode_multipart=True,<N>        multipart_boundary=None,<N>        **kw<N>    ):  # Abstract<N>        raise NotImplementedError(<N>            "Classes extending RequestMethods must implement "<N>            "their own ``urlopen`` method."<N>        )<N><N>
from __future__ import absolute_import<N><N>import datetime<N>import logging<N>import os<N>import re<N>import socket<N>import warnings<N>from socket import error as SocketError<N>from socket import timeout as SocketTimeout<N><N>from .packages import six<N>from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection<N>from .packages.six.moves.http_client import HTTPException  # noqa: F401<N>from .util.proxy import create_proxy_ssl_context<N><N>
try:  # Compiled with SSL?<N>    import ssl<N><N>    BaseSSLError = ssl.SSLError<N>except (ImportError, AttributeError):  # Platform-specific: No SSL.<N>    ssl = None<N><N>    class BaseSSLError(BaseException):<N>        pass<N><N><N>try:<N>    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.<N>    ConnectionError = ConnectionError<N>except NameError:<N>    # Python 2<N>    class ConnectionError(Exception):<N>        pass<N><N>
from __future__ import absolute_import<N><N>import email.utils<N>import mimetypes<N>import re<N><N>from .packages import six<N><N><N>def guess_content_type(filename, default="application/octet-stream"):<N>    """<N>    Guess the "Content-Type" of a file.<N><N>
    :param filename:<N>        The filename to guess the "Content-Type" of using :mod:`mimetypes`.<N>    :param default:<N>        If no "Content-Type" can be guessed, default to `default`.<N>    """<N>    if filename:<N>        return mimetypes.guess_type(filename)[0] or default<N>    return default<N><N>
<N>def format_header_param_rfc2231(name, value):<N>    """<N>    Helper function to format and quote a single header parameter using the<N>    strategy defined in RFC 2231.<N><N>    Particularly useful for header parameters which might contain<N>    non-ASCII values, like file names. This follows<N>    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.<N><N>
    :param name:<N>        The name of the parameter, a string expected to be ASCII only.<N>    :param value:<N>        The value of the parameter, provided as ``bytes`` or `str``.<N>    :ret:<N>        An RFC-2231-formatted unicode string.<N>    """<N>    if isinstance(value, six.binary_type):<N>        value = value.decode("utf-8")<N><N>
    if not any(ch in value for ch in '"\\\r\n'):<N>        result = u'%s="%s"' % (name, value)<N>        try:<N>            result.encode("ascii")<N>        except (UnicodeEncodeError, UnicodeDecodeError):<N>            pass<N>        else:<N>            return result<N><N>
    if six.PY2:  # Python 2:<N>        value = value.encode("utf-8")<N><N>    # encode_rfc2231 accepts an encoded string and returns an ascii-encoded<N>    # string in Python 2 but accepts and returns unicode strings in Python 3<N>    value = email.utils.encode_rfc2231(value, "utf-8")<N>    value = "%s*=%s" % (name, value)<N><N>
    if six.PY2:  # Python 2:<N>        value = value.decode("utf-8")<N><N>    return value<N><N><N>_HTML5_REPLACEMENTS = {<N>    u"\u0022": u"%22",<N>    # Replace "\" with "\\".<N>    u"\u005C": u"\u005C\u005C",<N>}<N><N># All control characters from 0x00 to 0x1F *except* 0x1B.<N>_HTML5_REPLACEMENTS.update(<N>    {<N>        six.unichr(cc): u"%{:02X}".format(cc)<N>        for cc in range(0x00, 0x1F + 1)<N>        if cc not in (0x1B,)<N>    }<N>)<N><N>
<N>def _replace_multiple(value, needles_and_replacements):<N>    def replacer(match):<N>        return needles_and_replacements[match.group(0)]<N><N>    pattern = re.compile(<N>        r"|".join([re.escape(needle) for needle in needles_and_replacements.keys()])<N>    )<N><N>
    result = pattern.sub(replacer, value)<N><N>    return result<N><N><N>def format_header_param_html5(name, value):<N>    """<N>    Helper function to format and quote a single header parameter using the<N>    HTML5 strategy.<N><N>    Particularly useful for header parameters which might contain<N>    non-ASCII values, like file names. This follows the `HTML5 Working Draft<N>    Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.<N><N>
    .. _HTML5 Working Draft Section 4.10.22.7:<N>        https://w3c.github.io/html/sec-forms.html#multipart-form-data<N><N>    :param name:<N>        The name of the parameter, a string expected to be ASCII only.<N>    :param value:<N>        The value of the parameter, provided as ``bytes`` or `str``.<N>    :ret:<N>        A unicode string, stripped of troublesome characters.<N>    """<N>    if isinstance(value, six.binary_type):<N>        value = value.decode("utf-8")<N><N>
    value = _replace_multiple(value, _HTML5_REPLACEMENTS)<N><N>    return u'%s="%s"' % (name, value)<N><N><N># For backwards-compatibility.<N>format_header_param = format_header_param_html5<N><N><N>class RequestField(object):<N>    """<N>    A data container for request body parameters.<N><N>
    :param name:<N>        The name of this request field. Must be unicode.<N>    :param data:<N>        The data/value body.<N>    :param filename:<N>        An optional filename of the request field. Must be unicode.<N>    :param headers:<N>        An optional dict-like object of headers to initially use for the field.<N>    :param header_formatter:<N>        An optional callable that is used to encode and format the headers. By<N>        default, this is :func:`format_header_param_html5`.<N>    """<N><N>
    def __init__(<N>        self,<N>        name,<N>        data,<N>        filename=None,<N>        headers=None,<N>        header_formatter=format_header_param_html5,<N>    ):<N>        self._name = name<N>        self._filename = filename<N>        self.data = data<N>        self.headers = {}<N>        if headers:<N>            self.headers = dict(headers)<N>        self.header_formatter = header_formatter<N><N>
    @classmethod<N>    def from_tuples(cls, fieldname, value, header_formatter=format_header_param_html5):<N>        """<N>        A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.<N><N>        Supports constructing :class:`~urllib3.fields.RequestField` from<N>        parameter of key/value strings AND key/filetuple. A filetuple is a<N>        (filename, data, MIME type) tuple where the MIME type is optional.<N>        For example::<N><N>
            'foo': 'bar',<N>            'fakefile': ('foofile.txt', 'contents of foofile'),<N>            'realfile': ('barfile.txt', open('realfile').read()),<N>            'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),<N>            'nonamefile': 'contents of nonamefile field',<N><N>
        Field names and filenames must be unicode.<N>        """<N>        if isinstance(value, tuple):<N>            if len(value) == 3:<N>                filename, data, content_type = value<N>            else:<N>                filename, data = value<N>                content_type = guess_content_type(filename)<N>        else:<N>            filename = None<N>            content_type = None<N>            data = value<N><N>
        request_param = cls(<N>            fieldname, data, filename=filename, header_formatter=header_formatter<N>        )<N>        request_param.make_multipart(content_type=content_type)<N><N>        return request_param<N><N>    def _render_part(self, name, value):<N>        """<N>        Overridable helper function to format a single header parameter. By<N>        default, this calls ``self.header_formatter``.<N><N>
        :param name:<N>            The name of the parameter, a string expected to be ASCII only.<N>        :param value:<N>            The value of the parameter, provided as a unicode string.<N>        """<N><N>        return self.header_formatter(name, value)<N><N>
from __future__ import absolute_import<N><N>from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead<N><N># Base Exceptions<N><N><N>class HTTPError(Exception):<N>    """Base exception used by this module."""<N><N>    pass<N><N><N>class HTTPWarning(Warning):<N>    """Base warning used by this module."""<N><N>
    pass<N><N><N>class PoolError(HTTPError):<N>    """Base exception for errors caused within a pool."""<N><N>    def __init__(self, pool, message):<N>        self.pool = pool<N>        HTTPError.__init__(self, "%s: %s" % (pool, message))<N><N>    def __reduce__(self):<N>        # For pickling purposes.<N>        return self.__class__, (None, None)<N><N>
<N>class RequestError(PoolError):<N>    """Base exception for PoolErrors that have associated URLs."""<N><N>    def __init__(self, pool, url, message):<N>        self.url = url<N>        PoolError.__init__(self, pool, message)<N><N>    def __reduce__(self):<N>        # For pickling purposes.<N>        return self.__class__, (None, self.url, None)<N><N>
<N>class SSLError(HTTPError):<N>    """Raised when SSL certificate fails in an HTTPS connection."""<N><N>    pass<N><N><N>class ProxyError(HTTPError):<N>    """Raised when the connection to a proxy fails."""<N><N>    def __init__(self, message, error, *args):<N>        super(ProxyError, self).__init__(message, error, *args)<N>        self.original_error = error<N><N>
<N>class DecodeError(HTTPError):<N>    """Raised when automatic decoding based on Content-Type fails."""<N><N>    pass<N><N><N>class ProtocolError(HTTPError):<N>    """Raised when something unexpected happens mid-request/response."""<N><N>    pass<N><N><N>#: Renamed to ProtocolError but aliased for backwards compatibility.<N>ConnectionError = ProtocolError<N><N>
<N># Leaf Exceptions<N><N><N>class MaxRetryError(RequestError):<N>    """Raised when the maximum number of retries is exceeded.<N><N>    :param pool: The connection pool<N>    :type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`<N>    :param string url: The requested Url<N>    :param exceptions.Exception reason: The underlying error<N><N>
    """<N><N>    def __init__(self, pool, url, reason=None):<N>        self.reason = reason<N><N>        message = "Max retries exceeded with url: %s (Caused by %r)" % (url, reason)<N><N>        RequestError.__init__(self, pool, url, message)<N><N><N>class HostChangedError(RequestError):<N>    """Raised when an existing pool gets a request for a foreign host."""<N><N>
    def __init__(self, pool, url, retries=3):<N>        message = "Tried to open a foreign host with url: %s" % url<N>        RequestError.__init__(self, pool, url, message)<N>        self.retries = retries<N><N><N>class TimeoutStateError(HTTPError):<N>    """Raised when passing an invalid state to a timeout"""<N><N>
    pass<N><N><N>class TimeoutError(HTTPError):<N>    """Raised when a socket timeout error occurs.<N><N>    Catching this error will catch both :exc:`ReadTimeoutErrors<N>    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.<N>    """<N><N>
    pass<N><N><N>class ReadTimeoutError(TimeoutError, RequestError):<N>    """Raised when a socket timeout occurs while receiving data from a server"""<N><N>    pass<N><N><N># This timeout error does not have a URL attached and needs to inherit from the<N># base HTTPError<N>class ConnectTimeoutError(TimeoutError):<N>    """Raised when a socket timeout occurs while connecting to a server"""<N><N>
    pass<N><N><N>class NewConnectionError(ConnectTimeoutError, PoolError):<N>    """Raised when we fail to establish a new connection. Usually ECONNREFUSED."""<N><N>    pass<N><N><N>class EmptyPoolError(PoolError):<N>    """Raised when a pool runs out of connections and no more are allowed."""<N><N>
    pass<N><N><N>class ClosedPoolError(PoolError):<N>    """Raised when a request enters a pool after the pool has been closed."""<N><N>    pass<N><N><N>class LocationValueError(ValueError, HTTPError):<N>    """Raised when there is something wrong with a given URL input."""<N><N>
    pass<N><N><N>class LocationParseError(LocationValueError):<N>    """Raised when get_host or similar fails to parse the URL input."""<N><N>    def __init__(self, location):<N>        message = "Failed to parse: %s" % location<N>        HTTPError.__init__(self, message)<N><N>
        self.location = location<N><N><N>class URLSchemeUnknown(LocationValueError):<N>    """Raised when a URL input has an unsupported scheme."""<N><N>    def __init__(self, scheme):<N>        message = "Not supported URL scheme %s" % scheme<N>        super(URLSchemeUnknown, self).__init__(message)<N><N>
        self.scheme = scheme<N><N><N>class ResponseError(HTTPError):<N>    """Used as a container for an error reason supplied in a MaxRetryError."""<N><N>    GENERIC_ERROR = "too many error responses"<N>    SPECIFIC_ERROR = "too many {status_code} error responses"<N><N>
<N>class SecurityWarning(HTTPWarning):<N>    """Warned when performing security reducing actions"""<N><N>    pass<N><N><N>class SubjectAltNameWarning(SecurityWarning):<N>    """Warned when connecting to a host with a certificate missing a SAN."""<N><N>    pass<N><N>
<N>class InsecureRequestWarning(SecurityWarning):<N>    """Warned when making an unverified HTTPS request."""<N><N>    pass<N><N><N>class SystemTimeWarning(SecurityWarning):<N>    """Warned when system time is suspected to be wrong"""<N><N>    pass<N><N><N>class InsecurePlatformWarning(SecurityWarning):<N>    """Warned when certain TLS/SSL configuration is not available on a platform."""<N><N>
    pass<N><N><N>class SNIMissingWarning(HTTPWarning):<N>    """Warned when making a HTTPS request without SNI available."""<N><N>    pass<N><N><N>class DependencyWarning(HTTPWarning):<N>    """<N>    Warned when an attempt is made to import a module with missing optional<N>    dependencies.<N>    """<N><N>
    pass<N><N><N>class ResponseNotChunked(ProtocolError, ValueError):<N>    """Response needs to be chunked in order to read it as chunks."""<N><N>    pass<N><N><N>class BodyNotHttplibCompatible(HTTPError):<N>    """<N>    Body should be :class:`http.client.HTTPResponse` like<N>    (have an fp attribute which returns raw chunks) for read_chunked().<N>    """<N><N>
    pass<N><N><N>class IncompleteRead(HTTPError, httplib_IncompleteRead):<N>    """<N>    Response length doesn't match expected Content-Length<N><N>    Subclass of :class:`http.client.IncompleteRead` to allow int value<N>    for ``partial`` to avoid creating large objects on streamed reads.<N>    """<N><N>
    def __init__(self, partial, expected):<N>        super(IncompleteRead, self).__init__(partial, expected)<N><N>    def __repr__(self):<N>        return "IncompleteRead(%i bytes read, %i more expected)" % (<N>            self.partial,<N>            self.expected,<N>        )<N><N>
<N>class InvalidChunkLength(HTTPError, httplib_IncompleteRead):<N>    """Invalid chunk length in a chunked response."""<N><N>    def __init__(self, response, length):<N>        super(InvalidChunkLength, self).__init__(<N>            response.tell(), response.length_remaining<N>        )<N>        self.response = response<N>        self.length = length<N><N>
    def __repr__(self):<N>        return "InvalidChunkLength(got length %r, %i bytes read)" % (<N>            self.length,<N>            self.partial,<N>        )<N><N><N>class InvalidHeader(HTTPError):<N>    """The header provided was somehow invalid."""<N><N>
from __future__ import absolute_import<N><N>import io<N>import logging<N>import zlib<N>from contextlib import contextmanager<N>from socket import error as SocketError<N>from socket import timeout as SocketTimeout<N><N>try:<N>    import brotli<N>except ImportError:<N>    brotli = None<N><N>
from ._collections import HTTPHeaderDict<N>from .connection import BaseSSLError, HTTPException<N>from .exceptions import (<N>    BodyNotHttplibCompatible,<N>    DecodeError,<N>    HTTPError,<N>    IncompleteRead,<N>    InvalidChunkLength,<N>    InvalidHeader,<N>    ProtocolError,<N>    ReadTimeoutError,<N>    ResponseNotChunked,<N>    SSLError,<N>)<N>from .packages import six<N>from .util.response import is_fp_closed, is_response_to_head<N><N>
log = logging.getLogger(__name__)<N><N><N>class DeflateDecoder(object):<N>    def __init__(self):<N>        self._first_try = True<N>        self._data = b""<N>        self._obj = zlib.decompressobj()<N><N>    def __getattr__(self, name):<N>        return getattr(self._obj, name)<N><N>
from __future__ import absolute_import<N><N>from . import ssl_match_hostname<N><N>__all__ = ("ssl_match_hostname",)<N>
import sys<N><N>try:<N>    # Our match_hostname function is the same as 3.5's, so we only want to<N>    # import the match_hostname function if it's at least that good.<N>    if sys.version_info < (3, 5):<N>        raise ImportError("Fallback to vendored code")<N><N>
    from ssl import CertificateError, match_hostname<N>except ImportError:<N>    try:<N>        # Backport of the function from a pypi module<N>        from backports.ssl_match_hostname import (  # type: ignore<N>            CertificateError,<N>            match_hostname,<N>        )<N>    except ImportError:<N>        # Our vendored copy<N>        from ._implementation import CertificateError, match_hostname  # type: ignore<N><N>
from __future__ import absolute_import<N><N>import re<N>from collections import namedtuple<N><N>from ..exceptions import LocationParseError<N>from ..packages import six<N><N>url_attrs = ["scheme", "auth", "host", "port", "path", "query", "fragment"]<N><N># We only want to normalize urls with an HTTP(S) scheme.<N># urllib3 infers URLs without a scheme (None) to be http.<N>NORMALIZABLE_SCHEMES = ("http", "https", None)<N><N>
# Almost all of these patterns were derived from the<N># 'rfc3986' module: https://github.com/python-hyper/rfc3986<N>PERCENT_RE = re.compile(r"%[a-fA-F0-9]{2}")<N>SCHEME_RE = re.compile(r"^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)")<N>URI_RE = re.compile(<N>    r"^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?"<N>    r"(?://([^\\/?#]*))?"<N>    r"([^?#]*)"<N>    r"(?:\?([^#]*))?"<N>    r"(?:#(.*))?$",<N>    re.UNICODE | re.DOTALL,<N>)<N><N>
import collections<N><N>from ..packages import six<N>from ..packages.six.moves import queue<N><N>if six.PY2:<N>    # Queue is imported for side effects on MS Windows. See issue #229.<N>    import Queue as _unused_module_Queue  # noqa: F401<N><N><N>class LifoQueue(queue.Queue):<N>    def _init(self, _):<N>        self.queue = collections.deque()<N><N>    def _qsize(self, len=len):<N>        return len(self.queue)<N><N>    def _put(self, item):<N>        self.queue.append(item)<N><N>    def _get(self):<N>        return self.queue.pop()<N>
import io<N>import socket<N>import ssl<N><N>from pip._vendor.urllib3.exceptions import ProxySchemeUnsupported<N>from pip._vendor.urllib3.packages import six<N><N>SSL_BLOCKSIZE = 16384<N><N><N>class SSLTransport:<N>    """<N>    The SSLTransport wraps an existing socket and establishes an SSL connection.<N><N>
    Contrary to Python's implementation of SSLSocket, it allows you to chain<N>    multiple TLS connections together. It's particularly useful if you need to<N>    implement TLS within TLS.<N><N>    The class supports most of the socket API operations.<N>    """<N><N>
    @staticmethod<N>    def _validate_ssl_context_for_tls_in_tls(ssl_context):<N>        """<N>        Raises a ProxySchemeUnsupported if the provided ssl_context can't be used<N>        for TLS in TLS.<N><N>        The only requirement is that the ssl_context provides the 'wrap_bio'<N>        methods.<N>        """<N><N>
        if not hasattr(ssl_context, "wrap_bio"):<N>            if six.PY2:<N>                raise ProxySchemeUnsupported(<N>                    "TLS in TLS requires SSLContext.wrap_bio() which isn't "<N>                    "supported on Python 2"<N>                )<N>            else:<N>                raise ProxySchemeUnsupported(<N>                    "TLS in TLS requires SSLContext.wrap_bio() which isn't "<N>                    "available on non-native SSLContext"<N>                )<N><N>
    def __init__(<N>        self, socket, ssl_context, server_hostname=None, suppress_ragged_eofs=True<N>    ):<N>        """<N>        Create an SSLTransport around socket using the provided ssl_context.<N>        """<N>        self.incoming = ssl.MemoryBIO()<N>        self.outgoing = ssl.MemoryBIO()<N><N>
        self.suppress_ragged_eofs = suppress_ragged_eofs<N>        self.socket = socket<N><N>        self.sslobj = ssl_context.wrap_bio(<N>            self.incoming, self.outgoing, server_hostname=server_hostname<N>        )<N><N>        # Perform initial handshake.<N>        self._ssl_io_loop(self.sslobj.do_handshake)<N><N>
    def __enter__(self):<N>        return self<N><N>    def __exit__(self, *_):<N>        self.close()<N><N>    def fileno(self):<N>        return self.socket.fileno()<N><N>    def read(self, len=1024, buffer=None):<N>        return self._wrap_ssl_read(len, buffer)<N><N>
from .ssl_ import create_urllib3_context, resolve_cert_reqs, resolve_ssl_version<N><N><N>def connection_requires_http_tunnel(<N>    proxy_url=None, proxy_config=None, destination_scheme=None<N>):<N>    """<N>    Returns True if the connection requires an HTTP CONNECT through the proxy.<N><N>
    :param URL proxy_url:<N>        URL of the proxy.<N>    :param ProxyConfig proxy_config:<N>        Proxy configuration from poolmanager.py<N>    :param str destination_scheme:<N>        The scheme of the destination. (i.e https, http, etc)<N>    """<N>    # If we're not using a proxy, no way to use a tunnel.<N>    if proxy_url is None:<N>        return False<N><N>
    # HTTP destinations never require tunneling, we always forward.<N>    if destination_scheme == "http":<N>        return False<N><N>    # Support for forwarding with HTTPS proxies and HTTPS destinations.<N>    if (<N>        proxy_url.scheme == "https"<N>        and proxy_config<N>        and proxy_config.use_forwarding_for_https<N>    ):<N>        return False<N><N>
from __future__ import absolute_import<N><N>from base64 import b64encode<N><N>from ..exceptions import UnrewindableBodyError<N>from ..packages.six import b, integer_types<N><N># Pass as a value within ``headers`` to skip<N># emitting some HTTP headers that are added automatically.<N># The only headers that are supported are ``Accept-Encoding``,<N># ``Host``, and ``User-Agent``.<N>SKIP_HEADER = "@@@SKIP_HEADER@@@"<N>SKIPPABLE_HEADERS = frozenset(["accept-encoding", "host", "user-agent"])<N><N>
ACCEPT_ENCODING = "gzip,deflate"<N>try:<N>    import brotli as _unused_module_brotli  # noqa: F401<N>except ImportError:<N>    pass<N>else:<N>    ACCEPT_ENCODING += ",br"<N><N>_FAILEDTELL = object()<N><N><N>def make_headers(<N>    keep_alive=None,<N>    accept_encoding=None,<N>    user_agent=None,<N>    basic_auth=None,<N>    proxy_basic_auth=None,<N>    disable_cache=None,<N>):<N>    """<N>    Shortcuts for generating request headers.<N><N>
    :param keep_alive:<N>        If ``True``, adds 'connection: keep-alive' header.<N><N>    :param accept_encoding:<N>        Can be a boolean, list, or string.<N>        ``True`` translates to 'gzip,deflate'.<N>        List will get joined by comma.<N>        String will be used as provided.<N><N>
    :param user_agent:<N>        String representing the user-agent you want, such as<N>        "python-urllib3/0.6"<N><N>    :param basic_auth:<N>        Colon-separated username:password string for 'authorization: basic ...'<N>        auth header.<N><N>    :param proxy_basic_auth:<N>        Colon-separated username:password string for 'proxy-authorization: basic ...'<N>        auth header.<N><N>
from __future__ import absolute_import<N><N>import email<N>import logging<N>import re<N>import time<N>import warnings<N>from collections import namedtuple<N>from itertools import takewhile<N><N>from ..exceptions import (<N>    ConnectTimeoutError,<N>    InvalidHeader,<N>    MaxRetryError,<N>    ProtocolError,<N>    ProxyError,<N>    ReadTimeoutError,<N>    ResponseError,<N>)<N>from ..packages import six<N><N>
log = logging.getLogger(__name__)<N><N><N># Data structure for representing the metadata of requests that result in a retry.<N>RequestHistory = namedtuple(<N>    "RequestHistory", ["method", "url", "error", "status", "redirect_location"]<N>)<N><N><N># TODO: In v2 we can remove this sentinel and metaclass with deprecated options.<N>_Default = object()<N><N>
<N>class _RetryMeta(type):<N>    @property<N>    def DEFAULT_METHOD_WHITELIST(cls):<N>        warnings.warn(<N>            "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "<N>            "will be removed in v2.0. Use 'Retry.DEFAULT_METHODS_ALLOWED' instead",<N>            DeprecationWarning,<N>        )<N>        return cls.DEFAULT_ALLOWED_METHODS<N><N>
    @DEFAULT_METHOD_WHITELIST.setter<N>    def DEFAULT_METHOD_WHITELIST(cls, value):<N>        warnings.warn(<N>            "Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "<N>            "will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",<N>            DeprecationWarning,<N>        )<N>        cls.DEFAULT_ALLOWED_METHODS = value<N><N>
    @property<N>    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):<N>        warnings.warn(<N>            "Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "<N>            "will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",<N>            DeprecationWarning,<N>        )<N>        return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT<N><N>
    @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter<N>    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):<N>        warnings.warn(<N>            "Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "<N>            "will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",<N>            DeprecationWarning,<N>        )<N>        cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value<N><N>
<N>@six.add_metaclass(_RetryMeta)<N>class Retry(object):<N>    """Retry configuration.<N><N>    Each retry attempt will create a new Retry object with updated values, so<N>    they can be safely reused.<N><N>    Retries can be defined as a default for a pool::<N><N>
        retries = Retry(connect=5, read=2, redirect=5)<N>        http = PoolManager(retries=retries)<N>        response = http.request('GET', 'http://example.com/')<N><N>    Or per-request (which overrides the default for the pool)::<N><N>        response = http.request('GET', 'http://example.com/', retries=Retry(10))<N><N>
    Retries can be disabled by passing ``False``::<N><N>        response = http.request('GET', 'http://example.com/', retries=False)<N><N>    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless<N>    retries are disabled, in which case the causing exception will be raised.<N><N>
    :param int total:<N>        Total number of retries to allow. Takes precedence over other counts.<N><N>        Set to ``None`` to remove this constraint and fall back on other<N>        counts.<N><N>        Set to ``0`` to fail on the first retry.<N><N>
        Set to ``False`` to disable and imply ``raise_on_redirect=False``.<N><N>    :param int connect:<N>        How many connection-related errors to retry on.<N><N>        These are errors raised before the request is sent to the remote server,<N>        which we assume has not triggered the server to process the request.<N><N>
        Set to ``0`` to fail on the first retry of this type.<N><N>    :param int read:<N>        How many times to retry on read errors.<N><N>        These errors are raised after the request was sent to the server, so the<N>        request may have side-effects.<N><N>
        Set to ``0`` to fail on the first retry of this type.<N><N>    :param int redirect:<N>        How many redirects to perform. Limit this to avoid infinite redirect<N>        loops.<N><N>        A redirect is a HTTP response with a status code 301, 302, 303, 307 or<N>        308.<N><N>
        Set to ``0`` to fail on the first retry of this type.<N><N>        Set to ``False`` to disable and imply ``raise_on_redirect=False``.<N><N>    :param int status:<N>        How many times to retry on bad status codes.<N><N>        These are retries made on responses, where status code matches<N>        ``status_forcelist``.<N><N>
        Set to ``0`` to fail on the first retry of this type.<N><N>    :param int other:<N>        How many times to retry on other errors.<N><N>        Other errors are errors that are not connect, read, redirect or status errors.<N>        These errors might be raised after the request was sent to the server, so the<N>        request might have side-effects.<N><N>
        Set to ``0`` to fail on the first retry of this type.<N><N>        If ``total`` is not set, it's a good idea to set this to 0 to account<N>        for unexpected edge cases and avoid infinite retry loops.<N><N>    :param iterable allowed_methods:<N>        Set of uppercased HTTP method verbs that we should retry on.<N><N>
        By default, we only retry on methods which are considered to be<N>        idempotent (multiple requests with the same parameters end with the<N>        same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.<N><N>        Set to a ``False`` value to retry on any verb.<N><N>
        .. warning::<N><N>            Previously this parameter was named ``method_whitelist``, that<N>            usage is deprecated in v1.26.0 and will be removed in v2.0.<N><N>    :param iterable status_forcelist:<N>        A set of integer HTTP status codes that we should force a retry on.<N>        A retry is initiated if the request method is in ``allowed_methods``<N>        and the response status code is in ``status_forcelist``.<N><N>
        By default, this is disabled with ``None``.<N><N>    :param float backoff_factor:<N>        A backoff factor to apply between attempts after the second try<N>        (most errors are resolved immediately by a second try without a<N>        delay). urllib3 will sleep for::<N><N>
            {backoff factor} * (2 ** ({number of total retries} - 1))<N><N>        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep<N>        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer<N>        than :attr:`Retry.BACKOFF_MAX`.<N><N>
        By default, backoff is disabled (set to 0).<N><N>    :param bool raise_on_redirect: Whether, if the number of redirects is<N>        exhausted, to raise a MaxRetryError, or to return a response with a<N>        response code in the 3xx range.<N><N>
    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:<N>        whether we should raise an exception, or return a response,<N>        if status falls in ``status_forcelist`` range and retries have<N>        been exhausted.<N><N>    :param tuple history: The history of the request encountered during<N>        each call to :meth:`~Retry.increment`. The list is in the order<N>        the requests occurred. Each list item is of class :class:`RequestHistory`.<N><N>
    :param bool respect_retry_after_header:<N>        Whether to respect Retry-After header on status codes defined as<N>        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.<N><N>    :param iterable remove_headers_on_redirect:<N>        Sequence of headers to remove from the request when a response<N>        indicating a redirect is returned before firing off the redirected<N>        request.<N>    """<N><N>
    #: Default methods to be used for ``allowed_methods``<N>    DEFAULT_ALLOWED_METHODS = frozenset(<N>        ["HEAD", "GET", "PUT", "DELETE", "OPTIONS", "TRACE"]<N>    )<N><N>    #: Default status codes to be used for ``status_forcelist``<N>    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])<N><N>
from __future__ import absolute_import<N><N>import socket<N><N>from pip._vendor.urllib3.exceptions import LocationParseError<N><N>from ..contrib import _appengine_environ<N>from ..packages import six<N>from .wait import NoWayToWaitForSocketError, wait_for_read<N><N>
from __future__ import absolute_import<N><N>import time<N><N># The default socket timeout, used by httplib to indicate that no timeout was<N># specified by the user<N>from socket import _GLOBAL_DEFAULT_TIMEOUT<N><N>from ..exceptions import TimeoutStateError<N><N>
# A sentinel value to indicate that no timeout was specified by the user in<N># urllib3<N>_Default = object()<N><N><N># Use time.monotonic if available.<N>current_time = getattr(time, "monotonic", time.time)<N><N><N>class Timeout(object):<N>    """Timeout configuration.<N><N>
    Timeouts can be defined as a default for a pool:<N><N>    .. code-block:: python<N><N>       timeout = Timeout(connect=2.0, read=7.0)<N>       http = PoolManager(timeout=timeout)<N>       response = http.request('GET', 'http://example.com/')<N><N>    Or per-request (which overrides the default for the pool):<N><N>
    .. code-block:: python<N><N>       response = http.request('GET', 'http://example.com/', timeout=Timeout(10))<N><N>    Timeouts can be disabled by setting all the parameters to ``None``:<N><N>    .. code-block:: python<N><N>       no_timeout = Timeout(connect=None, read=None)<N>       response = http.request('GET', 'http://example.com/, timeout=no_timeout)<N><N>
<N>    :param total:<N>        This combines the connect and read timeouts into one; the read timeout<N>        will be set to the time leftover from the connect attempt. In the<N>        event that both a connect timeout and a total are specified, or a read<N>        timeout and a total are specified, the shorter timeout will be applied.<N><N>
from __future__ import absolute_import<N><N>import hmac<N>import os<N>import sys<N>import warnings<N>from binascii import hexlify, unhexlify<N>from hashlib import md5, sha1, sha256<N><N>from ..exceptions import (<N>    InsecurePlatformWarning,<N>    ProxySchemeUnsupported,<N>    SNIMissingWarning,<N>    SSLError,<N>)<N>from ..packages import six<N>from .url import BRACELESS_IPV6_ADDRZ_RE, IPV4_RE<N><N>
SSLContext = None<N>SSLTransport = None<N>HAS_SNI = False<N>IS_PYOPENSSL = False<N>IS_SECURETRANSPORT = False<N>ALPN_PROTOCOLS = ["http/1.1"]<N><N># Maps the length of a digest to a possible hash function producing this digest<N>HASHFUNC_MAP = {32: md5, 40: sha1, 64: sha256}<N><N>
<N>def _const_compare_digest_backport(a, b):<N>    """<N>    Compare two digests of equal length in constant time.<N><N>    The digests must be of type str/bytes.<N>    Returns True if the digests match, and False otherwise.<N>    """<N>    result = abs(len(a) - len(b))<N>    for left, right in zip(bytearray(a), bytearray(b)):<N>        result |= left ^ right<N>    return result == 0<N><N>
<N>_const_compare_digest = getattr(hmac, "compare_digest", _const_compare_digest_backport)<N><N>try:  # Test for SSL features<N>    import ssl<N>    from ssl import CERT_REQUIRED, wrap_socket<N>except ImportError:<N>    pass<N><N>try:<N>    from ssl import HAS_SNI  # Has SNI?<N>except ImportError:<N>    pass<N><N>
try:<N>    from .ssltransport import SSLTransport<N>except ImportError:<N>    pass<N><N><N>try:  # Platform-specific: Python 3.6<N>    from ssl import PROTOCOL_TLS<N><N>    PROTOCOL_SSLv23 = PROTOCOL_TLS<N>except ImportError:<N>    try:<N>        from ssl import PROTOCOL_SSLv23 as PROTOCOL_TLS<N><N>
        PROTOCOL_SSLv23 = PROTOCOL_TLS<N>    except ImportError:<N>        PROTOCOL_SSLv23 = PROTOCOL_TLS = 2<N><N><N>try:<N>    from ssl import OP_NO_COMPRESSION, OP_NO_SSLv2, OP_NO_SSLv3<N>except ImportError:<N>    OP_NO_SSLv2, OP_NO_SSLv3 = 0x1000000, 0x2000000<N>    OP_NO_COMPRESSION = 0x20000<N><N>
import errno<N>import select<N>import sys<N>from functools import partial<N><N>try:<N>    from time import monotonic<N>except ImportError:<N>    from time import time as monotonic<N><N>__all__ = ["NoWayToWaitForSocketError", "wait_for_read", "wait_for_write"]<N><N>
from __future__ import absolute_import<N><N>from email.errors import MultipartInvariantViolationDefect, StartBoundaryNotFoundDefect<N><N>from ..exceptions import HeaderParsingError<N>from ..packages.six.moves import http_client as httplib<N><N><N>def is_fp_closed(obj):<N>    """<N>    Checks whether a given file-like object is closed.<N><N>
    :param obj:<N>        The file-like object to check.<N>    """<N><N>    try:<N>        # Check `isclosed()` first, in case Python3 doesn't set `closed`.<N>        # GH Issue #928<N>        return obj.isclosed()<N>    except AttributeError:<N>        pass<N><N>
    try:<N>        # Check via the official file-like-object way.<N>        return obj.closed<N>    except AttributeError:<N>        pass<N><N>    try:<N>        # Check if the object is a container for another file-like object that<N>        # gets released on exhaustion (e.g. HTTPResponse).<N>        return obj.fp is None<N>    except AttributeError:<N>        pass<N><N>
    raise ValueError("Unable to determine whether fp is closed.")<N><N><N>def assert_header_parsing(headers):<N>    """<N>    Asserts whether all headers have been successfully parsed.<N>    Extracts encountered errors from the result of parsing headers.<N><N>
    Only works on Python 3.<N><N>    :param http.client.HTTPMessage headers: Headers to verify.<N><N>    :raises urllib3.exceptions.HeaderParsingError:<N>        If parsing errors are found.<N>    """<N><N>    # This will fail silently if we pass in the wrong kind of parameter.<N>    # To make debugging easier add an explicit check.<N>    if not isinstance(headers, httplib.HTTPMessage):<N>        raise TypeError("expected httplib.Message, got {0}.".format(type(headers)))<N><N>
    defects = getattr(headers, "defects", None)<N>    get_payload = getattr(headers, "get_payload", None)<N><N>    unparsed_data = None<N>    if get_payload:<N>        # get_payload is actually email.message.Message.get_payload;<N>        # we're only interested in the result if it's not a multipart message<N>        if not headers.is_multipart():<N>            payload = get_payload()<N><N>
            if isinstance(payload, (bytes, str)):<N>                unparsed_data = payload<N>    if defects:<N>        # httplib is assuming a response body is available<N>        # when parsing headers even when httplib only sends<N>        # header data to parse_headers() This results in<N>        # defects on multipart responses in particular.<N>        # See: https://github.com/urllib3/urllib3/issues/800<N><N>
"""<N>SecureTranport support for urllib3 via ctypes.<N><N>This makes platform-native TLS available to urllib3 users on macOS without the<N>use of a compiler. This is an important feature because the Python Package<N>Index is moving to become a TLSv1.2-or-higher server, and the default OpenSSL<N>that ships with macOS is not capable of doing TLSv1.2. The only way to resolve<N>this is to give macOS users an alternative solution to the problem, and that<N>solution is to use SecureTransport.<N><N>
We use ctypes here because this solution must not require a compiler. That's<N>because pip is not allowed to require a compiler either.<N><N>This is not intended to be a seriously long-term solution to this problem.<N>The hope is that PEP 543 will eventually solve this issue for us, at which<N>point we can retire this contrib module. But in the short term, we need to<N>solve the impending tire fire that is Python on Mac without this kind of<N>contrib module. So...here we are.<N><N>
To use this module, simply import and inject it::<N><N>    import urllib3.contrib.securetransport<N>    urllib3.contrib.securetransport.inject_into_urllib3()<N><N>Happy TLSing!<N><N>This code is a bastardised version of the code found in Will Bond's oscrypto<N>library. An enormous debt is owed to him for blazing this trail for us. For<N>that reason, this code should be considered to be covered both by urllib3's<N>license and by oscrypto's:<N><N>
"""<N>TLS with SNI_-support for Python 2. Follow these instructions if you would<N>like to verify TLS certificates in Python 2. Note, the default libraries do<N>*not* do certificate checking; you need to do additional work to validate<N>certificates yourself.<N><N>
This needs the following packages installed:<N><N>* `pyOpenSSL`_ (tested with 16.0.0)<N>* `cryptography`_ (minimum 1.3.4, from pyopenssl)<N>* `idna`_ (minimum 2.0, from cryptography)<N><N>However, pyopenssl depends on cryptography, which depends on idna, so while we<N>use all three directly here we end up having relatively few packages required.<N><N>
You can install them with the following command:<N><N>.. code-block:: bash<N><N>    $ python -m pip install pyopenssl cryptography idna<N><N>To activate certificate checking, call<N>:func:`~urllib3.contrib.pyopenssl.inject_into_urllib3` from your Python code<N>before you begin making HTTP requests. This can be done in a ``sitecustomize``<N>module, or at any other time before your application begins using ``urllib3``,<N>like this:<N><N>
.. code-block:: python<N><N>    try:<N>        import urllib3.contrib.pyopenssl<N>        urllib3.contrib.pyopenssl.inject_into_urllib3()<N>    except ImportError:<N>        pass<N><N>Now you can use :mod:`urllib3` as you normally would, and it will support SNI<N>when the required modules are installed.<N><N>
Activating this module also has the positive side effect of disabling SSL/TLS<N>compression in Python 2 (see `CRIME attack`_).<N><N>.. _sni: https://en.wikipedia.org/wiki/Server_Name_Indication<N>.. _crime attack: https://en.wikipedia.org/wiki/CRIME_(security_exploit)<N>.. _pyopenssl: https://www.pyopenssl.org<N>.. _cryptography: https://cryptography.io<N>.. _idna: https://github.com/kjd/idna<N>"""<N>from __future__ import absolute_import<N><N>
import OpenSSL.SSL<N>from cryptography import x509<N>from cryptography.hazmat.backends.openssl import backend as openssl_backend<N>from cryptography.hazmat.backends.openssl.x509 import _Certificate<N><N>try:<N>    from cryptography.x509 import UnsupportedExtension<N>except ImportError:<N>    # UnsupportedExtension is gone in cryptography >= 2.1.0<N>    class UnsupportedExtension(Exception):<N>        pass<N><N>
<N>from io import BytesIO<N>from socket import error as SocketError<N>from socket import timeout<N><N>try:  # Platform-specific: Python 2<N>    from socket import _fileobject<N>except ImportError:  # Platform-specific: Python 3<N>    _fileobject = None<N>    from ..packages.backports.makefile import backport_makefile<N><N>
import logging<N>import ssl<N>import sys<N><N>from .. import util<N>from ..packages import six<N><N>__all__ = ["inject_into_urllib3", "extract_from_urllib3"]<N><N># SNI always works.<N>HAS_SNI = True<N><N># Map from urllib3 to PyOpenSSL compatible parameter-values.<N>_openssl_versions = {<N>    util.PROTOCOL_TLS: OpenSSL.SSL.SSLv23_METHOD,<N>    ssl.PROTOCOL_TLSv1: OpenSSL.SSL.TLSv1_METHOD,<N>}<N><N>
if hasattr(ssl, "PROTOCOL_SSLv3") and hasattr(OpenSSL.SSL, "SSLv3_METHOD"):<N>    _openssl_versions[ssl.PROTOCOL_SSLv3] = OpenSSL.SSL.SSLv3_METHOD<N><N>if hasattr(ssl, "PROTOCOL_TLSv1_1") and hasattr(OpenSSL.SSL, "TLSv1_1_METHOD"):<N>    _openssl_versions[ssl.PROTOCOL_TLSv1_1] = OpenSSL.SSL.TLSv1_1_METHOD<N><N>
if hasattr(ssl, "PROTOCOL_TLSv1_2") and hasattr(OpenSSL.SSL, "TLSv1_2_METHOD"):<N>    _openssl_versions[ssl.PROTOCOL_TLSv1_2] = OpenSSL.SSL.TLSv1_2_METHOD<N><N><N>_stdlib_to_openssl_verify = {<N>    ssl.CERT_NONE: OpenSSL.SSL.VERIFY_NONE,<N>    ssl.CERT_OPTIONAL: OpenSSL.SSL.VERIFY_PEER,<N>    ssl.CERT_REQUIRED: OpenSSL.SSL.VERIFY_PEER<N>    + OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT,<N>}<N>_openssl_to_stdlib_verify = dict((v, k) for k, v in _stdlib_to_openssl_verify.items())<N><N>
# OpenSSL will only write 16K at a time<N>SSL_WRITE_BLOCKSIZE = 16384<N><N>orig_util_HAS_SNI = util.HAS_SNI<N>orig_util_SSLContext = util.ssl_.SSLContext<N><N><N>log = logging.getLogger(__name__)<N><N><N>def inject_into_urllib3():<N>    "Monkey-patch urllib3 with PyOpenSSL-backed SSL-support."<N><N>
    _validate_dependencies_met()<N><N>    util.SSLContext = PyOpenSSLContext<N>    util.ssl_.SSLContext = PyOpenSSLContext<N>    util.HAS_SNI = HAS_SNI<N>    util.ssl_.HAS_SNI = HAS_SNI<N>    util.IS_PYOPENSSL = True<N>    util.ssl_.IS_PYOPENSSL = True<N><N>
<N>def extract_from_urllib3():<N>    "Undo monkey-patching by :func:`inject_into_urllib3`."<N><N>    util.SSLContext = orig_util_SSLContext<N>    util.ssl_.SSLContext = orig_util_SSLContext<N>    util.HAS_SNI = orig_util_HAS_SNI<N>    util.ssl_.HAS_SNI = orig_util_HAS_SNI<N>    util.IS_PYOPENSSL = False<N>    util.ssl_.IS_PYOPENSSL = False<N><N>
<N>def _validate_dependencies_met():<N>    """<N>    Verifies that PyOpenSSL's package-level dependencies have been met.<N>    Throws `ImportError` if they are not met.<N>    """<N>    # Method added in `cryptography==1.1`; not available in older versions<N>    from cryptography.x509.extensions import Extensions<N><N>
    if getattr(Extensions, "get_extension_for_class", None) is None:<N>        raise ImportError(<N>            "'cryptography' module missing required functionality.  "<N>            "Try upgrading to v1.3.4 or newer."<N>        )<N><N>    # pyOpenSSL 0.14 and above use cryptography for OpenSSL bindings. The _x509<N>    # attribute is only present on those versions.<N>    from OpenSSL.crypto import X509<N><N>
    x509 = X509()<N>    if getattr(x509, "_x509", None) is None:<N>        raise ImportError(<N>            "'pyOpenSSL' module missing required functionality. "<N>            "Try upgrading to v0.14 or newer."<N>        )<N><N><N>def _dnsname_to_stdlib(name):<N>    """<N>    Converts a dNSName SubjectAlternativeName field to the form used by the<N>    standard library on the given Python version.<N><N>
    Cryptography produces a dNSName as a unicode string that was idna-decoded<N>    from ASCII bytes. We need to idna-encode that string to get it back, and<N>    then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib<N>    uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).<N><N>
    If the name cannot be idna-encoded then we return None signalling that<N>    the name given should be skipped.<N>    """<N><N>    def idna_encode(name):<N>        """<N>        Borrowed wholesale from the Python Cryptography Project. It turns out<N>        that we can't just safely call `idna.encode`: it can explode for<N>        wildcard names. This avoids that problem.<N>        """<N>        from pip._vendor import idna<N><N>
        try:<N>            for prefix in [u"*.", u"."]:<N>                if name.startswith(prefix):<N>                    name = name[len(prefix) :]<N>                    return prefix.encode("ascii") + idna.encode(name)<N>            return idna.encode(name)<N>        except idna.core.IDNAError:<N>            return None<N><N>
    # Don't send IPv6 addresses through the IDNA encoder.<N>    if ":" in name:<N>        return name<N><N>    name = idna_encode(name)<N>    if name is None:<N>        return None<N>    elif sys.version_info >= (3, 0):<N>        name = name.decode("utf-8")<N>    return name<N><N>
"""<N>NTLM authenticating pool, contributed by erikcederstran<N><N>Issue #10, see: http://code.google.com/p/urllib3/issues/detail?id=10<N>"""<N>from __future__ import absolute_import<N><N>from logging import getLogger<N><N>from ntlm import ntlm<N><N>from .. import HTTPSConnectionPool<N>from ..packages.six.moves.http_client import HTTPSConnection<N><N>
"""<N>This module provides means to detect the App Engine environment.<N>"""<N><N>import os<N><N><N>def is_appengine():<N>    return is_local_appengine() or is_prod_appengine()<N><N><N>def is_appengine_sandbox():<N>    """Reports if the app is running in the first generation sandbox.<N><N>
    The second generation runtimes are technically still in a sandbox, but it<N>    is much less restrictive, so generally you shouldn't need to check for it.<N>    see https://cloud.google.com/appengine/docs/standard/runtimes<N>    """<N>    return is_appengine() and os.environ["APPENGINE_RUNTIME"] == "python27"<N><N>
<N>def is_local_appengine():<N>    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(<N>        "SERVER_SOFTWARE", ""<N>    ).startswith("Development/")<N><N><N>def is_prod_appengine():<N>    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(<N>        "SERVER_SOFTWARE", ""<N>    ).startswith("Google App Engine/")<N><N>
"""<N>This module provides a pool manager that uses Google App Engine's<N>`URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.<N><N>Example usage::<N><N>    from pip._vendor.urllib3 import PoolManager<N>    from pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox<N><N>
    if is_appengine_sandbox():<N>        # AppEngineManager uses AppEngine's URLFetch API behind the scenes<N>        http = AppEngineManager()<N>    else:<N>        # PoolManager uses a socket-level API behind the scenes<N>        http = PoolManager()<N><N>
    r = http.request('GET', 'https://google.com/')<N><N>There are `limitations <https://cloud.google.com/appengine/docs/python/\<N>urlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be<N>the best choice for your application. There are three options for using<N>urllib3 on Google App Engine:<N><N>
# -*- coding: utf-8 -*-<N>"""<N>This module contains provisional support for SOCKS proxies from within<N>urllib3. This module supports SOCKS4, SOCKS4A (an extension of SOCKS4), and<N>SOCKS5. To enable its functionality, either install PySocks or install this<N>module with the ``socks`` extra.<N><N>
The SOCKS implementation supports the full range of urllib3 features. It also<N>supports the following SOCKS features:<N><N>- SOCKS4A (``proxy_url='socks4a://...``)<N>- SOCKS4 (``proxy_url='socks4://...``)<N>- SOCKS5 with remote DNS (``proxy_url='socks5h://...``)<N>- SOCKS5 with local DNS (``proxy_url='socks5://...``)<N>- Usernames and passwords for the SOCKS proxy<N><N>
.. note::<N>   It is recommended to use ``socks5h://`` or ``socks4a://`` schemes in<N>   your ``proxy_url`` to ensure that DNS resolution is done from the remote<N>   server instead of client-side when connecting to a domain name.<N><N>SOCKS4 supports IPv4 and domain names with the SOCKS4A extension. SOCKS5<N>supports IPv4, IPv6, and domain names.<N><N>
When connecting to a SOCKS4 proxy the ``username`` portion of the ``proxy_url``<N>will be sent as the ``userid`` section of the SOCKS request:<N><N>.. code-block:: python<N><N>    proxy_url="socks4a://<userid>@proxy-host"<N><N>When connecting to a SOCKS5 proxy the ``username`` and ``password`` portion<N>of the ``proxy_url`` will be sent as the username/password to authenticate<N>with the proxy:<N><N>
.. code-block:: python<N><N>    proxy_url="socks5h://<username>:<password>@proxy-host"<N><N>"""<N>from __future__ import absolute_import<N><N>try:<N>    import socks<N>except ImportError:<N>    import warnings<N><N>    from ..exceptions import DependencyWarning<N><N>
    warnings.warn(<N>        (<N>            "SOCKS support in urllib3 requires the installation of optional "<N>            "dependencies: specifically, PySocks.  For more information, see "<N>            "https://urllib3.readthedocs.io/en/latest/contrib.html#socks-proxies"<N>        ),<N>        DependencyWarning,<N>    )<N>    raise<N><N>
from socket import error as SocketError<N>from socket import timeout as SocketTimeout<N><N>from ..connection import HTTPConnection, HTTPSConnection<N>from ..connectionpool import HTTPConnectionPool, HTTPSConnectionPool<N>from ..exceptions import ConnectTimeoutError, NewConnectionError<N>from ..poolmanager import PoolManager<N>from ..util.url import parse_url<N><N>
try:<N>    import ssl<N>except ImportError:<N>    ssl = None<N><N><N>class SOCKSConnection(HTTPConnection):<N>    """<N>    A plain-text HTTP connection that connects via a SOCKS proxy.<N>    """<N><N>    def __init__(self, *args, **kwargs):<N>        self._socks_options = kwargs.pop("_socks_options")<N>        super(SOCKSConnection, self).__init__(*args, **kwargs)<N><N>
    def _new_conn(self):<N>        """<N>        Establish a new connection via the SOCKS proxy.<N>        """<N>        extra_kw = {}<N>        if self.source_address:<N>            extra_kw["source_address"] = self.source_address<N><N>        if self.socket_options:<N>            extra_kw["socket_options"] = self.socket_options<N><N>
"""<N>This module uses ctypes to bind a whole bunch of functions and constants from<N>SecureTransport. The goal here is to provide the low-level API to<N>SecureTransport. These are essentially the C-level functions and constants, and<N>they're pretty gross to work with.<N><N>
This code is a bastardised version of the code found in Will Bond's oscrypto<N>library. An enormous debt is owed to him for blazing this trail for us. For<N>that reason, this code should be considered to be covered both by urllib3's<N>license and by oscrypto's:<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2013-2017 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>from __future__ import absolute_import<N><N>import os<N>import re<N>import sys<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2019 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>import logging<N><N>__version__ = '0.3.1'<N><N>class DistlibException(Exception):<N>    pass<N><N>
try:<N>    from logging import NullHandler<N>except ImportError: # pragma: no cover<N>    class NullHandler(logging.Handler):<N>        def handle(self, record): pass<N>        def emit(self, record): pass<N>        def createLock(self): self.lock = None<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2013 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>import hashlib<N>import logging<N>import os<N>import shutil<N>import subprocess<N>import tempfile<N>try:<N>    from threading import Thread<N>except ImportError:<N>    from dummy_threading import Thread<N><N>
from . import DistlibException<N>from .compat import (HTTPBasicAuthHandler, Request, HTTPPasswordMgr,<N>                     urlparse, build_opener, string_types)<N>from .util import cached_property, zip_dir, ServerProxy<N><N>logger = logging.getLogger(__name__)<N><N>
DEFAULT_INDEX = 'https://pypi.org/pypi'<N>DEFAULT_REALM = 'pypi'<N><N>class PackageIndex(object):<N>    """<N>    This class represents a package index compatible with PyPI, the Python<N>    Package Index.<N>    """<N><N>    boundary = b'----------ThIs_Is_tHe_distlib_index_bouNdaRY_$'<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""Implementation of the Metadata for Python packages PEPs.<N><N>Supports all metadata formats (1.0, 1.1, 1.2, 1.3/2.1 and withdrawn 2.0).<N>"""<N>from __future__ import unicode_literals<N><N>
import codecs<N>from email import message_from_file<N>import json<N>import logging<N>import re<N><N><N>from . import DistlibException, __version__<N>from .compat import StringIO, string_types, text_type<N>from .markers import interpret<N>from .util import extract_by_key, get_extras<N>from .version import get_scheme, PEP440_VERSION_RE<N><N>
logger = logging.getLogger(__name__)<N><N><N>class MetadataMissingError(DistlibException):<N>    """A required metadata is missing"""<N><N><N>class MetadataConflictError(DistlibException):<N>    """Attempt to read or write metadata fields that are conflictual."""<N><N>
<N>class MetadataUnrecognizedVersionError(DistlibException):<N>    """Unknown metadata version number."""<N><N><N>class MetadataInvalidError(DistlibException):<N>    """A metadata value is invalid"""<N><N># public API of this module<N>__all__ = ['Metadata', 'PKG_INFO_ENCODING', 'PKG_INFO_PREFERRED_VERSION']<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2013-2015 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>from io import BytesIO<N>import logging<N>import os<N>import re<N>import struct<N>import sys<N><N>
from .compat import sysconfig, detect_encoding, ZipFile<N>from .resources import finder<N>from .util import (FileOperator, get_export_entry, convert_path,<N>                   get_executable, in_venv)<N><N>logger = logging.getLogger(__name__)<N><N>_DEFAULT_MANIFEST = '''<N><?xml version="1.0" encoding="UTF-8" standalone="yes"?><N><assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0"><N> <assemblyIdentity version="1.0.0.0"<N> processorArchitecture="X86"<N> name="%s"<N> type="win32"/><N><N>
 <!-- Identify the application security requirements. --><N> <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3"><N> <security><N> <requestedPrivileges><N> <requestedExecutionLevel level="asInvoker" uiAccess="false"/><N> </requestedPrivileges><N> </security><N> </trustInfo><N></assembly>'''.strip()<N><N>
# check if Python is called on the first line with this expression<N>FIRST_LINE_RE = re.compile(b'^#!.*pythonw?[0-9.]*([ \t].*)?$')<N>SCRIPT_TEMPLATE = r'''# -*- coding: utf-8 -*-<N>import re<N>import sys<N>from %(module)s import %(import_name)s<N>if __name__ == '__main__':<N>    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])<N>    sys.exit(%(func)s())<N>'''<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2017 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""<N>Implementation of a flexible versioning scheme providing support for PEP-440,<N>setuptools-compatible and semantic versioning.<N>"""<N><N>
import logging<N>import re<N><N>from .compat import string_types<N>from .util import parse_requirement<N><N>__all__ = ['NormalizedVersion', 'NormalizedMatcher',<N>           'LegacyVersion', 'LegacyMatcher',<N>           'SemanticVersion', 'SemanticMatcher',<N>           'UnsupportedVersionError', 'get_scheme']<N><N>
logger = logging.getLogger(__name__)<N><N><N>class UnsupportedVersionError(ValueError):<N>    """This is an unsupported version."""<N>    pass<N><N><N>class Version(object):<N>    def __init__(self, s):<N>        self._string = s = s.strip()<N>        self._parts = parts = self.parse(s)<N>        assert isinstance(parts, tuple)<N>        assert len(parts) > 0<N><N>
    def parse(self, s):<N>        raise NotImplementedError('please implement in a subclass')<N><N>    def _check_compatible(self, other):<N>        if type(self) != type(other):<N>            raise TypeError('cannot compare %r and %r' % (self, other))<N><N>
    def __eq__(self, other):<N>        self._check_compatible(other)<N>        return self._parts == other._parts<N><N>    def __ne__(self, other):<N>        return not self.__eq__(other)<N><N>    def __lt__(self, other):<N>        self._check_compatible(other)<N>        return self._parts < other._parts<N><N>
    def __gt__(self, other):<N>        return not (self.__lt__(other) or self.__eq__(other))<N><N>    def __le__(self, other):<N>        return self.__lt__(other) or self.__eq__(other)<N><N>    def __ge__(self, other):<N>        return self.__gt__(other) or self.__eq__(other)<N><N>
    # See http://docs.python.org/reference/datamodel#object.__hash__<N>    def __hash__(self):<N>        return hash(self._parts)<N><N>    def __repr__(self):<N>        return "%s('%s')" % (self.__class__.__name__, self._string)<N><N>    def __str__(self):<N>        return self._string<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2017 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""<N>Parser for the environment markers micro-language defined in PEP 508.<N>"""<N><N>
# Note: In PEP 345, the micro-language was Python compatible, so the ast<N># module could be used to parse it. However, PEP 508 introduced operators such<N># as ~= and === which aren't in Python, necessitating a different approach.<N><N>import os<N>import sys<N>import platform<N>import re<N><N>
from .compat import python_implementation, urlparse, string_types<N>from .util import in_venv, parse_marker<N><N>__all__ = ['interpret']<N><N>def _is_literal(o):<N>    if not isinstance(o, string_types) or not o:<N>        return False<N>    return o[0] in '\'"'<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2017 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""PEP 376 implementation."""<N><N>from __future__ import unicode_literals<N><N>import base64<N>import codecs<N>import contextlib<N>import hashlib<N>import logging<N>import os<N>import posixpath<N>import sys<N>import zipimport<N><N>
from . import DistlibException, resources<N>from .compat import StringIO<N>from .version import get_scheme, UnsupportedVersionError<N>from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,<N>                       LEGACY_METADATA_FILENAME)<N>from .util import (parse_requirement, cached_property, parse_name_and_version,<N>                   read_exports, write_exports, CSVReader, CSVWriter)<N><N>
<N>__all__ = ['Distribution', 'BaseInstalledDistribution',<N>           'InstalledDistribution', 'EggInfoDistribution',<N>           'DistributionPath']<N><N><N>logger = logging.getLogger(__name__)<N><N>EXPORTS_FILENAME = 'pydist-exports.json'<N>COMMANDS_FILENAME = 'pydist-commands.json'<N><N>
DIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED',<N>              'RESOURCES', EXPORTS_FILENAME, 'SHARED')<N><N>DISTINFO_EXT = '.dist-info'<N><N><N>class _Cache(object):<N>    """<N>    A simple cache mapping names and .dist-info paths to distributions<N>    """<N>    def __init__(self):<N>        """<N>        Initialise an instance. There is normally one for each DistributionPath.<N>        """<N>        self.name = {}<N>        self.path = {}<N>        self.generated = False<N><N>
    def clear(self):<N>        """<N>        Clear the cache, setting it to its initial state.<N>        """<N>        self.name.clear()<N>        self.path.clear()<N>        self.generated = False<N><N>    def add(self, dist):<N>        """<N>        Add a distribution to the cache.<N>        :param dist: The distribution to add.<N>        """<N>        if dist.path not in self.path:<N>            self.path[dist.path] = dist<N>            self.name.setdefault(dist.key, []).append(dist)<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2015 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N><N>import gzip<N>from io import BytesIO<N>import json<N>import logging<N>import os<N>import posixpath<N>import re<N>try:<N>    import threading<N>except ImportError:  # pragma: no cover<N>    import dummy_threading as threading<N>import zlib<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012-2013 Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""<N>Class representing the list of files in a distribution.<N><N>Equivalent to distutils.filelist, but fixes some problems.<N>"""<N>import fnmatch<N>import logging<N>import os<N>import re<N>import sys<N><N>
from . import DistlibException<N>from .compat import fsdecode<N>from .util import convert_path<N><N><N>__all__ = ['Manifest']<N><N>logger = logging.getLogger(__name__)<N><N># a \ followed by some spaces + EOL<N>_COLLAPSE_PATTERN = re.compile('\\\\w*\n', re.M)<N>_COMMENTED_LINE = re.compile('#.*?(?=\n)|\n(?=$)', re.M | re.S)<N><N>
#<N># Due to the different results returned by fnmatch.translate, we need<N># to do slightly different processing for Python 2.7 and 3.2 ... this needed<N># to be brought in for Python 3.6 onwards.<N>#<N>_PYTHON_VERSION = sys.version_info[:2]<N><N>class Manifest(object):<N>    """A list of files built by on exploring the filesystem and filtered by<N>    applying various patterns to what we find there.<N>    """<N><N>
    def __init__(self, base=None):<N>        """<N>        Initialise an instance.<N><N>        :param base: The base directory to explore under.<N>        """<N>        self.base = os.path.abspath(os.path.normpath(base or os.getcwd()))<N>        self.prefix = self.base + os.sep<N>        self.allfiles = None<N>        self.files = set()<N><N>
    #<N>    # Public API<N>    #<N><N>    def findall(self):<N>        """Find all files under the base and set ``allfiles`` to the absolute<N>        pathnames of files found.<N>        """<N>        from stat import S_ISREG, S_ISDIR, S_ISLNK<N><N>        self.allfiles = allfiles = []<N>        root = self.base<N>        stack = [root]<N>        pop = stack.pop<N>        push = stack.append<N><N>
#<N># Copyright (C) 2012-2017 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>import codecs<N>from collections import deque<N>import contextlib<N>import csv<N>from glob import iglob as std_iglob<N>import io<N>import json<N>import logging<N>import os<N>import py_compile<N>import re<N>import socket<N>try:<N>    import ssl<N>except ImportError:  # pragma: no cover<N>    ssl = None<N>import subprocess<N>import sys<N>import tarfile<N>import tempfile<N>import textwrap<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2013-2017 Vinay Sajip.<N># Licensed to the Python Software Foundation under a contributor agreement.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>from __future__ import unicode_literals<N><N>import bisect<N>import io<N>import logging<N>import os<N>import pkgutil<N>import shutil<N>import sys<N>import types<N>import zipimport<N><N>
from . import DistlibException<N>from .util import cached_property, get_cache_base, path_to_cache_dir, Cache<N><N>logger = logging.getLogger(__name__)<N><N><N>cache = None    # created when needed<N><N><N>class ResourceCache(Cache):<N>    def __init__(self, base=None):<N>        if base is None:<N>            # Use native string to avoid issues on 2.x: see Python #20140.<N>            base = os.path.join(get_cache_base(), str('resource-cache'))<N>        super(ResourceCache, self).__init__(base)<N><N>
    def is_stale(self, resource, path):<N>        """<N>        Is the cache stale for the given resource?<N><N>        :param resource: The :class:`Resource` being cached.<N>        :param path: The path of the resource in the cache.<N>        :return: True if the cache is stale.<N>        """<N>        # Cache invalidation is a hard problem :-)<N>        return True<N><N>
"""Modules copied from Python 3 standard libraries, for internal use only.<N><N>Individual classes and functions are found in d2._backport.misc.  Intended<N>usage is to always import things missing from 3.1 from that module: the<N>built-in/stdlib objects will be used if found.<N>"""<N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""Access to Python's configuration information."""<N><N>import codecs<N>import os<N>import re<N>import sys<N>from os.path import pardir, realpath<N>try:<N>    import configparser<N>except ImportError:<N>    import ConfigParser as configparser<N><N>
<N>__all__ = [<N>    'get_config_h_filename',<N>    'get_config_var',<N>    'get_config_vars',<N>    'get_makefile_filename',<N>    'get_path',<N>    'get_path_names',<N>    'get_paths',<N>    'get_platform',<N>    'get_python_version',<N>    'get_scheme_names',<N>    'parse_config_h',<N>]<N><N>
<N>def _safe_realpath(path):<N>    try:<N>        return realpath(path)<N>    except OSError:<N>        return path<N><N><N>if sys.executable:<N>    _PROJECT_BASE = os.path.dirname(_safe_realpath(sys.executable))<N>else:<N>    # sys.executable can be empty if argv[0] has been changed and Python is<N>    # unable to retrieve the real program name<N>    _PROJECT_BASE = _safe_realpath(os.getcwd())<N><N>
if os.name == "nt" and "pcbuild" in _PROJECT_BASE[-8:].lower():<N>    _PROJECT_BASE = _safe_realpath(os.path.join(_PROJECT_BASE, pardir))<N># PC/VS7.1<N>if os.name == "nt" and "\\pc\\v" in _PROJECT_BASE[-10:].lower():<N>    _PROJECT_BASE = _safe_realpath(os.path.join(_PROJECT_BASE, pardir, pardir))<N># PC/AMD64<N>if os.name == "nt" and "\\pcbuild\\amd64" in _PROJECT_BASE[-14:].lower():<N>    _PROJECT_BASE = _safe_realpath(os.path.join(_PROJECT_BASE, pardir, pardir))<N><N>
<N>def is_python_build():<N>    for fn in ("Setup.dist", "Setup.local"):<N>        if os.path.isfile(os.path.join(_PROJECT_BASE, "Modules", fn)):<N>            return True<N>    return False<N><N>_PYTHON_BUILD = is_python_build()<N><N>_cfg_read = False<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""Utility functions for copying and archiving files and directory trees.<N><N>XXX The functions here don't copy the resource fork or other metadata on Mac.<N><N>
"""<N><N>import os<N>import sys<N>import stat<N>from os.path import abspath<N>import fnmatch<N>try:<N>    from collections.abc import Callable<N>except ImportError:<N>    from collections import Callable<N>import errno<N>from . import tarfile<N><N>try:<N>    import bz2<N>    _BZ2_SUPPORTED = True<N>except ImportError:<N>    _BZ2_SUPPORTED = False<N><N>
# -*- coding: utf-8 -*-<N>#<N># Copyright (C) 2012 The Python Software Foundation.<N># See LICENSE.txt and CONTRIBUTORS.txt.<N>#<N>"""Backports for individual classes and functions."""<N><N>import os<N>import sys<N><N>__all__ = ['cache_from_source', 'callable', 'fsencode']<N><N>
<N>try:<N>    from imp import cache_from_source<N>except ImportError:<N>    def cache_from_source(py_file, debug=__debug__):<N>        ext = debug and 'c' or 'o'<N>        return py_file + ext<N><N><N>try:<N>    callable = callable<N>except NameError:<N>    from collections import Callable<N><N>
    def callable(obj):<N>        return isinstance(obj, Callable)<N><N><N>try:<N>    fsencode = os.fsencode<N>except AttributeError:<N>    def fsencode(filename):<N>        if isinstance(filename, bytes):<N>            return filename<N>        elif isinstance(filename, str):<N>            return filename.encode(sys.getfilesystemencoding())<N>        else:<N>            raise TypeError("expect bytes or str, not %s" %<N>                            type(filename).__name__)<N><N><N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N>from . import win32<N><N><N># from wincon.h<N>class WinColor(object):<N>    BLACK   = 0<N>    BLUE    = 1<N>    GREEN   = 2<N>    CYAN    = 3<N>    RED     = 4<N>    MAGENTA = 5<N>    YELLOW  = 6<N>    GREY    = 7<N><N>
# from wincon.h<N>class WinStyle(object):<N>    NORMAL              = 0x00 # dim text, dim background<N>    BRIGHT              = 0x08 # bright text, dim background<N>    BRIGHT_BACKGROUND   = 0x80 # dim text, bright background<N><N>class WinTerm(object):<N><N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N><N># from winbase.h<N>STDOUT = -11<N>STDERR = -12<N><N>try:<N>    import ctypes<N>    from ctypes import LibraryLoader<N>    windll = LibraryLoader(ctypes.WinDLL)<N>    from ctypes import wintypes<N>except (AttributeError, ImportError):<N>    windll = None<N>    SetConsoleTextAttribute = lambda *_: None<N>    winapi_test = lambda *_: None<N>else:<N>    from ctypes import byref, Structure, c_char, POINTER<N><N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N>from .initialise import init, deinit, reinit, colorama_text<N>from .ansi import Fore, Back, Style, Cursor<N>from .ansitowin32 import AnsiToWin32<N><N>__version__ = '0.4.4'<N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N>import atexit<N>import contextlib<N>import sys<N><N>from .ansitowin32 import AnsiToWin32<N><N><N>orig_stdout = None<N>orig_stderr = None<N><N>wrapped_stdout = None<N>wrapped_stderr = None<N><N>
atexit_done = False<N><N><N>def reset_all():<N>    if AnsiToWin32 is not None:    # Issue #74: objects might become None at exit<N>        AnsiToWin32(orig_stdout).reset_all()<N><N><N>def init(autoreset=False, convert=None, strip=None, wrap=True):<N><N>    if not wrap and any([autoreset, convert, strip]):<N>        raise ValueError('wrap=False conflicts with any other arg=True')<N><N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N>'''<N>This module generates ANSI character codes to printing colors to terminals.<N>See: http://en.wikipedia.org/wiki/ANSI_escape_code<N>'''<N><N>CSI = '\033['<N>OSC = '\033]'<N>BEL = '\a'<N><N>
<N>def code_to_chars(code):<N>    return CSI + str(code) + 'm'<N><N>def set_title(title):<N>    return OSC + '2;' + title + BEL<N><N>def clear_screen(mode=2):<N>    return CSI + str(mode) + 'J'<N><N>def clear_line(mode=2):<N>    return CSI + str(mode) + 'K'<N><N>
<N>class AnsiCodes(object):<N>    def __init__(self):<N>        # the subclasses declare class attributes which are numbers.<N>        # Upon instantiation we define instance attributes, which are the same<N>        # as the class attributes but wrapped with the ANSI escape sequence<N>        for name in dir(self):<N>            if not name.startswith('_'):<N>                value = getattr(self, name)<N>                setattr(self, name, code_to_chars(value))<N><N>
<N>class AnsiCursor(object):<N>    def UP(self, n=1):<N>        return CSI + str(n) + 'A'<N>    def DOWN(self, n=1):<N>        return CSI + str(n) + 'B'<N>    def FORWARD(self, n=1):<N>        return CSI + str(n) + 'C'<N>    def BACK(self, n=1):<N>        return CSI + str(n) + 'D'<N>    def POS(self, x=1, y=1):<N>        return CSI + str(y) + ';' + str(x) + 'H'<N><N>
<N>class AnsiFore(AnsiCodes):<N>    BLACK           = 30<N>    RED             = 31<N>    GREEN           = 32<N>    YELLOW          = 33<N>    BLUE            = 34<N>    MAGENTA         = 35<N>    CYAN            = 36<N>    WHITE           = 37<N>    RESET           = 39<N><N>
    # These are fairly well supported, but not part of the standard.<N>    LIGHTBLACK_EX   = 90<N>    LIGHTRED_EX     = 91<N>    LIGHTGREEN_EX   = 92<N>    LIGHTYELLOW_EX  = 93<N>    LIGHTBLUE_EX    = 94<N>    LIGHTMAGENTA_EX = 95<N>    LIGHTCYAN_EX    = 96<N>    LIGHTWHITE_EX   = 97<N><N>
<N>class AnsiBack(AnsiCodes):<N>    BLACK           = 40<N>    RED             = 41<N>    GREEN           = 42<N>    YELLOW          = 43<N>    BLUE            = 44<N>    MAGENTA         = 45<N>    CYAN            = 46<N>    WHITE           = 47<N>    RESET           = 49<N><N>
    # These are fairly well supported, but not part of the standard.<N>    LIGHTBLACK_EX   = 100<N>    LIGHTRED_EX     = 101<N>    LIGHTGREEN_EX   = 102<N>    LIGHTYELLOW_EX  = 103<N>    LIGHTBLUE_EX    = 104<N>    LIGHTMAGENTA_EX = 105<N>    LIGHTCYAN_EX    = 106<N>    LIGHTWHITE_EX   = 107<N><N>
# Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.<N>import re<N>import sys<N>import os<N><N>from .ansi import AnsiFore, AnsiBack, AnsiStyle, Style, BEL<N>from .winterm import WinTerm, WinColor, WinStyle<N>from .win32 import windll, winapi_test<N><N>
"""<N>HTML parsing library based on the `WHATWG HTML specification<N><https://whatwg.org/html>`_. The parser is designed to be compatible with<N>existing HTML found in the wild and implements well-defined error recovery that<N>is largely compatible with modern desktop web browsers.<N><N>
Example usage::<N><N>    from pip._vendor import html5lib<N>    with open("my_document.html", "rb") as f:<N>        tree = html5lib.parse(f)<N><N>For convenience, this module re-exports the following names:<N><N>* :func:`~.html5parser.parse`<N>* :func:`~.html5parser.parseFragment`<N>* :class:`~.html5parser.HTMLParser`<N>* :func:`~.treebuilders.getTreeBuilder`<N>* :func:`~.treewalkers.getTreeWalker`<N>* :func:`~.serializer.serialize`<N>"""<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from .html5parser import HTMLParser, parse, parseFragment<N>from .treebuilders import getTreeBuilder<N>from .treewalkers import getTreeWalker<N>from .serializer import serialize<N><N>__all__ = ["HTMLParser", "parse", "parseFragment", "getTreeBuilder",<N>           "getTreeWalker", "serialize"]<N><N>
from __future__ import absolute_import, division, unicode_literals<N>from pip._vendor.six import text_type<N><N>import re<N><N>from codecs import register_error, xmlcharrefreplace_errors<N><N>from .constants import voidElements, booleanAttributes, spaceCharacters<N>from .constants import rcdataElements, entities, xmlEntities<N>from . import treewalkers, _utils<N>from xml.sax.saxutils import escape<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from pip._vendor.six import unichr as chr<N><N>from collections import deque, OrderedDict<N>from sys import version_info<N><N>from .constants import spaceCharacters<N>from .constants import entities<N>from .constants import asciiLetters, asciiUpper2Lower<N>from .constants import digits, hexDigits, EOF<N>from .constants import tokenTypes, tagTokenTypes<N>from .constants import replacementCharacters<N><N>
from ._inputstream import HTMLInputStream<N><N>from ._trie import Trie<N><N>entitiesTrie = Trie(entities)<N><N>if version_info >= (3, 7):<N>    attributeMap = dict<N>else:<N>    attributeMap = OrderedDict<N><N><N>class HTMLTokenizer(object):<N>    """ This class takes care of tokenizing HTML.<N><N>
    * self.currentToken<N>      Holds the token that is currently being processed.<N><N>    * self.state<N>      Holds a reference to the method to be invoked... XXX<N><N>    * self.stream<N>      Points to HTMLInputStream object.<N>    """<N><N>    def __init__(self, stream, parser=None, **kwargs):<N><N>
        self.stream = HTMLInputStream(stream, **kwargs)<N>        self.parser = parser<N><N>        # Setup the initial tokenizer state<N>        self.escapeFlag = False<N>        self.lastFourChars = []<N>        self.state = self.dataState<N>        self.escape = False<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from types import ModuleType<N><N>try:<N>    from collections.abc import Mapping<N>except ImportError:<N>    from collections import Mapping<N><N>from pip._vendor.six import text_type, PY3<N><N>
if PY3:<N>    import xml.etree.ElementTree as default_etree<N>else:<N>    try:<N>        import xml.etree.cElementTree as default_etree<N>    except ImportError:<N>        import xml.etree.ElementTree as default_etree<N><N><N>__all__ = ["default_etree", "MethodDispatcher", "isSurrogatePair",<N>           "surrogatePairToCodepoint", "moduleFactoryFactory",<N>           "supports_lone_surrogates"]<N><N>
from __future__ import absolute_import, division, unicode_literals<N>from pip._vendor.six import with_metaclass, viewkeys<N><N>import types<N><N>from . import _inputstream<N>from . import _tokenizer<N><N>from . import treebuilders<N>from .treebuilders.base import Marker<N><N>
from . import _utils<N>from .constants import (<N>    spaceCharacters, asciiUpper2Lower,<N>    specialElements, headingElements, cdataElements, rcdataElements,<N>    tokenTypes, tagTokenTypes,<N>    namespaces,<N>    htmlIntegrationPointElements, mathmlTextIntegrationPointElements,<N>    adjustForeignAttributes as adjustForeignAttributesMap,<N>    adjustMathMLAttributes, adjustSVGAttributes,<N>    E,<N>    _ReparseException<N>)<N><N>
<N>def parse(doc, treebuilder="etree", namespaceHTMLElements=True, **kwargs):<N>    """Parse an HTML document as a string or file-like object into a tree<N><N>    :arg doc: the document to parse as a string or file-like object<N><N>    :arg treebuilder: the treebuilder to use when parsing<N><N>
    :arg namespaceHTMLElements: whether or not to namespace HTML elements<N><N>    :returns: parsed tree<N><N>    Example:<N><N>    >>> from html5lib.html5parser import parse<N>    >>> parse('<html><body><p>This is a doc</p></body></html>')<N>    <Element u'{http://www.w3.org/1999/xhtml}html' at 0x7feac4909db0><N><N>
    """<N>    tb = treebuilders.getTreeBuilder(treebuilder)<N>    p = HTMLParser(tb, namespaceHTMLElements=namespaceHTMLElements)<N>    return p.parse(doc, **kwargs)<N><N><N>def parseFragment(doc, container="div", treebuilder="etree", namespaceHTMLElements=True, **kwargs):<N>    """Parse an HTML fragment as a string or file-like object into a tree<N><N>
    :arg doc: the fragment to parse as a string or file-like object<N><N>    :arg container: the container context to parse the fragment in<N><N>    :arg treebuilder: the treebuilder to use when parsing<N><N>    :arg namespaceHTMLElements: whether or not to namespace HTML elements<N><N>
    :returns: parsed tree<N><N>    Example:<N><N>    >>> from html5lib.html5libparser import parseFragment<N>    >>> parseFragment('<b>this is a fragment</b>')<N>    <Element u'DOCUMENT_FRAGMENT' at 0x7feac484b090><N><N>    """<N>    tb = treebuilders.getTreeBuilder(treebuilder)<N>    p = HTMLParser(tb, namespaceHTMLElements=namespaceHTMLElements)<N>    return p.parseFragment(doc, container=container, **kwargs)<N><N>
<N>def method_decorator_metaclass(function):<N>    class Decorated(type):<N>        def __new__(meta, classname, bases, classDict):<N>            for attributeName, attribute in classDict.items():<N>                if isinstance(attribute, types.FunctionType):<N>                    attribute = function(attribute)<N><N>
                classDict[attributeName] = attribute<N>            return type.__new__(meta, classname, bases, classDict)<N>    return Decorated<N><N><N>class HTMLParser(object):<N>    """HTML parser<N><N>    Generates a tree structure from a stream of (possibly malformed) HTML.<N><N>
    """<N><N>    def __init__(self, tree=None, strict=False, namespaceHTMLElements=True, debug=False):<N>        """<N>        :arg tree: a treebuilder class controlling the type of tree that will be<N>            returned. Built in treebuilders can be accessed through<N>            html5lib.treebuilders.getTreeBuilder(treeType)<N><N>
        :arg strict: raise an exception when a parse error is encountered<N><N>        :arg namespaceHTMLElements: whether or not to namespace HTML elements<N><N>        :arg debug: whether or not to enable debug mode which logs things<N><N>        Example:<N><N>
        >>> from html5lib.html5parser import HTMLParser<N>        >>> parser = HTMLParser()                     # generates parser with etree builder<N>        >>> parser = HTMLParser('lxml', strict=True)  # generates parser with lxml builder which is strict<N><N>
        """<N><N>        # Raise an exception on the first error encountered<N>        self.strict = strict<N><N>        if tree is None:<N>            tree = treebuilders.getTreeBuilder("etree")<N>        self.tree = tree(namespaceHTMLElements)<N>        self.errors = []<N><N>
        self.phases = {name: cls(self, self.tree) for name, cls in<N>                       getPhases(debug).items()}<N><N>    def _parse(self, stream, innerHTML=False, container="div", scripting=False, **kwargs):<N><N>        self.innerHTMLMode = innerHTML<N>        self.container = container<N>        self.scripting = scripting<N>        self.tokenizer = _tokenizer.HTMLTokenizer(stream, parser=self, **kwargs)<N>        self.reset()<N><N>
        try:<N>            self.mainLoop()<N>        except _ReparseException:<N>            self.reset()<N>            self.mainLoop()<N><N>    def reset(self):<N>        self.tree.reset()<N>        self.firstStartTag = False<N>        self.errors = []<N>        self.log = []  # only used with debug mode<N>        # "quirks" / "limited quirks" / "no quirks"<N>        self.compatMode = "no quirks"<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from pip._vendor.six import text_type<N>from pip._vendor.six.moves import http_client, urllib<N><N>import codecs<N>import re<N>from io import BytesIO, StringIO<N><N>from pip._vendor import webencodings<N><N>
from __future__ import absolute_import, division, unicode_literals<N>from pip._vendor.six import text_type<N><N>from collections import OrderedDict<N><N>from lxml import etree<N>from ..treebuilders.etree import tag_regexp<N><N>from . import base<N><N>from .. import _ihatexml<N><N>
<N>def ensure_str(s):<N>    if s is None:<N>        return None<N>    elif isinstance(s, text_type):<N>        return s<N>    else:<N>        return s.decode("ascii", "strict")<N><N><N>class Root(object):<N>    def __init__(self, et):<N>        self.elementtree = et<N>        self.children = []<N><N>
        try:<N>            if et.docinfo.internalDTD:<N>                self.children.append(Doctype(self,<N>                                             ensure_str(et.docinfo.root_name),<N>                                             ensure_str(et.docinfo.public_id),<N>                                             ensure_str(et.docinfo.system_url)))<N>        except AttributeError:<N>            pass<N><N>
        try:<N>            node = et.getroot()<N>        except AttributeError:<N>            node = et<N><N>        while node.getprevious() is not None:<N>            node = node.getprevious()<N>        while node is not None:<N>            self.children.append(node)<N>            node = node.getnext()<N><N>
        self.text = None<N>        self.tail = None<N><N>    def __getitem__(self, key):<N>        return self.children[key]<N><N>    def getnext(self):<N>        return None<N><N>    def __len__(self):<N>        return 1<N><N><N>class Doctype(object):<N>    def __init__(self, root_node, name, public_id, system_id):<N>        self.root_node = root_node<N>        self.name = name<N>        self.public_id = public_id<N>        self.system_id = system_id<N><N>
        self.text = None<N>        self.tail = None<N><N>    def getnext(self):<N>        return self.root_node.children[1]<N><N><N>class FragmentRoot(Root):<N>    def __init__(self, children):<N>        self.children = [FragmentWrapper(self, child) for child in children]<N>        self.text = self.tail = None<N><N>
    def getnext(self):<N>        return None<N><N><N>class FragmentWrapper(object):<N>    def __init__(self, fragment_root, obj):<N>        self.root_node = fragment_root<N>        self.obj = obj<N>        if hasattr(self.obj, 'text'):<N>            self.text = ensure_str(self.obj.text)<N>        else:<N>            self.text = None<N>        if hasattr(self.obj, 'tail'):<N>            self.tail = ensure_str(self.obj.tail)<N>        else:<N>            self.tail = None<N><N>
    def __getattr__(self, name):<N>        return getattr(self.obj, name)<N><N>    def getnext(self):<N>        siblings = self.root_node.children<N>        idx = siblings.index(self)<N>        if idx < len(siblings) - 1:<N>            return siblings[idx + 1]<N>        else:<N>            return None<N><N>
    def __getitem__(self, key):<N>        return self.obj[key]<N><N>    def __bool__(self):<N>        return bool(self.obj)<N><N>    def getparent(self):<N>        return None<N><N>    def __str__(self):<N>        return str(self.obj)<N><N>    def __unicode__(self):<N>        return str(self.obj)<N><N>
"""A collection of modules for iterating through different kinds of<N>tree, generating tokens identical to those produced by the tokenizer<N>module.<N><N>To create a tree walker for a new type of tree, you need to<N>implement a tree walker object (called TreeWalker by convention) that<N>implements a 'serialize' method which takes a tree as sole argument and<N>returns an iterator which generates tokens.<N>"""<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from .. import constants<N>from .._utils import default_etree<N><N>__all__ = ["getTreeWalker", "pprint"]<N><N>treeWalkerCache = {}<N><N><N>def getTreeWalker(treeType, implementation=None, **kwargs):<N>    """Get a TreeWalker class for various types of tree with built-in support<N><N>
    :arg str treeType: the name of the tree type required (case-insensitive).<N>        Supported values are:<N><N>        * "dom": The xml.dom.minidom DOM implementation<N>        * "etree": A generic walker for tree implementations exposing an<N>          elementtree-like interface (known to work with ElementTree,<N>          cElementTree and lxml.etree).<N>        * "lxml": Optimized walker for lxml.etree<N>        * "genshi": a Genshi stream<N><N>
    :arg implementation: A module implementing the tree type e.g.<N>        xml.etree.ElementTree or cElementTree (Currently applies to the "etree"<N>        tree type only).<N><N>    :arg kwargs: keyword arguments passed to the etree walker--for other<N>        walkers, this has no effect<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from collections import OrderedDict<N>import re<N><N>from pip._vendor.six import string_types<N><N>from . import base<N>from .._utils import moduleFactoryFactory<N><N>tag_regexp = re.compile("{([^}]*)}(.*)")<N><N>
<N>def getETreeBuilder(ElementTreeImplementation):<N>    ElementTree = ElementTreeImplementation<N>    ElementTreeCommentType = ElementTree.Comment("asd").tag<N><N>    class TreeWalker(base.NonRecursiveTreeWalker):  # pylint:disable=unused-variable<N>        """Given the particular ElementTree representation, this implementation,<N>        to avoid using recursion, returns "nodes" as tuples with the following<N>        content:<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from xml.dom import Node<N><N>from . import base<N><N><N>class TreeWalker(base.NonRecursiveTreeWalker):<N>    def getNodeDetails(self, node):<N>        if node.nodeType == Node.DOCUMENT_TYPE_NODE:<N>            return base.DOCTYPE, node.name, node.publicId, node.systemId<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from xml.dom import Node<N>from ..constants import namespaces, voidElements, spaceCharacters<N><N>__all__ = ["DOCUMENT", "DOCTYPE", "TEXT", "ELEMENT", "COMMENT", "ENTITY", "UNKNOWN",<N>           "TreeWalker", "NonRecursiveTreeWalker"]<N><N>
DOCUMENT = Node.DOCUMENT_NODE<N>DOCTYPE = Node.DOCUMENT_TYPE_NODE<N>TEXT = Node.TEXT_NODE<N>ELEMENT = Node.ELEMENT_NODE<N>COMMENT = Node.COMMENT_NODE<N>ENTITY = Node.ENTITY_NODE<N>UNKNOWN = "<#UNKNOWN#>"<N><N>spaceCharacters = "".join(spaceCharacters)<N><N>
<N>class TreeWalker(object):<N>    """Walks a tree yielding tokens<N><N>    Tokens are dicts that all have a ``type`` field specifying the type of the<N>    token.<N><N>    """<N>    def __init__(self, tree):<N>        """Creates a TreeWalker<N><N>        :arg tree: the tree to walk<N><N>
        """<N>        self.tree = tree<N><N>    def __iter__(self):<N>        raise NotImplementedError<N><N>    def error(self, msg):<N>        """Generates an error token with the given message<N><N>        :arg msg: the error message<N><N>        :returns: SerializeError token<N><N>
        """<N>        return {"type": "SerializeError", "data": msg}<N><N>    def emptyTag(self, namespace, name, attrs, hasChildren=False):<N>        """Generates an EmptyTag token<N><N>        :arg namespace: the namespace of the token--can be ``None``<N><N>
        :arg name: the name of the element<N><N>        :arg attrs: the attributes of the element as a dict<N><N>        :arg hasChildren: whether or not to yield a SerializationError because<N>            this tag shouldn't have children<N><N>        :returns: EmptyTag token<N><N>
        """<N>        yield {"type": "EmptyTag", "name": name,<N>               "namespace": namespace,<N>               "data": attrs}<N>        if hasChildren:<N>            yield self.error("Void element has children")<N><N>    def startTag(self, namespace, name, attrs):<N>        """Generates a StartTag token<N><N>
        :arg namespace: the namespace of the token--can be ``None``<N><N>        :arg name: the name of the element<N><N>        :arg attrs: the attributes of the element as a dict<N><N>        :returns: StartTag token<N><N>        """<N>        return {"type": "StartTag",<N>                "name": name,<N>                "namespace": namespace,<N>                "data": attrs}<N><N>
    def endTag(self, namespace, name):<N>        """Generates an EndTag token<N><N>        :arg namespace: the namespace of the token--can be ``None``<N><N>        :arg name: the name of the element<N><N>        :returns: EndTag token<N><N>        """<N>        return {"type": "EndTag",<N>                "name": name,<N>                "namespace": namespace}<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from genshi.core import QName<N>from genshi.core import START, END, XML_NAMESPACE, DOCTYPE, TEXT<N>from genshi.core import START_NS, END_NS, START_CDATA, END_CDATA, PI, COMMENT<N><N>from . import base<N><N>
from ..constants import voidElements, namespaces<N><N><N>class TreeWalker(base.TreeWalker):<N>    def __iter__(self):<N>        # Buffer the events so we can pass in the following one<N>        previous = None<N>        for event in self.tree:<N>            if previous is not None:<N>                for token in self.tokens(previous, event):<N>                    yield token<N>            previous = event<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from xml.sax.xmlreader import AttributesNSImpl<N><N>from ..constants import adjustForeignAttributes, unadjustForeignAttributes<N><N>prefix_mapping = {}<N>for prefix, localName, namespace in adjustForeignAttributes.values():<N>    if prefix is not None:<N>        prefix_mapping[prefix] = namespace<N><N>
<N>def to_sax(walker, handler):<N>    """Call SAX-like content handler based on treewalker walker<N><N>    :arg walker: the treewalker to use to walk the tree to convert it<N><N>    :arg handler: SAX handler to use<N><N>    """<N>    handler.startDocument()<N>    for prefix, namespace in prefix_mapping.items():<N>        handler.startPrefixMapping(prefix, namespace)<N><N>
"""Tree adapters let you convert from one tree structure to another<N><N>Example:<N><N>.. code-block:: python<N><N>   from pip._vendor import html5lib<N>   from pip._vendor.html5lib.treeadapters import genshi<N><N>   doc = '<html><body>Hi!</body></html>'<N>   treebuilder = html5lib.getTreeBuilder('etree')<N>   parser = html5lib.HTMLParser(tree=treebuilder)<N>   tree = parser.parse(doc)<N>   TreeWalker = html5lib.getTreeWalker('etree')<N><N>
   genshi_tree = genshi.to_genshi(TreeWalker(tree))<N><N>"""<N>from __future__ import absolute_import, division, unicode_literals<N><N>from . import sax<N><N>__all__ = ["sax"]<N><N>try:<N>    from . import genshi  # noqa<N>except ImportError:<N>    pass<N>else:<N>    __all__.append("genshi")<N><N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from genshi.core import QName, Attrs<N>from genshi.core import START, END, TEXT, COMMENT, DOCTYPE<N><N><N>def to_genshi(walker):<N>    """Convert a tree to a genshi tree<N><N>    :arg walker: the treewalker to use to walk the tree to convert it<N><N>
    :returns: generator of genshi nodes<N><N>    """<N>    text = []<N>    for token in walker:<N>        type = token["type"]<N>        if type in ("Characters", "SpaceCharacters"):<N>            text.append(token["data"])<N>        elif text:<N>            yield TEXT, "".join(text), (None, -1, -1)<N>            text = []<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from pip._vendor.six import text_type<N><N>from . import base<N>from ..constants import namespaces, voidElements<N><N>from ..constants import spaceCharacters<N>spaceCharacters = "".join(spaceCharacters)<N><N>
<N>class Filter(base.Filter):<N>    """Lints the token stream for errors<N><N>    If it finds any errors, it'll raise an ``AssertionError``.<N><N>    """<N>    def __init__(self, source, require_matching_tags=True):<N>        """Creates a Filter<N><N>        :arg source: the source token stream<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>import re<N><N>from . import base<N>from ..constants import rcdataElements, spaceCharacters<N>spaceCharacters = "".join(spaceCharacters)<N><N>SPACES_REGEX = re.compile("[%s]+" % spaceCharacters)<N><N>
<N>class Filter(base.Filter):<N>    """Collapses whitespace except in pre, textarea, and script elements"""<N>    spacePreserveElements = frozenset(["pre", "textarea"] + list(rcdataElements))<N><N>    def __iter__(self):<N>        preserve = 0<N>        for token in base.Filter.__iter__(self):<N>            type = token["type"]<N>            if type == "StartTag" \<N>                    and (preserve or token["name"] in self.spacePreserveElements):<N>                preserve += 1<N><N>
            elif type == "EndTag" and preserve:<N>                preserve -= 1<N><N>            elif not preserve and type == "SpaceCharacters" and token["data"]:<N>                # Test on token["data"] above to not introduce spaces where there were not<N>                token["data"] = " "<N><N>
"""Deprecated from html5lib 1.1.<N><N>See `here <https://github.com/html5lib/html5lib-python/issues/443>`_ for<N>information about its deprecation; `Bleach <https://github.com/mozilla/bleach>`_<N>is recommended as a replacement. Please let us know in the aforementioned issue<N>if Bleach is unsuitable for your needs.<N><N>
"""<N>from __future__ import absolute_import, division, unicode_literals<N><N>import re<N>import warnings<N>from xml.sax.saxutils import escape, unescape<N><N>from pip._vendor.six.moves import urllib_parse as urlparse<N><N>from . import base<N>from ..constants import namespaces, prefixes<N><N>
__all__ = ["Filter"]<N><N><N>_deprecation_msg = (<N>    "html5lib's sanitizer is deprecated; see " +<N>    "https://github.com/html5lib/html5lib-python/issues/443 and please let " +<N>    "us know if Bleach is unsuitable for your needs"<N>)<N><N>warnings.warn(_deprecation_msg, DeprecationWarning)<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from . import base<N><N>from collections import OrderedDict<N><N><N>def _attr_key(attr):<N>    """Return an appropriate key for an attribute for sorting<N><N>    Attributes have a namespace that can be either ``None`` or a string. We<N>    can't compare the two because they're different types, so we convert<N>    ``None`` to an empty string first.<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N>from . import base<N><N><N>class Filter(base.Filter):<N>    """Injects ``<meta charset=ENCODING>`` tag into head of document"""<N>    def __init__(self, source, encoding):<N>        """Creates a Filter<N><N>
        :arg source: the source token stream<N><N>        :arg encoding: the encoding to set<N><N>        """<N>        base.Filter.__init__(self, source)<N>        self.encoding = encoding<N><N>    def __iter__(self):<N>        state = "pre_head"<N>        meta_found = (self.encoding is None)<N>        pending = []<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N><N>class Filter(object):<N>    def __init__(self, source):<N>        self.source = source<N><N>    def __iter__(self):<N>        return iter(self.source)<N><N>    def __getattr__(self, name):<N>        return getattr(self.source, name)<N>
from __future__ import absolute_import, division, unicode_literals<N><N>from .py import Trie<N><N>__all__ = ["Trie"]<N>
from __future__ import absolute_import, division, unicode_literals<N><N>try:<N>    from collections.abc import Mapping<N>except ImportError:  # Python 2.7<N>    from collections import Mapping<N><N><N>class Trie(Mapping):<N>    """Abstract base class for tries"""<N><N>
    def keys(self, prefix=None):<N>        # pylint:disable=arguments-differ<N>        keys = super(Trie, self).keys()<N><N>        if prefix is None:<N>            return set(keys)<N><N>        return {x for x in keys if x.startswith(prefix)}<N><N>    def has_keys_with_prefix(self, prefix):<N>        for key in self.keys():<N>            if key.startswith(prefix):<N>                return True<N><N>
        return False<N><N>    def longest_prefix(self, prefix):<N>        if prefix in self:<N>            return prefix<N><N>        for i in range(1, len(prefix) + 1):<N>            if prefix[:-i] in self:<N>                return prefix[:-i]<N><N>        raise KeyError(prefix)<N><N>
from __future__ import absolute_import, division, unicode_literals<N>from pip._vendor.six import text_type<N><N>from bisect import bisect_left<N><N>from ._base import Trie as ABCTrie<N><N><N>class Trie(ABCTrie):<N>    def __init__(self, data):<N>        if not all(isinstance(x, text_type) for x in data.keys()):<N>            raise TypeError("All keys must be strings")<N><N>
        self._data = data<N>        self._keys = sorted(data.keys())<N>        self._cachestr = ""<N>        self._cachepoints = (0, len(data))<N><N>    def __contains__(self, key):<N>        return key in self._data<N><N>    def __len__(self):<N>        return len(self._data)<N><N>
    def __iter__(self):<N>        return iter(self._data)<N><N>    def __getitem__(self, key):<N>        return self._data[key]<N><N>    def keys(self, prefix=None):<N>        if prefix is None or prefix == "" or not self._keys:<N>            return set(self._keys)<N><N>
        if prefix.startswith(self._cachestr):<N>            lo, hi = self._cachepoints<N>            start = i = bisect_left(self._keys, prefix, lo, hi)<N>        else:<N>            start = i = bisect_left(self._keys, prefix)<N><N>        keys = set()<N>        if start == len(self._keys):<N>            return keys<N><N>
        while self._keys[i].startswith(prefix):<N>            keys.add(self._keys[i])<N>            i += 1<N><N>        self._cachestr = prefix<N>        self._cachepoints = (start, i)<N><N>        return keys<N><N>    def has_keys_with_prefix(self, prefix):<N>        if prefix in self._data:<N>            return True<N><N>
        if prefix.startswith(self._cachestr):<N>            lo, hi = self._cachepoints<N>            i = bisect_left(self._keys, prefix, lo, hi)<N>        else:<N>            i = bisect_left(self._keys, prefix)<N><N>        if i == len(self._keys):<N>            return False<N><N>
"""Module for supporting the lxml.etree library. The idea here is to use as much<N>of the native library as possible, without using fragile hacks like custom element<N>names that break between releases. The downside of this is that we cannot represent<N>all possible trees; specifically the following are known to cause problems:<N><N>
Text or comments as siblings of the root element<N>Docypes with no name<N><N>When any of these things occur, we emit a DataLossWarning<N>"""<N><N>from __future__ import absolute_import, division, unicode_literals<N># pylint:disable=protected-access<N><N>import warnings<N>import re<N>import sys<N><N>
try:<N>    from collections.abc import MutableMapping<N>except ImportError:<N>    from collections import MutableMapping<N><N>from . import base<N>from ..constants import DataLossWarning<N>from .. import constants<N>from . import etree as etree_builders<N>from .. import _ihatexml<N><N>
import lxml.etree as etree<N>from pip._vendor.six import PY3, binary_type<N><N><N>fullTree = True<N>tag_regexp = re.compile("{([^}]*)}(.*)")<N><N>comment_type = etree.Comment("asd").tag<N><N><N>class DocumentType(object):<N>    def __init__(self, name, publicId, systemId):<N>        self.name = name<N>        self.publicId = publicId<N>        self.systemId = systemId<N><N>
<N>class Document(object):<N>    def __init__(self):<N>        self._elementTree = None<N>        self._childNodes = []<N><N>    def appendChild(self, element):<N>        last = self._elementTree.getroot()<N>        for last in self._elementTree.getroot().itersiblings():<N>            pass<N><N>
        last.addnext(element._element)<N><N>    def _getChildNodes(self):<N>        return self._childNodes<N><N>    childNodes = property(_getChildNodes)<N><N><N>def testSerializer(element):<N>    rv = []<N>    infosetFilter = _ihatexml.InfosetFilter(preventDoubleDashComments=True)<N><N>
from __future__ import absolute_import, division, unicode_literals<N># pylint:disable=protected-access<N><N>from pip._vendor.six import text_type<N><N>import re<N><N>from copy import copy<N><N>from . import base<N>from .. import _ihatexml<N>from .. import constants<N>from ..constants import namespaces<N>from .._utils import moduleFactoryFactory<N><N>
from __future__ import absolute_import, division, unicode_literals<N><N><N>try:<N>    from collections.abc import MutableMapping<N>except ImportError:  # Python 2.7<N>    from collections import MutableMapping<N>from xml.dom import minidom, Node<N>import weakref<N><N>
from . import base<N>from .. import constants<N>from ..constants import namespaces<N>from .._utils import moduleFactoryFactory<N><N><N>def getDomBuilder(DomImplementation):<N>    Dom = DomImplementation<N><N>    class AttrList(MutableMapping):<N>        def __init__(self, element):<N>            self.element = element<N><N>
        def __iter__(self):<N>            return iter(self.element.attributes.keys())<N><N>        def __setitem__(self, name, value):<N>            if isinstance(name, tuple):<N>                raise NotImplementedError<N>            else:<N>                attr = self.element.ownerDocument.createAttribute(name)<N>                attr.value = value<N>                self.element.attributes[name] = attr<N><N>
        def __len__(self):<N>            return len(self.element.attributes)<N><N>        def items(self):<N>            return list(self.element.attributes.items())<N><N>        def values(self):<N>            return list(self.element.attributes.values())<N><N>
        def __getitem__(self, name):<N>            if isinstance(name, tuple):<N>                raise NotImplementedError<N>            else:<N>                return self.element.attributes[name].value<N><N>        def __delitem__(self, name):<N>            if isinstance(name, tuple):<N>                raise NotImplementedError<N>            else:<N>                del self.element.attributes[name]<N><N>
    class NodeBuilder(base.Node):<N>        def __init__(self, element):<N>            base.Node.__init__(self, element.nodeName)<N>            self.element = element<N><N>        namespace = property(lambda self: hasattr(self.element, "namespaceURI") and<N>                             self.element.namespaceURI or None)<N><N>
        def appendChild(self, node):<N>            node.parent = self<N>            self.element.appendChild(node.element)<N><N>        def insertText(self, data, insertBefore=None):<N>            text = self.element.ownerDocument.createTextNode(data)<N>            if insertBefore:<N>                self.element.insertBefore(text, insertBefore.element)<N>            else:<N>                self.element.appendChild(text)<N><N>
        def insertBefore(self, node, refNode):<N>            self.element.insertBefore(node.element, refNode.element)<N>            node.parent = self<N><N>        def removeChild(self, node):<N>            if node.element.parentNode == self.element:<N>                self.element.removeChild(node.element)<N>            node.parent = None<N><N>
        def reparentChildren(self, newParent):<N>            while self.element.hasChildNodes():<N>                child = self.element.firstChild<N>                self.element.removeChild(child)<N>                newParent.element.appendChild(child)<N>            self.childNodes = []<N><N>
from __future__ import absolute_import, division, unicode_literals<N>from pip._vendor.six import text_type<N><N>from ..constants import scopingElements, tableInsertModeElements, namespaces<N><N># The scope markers are inserted when entering object elements,<N># marquees, table cells, and table captions, and are used to prevent formatting<N># from "leaking" into tables, object elements, and marquees.<N>Marker = None<N><N>
# coding: utf-8<N>"""<N>Package resource API<N>--------------------<N><N>A resource is a logical file contained within a package, or a logical<N>subdirectory thereof.  The package resource API expects resource names<N>to have their path parts separated with ``/``, *not* whatever the local<N>path separator is.  Do not use os.path operations to manipulate resource<N>names being passed into the API.<N><N>
The package resource API is designed to work with normal filesystem packages,<N>.egg files, and unpacked .egg files.  It can also work in a limited way with<N>.zip files and with custom PEP 302 loaders that support the ``get_data()``<N>method.<N>"""<N><N>from __future__ import absolute_import<N><N>
import sys<N>import os<N>import io<N>import time<N>import re<N>import types<N>import zipfile<N>import zipimport<N>import warnings<N>import stat<N>import functools<N>import pkgutil<N>import operator<N>import platform<N>import collections<N>import plistlib<N>import email.parser<N>import errno<N>import tempfile<N>import textwrap<N>import itertools<N>import inspect<N>import ntpath<N>import posixpath<N>from pkgutil import get_importer<N><N>
try:<N>    import _imp<N>except ImportError:<N>    # Python 3.2 compatibility<N>    import imp as _imp<N><N>try:<N>    FileExistsError<N>except NameError:<N>    FileExistsError = OSError<N><N>from pip._vendor import six<N>from pip._vendor.six.moves import urllib, map, filter<N><N>
# capture these to bypass sandboxing<N>from os import utime<N>try:<N>    from os import mkdir, rename, unlink<N>    WRITE_SUPPORT = True<N>except ImportError:<N>    # no write support, probably under GAE<N>    WRITE_SUPPORT = False<N><N>from os import open as os_open<N>from os.path import isdir, split<N><N>
import os<N>import errno<N>import sys<N><N>from pip._vendor import six<N><N><N>def _makedirs_31(path, exist_ok=False):<N>    try:<N>        os.makedirs(path)<N>    except OSError as exc:<N>        if not exist_ok or exc.errno != errno.EEXIST:<N>            raise<N><N>
<N># rely on compatibility behavior until mode considerations<N>#  and exists_ok considerations are disentangled.<N># See https://github.com/pypa/setuptools/pull/1083#issuecomment-315168663<N>needs_makedirs = (<N>    six.PY2 or<N>    (3, 4) <= sys.version_info < (3, 4, 1)<N>)<N>makedirs = _makedirs_31 if needs_makedirs else os.makedirs<N><N><N>
class AbstractProvider(object):<N>    """Delegate class to provide requirement interface for the resolver."""<N><N>    def identify(self, requirement_or_candidate):<N>        """Given a requirement, return an identifier for it.<N><N>        This is used to identify a requirement, e.g. whether two requirements<N>        should have their specifier parts merged.<N>        """<N>        raise NotImplementedError<N><N>
    def get_preference(self, identifier, resolutions, candidates, information):<N>        """Produce a sort key for given requirement based on preference.<N><N>        The preference is defined as "I think this requirement should be<N>        resolved first". The lower the return value is, the more preferred<N>        this group of arguments is.<N><N>
__all__ = [<N>    "__version__",<N>    "AbstractProvider",<N>    "AbstractResolver",<N>    "BaseReporter",<N>    "InconsistentCandidate",<N>    "Resolver",<N>    "RequirementsConflicted",<N>    "ResolutionError",<N>    "ResolutionImpossible",<N>    "ResolutionTooDeep",<N>]<N><N>
__version__ = "0.7.0"<N><N><N>from .providers import AbstractProvider, AbstractResolver<N>from .reporters import BaseReporter<N>from .resolvers import (<N>    InconsistentCandidate,<N>    RequirementsConflicted,<N>    Resolver,<N>    ResolutionError,<N>    ResolutionImpossible,<N>    ResolutionTooDeep,<N>)<N><N><N>
class BaseReporter(object):<N>    """Delegate class to provider progress reporting for the resolver."""<N><N>    def starting(self):<N>        """Called before the resolution actually starts."""<N><N>    def starting_round(self, index):<N>        """Called before each round of resolution starts.<N><N>
        The index is zero-based.<N>        """<N><N>    def ending_round(self, index, state):<N>        """Called before each round of resolution ends.<N><N>        This is NOT called if the resolution ends at this round. Use `ending`<N>        if you want to report finalization. The index is zero-based.<N>        """<N><N>
import collections<N>import operator<N><N>from .providers import AbstractResolver<N>from .structs import DirectedGraph, IteratorMapping, build_iter_view<N><N><N>RequirementInformation = collections.namedtuple(<N>    "RequirementInformation", ["requirement", "parent"]<N>)<N><N>
<N>class ResolverException(Exception):<N>    """A base class for all exceptions raised by this module.<N><N>    Exceptions derived by this class should all be handled in this module. Any<N>    bubbling pass the resolver should be treated as a bug.<N>    """<N><N>
<N>class RequirementsConflicted(ResolverException):<N>    def __init__(self, criterion):<N>        super(RequirementsConflicted, self).__init__(criterion)<N>        self.criterion = criterion<N><N>    def __str__(self):<N>        return "Requirements conflict: {}".format(<N>            ", ".join(repr(r) for r in self.criterion.iter_requirement()),<N>        )<N><N>
<N>class InconsistentCandidate(ResolverException):<N>    def __init__(self, candidate, criterion):<N>        super(InconsistentCandidate, self).__init__(candidate, criterion)<N>        self.candidate = candidate<N>        self.criterion = criterion<N><N>    def __str__(self):<N>        return "Provided candidate {!r} does not satisfy {}".format(<N>            self.candidate,<N>            ", ".join(repr(r) for r in self.criterion.iter_requirement()),<N>        )<N><N>
import itertools<N><N>from .compat import collections_abc<N><N><N>class DirectedGraph(object):<N>    """A graph structure with directed edges."""<N><N>    def __init__(self):<N>        self._vertices = set()<N>        self._forwards = {}  # <key> -> Set[<key>]<N>        self._backwards = {}  # <key> -> Set[<key>]<N><N>
__all__ = ["Mapping", "Sequence"]<N><N>try:<N>    from collections.abc import Mapping, Sequence<N>except ImportError:<N>    from collections import Mapping, Sequence<N>
from .core import TomlError<N>from .parser import load, loads<N>from .test import translate_to_test<N>from .writer import dump, dumps
from __future__ import unicode_literals<N>import io, datetime, math, string, sys<N><N>from .utils import format_rfc3339<N><N>try:<N>    from pathlib import PurePath as _path_types<N>except ImportError:<N>    _path_types = ()<N><N><N>if sys.version_info[0] == 3:<N>    long = int<N>    unicode = str<N><N>
<N>def dumps(obj, sort_keys=False):<N>    fout = io.StringIO()<N>    dump(obj, fout, sort_keys=sort_keys)<N>    return fout.getvalue()<N><N><N>_escapes = {'\n': 'n', '\r': 'r', '\\': '\\', '\t': 't', '\b': 'b', '\f': 'f', '"': '"'}<N><N><N>def _escape_string(s):<N>    res = []<N>    start = 0<N><N>
    def flush():<N>        if start != i:<N>            res.append(s[start:i])<N>        return i + 1<N><N>    i = 0<N>    while i < len(s):<N>        c = s[i]<N>        if c in '"\\\n\r\t\b\f':<N>            start = flush()<N>            res.append('\\' + _escapes[c])<N>        elif ord(c) < 0x20:<N>            start = flush()<N>            res.append('\\u%04x' % ord(c))<N>        i += 1<N><N>
class TomlError(RuntimeError):<N>    def __init__(self, message, line, col, filename):<N>        RuntimeError.__init__(self, message, line, col, filename)<N>        self.message = message<N>        self.line = line<N>        self.col = col<N>        self.filename = filename<N><N>    def __str__(self):<N>        return '{}({}, {}): {}'.format(self.filename, self.line, self.col, self.message)<N><N>    def __repr__(self):<N>        return 'TomlError({!r}, {!r}, {!r}, {!r})'.format(self.message, self.line, self.col, self.filename)<N>
import re, sys<N>from .core import TomlError<N>from .utils import rfc3339_re, parse_rfc3339_re<N><N>if sys.version_info[0] == 2:<N>    _chr = unichr<N>else:<N>    _chr = chr<N><N>def load(fin, translate=lambda t, x, v: v, object_pairs_hook=dict):<N>    return loads(fin.read(), translate=translate, object_pairs_hook=object_pairs_hook, filename=getattr(fin, 'name', repr(fin)))<N><N>
def loads(s, filename='<string>', translate=lambda t, x, v: v, object_pairs_hook=dict):<N>    if isinstance(s, bytes):<N>        s = s.decode('utf-8')<N><N>    s = s.replace('\r\n', '\n')<N><N>    root = object_pairs_hook()<N>    tables = object_pairs_hook()<N>    scope = root<N><N>
import datetime<N>import re<N><N>rfc3339_re = re.compile(r'(\d{4})-(\d{2})-(\d{2})T(\d{2}):(\d{2}):(\d{2})(\.\d+)?(?:Z|([+-]\d{2}):(\d{2}))')<N><N>def parse_rfc3339(v):<N>    m = rfc3339_re.match(v)<N>    if not m or m.group(0) != v:<N>        return None<N>    return parse_rfc3339_re(m)<N><N>
def parse_rfc3339_re(m):<N>    r = map(int, m.groups()[:6])<N>    if m.group(7):<N>        micro = float(m.group(7))<N>    else:<N>        micro = 0<N><N>    if m.group(8):<N>        g = int(m.group(8), 10) * 60 + int(m.group(9), 10)<N>        tz = _TimeZone(datetime.timedelta(0, g * 60))<N>    else:<N>        tz = _TimeZone(datetime.timedelta(0, 0))<N><N>
    y, m, d, H, M, S = r<N>    return datetime.datetime(y, m, d, H, M, S, int(micro * 1000000), tz)<N><N><N>def format_rfc3339(v):<N>    offs = v.utcoffset()<N>    offs = int(offs.total_seconds()) // 60 if offs is not None else 0<N><N>    if offs == 0:<N>        suffix = 'Z'<N>    else:<N>        if offs > 0:<N>            suffix = '+'<N>        else:<N>            suffix = '-'<N>            offs = -offs<N>        suffix = '{0}{1:02}:{2:02}'.format(suffix, offs // 60, offs % 60)<N><N>
    if v.microsecond:<N>        return v.strftime('%Y-%m-%dT%H:%M:%S.%f') + suffix<N>    else:<N>        return v.strftime('%Y-%m-%dT%H:%M:%S') + suffix<N><N>class _TimeZone(datetime.tzinfo):<N>    def __init__(self, offset):<N>        self._offset = offset<N><N>
    def utcoffset(self, dt):<N>        return self._offset<N><N>    def dst(self, dt):<N>        return None<N><N>    def tzname(self, dt):<N>        m = self._offset.total_seconds() // 60<N>        if m < 0:<N>            res = '-'<N>            m = -m<N>        else:<N>            res = '+'<N>        h = m // 60<N>        m = m - h * 60<N>        return '{}{:.02}{:.02}'.format(res, h, m)<N><N><N>
"""Simple base-classes for extensions and filters.<N><N>None of the filter and extension functions are considered 'optional' by the<N>framework.  These base-classes provide simple implementations for the<N>Initialize and Terminate functions, allowing you to omit them,<N><N>
It is not necessary to use these base-classes - but if you don't, you<N>must ensure each of the required methods are implemented.<N>"""<N><N>class SimpleExtension:<N>    "Base class for a simple ISAPI extension"<N>    def __init__(self):<N>        pass<N><N>
    def GetExtensionVersion(self, vi):<N>        """Called by the ISAPI framework to get the extension version<N>        <N>        The default implementation uses the classes docstring to<N>        set the extension description."""<N>        # nod to our reload capability - vi is None when we are reloaded.<N>        if vi is not None:<N>            vi.ExtensionDesc = self.__doc__<N><N>
    def HttpExtensionProc(self, control_block):<N>        """Called by the ISAPI framework for each extension request.<N>        <N>        sub-classes must provide an implementation for this method.<N>        """<N>        raise NotImplementedError("sub-classes should override HttpExtensionProc")<N><N>
    def TerminateExtension(self, status):<N>        """Called by the ISAPI framework as the extension terminates.<N>        """<N>        pass<N><N>class SimpleFilter:<N>    "Base class for a a simple ISAPI filter"<N>    filter_flags = None<N>    def __init__(self):<N>        pass<N><N>
"""An ISAPI extension base class implemented using a thread-pool."""<N># $Id$<N><N>import sys<N>import time<N>from isapi import isapicon, ExtensionError<N>import isapi.simple<N>from win32file import GetQueuedCompletionStatus, CreateIoCompletionPort, \<N>                      PostQueuedCompletionStatus, CloseHandle<N>from win32security import SetThreadToken<N>from win32event import INFINITE<N>from pywintypes import OVERLAPPED<N><N>
import threading<N>import traceback<N><N>ISAPI_REQUEST = 1<N>ISAPI_SHUTDOWN = 2<N><N>class WorkerThread(threading.Thread):<N>    def __init__(self, extension, io_req_port):<N>        self.running = False<N>        self.io_req_port = io_req_port<N>        self.extension = extension<N>        threading.Thread.__init__(self)<N>        # We wait 15 seconds for a thread to terminate, but if it fails to,<N>        # we don't want the process to hang at exit waiting for it...<N>        self.setDaemon(True)<N><N>
    def run(self):<N>        self.running = True<N>        while self.running:<N>            errCode, bytes, key, overlapped = \<N>                GetQueuedCompletionStatus(self.io_req_port, INFINITE)<N>            if key == ISAPI_SHUTDOWN and overlapped is None:<N>                break<N><N>
            # Let the parent extension handle the command.<N>            dispatcher = self.extension.dispatch_map.get(key)<N>            if dispatcher is None:<N>                raise RuntimeError("Bad request '%s'" % (key,))<N>            <N>            dispatcher(errCode, bytes, key, overlapped)<N><N>
"""Installation utilities for Python ISAPI filters and extensions."""<N><N># this code adapted from "Tomcat JK2 ISAPI redirector", part of Apache<N># Created July 2004, Mark Hammond.<N>import sys, os, imp, shutil, stat<N>import operator<N>from win32com.client import GetObject, Dispatch<N>from win32com.client.gencache import EnsureModule, EnsureDispatch<N>import win32api<N>import pythoncom<N>import winerror<N>import traceback<N><N>
_APP_INPROC  = 0<N>_APP_OUTPROC = 1<N>_APP_POOLED  = 2<N>_IIS_OBJECT  = "IIS://LocalHost/W3SVC"<N>_IIS_SERVER  = "IIsWebServer"<N>_IIS_WEBDIR  = "IIsWebDirectory"<N>_IIS_WEBVIRTUALDIR  = "IIsWebVirtualDir"<N>_IIS_FILTERS = "IIsFilters"<N>_IIS_FILTER  = "IIsFilter"<N><N>
_DEFAULT_SERVER_NAME = "Default Web Site"<N>_DEFAULT_HEADERS     = "X-Powered-By: Python"<N>_DEFAULT_PROTECTION  = _APP_POOLED<N><N># Default is for 'execute' only access - ie, only the extension<N># can be used.  This can be overridden via your install script.<N>_DEFAULT_ACCESS_EXECUTE = True<N>_DEFAULT_ACCESS_READ = False<N>_DEFAULT_ACCESS_WRITE = False<N>_DEFAULT_ACCESS_SCRIPT = False<N>_DEFAULT_CONTENT_INDEXED = False<N>_DEFAULT_ENABLE_DIR_BROWSING = False<N>_DEFAULT_ENABLE_DEFAULT_DOC = False<N><N>
# This is an ISAPI extension purely for testing purposes.  It is NOT<N># a 'demo' (even though it may be useful!)<N>#<N># Install this extension, then point your browser to:<N># "http://localhost/pyisapi_test/test1"<N># This will execute the method 'test1' below.  See below for the list of<N># test methods that are acceptable.<N><N>
from isapi import isapicon, threaded_extension, ExtensionError<N>from isapi.simple import SimpleFilter<N>import traceback<N>import urllib.request, urllib.parse, urllib.error<N>import winerror<N><N># If we have no console (eg, am running from inside IIS), redirect output<N># somewhere useful - in this case, the standard win32 trace collector.<N>import win32api<N>try:<N>    win32api.GetConsoleTitle()<N>except win32api.error:<N>    # No console - redirect<N>    import win32traceutil<N><N>
# This is a sample configuration file for an ISAPI filter and extension<N># written in Python.<N>#<N># Please see README.txt in this directory, and specifically the<N># information about the "loader" DLL - installing this sample will create<N># "_redirector_with_filter.dll" in the current directory.  The readme explains<N># this.<N><N>
# This is a sample ISAPI extension written in Python.<N>#<N># Please see README.txt in this directory, and specifically the<N># information about the "loader" DLL - installing this sample will create<N># "_redirector.dll" in the current directory.  The readme explains this.<N><N>
# This extension is used mainly for testing purposes - it is not<N># designed to be a simple sample, but instead is a hotch-potch of things<N># that attempts to exercise the framework.<N><N>from isapi import isapicon<N>from isapi.simple import SimpleExtension<N>import sys, os, stat<N><N>
# This is a sample ISAPI extension written in Python.<N><N># This is like the other 'redirector' samples, but uses asnch IO when writing<N># back to the client (it does *not* use asynch io talking to the remote<N># server!)<N><N>from isapi import isapicon, threaded_extension<N>import sys<N>import traceback<N>import urllib.request, urllib.parse, urllib.error<N><N>
# sys.isapidllhandle will exist when we are loaded by the IIS framework.<N># In this case we redirect our output to the win32traceutil collector.<N>if hasattr(sys, "isapidllhandle"):<N>    import win32traceutil<N><N># The site we are proxying.<N>proxy = "http://www.python.org"<N><N>
#<N># Initialization for the win32com package<N>#<N><N>import win32api, sys, os<N>import pythoncom<N><N># flag if we are in a "frozen" build.<N>_frozen = getattr(sys, "frozen", 1==0)<N># pythoncom dumbly defaults this to zero - we believe sys.frozen over it.<N>if _frozen and not getattr(pythoncom, "frozen", 0):<N>	pythoncom.frozen = sys.frozen<N><N>
# Code that packs and unpacks the Univgw structures.<N><N># See if we have a special directory for the binaries (for developers)<N>import types<N>import pythoncom<N>from win32com.client import gencache<N><N>com_error = pythoncom.com_error<N>_univgw = pythoncom._univgw<N><N>
"""Constants related to IStorage and related interfaces<N><N>This file was generated by h2py from d:\msdev\include\objbase.h<N>then hand edited, a few extra constants added, etc.<N>"""<N><N>STGC_DEFAULT        = 0<N>STGC_OVERWRITE      = 1<N>STGC_ONLYIFCURRENT  = 2<N>STGC_DANGEROUSLYCOMMITMERELYTODISKCACHE = 4<N>STGC_CONSOLIDATE    = 8<N><N>
"""Constants used by COM Controls<N><N>  Hand created version of OLECTL.H constants.<N>"""<N><N>import winerror<N><N>FACILITY_CONTROL = 0xa<N><N>def MAKE_SCODE(sev, fac, code):<N>	return int((int(-sev)<<31) | ((fac)<<16) | ((code)))<N><N>def STD_CTL_SCODE(n):<N>	return MAKE_SCODE(winerror.SEVERITY_ERROR, FACILITY_CONTROL, n)<N><N>
# A sample originally provided by Richard Bell, and modified by Mark Hammond.<N><N># This sample demonstrates how to use COM events in a free-threaded world.<N># In this world, there is no need to marshall calls across threads, so<N># no message loops are needed at all.  This means regular cross-thread <N># sychronization can be used.  In this sample we just wait on win32 event<N># objects.<N><N>
"""Excel IRTDServer implementation.<N><N>This module is a functional example of how to implement the IRTDServer interface<N>in python, using the pywin32 extensions. Further details, about this interface<N>and it can be found at:<N>     http://msdn.microsoft.com/library/default.asp?url=/library/en-us/dnexcl2k2/html/odc_xlrtdfaq.asp<N>"""<N><N>
